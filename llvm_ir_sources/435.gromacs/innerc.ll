; ModuleID = '../../SPEC/benchspec/CPU2006/435.gromacs/src/innerc.c'
target datalayout = "e-p:64:64:64-i1:8:8-i8:8:8-i16:16:16-i32:32:32-i64:64:64-f32:32:32-f64:64:64-v64:64:64-v128:128:128-a0:0:64-s0:64:64-f80:128:128-n8:16:32:64-S128"
target triple = "x86_64-unknown-linux-gnu"

; Function Attrs: nounwind optsize uwtable
define void @inl0100(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb) #0 {
entry:
  %cmp244 = icmp sgt i32 %nri, 0
  br i1 %cmp244, label %for.body.lr.ph, label %for.end145

for.body.lr.ph:                                   ; preds = %entry
  %mul27 = shl i32 %ntype, 1
  %.pre = load i32* %jindex, align 4, !tbaa !0
  br label %for.body

for.body:                                         ; preds = %for.end, %for.body.lr.ph
  %0 = phi i32 [ %.pre, %for.body.lr.ph ], [ %6, %for.end ]
  %indvars.iv246 = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next247, %for.end ]
  %arrayidx = getelementptr inbounds i32* %shift, i64 %indvars.iv246
  %1 = load i32* %arrayidx, align 4, !tbaa !0
  %mul = mul nsw i32 %1, 3
  %idxprom1 = sext i32 %mul to i64
  %arrayidx2 = getelementptr inbounds float* %shiftvec, i64 %idxprom1
  %2 = load float* %arrayidx2, align 4, !tbaa !3
  %add = add nsw i32 %mul, 1
  %idxprom3 = sext i32 %add to i64
  %arrayidx4 = getelementptr inbounds float* %shiftvec, i64 %idxprom3
  %3 = load float* %arrayidx4, align 4, !tbaa !3
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds float* %shiftvec, i64 %idxprom6
  %4 = load float* %arrayidx7, align 4, !tbaa !3
  %arrayidx9 = getelementptr inbounds i32* %iinr, i64 %indvars.iv246
  %5 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %5, 3
  %indvars.iv.next247 = add i64 %indvars.iv246, 1
  %arrayidx15 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next247
  %6 = load i32* %arrayidx15, align 4, !tbaa !0
  %idxprom16 = sext i32 %mul10 to i64
  %arrayidx17 = getelementptr inbounds float* %pos, i64 %idxprom16
  %7 = load float* %arrayidx17, align 4, !tbaa !3
  %add18 = fadd float %2, %7
  %add19 = add nsw i32 %mul10, 1
  %idxprom20 = sext i32 %add19 to i64
  %arrayidx21 = getelementptr inbounds float* %pos, i64 %idxprom20
  %8 = load float* %arrayidx21, align 4, !tbaa !3
  %add22 = fadd float %3, %8
  %add23 = add nsw i32 %mul10, 2
  %idxprom24 = sext i32 %add23 to i64
  %arrayidx25 = getelementptr inbounds float* %pos, i64 %idxprom24
  %9 = load float* %arrayidx25, align 4, !tbaa !3
  %add26 = fadd float %4, %9
  %idxprom28 = sext i32 %5 to i64
  %arrayidx29 = getelementptr inbounds i32* %type, i64 %idxprom28
  %10 = load i32* %arrayidx29, align 4, !tbaa !0
  %mul30 = mul nsw i32 %mul27, %10
  %cmp32235 = icmp slt i32 %0, %6
  br i1 %cmp32235, label %for.body33.lr.ph, label %for.end

for.body33.lr.ph:                                 ; preds = %for.body
  %11 = sext i32 %0 to i64
  br label %for.body33

for.body33:                                       ; preds = %for.body33.lr.ph, %for.body33
  %indvars.iv = phi i64 [ %11, %for.body33.lr.ph ], [ %indvars.iv.next, %for.body33 ]
  %vnbtot.0239 = phi float [ 0.000000e+00, %for.body33.lr.ph ], [ %sub68, %for.body33 ]
  %fix1.0238 = phi float [ 0.000000e+00, %for.body33.lr.ph ], [ %add76, %for.body33 ]
  %fiy1.0237 = phi float [ 0.000000e+00, %for.body33.lr.ph ], [ %add77, %for.body33 ]
  %fiz1.0236 = phi float [ 0.000000e+00, %for.body33.lr.ph ], [ %add78, %for.body33 ]
  %arrayidx35 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %12 = load i32* %arrayidx35, align 4, !tbaa !0
  %mul36 = mul nsw i32 %12, 3
  %idxprom37 = sext i32 %mul36 to i64
  %arrayidx38 = getelementptr inbounds float* %pos, i64 %idxprom37
  %13 = load float* %arrayidx38, align 4, !tbaa !3
  %add39 = add nsw i32 %mul36, 1
  %idxprom40 = sext i32 %add39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %14 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = add nsw i32 %mul36, 2
  %idxprom43 = sext i32 %add42 to i64
  %arrayidx44 = getelementptr inbounds float* %pos, i64 %idxprom43
  %15 = load float* %arrayidx44, align 4, !tbaa !3
  %sub = fsub float %add18, %13
  %sub45 = fsub float %add22, %14
  %sub46 = fsub float %add26, %15
  %mul47 = fmul float %sub, %sub
  %mul48 = fmul float %sub45, %sub45
  %add49 = fadd float %mul47, %mul48
  %mul50 = fmul float %sub46, %sub46
  %add51 = fadd float %add49, %mul50
  %conv52 = fdiv float 1.000000e+00, %add51
  %mul53 = fmul float %conv52, %conv52
  %mul54 = fmul float %conv52, %mul53
  %idxprom55 = sext i32 %12 to i64
  %arrayidx56 = getelementptr inbounds i32* %type, i64 %idxprom55
  %16 = load i32* %arrayidx56, align 4, !tbaa !0
  %mul57 = shl nsw i32 %16, 1
  %add58 = add nsw i32 %mul57, %mul30
  %idxprom59 = sext i32 %add58 to i64
  %arrayidx60 = getelementptr inbounds float* %nbfp, i64 %idxprom59
  %17 = load float* %arrayidx60, align 4, !tbaa !3
  %mul61 = fmul float %mul54, %17
  %mul62 = fmul float %mul54, %mul54
  %add63234 = or i32 %add58, 1
  %idxprom64 = sext i32 %add63234 to i64
  %arrayidx65 = getelementptr inbounds float* %nbfp, i64 %idxprom64
  %18 = load float* %arrayidx65, align 4, !tbaa !3
  %mul66 = fmul float %mul62, %18
  %add67 = fadd float %vnbtot.0239, %mul66
  %sub68 = fsub float %add67, %mul61
  %mul69 = fmul float %mul66, 1.200000e+01
  %mul70 = fmul float %mul61, 6.000000e+00
  %sub71 = fsub float %mul69, %mul70
  %mul72 = fmul float %conv52, %sub71
  %mul73 = fmul float %sub, %mul72
  %mul74 = fmul float %sub45, %mul72
  %mul75 = fmul float %sub46, %mul72
  %add76 = fadd float %fix1.0238, %mul73
  %add77 = fadd float %fiy1.0237, %mul74
  %add78 = fadd float %fiz1.0236, %mul75
  %arrayidx80 = getelementptr inbounds float* %faction, i64 %idxprom37
  %19 = load float* %arrayidx80, align 4, !tbaa !3
  %sub81 = fsub float %19, %mul73
  store float %sub81, float* %arrayidx80, align 4, !tbaa !3
  %arrayidx86 = getelementptr inbounds float* %faction, i64 %idxprom40
  %20 = load float* %arrayidx86, align 4, !tbaa !3
  %sub87 = fsub float %20, %mul74
  store float %sub87, float* %arrayidx86, align 4, !tbaa !3
  %arrayidx93 = getelementptr inbounds float* %faction, i64 %idxprom43
  %21 = load float* %arrayidx93, align 4, !tbaa !3
  %sub94 = fsub float %21, %mul75
  store float %sub94, float* %arrayidx93, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %22 = trunc i64 %indvars.iv.next to i32
  %cmp32 = icmp slt i32 %22, %6
  br i1 %cmp32, label %for.body33, label %for.end

for.end:                                          ; preds = %for.body33, %for.body
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %sub68, %for.body33 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add76, %for.body33 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add77, %for.body33 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add78, %for.body33 ]
  %arrayidx99 = getelementptr inbounds float* %faction, i64 %idxprom16
  %23 = load float* %arrayidx99, align 4, !tbaa !3
  %add100 = fadd float %fix1.0.lcssa, %23
  store float %add100, float* %arrayidx99, align 4, !tbaa !3
  %arrayidx105 = getelementptr inbounds float* %faction, i64 %idxprom20
  %24 = load float* %arrayidx105, align 4, !tbaa !3
  %add106 = fadd float %fiy1.0.lcssa, %24
  store float %add106, float* %arrayidx105, align 4, !tbaa !3
  %arrayidx112 = getelementptr inbounds float* %faction, i64 %idxprom24
  %25 = load float* %arrayidx112, align 4, !tbaa !3
  %add113 = fadd float %fiz1.0.lcssa, %25
  store float %add113, float* %arrayidx112, align 4, !tbaa !3
  %arrayidx118 = getelementptr inbounds float* %fshift, i64 %idxprom1
  %26 = load float* %arrayidx118, align 4, !tbaa !3
  %add119 = fadd float %fix1.0.lcssa, %26
  store float %add119, float* %arrayidx118, align 4, !tbaa !3
  %arrayidx124 = getelementptr inbounds float* %fshift, i64 %idxprom3
  %27 = load float* %arrayidx124, align 4, !tbaa !3
  %add125 = fadd float %fiy1.0.lcssa, %27
  store float %add125, float* %arrayidx124, align 4, !tbaa !3
  %arrayidx131 = getelementptr inbounds float* %fshift, i64 %idxprom6
  %28 = load float* %arrayidx131, align 4, !tbaa !3
  %add132 = fadd float %fiz1.0.lcssa, %28
  store float %add132, float* %arrayidx131, align 4, !tbaa !3
  %arrayidx137 = getelementptr inbounds i32* %gid, i64 %indvars.iv246
  %29 = load i32* %arrayidx137, align 4, !tbaa !0
  %idxprom138 = sext i32 %29 to i64
  %arrayidx139 = getelementptr inbounds float* %Vnb, i64 %idxprom138
  %30 = load float* %arrayidx139, align 4, !tbaa !3
  %add140 = fadd float %vnbtot.0.lcssa, %30
  store float %add140, float* %arrayidx139, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next247 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end145, label %for.body

for.end145:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl0110(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, i32* nocapture %nsatoms) #0 {
entry:
  %cmp556 = icmp sgt i32 %nri, 0
  br i1 %cmp556, label %for.body.lr.ph, label %for.end303

for.body.lr.ph:                                   ; preds = %entry
  %mul173 = shl i32 %ntype, 1
  %.pre = load i32* %jindex, align 4, !tbaa !0
  br label %for.body

for.body:                                         ; preds = %for.end293, %for.body.lr.ph
  %0 = phi i32 [ %.pre, %for.body.lr.ph ], [ %10, %for.end293 ]
  %indvars.iv573 = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next574, %for.end293 ]
  %1 = trunc i64 %indvars.iv573 to i32
  %mul = mul nsw i32 %1, 3
  %idxprom = sext i32 %mul to i64
  %arrayidx = getelementptr inbounds i32* %nsatoms, i64 %idxprom
  %2 = load i32* %arrayidx, align 4, !tbaa !0
  %add = add nsw i32 %mul, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds i32* %nsatoms, i64 %idxprom2
  %3 = load i32* %arrayidx3, align 4, !tbaa !0
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds i32* %nsatoms, i64 %idxprom6
  %4 = load i32* %arrayidx7, align 4, !tbaa !0
  %arrayidx9 = getelementptr inbounds i32* %shift, i64 %indvars.iv573
  %5 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %5, 3
  %idxprom11 = sext i32 %mul10 to i64
  %arrayidx12 = getelementptr inbounds float* %shiftvec, i64 %idxprom11
  %6 = load float* %arrayidx12, align 4, !tbaa !3
  %add13 = add nsw i32 %mul10, 1
  %idxprom14 = sext i32 %add13 to i64
  %arrayidx15 = getelementptr inbounds float* %shiftvec, i64 %idxprom14
  %7 = load float* %arrayidx15, align 4, !tbaa !3
  %add16 = add nsw i32 %mul10, 2
  %idxprom17 = sext i32 %add16 to i64
  %arrayidx18 = getelementptr inbounds float* %shiftvec, i64 %idxprom17
  %8 = load float* %arrayidx18, align 4, !tbaa !3
  %arrayidx20 = getelementptr inbounds i32* %iinr, i64 %indvars.iv573
  %9 = load i32* %arrayidx20, align 4, !tbaa !0
  %indvars.iv.next574 = add i64 %indvars.iv573, 1
  %arrayidx26 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next574
  %10 = load i32* %arrayidx26, align 4, !tbaa !0
  %cmp28533 = icmp sgt i32 %3, 0
  br i1 %cmp28533, label %for.body29.lr.ph, label %for.end154

for.body29.lr.ph:                                 ; preds = %for.body
  %cmp46524 = icmp slt i32 %0, %10
  %arrayidx132 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx138 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx145 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %11 = sext i32 %0 to i64
  %12 = sext i32 %9 to i64
  %13 = mul i32 %9, 3
  %14 = sext i32 %13 to i64
  br label %for.body29

for.body29:                                       ; preds = %for.end, %for.body29.lr.ph
  %indvars.iv560 = phi i64 [ %14, %for.body29.lr.ph ], [ %indvars.iv.next561, %for.end ]
  %indvars.iv558 = phi i64 [ %12, %for.body29.lr.ph ], [ %indvars.iv.next559, %for.end ]
  %s.0535 = phi i32 [ 0, %for.body29.lr.ph ], [ %inc153, %for.end ]
  %vnbtot.0534 = phi float [ 0.000000e+00, %for.body29.lr.ph ], [ %vnbtot.1.lcssa, %for.end ]
  %arrayidx31 = getelementptr inbounds float* %pos, i64 %indvars.iv560
  %15 = load float* %arrayidx31, align 4, !tbaa !3
  %add32 = fadd float %6, %15
  %16 = add nsw i64 %indvars.iv560, 1
  %arrayidx35 = getelementptr inbounds float* %pos, i64 %16
  %17 = load float* %arrayidx35, align 4, !tbaa !3
  %add36 = fadd float %7, %17
  %18 = add nsw i64 %indvars.iv560, 2
  %arrayidx39 = getelementptr inbounds float* %pos, i64 %18
  %19 = load float* %arrayidx39, align 4, !tbaa !3
  %add40 = fadd float %8, %19
  %arrayidx43 = getelementptr inbounds i32* %type, i64 %indvars.iv558
  %20 = load i32* %arrayidx43, align 4, !tbaa !0
  %mul44 = mul nsw i32 %mul173, %20
  br i1 %cmp46524, label %for.body47, label %for.end

for.body47:                                       ; preds = %for.body29, %for.body47
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body47 ], [ %11, %for.body29 ]
  %fiz1.0528 = phi float [ %add92, %for.body47 ], [ 0.000000e+00, %for.body29 ]
  %fiy1.0527 = phi float [ %add91, %for.body47 ], [ 0.000000e+00, %for.body29 ]
  %fix1.0526 = phi float [ %add90, %for.body47 ], [ 0.000000e+00, %for.body29 ]
  %vnbtot.1525 = phi float [ %sub82, %for.body47 ], [ %vnbtot.0534, %for.body29 ]
  %arrayidx49 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %21 = load i32* %arrayidx49, align 4, !tbaa !0
  %mul50 = mul nsw i32 %21, 3
  %idxprom51 = sext i32 %mul50 to i64
  %arrayidx52 = getelementptr inbounds float* %pos, i64 %idxprom51
  %22 = load float* %arrayidx52, align 4, !tbaa !3
  %add53 = add nsw i32 %mul50, 1
  %idxprom54 = sext i32 %add53 to i64
  %arrayidx55 = getelementptr inbounds float* %pos, i64 %idxprom54
  %23 = load float* %arrayidx55, align 4, !tbaa !3
  %add56 = add nsw i32 %mul50, 2
  %idxprom57 = sext i32 %add56 to i64
  %arrayidx58 = getelementptr inbounds float* %pos, i64 %idxprom57
  %24 = load float* %arrayidx58, align 4, !tbaa !3
  %sub = fsub float %add32, %22
  %sub59 = fsub float %add36, %23
  %sub60 = fsub float %add40, %24
  %mul61 = fmul float %sub, %sub
  %mul62 = fmul float %sub59, %sub59
  %add63 = fadd float %mul61, %mul62
  %mul64 = fmul float %sub60, %sub60
  %add65 = fadd float %add63, %mul64
  %conv66 = fdiv float 1.000000e+00, %add65
  %mul67 = fmul float %conv66, %conv66
  %mul68 = fmul float %conv66, %mul67
  %idxprom69 = sext i32 %21 to i64
  %arrayidx70 = getelementptr inbounds i32* %type, i64 %idxprom69
  %25 = load i32* %arrayidx70, align 4, !tbaa !0
  %mul71 = shl nsw i32 %25, 1
  %add72 = add nsw i32 %mul71, %mul44
  %idxprom73 = sext i32 %add72 to i64
  %arrayidx74 = getelementptr inbounds float* %nbfp, i64 %idxprom73
  %26 = load float* %arrayidx74, align 4, !tbaa !3
  %mul75 = fmul float %mul68, %26
  %mul76 = fmul float %mul68, %mul68
  %add77523 = or i32 %add72, 1
  %idxprom78 = sext i32 %add77523 to i64
  %arrayidx79 = getelementptr inbounds float* %nbfp, i64 %idxprom78
  %27 = load float* %arrayidx79, align 4, !tbaa !3
  %mul80 = fmul float %mul76, %27
  %add81 = fadd float %vnbtot.1525, %mul80
  %sub82 = fsub float %add81, %mul75
  %mul83 = fmul float %mul80, 1.200000e+01
  %mul84 = fmul float %mul75, 6.000000e+00
  %sub85 = fsub float %mul83, %mul84
  %mul86 = fmul float %conv66, %sub85
  %mul87 = fmul float %sub, %mul86
  %mul88 = fmul float %sub59, %mul86
  %mul89 = fmul float %sub60, %mul86
  %add90 = fadd float %fix1.0526, %mul87
  %add91 = fadd float %fiy1.0527, %mul88
  %add92 = fadd float %fiz1.0528, %mul89
  %arrayidx94 = getelementptr inbounds float* %faction, i64 %idxprom51
  %28 = load float* %arrayidx94, align 4, !tbaa !3
  %sub95 = fsub float %28, %mul87
  store float %sub95, float* %arrayidx94, align 4, !tbaa !3
  %arrayidx100 = getelementptr inbounds float* %faction, i64 %idxprom54
  %29 = load float* %arrayidx100, align 4, !tbaa !3
  %sub101 = fsub float %29, %mul88
  store float %sub101, float* %arrayidx100, align 4, !tbaa !3
  %arrayidx107 = getelementptr inbounds float* %faction, i64 %idxprom57
  %30 = load float* %arrayidx107, align 4, !tbaa !3
  %sub108 = fsub float %30, %mul89
  store float %sub108, float* %arrayidx107, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %31 = trunc i64 %indvars.iv.next to i32
  %cmp46 = icmp slt i32 %31, %10
  br i1 %cmp46, label %for.body47, label %for.end

for.end:                                          ; preds = %for.body47, %for.body29
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add92, %for.body47 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add91, %for.body47 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add90, %for.body47 ]
  %vnbtot.1.lcssa = phi float [ %vnbtot.0534, %for.body29 ], [ %sub82, %for.body47 ]
  %arrayidx113 = getelementptr inbounds float* %faction, i64 %indvars.iv560
  %32 = load float* %arrayidx113, align 4, !tbaa !3
  %add114 = fadd float %fix1.0.lcssa, %32
  store float %add114, float* %arrayidx113, align 4, !tbaa !3
  %arrayidx119 = getelementptr inbounds float* %faction, i64 %16
  %33 = load float* %arrayidx119, align 4, !tbaa !3
  %add120 = fadd float %fiy1.0.lcssa, %33
  store float %add120, float* %arrayidx119, align 4, !tbaa !3
  %arrayidx126 = getelementptr inbounds float* %faction, i64 %18
  %34 = load float* %arrayidx126, align 4, !tbaa !3
  %add127 = fadd float %fiz1.0.lcssa, %34
  store float %add127, float* %arrayidx126, align 4, !tbaa !3
  %35 = load float* %arrayidx132, align 4, !tbaa !3
  %add133 = fadd float %fix1.0.lcssa, %35
  store float %add133, float* %arrayidx132, align 4, !tbaa !3
  %36 = load float* %arrayidx138, align 4, !tbaa !3
  %add139 = fadd float %fiy1.0.lcssa, %36
  store float %add139, float* %arrayidx138, align 4, !tbaa !3
  %37 = load float* %arrayidx145, align 4, !tbaa !3
  %add146 = fadd float %fiz1.0.lcssa, %37
  store float %add146, float* %arrayidx145, align 4, !tbaa !3
  %indvars.iv.next559 = add i64 %indvars.iv558, 1
  %indvars.iv.next561 = add i64 %indvars.iv560, 3
  %inc153 = add nsw i32 %s.0535, 1
  %exitcond = icmp eq i32 %inc153, %3
  br i1 %exitcond, label %for.cond27.for.end154_crit_edge, label %for.body29

for.cond27.for.end154_crit_edge:                  ; preds = %for.end
  %38 = add i32 %3, %9
  br label %for.end154

for.end154:                                       ; preds = %for.cond27.for.end154_crit_edge, %for.body
  %ii.0.lcssa = phi i32 [ %38, %for.cond27.for.end154_crit_edge ], [ %9, %for.body ]
  %vnbtot.0.lcssa = phi float [ %vnbtot.1.lcssa, %for.cond27.for.end154_crit_edge ], [ 0.000000e+00, %for.body ]
  %cmp159550 = icmp slt i32 %4, %2
  br i1 %cmp159550, label %for.body161.lr.ph, label %for.end293

for.body161.lr.ph:                                ; preds = %for.end154
  %cmp178540 = icmp slt i32 %0, %10
  %arrayidx271 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx277 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx284 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %39 = sext i32 %0 to i64
  %40 = add i32 %ii.0.lcssa, %4
  %41 = sub i32 %40, %3
  %42 = sext i32 %41 to i64
  %43 = mul i32 %41, 3
  %44 = sext i32 %43 to i64
  br label %for.body161

for.body161:                                      ; preds = %for.end250, %for.body161.lr.ph
  %indvars.iv568 = phi i64 [ %44, %for.body161.lr.ph ], [ %indvars.iv.next569, %for.end250 ]
  %indvars.iv566 = phi i64 [ %42, %for.body161.lr.ph ], [ %indvars.iv.next567, %for.end250 ]
  %s.1552 = phi i32 [ %4, %for.body161.lr.ph ], [ %inc292, %for.end250 ]
  %vnbtot.2551 = phi float [ %vnbtot.0.lcssa, %for.body161.lr.ph ], [ %vnbtot.3.lcssa, %for.end250 ]
  %arrayidx163 = getelementptr inbounds float* %pos, i64 %indvars.iv568
  %45 = load float* %arrayidx163, align 4, !tbaa !3
  %add164 = fadd float %6, %45
  %46 = add nsw i64 %indvars.iv568, 1
  %arrayidx167 = getelementptr inbounds float* %pos, i64 %46
  %47 = load float* %arrayidx167, align 4, !tbaa !3
  %add168 = fadd float %7, %47
  %48 = add nsw i64 %indvars.iv568, 2
  %arrayidx171 = getelementptr inbounds float* %pos, i64 %48
  %49 = load float* %arrayidx171, align 4, !tbaa !3
  %add172 = fadd float %8, %49
  %arrayidx175 = getelementptr inbounds i32* %type, i64 %indvars.iv566
  %50 = load i32* %arrayidx175, align 4, !tbaa !0
  %mul176 = mul nsw i32 %mul173, %50
  br i1 %cmp178540, label %for.body180, label %for.end250

for.body180:                                      ; preds = %for.body161, %for.body180
  %indvars.iv564 = phi i64 [ %indvars.iv.next565, %for.body180 ], [ %39, %for.body161 ]
  %fiz1.1544 = phi float [ %add228, %for.body180 ], [ 0.000000e+00, %for.body161 ]
  %fiy1.1543 = phi float [ %add227, %for.body180 ], [ 0.000000e+00, %for.body161 ]
  %fix1.1542 = phi float [ %add226, %for.body180 ], [ 0.000000e+00, %for.body161 ]
  %vnbtot.3541 = phi float [ %sub218, %for.body180 ], [ %vnbtot.2551, %for.body161 ]
  %arrayidx182 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv564
  %51 = load i32* %arrayidx182, align 4, !tbaa !0
  %mul183 = mul nsw i32 %51, 3
  %idxprom184 = sext i32 %mul183 to i64
  %arrayidx185 = getelementptr inbounds float* %pos, i64 %idxprom184
  %52 = load float* %arrayidx185, align 4, !tbaa !3
  %add186 = add nsw i32 %mul183, 1
  %idxprom187 = sext i32 %add186 to i64
  %arrayidx188 = getelementptr inbounds float* %pos, i64 %idxprom187
  %53 = load float* %arrayidx188, align 4, !tbaa !3
  %add189 = add nsw i32 %mul183, 2
  %idxprom190 = sext i32 %add189 to i64
  %arrayidx191 = getelementptr inbounds float* %pos, i64 %idxprom190
  %54 = load float* %arrayidx191, align 4, !tbaa !3
  %sub192 = fsub float %add164, %52
  %sub193 = fsub float %add168, %53
  %sub194 = fsub float %add172, %54
  %mul195 = fmul float %sub192, %sub192
  %mul196 = fmul float %sub193, %sub193
  %add197 = fadd float %mul195, %mul196
  %mul198 = fmul float %sub194, %sub194
  %add199 = fadd float %add197, %mul198
  %conv202 = fdiv float 1.000000e+00, %add199
  %mul203 = fmul float %conv202, %conv202
  %mul204 = fmul float %conv202, %mul203
  %idxprom205 = sext i32 %51 to i64
  %arrayidx206 = getelementptr inbounds i32* %type, i64 %idxprom205
  %55 = load i32* %arrayidx206, align 4, !tbaa !0
  %mul207 = shl nsw i32 %55, 1
  %add208 = add nsw i32 %mul207, %mul176
  %idxprom209 = sext i32 %add208 to i64
  %arrayidx210 = getelementptr inbounds float* %nbfp, i64 %idxprom209
  %56 = load float* %arrayidx210, align 4, !tbaa !3
  %mul211 = fmul float %mul204, %56
  %mul212 = fmul float %mul204, %mul204
  %add213522 = or i32 %add208, 1
  %idxprom214 = sext i32 %add213522 to i64
  %arrayidx215 = getelementptr inbounds float* %nbfp, i64 %idxprom214
  %57 = load float* %arrayidx215, align 4, !tbaa !3
  %mul216 = fmul float %mul212, %57
  %add217 = fadd float %vnbtot.3541, %mul216
  %sub218 = fsub float %add217, %mul211
  %mul219 = fmul float %mul216, 1.200000e+01
  %mul220 = fmul float %mul211, 6.000000e+00
  %sub221 = fsub float %mul219, %mul220
  %mul222 = fmul float %conv202, %sub221
  %mul223 = fmul float %sub192, %mul222
  %mul224 = fmul float %sub193, %mul222
  %mul225 = fmul float %sub194, %mul222
  %add226 = fadd float %fix1.1542, %mul223
  %add227 = fadd float %fiy1.1543, %mul224
  %add228 = fadd float %fiz1.1544, %mul225
  %arrayidx230 = getelementptr inbounds float* %faction, i64 %idxprom184
  %58 = load float* %arrayidx230, align 4, !tbaa !3
  %sub231 = fsub float %58, %mul223
  store float %sub231, float* %arrayidx230, align 4, !tbaa !3
  %arrayidx236 = getelementptr inbounds float* %faction, i64 %idxprom187
  %59 = load float* %arrayidx236, align 4, !tbaa !3
  %sub237 = fsub float %59, %mul224
  store float %sub237, float* %arrayidx236, align 4, !tbaa !3
  %arrayidx243 = getelementptr inbounds float* %faction, i64 %idxprom190
  %60 = load float* %arrayidx243, align 4, !tbaa !3
  %sub244 = fsub float %60, %mul225
  store float %sub244, float* %arrayidx243, align 4, !tbaa !3
  %indvars.iv.next565 = add i64 %indvars.iv564, 1
  %61 = trunc i64 %indvars.iv.next565 to i32
  %cmp178 = icmp slt i32 %61, %10
  br i1 %cmp178, label %for.body180, label %for.end250

for.end250:                                       ; preds = %for.body180, %for.body161
  %fiz1.1.lcssa = phi float [ 0.000000e+00, %for.body161 ], [ %add228, %for.body180 ]
  %fiy1.1.lcssa = phi float [ 0.000000e+00, %for.body161 ], [ %add227, %for.body180 ]
  %fix1.1.lcssa = phi float [ 0.000000e+00, %for.body161 ], [ %add226, %for.body180 ]
  %vnbtot.3.lcssa = phi float [ %vnbtot.2551, %for.body161 ], [ %sub218, %for.body180 ]
  %arrayidx252 = getelementptr inbounds float* %faction, i64 %indvars.iv568
  %62 = load float* %arrayidx252, align 4, !tbaa !3
  %add253 = fadd float %fix1.1.lcssa, %62
  store float %add253, float* %arrayidx252, align 4, !tbaa !3
  %arrayidx258 = getelementptr inbounds float* %faction, i64 %46
  %63 = load float* %arrayidx258, align 4, !tbaa !3
  %add259 = fadd float %fiy1.1.lcssa, %63
  store float %add259, float* %arrayidx258, align 4, !tbaa !3
  %arrayidx265 = getelementptr inbounds float* %faction, i64 %48
  %64 = load float* %arrayidx265, align 4, !tbaa !3
  %add266 = fadd float %fiz1.1.lcssa, %64
  store float %add266, float* %arrayidx265, align 4, !tbaa !3
  %65 = load float* %arrayidx271, align 4, !tbaa !3
  %add272 = fadd float %fix1.1.lcssa, %65
  store float %add272, float* %arrayidx271, align 4, !tbaa !3
  %66 = load float* %arrayidx277, align 4, !tbaa !3
  %add278 = fadd float %fiy1.1.lcssa, %66
  store float %add278, float* %arrayidx277, align 4, !tbaa !3
  %67 = load float* %arrayidx284, align 4, !tbaa !3
  %add285 = fadd float %fiz1.1.lcssa, %67
  store float %add285, float* %arrayidx284, align 4, !tbaa !3
  %indvars.iv.next567 = add i64 %indvars.iv566, 1
  %indvars.iv.next569 = add i64 %indvars.iv568, 3
  %inc292 = add nsw i32 %s.1552, 1
  %exitcond572 = icmp eq i32 %inc292, %2
  br i1 %exitcond572, label %for.end293, label %for.body161

for.end293:                                       ; preds = %for.end250, %for.end154
  %vnbtot.2.lcssa = phi float [ %vnbtot.0.lcssa, %for.end154 ], [ %vnbtot.3.lcssa, %for.end250 ]
  %arrayidx295 = getelementptr inbounds i32* %gid, i64 %indvars.iv573
  %68 = load i32* %arrayidx295, align 4, !tbaa !0
  %idxprom296 = sext i32 %68 to i64
  %arrayidx297 = getelementptr inbounds float* %Vnb, i64 %idxprom296
  %69 = load float* %arrayidx297, align 4, !tbaa !3
  %add298 = fadd float %vnbtot.2.lcssa, %69
  store float %add298, float* %arrayidx297, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next574 to i32
  %exitcond575 = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond575, label %for.end303, label %for.body

for.end303:                                       ; preds = %for.end293, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl0200(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb) #0 {
entry:
  %cmp258 = icmp sgt i32 %nri, 0
  br i1 %cmp258, label %for.body, label %for.end155

for.body:                                         ; preds = %for.end, %entry
  %indvars.iv260 = phi i64 [ 0, %entry ], [ %indvars.iv.next261, %for.end ]
  %arrayidx = getelementptr inbounds i32* %shift, i64 %indvars.iv260
  %0 = load i32* %arrayidx, align 4, !tbaa !0
  %mul = mul nsw i32 %0, 3
  %idxprom1 = sext i32 %mul to i64
  %arrayidx2 = getelementptr inbounds float* %shiftvec, i64 %idxprom1
  %1 = load float* %arrayidx2, align 4, !tbaa !3
  %add = add nsw i32 %mul, 1
  %idxprom3 = sext i32 %add to i64
  %arrayidx4 = getelementptr inbounds float* %shiftvec, i64 %idxprom3
  %2 = load float* %arrayidx4, align 4, !tbaa !3
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds float* %shiftvec, i64 %idxprom6
  %3 = load float* %arrayidx7, align 4, !tbaa !3
  %arrayidx9 = getelementptr inbounds i32* %iinr, i64 %indvars.iv260
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %arrayidx12 = getelementptr inbounds i32* %jindex, i64 %indvars.iv260
  %5 = load i32* %arrayidx12, align 4, !tbaa !0
  %indvars.iv.next261 = add i64 %indvars.iv260, 1
  %arrayidx15 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next261
  %6 = load i32* %arrayidx15, align 4, !tbaa !0
  %idxprom16 = sext i32 %mul10 to i64
  %arrayidx17 = getelementptr inbounds float* %pos, i64 %idxprom16
  %7 = load float* %arrayidx17, align 4, !tbaa !3
  %add18 = fadd float %1, %7
  %add19 = add nsw i32 %mul10, 1
  %idxprom20 = sext i32 %add19 to i64
  %arrayidx21 = getelementptr inbounds float* %pos, i64 %idxprom20
  %8 = load float* %arrayidx21, align 4, !tbaa !3
  %add22 = fadd float %2, %8
  %add23 = add nsw i32 %mul10, 2
  %idxprom24 = sext i32 %add23 to i64
  %arrayidx25 = getelementptr inbounds float* %pos, i64 %idxprom24
  %9 = load float* %arrayidx25, align 4, !tbaa !3
  %add26 = fadd float %3, %9
  %idxprom28 = sext i32 %4 to i64
  %arrayidx29 = getelementptr inbounds i32* %type, i64 %idxprom28
  %10 = load i32* %arrayidx29, align 4, !tbaa !0
  %mul30 = mul i32 %10, %ntype
  %cmp32249 = icmp slt i32 %5, %6
  br i1 %cmp32249, label %for.body33.lr.ph, label %for.end

for.body33.lr.ph:                                 ; preds = %for.body
  %11 = sext i32 %5 to i64
  br label %for.body33

for.body33:                                       ; preds = %for.body33.lr.ph, %for.body33
  %indvars.iv = phi i64 [ %11, %for.body33.lr.ph ], [ %indvars.iv.next, %for.body33 ]
  %vnbtot.0253 = phi float [ 0.000000e+00, %for.body33.lr.ph ], [ %sub78, %for.body33 ]
  %fix1.0252 = phi float [ 0.000000e+00, %for.body33.lr.ph ], [ %add86, %for.body33 ]
  %fiy1.0251 = phi float [ 0.000000e+00, %for.body33.lr.ph ], [ %add87, %for.body33 ]
  %fiz1.0250 = phi float [ 0.000000e+00, %for.body33.lr.ph ], [ %add88, %for.body33 ]
  %arrayidx35 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %12 = load i32* %arrayidx35, align 4, !tbaa !0
  %mul36 = mul nsw i32 %12, 3
  %idxprom37 = sext i32 %mul36 to i64
  %arrayidx38 = getelementptr inbounds float* %pos, i64 %idxprom37
  %13 = load float* %arrayidx38, align 4, !tbaa !3
  %add39 = add nsw i32 %mul36, 1
  %idxprom40 = sext i32 %add39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %14 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = add nsw i32 %mul36, 2
  %idxprom43 = sext i32 %add42 to i64
  %arrayidx44 = getelementptr inbounds float* %pos, i64 %idxprom43
  %15 = load float* %arrayidx44, align 4, !tbaa !3
  %sub = fsub float %add18, %13
  %sub45 = fsub float %add22, %14
  %sub46 = fsub float %add26, %15
  %mul47 = fmul float %sub, %sub
  %mul48 = fmul float %sub45, %sub45
  %add49 = fadd float %mul47, %mul48
  %mul50 = fmul float %sub46, %sub46
  %add51 = fadd float %add49, %mul50
  %conv = fpext float %add51 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv52 = fptrunc double %div to float
  %mul53 = fmul float %add51, %conv52
  %mul54 = fmul float %conv52, %conv52
  %mul55 = fmul float %mul54, %mul54
  %mul56 = fmul float %mul54, %mul55
  %idxprom57 = sext i32 %12 to i64
  %arrayidx58 = getelementptr inbounds i32* %type, i64 %idxprom57
  %16 = load i32* %arrayidx58, align 4, !tbaa !0
  %tmp = add i32 %16, %mul30
  %tmp248 = mul i32 %tmp, 3
  %idxprom61 = sext i32 %tmp248 to i64
  %arrayidx62 = getelementptr inbounds float* %nbfp, i64 %idxprom61
  %17 = load float* %arrayidx62, align 4, !tbaa !3
  %mul63 = fmul float %17, %mul56
  %add64 = add nsw i32 %tmp248, 2
  %idxprom65 = sext i32 %add64 to i64
  %arrayidx66 = getelementptr inbounds float* %nbfp, i64 %idxprom65
  %18 = load float* %arrayidx66, align 4, !tbaa !3
  %mul67 = fmul float %mul53, %18
  %sub68 = fsub float -0.000000e+00, %mul67
  %conv69 = fpext float %sub68 to double
  %call70 = tail call double @exp(double %conv69) #2
  %add71 = add nsw i32 %tmp248, 1
  %idxprom72 = sext i32 %add71 to i64
  %arrayidx73 = getelementptr inbounds float* %nbfp, i64 %idxprom72
  %19 = load float* %arrayidx73, align 4, !tbaa !3
  %conv74 = fpext float %19 to double
  %mul75 = fmul double %call70, %conv74
  %conv76 = fptrunc double %mul75 to float
  %add77 = fadd float %vnbtot.0253, %conv76
  %sub78 = fsub float %add77, %mul63
  %mul79 = fmul float %mul67, %conv76
  %mul80 = fmul float %mul63, 6.000000e+00
  %sub81 = fsub float %mul79, %mul80
  %mul82 = fmul float %mul54, %sub81
  %mul83 = fmul float %sub, %mul82
  %mul84 = fmul float %sub45, %mul82
  %mul85 = fmul float %sub46, %mul82
  %add86 = fadd float %fix1.0252, %mul83
  %add87 = fadd float %fiy1.0251, %mul84
  %add88 = fadd float %fiz1.0250, %mul85
  %arrayidx90 = getelementptr inbounds float* %faction, i64 %idxprom37
  %20 = load float* %arrayidx90, align 4, !tbaa !3
  %sub91 = fsub float %20, %mul83
  store float %sub91, float* %arrayidx90, align 4, !tbaa !3
  %arrayidx96 = getelementptr inbounds float* %faction, i64 %idxprom40
  %21 = load float* %arrayidx96, align 4, !tbaa !3
  %sub97 = fsub float %21, %mul84
  store float %sub97, float* %arrayidx96, align 4, !tbaa !3
  %arrayidx103 = getelementptr inbounds float* %faction, i64 %idxprom43
  %22 = load float* %arrayidx103, align 4, !tbaa !3
  %sub104 = fsub float %22, %mul85
  store float %sub104, float* %arrayidx103, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %23 = trunc i64 %indvars.iv.next to i32
  %cmp32 = icmp slt i32 %23, %6
  br i1 %cmp32, label %for.body33, label %for.end

for.end:                                          ; preds = %for.body33, %for.body
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %sub78, %for.body33 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add86, %for.body33 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add87, %for.body33 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add88, %for.body33 ]
  %arrayidx109 = getelementptr inbounds float* %faction, i64 %idxprom16
  %24 = load float* %arrayidx109, align 4, !tbaa !3
  %add110 = fadd float %fix1.0.lcssa, %24
  store float %add110, float* %arrayidx109, align 4, !tbaa !3
  %arrayidx115 = getelementptr inbounds float* %faction, i64 %idxprom20
  %25 = load float* %arrayidx115, align 4, !tbaa !3
  %add116 = fadd float %fiy1.0.lcssa, %25
  store float %add116, float* %arrayidx115, align 4, !tbaa !3
  %arrayidx122 = getelementptr inbounds float* %faction, i64 %idxprom24
  %26 = load float* %arrayidx122, align 4, !tbaa !3
  %add123 = fadd float %fiz1.0.lcssa, %26
  store float %add123, float* %arrayidx122, align 4, !tbaa !3
  %arrayidx128 = getelementptr inbounds float* %fshift, i64 %idxprom1
  %27 = load float* %arrayidx128, align 4, !tbaa !3
  %add129 = fadd float %fix1.0.lcssa, %27
  store float %add129, float* %arrayidx128, align 4, !tbaa !3
  %arrayidx134 = getelementptr inbounds float* %fshift, i64 %idxprom3
  %28 = load float* %arrayidx134, align 4, !tbaa !3
  %add135 = fadd float %fiy1.0.lcssa, %28
  store float %add135, float* %arrayidx134, align 4, !tbaa !3
  %arrayidx141 = getelementptr inbounds float* %fshift, i64 %idxprom6
  %29 = load float* %arrayidx141, align 4, !tbaa !3
  %add142 = fadd float %fiz1.0.lcssa, %29
  store float %add142, float* %arrayidx141, align 4, !tbaa !3
  %arrayidx147 = getelementptr inbounds i32* %gid, i64 %indvars.iv260
  %30 = load i32* %arrayidx147, align 4, !tbaa !0
  %idxprom148 = sext i32 %30 to i64
  %arrayidx149 = getelementptr inbounds float* %Vnb, i64 %idxprom148
  %31 = load float* %arrayidx149, align 4, !tbaa !3
  %add150 = fadd float %vnbtot.0.lcssa, %31
  store float %add150, float* %arrayidx149, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next261 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end155, label %for.body

for.end155:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize
declare double @sqrt(double) #1

; Function Attrs: nounwind optsize
declare double @exp(double) #1

; Function Attrs: nounwind optsize uwtable
define void @inl0210(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, i32* nocapture %nsatoms) #0 {
entry:
  %cmp589 = icmp sgt i32 %nri, 0
  br i1 %cmp589, label %for.body, label %for.end324

for.body:                                         ; preds = %for.end314, %entry
  %indvars.iv606 = phi i64 [ 0, %entry ], [ %indvars.iv.next607, %for.end314 ]
  %0 = trunc i64 %indvars.iv606 to i32
  %mul = mul nsw i32 %0, 3
  %idxprom = sext i32 %mul to i64
  %arrayidx = getelementptr inbounds i32* %nsatoms, i64 %idxprom
  %1 = load i32* %arrayidx, align 4, !tbaa !0
  %add = add nsw i32 %mul, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds i32* %nsatoms, i64 %idxprom2
  %2 = load i32* %arrayidx3, align 4, !tbaa !0
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds i32* %nsatoms, i64 %idxprom6
  %3 = load i32* %arrayidx7, align 4, !tbaa !0
  %arrayidx9 = getelementptr inbounds i32* %shift, i64 %indvars.iv606
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %idxprom11 = sext i32 %mul10 to i64
  %arrayidx12 = getelementptr inbounds float* %shiftvec, i64 %idxprom11
  %5 = load float* %arrayidx12, align 4, !tbaa !3
  %add13 = add nsw i32 %mul10, 1
  %idxprom14 = sext i32 %add13 to i64
  %arrayidx15 = getelementptr inbounds float* %shiftvec, i64 %idxprom14
  %6 = load float* %arrayidx15, align 4, !tbaa !3
  %add16 = add nsw i32 %mul10, 2
  %idxprom17 = sext i32 %add16 to i64
  %arrayidx18 = getelementptr inbounds float* %shiftvec, i64 %idxprom17
  %7 = load float* %arrayidx18, align 4, !tbaa !3
  %arrayidx20 = getelementptr inbounds i32* %iinr, i64 %indvars.iv606
  %8 = load i32* %arrayidx20, align 4, !tbaa !0
  %arrayidx23 = getelementptr inbounds i32* %jindex, i64 %indvars.iv606
  %9 = load i32* %arrayidx23, align 4, !tbaa !0
  %indvars.iv.next607 = add i64 %indvars.iv606, 1
  %arrayidx26 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next607
  %10 = load i32* %arrayidx26, align 4, !tbaa !0
  %cmp28566 = icmp sgt i32 %2, 0
  br i1 %cmp28566, label %for.body29.lr.ph, label %for.end164

for.body29.lr.ph:                                 ; preds = %for.body
  %cmp46557 = icmp slt i32 %9, %10
  %arrayidx142 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx148 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx155 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %11 = sext i32 %9 to i64
  %12 = sext i32 %8 to i64
  %13 = mul i32 %8, 3
  %14 = sext i32 %13 to i64
  br label %for.body29

for.body29:                                       ; preds = %for.end, %for.body29.lr.ph
  %indvars.iv593 = phi i64 [ %14, %for.body29.lr.ph ], [ %indvars.iv.next594, %for.end ]
  %indvars.iv591 = phi i64 [ %12, %for.body29.lr.ph ], [ %indvars.iv.next592, %for.end ]
  %s.0568 = phi i32 [ 0, %for.body29.lr.ph ], [ %inc163, %for.end ]
  %vnbtot.0567 = phi float [ 0.000000e+00, %for.body29.lr.ph ], [ %vnbtot.1.lcssa, %for.end ]
  %arrayidx31 = getelementptr inbounds float* %pos, i64 %indvars.iv593
  %15 = load float* %arrayidx31, align 4, !tbaa !3
  %add32 = fadd float %5, %15
  %16 = add nsw i64 %indvars.iv593, 1
  %arrayidx35 = getelementptr inbounds float* %pos, i64 %16
  %17 = load float* %arrayidx35, align 4, !tbaa !3
  %add36 = fadd float %6, %17
  %18 = add nsw i64 %indvars.iv593, 2
  %arrayidx39 = getelementptr inbounds float* %pos, i64 %18
  %19 = load float* %arrayidx39, align 4, !tbaa !3
  %add40 = fadd float %7, %19
  %arrayidx43 = getelementptr inbounds i32* %type, i64 %indvars.iv591
  %20 = load i32* %arrayidx43, align 4, !tbaa !0
  %mul44 = mul i32 %20, %ntype
  br i1 %cmp46557, label %for.body47, label %for.end

for.body47:                                       ; preds = %for.body29, %for.body47
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body47 ], [ %11, %for.body29 ]
  %fiz1.0561 = phi float [ %add102, %for.body47 ], [ 0.000000e+00, %for.body29 ]
  %fiy1.0560 = phi float [ %add101, %for.body47 ], [ 0.000000e+00, %for.body29 ]
  %fix1.0559 = phi float [ %add100, %for.body47 ], [ 0.000000e+00, %for.body29 ]
  %vnbtot.1558 = phi float [ %sub92, %for.body47 ], [ %vnbtot.0567, %for.body29 ]
  %arrayidx49 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %21 = load i32* %arrayidx49, align 4, !tbaa !0
  %mul50 = mul nsw i32 %21, 3
  %idxprom51 = sext i32 %mul50 to i64
  %arrayidx52 = getelementptr inbounds float* %pos, i64 %idxprom51
  %22 = load float* %arrayidx52, align 4, !tbaa !3
  %add53 = add nsw i32 %mul50, 1
  %idxprom54 = sext i32 %add53 to i64
  %arrayidx55 = getelementptr inbounds float* %pos, i64 %idxprom54
  %23 = load float* %arrayidx55, align 4, !tbaa !3
  %add56 = add nsw i32 %mul50, 2
  %idxprom57 = sext i32 %add56 to i64
  %arrayidx58 = getelementptr inbounds float* %pos, i64 %idxprom57
  %24 = load float* %arrayidx58, align 4, !tbaa !3
  %sub = fsub float %add32, %22
  %sub59 = fsub float %add36, %23
  %sub60 = fsub float %add40, %24
  %mul61 = fmul float %sub, %sub
  %mul62 = fmul float %sub59, %sub59
  %add63 = fadd float %mul61, %mul62
  %mul64 = fmul float %sub60, %sub60
  %add65 = fadd float %add63, %mul64
  %conv = fpext float %add65 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv66 = fptrunc double %div to float
  %mul67 = fmul float %add65, %conv66
  %mul68 = fmul float %conv66, %conv66
  %mul69 = fmul float %mul68, %mul68
  %mul70 = fmul float %mul68, %mul69
  %idxprom71 = sext i32 %21 to i64
  %arrayidx72 = getelementptr inbounds i32* %type, i64 %idxprom71
  %25 = load i32* %arrayidx72, align 4, !tbaa !0
  %tmp = add i32 %25, %mul44
  %tmp554 = mul i32 %tmp, 3
  %idxprom75 = sext i32 %tmp554 to i64
  %arrayidx76 = getelementptr inbounds float* %nbfp, i64 %idxprom75
  %26 = load float* %arrayidx76, align 4, !tbaa !3
  %mul77 = fmul float %26, %mul70
  %add78 = add nsw i32 %tmp554, 2
  %idxprom79 = sext i32 %add78 to i64
  %arrayidx80 = getelementptr inbounds float* %nbfp, i64 %idxprom79
  %27 = load float* %arrayidx80, align 4, !tbaa !3
  %mul81 = fmul float %mul67, %27
  %sub82 = fsub float -0.000000e+00, %mul81
  %conv83 = fpext float %sub82 to double
  %call84 = tail call double @exp(double %conv83) #2
  %add85 = add nsw i32 %tmp554, 1
  %idxprom86 = sext i32 %add85 to i64
  %arrayidx87 = getelementptr inbounds float* %nbfp, i64 %idxprom86
  %28 = load float* %arrayidx87, align 4, !tbaa !3
  %conv88 = fpext float %28 to double
  %mul89 = fmul double %call84, %conv88
  %conv90 = fptrunc double %mul89 to float
  %add91 = fadd float %vnbtot.1558, %conv90
  %sub92 = fsub float %add91, %mul77
  %mul93 = fmul float %mul81, %conv90
  %mul94 = fmul float %mul77, 6.000000e+00
  %sub95 = fsub float %mul93, %mul94
  %mul96 = fmul float %mul68, %sub95
  %mul97 = fmul float %sub, %mul96
  %mul98 = fmul float %sub59, %mul96
  %mul99 = fmul float %sub60, %mul96
  %add100 = fadd float %fix1.0559, %mul97
  %add101 = fadd float %fiy1.0560, %mul98
  %add102 = fadd float %fiz1.0561, %mul99
  %arrayidx104 = getelementptr inbounds float* %faction, i64 %idxprom51
  %29 = load float* %arrayidx104, align 4, !tbaa !3
  %sub105 = fsub float %29, %mul97
  store float %sub105, float* %arrayidx104, align 4, !tbaa !3
  %arrayidx110 = getelementptr inbounds float* %faction, i64 %idxprom54
  %30 = load float* %arrayidx110, align 4, !tbaa !3
  %sub111 = fsub float %30, %mul98
  store float %sub111, float* %arrayidx110, align 4, !tbaa !3
  %arrayidx117 = getelementptr inbounds float* %faction, i64 %idxprom57
  %31 = load float* %arrayidx117, align 4, !tbaa !3
  %sub118 = fsub float %31, %mul99
  store float %sub118, float* %arrayidx117, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %32 = trunc i64 %indvars.iv.next to i32
  %cmp46 = icmp slt i32 %32, %10
  br i1 %cmp46, label %for.body47, label %for.end

for.end:                                          ; preds = %for.body47, %for.body29
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add102, %for.body47 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add101, %for.body47 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add100, %for.body47 ]
  %vnbtot.1.lcssa = phi float [ %vnbtot.0567, %for.body29 ], [ %sub92, %for.body47 ]
  %arrayidx123 = getelementptr inbounds float* %faction, i64 %indvars.iv593
  %33 = load float* %arrayidx123, align 4, !tbaa !3
  %add124 = fadd float %fix1.0.lcssa, %33
  store float %add124, float* %arrayidx123, align 4, !tbaa !3
  %arrayidx129 = getelementptr inbounds float* %faction, i64 %16
  %34 = load float* %arrayidx129, align 4, !tbaa !3
  %add130 = fadd float %fiy1.0.lcssa, %34
  store float %add130, float* %arrayidx129, align 4, !tbaa !3
  %arrayidx136 = getelementptr inbounds float* %faction, i64 %18
  %35 = load float* %arrayidx136, align 4, !tbaa !3
  %add137 = fadd float %fiz1.0.lcssa, %35
  store float %add137, float* %arrayidx136, align 4, !tbaa !3
  %36 = load float* %arrayidx142, align 4, !tbaa !3
  %add143 = fadd float %fix1.0.lcssa, %36
  store float %add143, float* %arrayidx142, align 4, !tbaa !3
  %37 = load float* %arrayidx148, align 4, !tbaa !3
  %add149 = fadd float %fiy1.0.lcssa, %37
  store float %add149, float* %arrayidx148, align 4, !tbaa !3
  %38 = load float* %arrayidx155, align 4, !tbaa !3
  %add156 = fadd float %fiz1.0.lcssa, %38
  store float %add156, float* %arrayidx155, align 4, !tbaa !3
  %indvars.iv.next592 = add i64 %indvars.iv591, 1
  %indvars.iv.next594 = add i64 %indvars.iv593, 3
  %inc163 = add nsw i32 %s.0568, 1
  %exitcond = icmp eq i32 %inc163, %2
  br i1 %exitcond, label %for.cond27.for.end164_crit_edge, label %for.body29

for.cond27.for.end164_crit_edge:                  ; preds = %for.end
  %39 = add i32 %2, %8
  br label %for.end164

for.end164:                                       ; preds = %for.cond27.for.end164_crit_edge, %for.body
  %ii.0.lcssa = phi i32 [ %39, %for.cond27.for.end164_crit_edge ], [ %8, %for.body ]
  %vnbtot.0.lcssa = phi float [ %vnbtot.1.lcssa, %for.cond27.for.end164_crit_edge ], [ 0.000000e+00, %for.body ]
  %cmp169583 = icmp slt i32 %3, %1
  br i1 %cmp169583, label %for.body171.lr.ph, label %for.end314

for.body171.lr.ph:                                ; preds = %for.end164
  %cmp188573 = icmp slt i32 %9, %10
  %arrayidx292 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx298 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx305 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %40 = sext i32 %9 to i64
  %41 = add i32 %ii.0.lcssa, %3
  %42 = sub i32 %41, %2
  %43 = sext i32 %42 to i64
  %44 = mul i32 %42, 3
  %45 = sext i32 %44 to i64
  br label %for.body171

for.body171:                                      ; preds = %for.end271, %for.body171.lr.ph
  %indvars.iv601 = phi i64 [ %45, %for.body171.lr.ph ], [ %indvars.iv.next602, %for.end271 ]
  %indvars.iv599 = phi i64 [ %43, %for.body171.lr.ph ], [ %indvars.iv.next600, %for.end271 ]
  %s.1585 = phi i32 [ %3, %for.body171.lr.ph ], [ %inc313, %for.end271 ]
  %vnbtot.2584 = phi float [ %vnbtot.0.lcssa, %for.body171.lr.ph ], [ %vnbtot.3.lcssa, %for.end271 ]
  %arrayidx173 = getelementptr inbounds float* %pos, i64 %indvars.iv601
  %46 = load float* %arrayidx173, align 4, !tbaa !3
  %add174 = fadd float %5, %46
  %47 = add nsw i64 %indvars.iv601, 1
  %arrayidx177 = getelementptr inbounds float* %pos, i64 %47
  %48 = load float* %arrayidx177, align 4, !tbaa !3
  %add178 = fadd float %6, %48
  %49 = add nsw i64 %indvars.iv601, 2
  %arrayidx181 = getelementptr inbounds float* %pos, i64 %49
  %50 = load float* %arrayidx181, align 4, !tbaa !3
  %add182 = fadd float %7, %50
  %arrayidx185 = getelementptr inbounds i32* %type, i64 %indvars.iv599
  %51 = load i32* %arrayidx185, align 4, !tbaa !0
  %mul186 = mul i32 %51, %ntype
  br i1 %cmp188573, label %for.body190, label %for.end271

for.body190:                                      ; preds = %for.body171, %for.body190
  %indvars.iv597 = phi i64 [ %indvars.iv.next598, %for.body190 ], [ %40, %for.body171 ]
  %fiz1.1577 = phi float [ %add249, %for.body190 ], [ 0.000000e+00, %for.body171 ]
  %fiy1.1576 = phi float [ %add248, %for.body190 ], [ 0.000000e+00, %for.body171 ]
  %fix1.1575 = phi float [ %add247, %for.body190 ], [ 0.000000e+00, %for.body171 ]
  %vnbtot.3574 = phi float [ %sub239, %for.body190 ], [ %vnbtot.2584, %for.body171 ]
  %arrayidx192 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv597
  %52 = load i32* %arrayidx192, align 4, !tbaa !0
  %mul193 = mul nsw i32 %52, 3
  %idxprom194 = sext i32 %mul193 to i64
  %arrayidx195 = getelementptr inbounds float* %pos, i64 %idxprom194
  %53 = load float* %arrayidx195, align 4, !tbaa !3
  %add196 = add nsw i32 %mul193, 1
  %idxprom197 = sext i32 %add196 to i64
  %arrayidx198 = getelementptr inbounds float* %pos, i64 %idxprom197
  %54 = load float* %arrayidx198, align 4, !tbaa !3
  %add199 = add nsw i32 %mul193, 2
  %idxprom200 = sext i32 %add199 to i64
  %arrayidx201 = getelementptr inbounds float* %pos, i64 %idxprom200
  %55 = load float* %arrayidx201, align 4, !tbaa !3
  %sub202 = fsub float %add174, %53
  %sub203 = fsub float %add178, %54
  %sub204 = fsub float %add182, %55
  %mul205 = fmul float %sub202, %sub202
  %mul206 = fmul float %sub203, %sub203
  %add207 = fadd float %mul205, %mul206
  %mul208 = fmul float %sub204, %sub204
  %add209 = fadd float %add207, %mul208
  %conv210 = fpext float %add209 to double
  %call211 = tail call double @sqrt(double %conv210) #2
  %div212 = fdiv double 1.000000e+00, %call211
  %conv213 = fptrunc double %div212 to float
  %mul214 = fmul float %add209, %conv213
  %mul215 = fmul float %conv213, %conv213
  %mul216 = fmul float %mul215, %mul215
  %mul217 = fmul float %mul215, %mul216
  %idxprom218 = sext i32 %52 to i64
  %arrayidx219 = getelementptr inbounds i32* %type, i64 %idxprom218
  %56 = load i32* %arrayidx219, align 4, !tbaa !0
  %tmp555 = add i32 %56, %mul186
  %tmp556 = mul i32 %tmp555, 3
  %idxprom222 = sext i32 %tmp556 to i64
  %arrayidx223 = getelementptr inbounds float* %nbfp, i64 %idxprom222
  %57 = load float* %arrayidx223, align 4, !tbaa !3
  %mul224 = fmul float %57, %mul217
  %add225 = add nsw i32 %tmp556, 2
  %idxprom226 = sext i32 %add225 to i64
  %arrayidx227 = getelementptr inbounds float* %nbfp, i64 %idxprom226
  %58 = load float* %arrayidx227, align 4, !tbaa !3
  %mul228 = fmul float %mul214, %58
  %sub229 = fsub float -0.000000e+00, %mul228
  %conv230 = fpext float %sub229 to double
  %call231 = tail call double @exp(double %conv230) #2
  %add232 = add nsw i32 %tmp556, 1
  %idxprom233 = sext i32 %add232 to i64
  %arrayidx234 = getelementptr inbounds float* %nbfp, i64 %idxprom233
  %59 = load float* %arrayidx234, align 4, !tbaa !3
  %conv235 = fpext float %59 to double
  %mul236 = fmul double %call231, %conv235
  %conv237 = fptrunc double %mul236 to float
  %add238 = fadd float %vnbtot.3574, %conv237
  %sub239 = fsub float %add238, %mul224
  %mul240 = fmul float %mul228, %conv237
  %mul241 = fmul float %mul224, 6.000000e+00
  %sub242 = fsub float %mul240, %mul241
  %mul243 = fmul float %mul215, %sub242
  %mul244 = fmul float %sub202, %mul243
  %mul245 = fmul float %sub203, %mul243
  %mul246 = fmul float %sub204, %mul243
  %add247 = fadd float %fix1.1575, %mul244
  %add248 = fadd float %fiy1.1576, %mul245
  %add249 = fadd float %fiz1.1577, %mul246
  %arrayidx251 = getelementptr inbounds float* %faction, i64 %idxprom194
  %60 = load float* %arrayidx251, align 4, !tbaa !3
  %sub252 = fsub float %60, %mul244
  store float %sub252, float* %arrayidx251, align 4, !tbaa !3
  %arrayidx257 = getelementptr inbounds float* %faction, i64 %idxprom197
  %61 = load float* %arrayidx257, align 4, !tbaa !3
  %sub258 = fsub float %61, %mul245
  store float %sub258, float* %arrayidx257, align 4, !tbaa !3
  %arrayidx264 = getelementptr inbounds float* %faction, i64 %idxprom200
  %62 = load float* %arrayidx264, align 4, !tbaa !3
  %sub265 = fsub float %62, %mul246
  store float %sub265, float* %arrayidx264, align 4, !tbaa !3
  %indvars.iv.next598 = add i64 %indvars.iv597, 1
  %63 = trunc i64 %indvars.iv.next598 to i32
  %cmp188 = icmp slt i32 %63, %10
  br i1 %cmp188, label %for.body190, label %for.end271

for.end271:                                       ; preds = %for.body190, %for.body171
  %fiz1.1.lcssa = phi float [ 0.000000e+00, %for.body171 ], [ %add249, %for.body190 ]
  %fiy1.1.lcssa = phi float [ 0.000000e+00, %for.body171 ], [ %add248, %for.body190 ]
  %fix1.1.lcssa = phi float [ 0.000000e+00, %for.body171 ], [ %add247, %for.body190 ]
  %vnbtot.3.lcssa = phi float [ %vnbtot.2584, %for.body171 ], [ %sub239, %for.body190 ]
  %arrayidx273 = getelementptr inbounds float* %faction, i64 %indvars.iv601
  %64 = load float* %arrayidx273, align 4, !tbaa !3
  %add274 = fadd float %fix1.1.lcssa, %64
  store float %add274, float* %arrayidx273, align 4, !tbaa !3
  %arrayidx279 = getelementptr inbounds float* %faction, i64 %47
  %65 = load float* %arrayidx279, align 4, !tbaa !3
  %add280 = fadd float %fiy1.1.lcssa, %65
  store float %add280, float* %arrayidx279, align 4, !tbaa !3
  %arrayidx286 = getelementptr inbounds float* %faction, i64 %49
  %66 = load float* %arrayidx286, align 4, !tbaa !3
  %add287 = fadd float %fiz1.1.lcssa, %66
  store float %add287, float* %arrayidx286, align 4, !tbaa !3
  %67 = load float* %arrayidx292, align 4, !tbaa !3
  %add293 = fadd float %fix1.1.lcssa, %67
  store float %add293, float* %arrayidx292, align 4, !tbaa !3
  %68 = load float* %arrayidx298, align 4, !tbaa !3
  %add299 = fadd float %fiy1.1.lcssa, %68
  store float %add299, float* %arrayidx298, align 4, !tbaa !3
  %69 = load float* %arrayidx305, align 4, !tbaa !3
  %add306 = fadd float %fiz1.1.lcssa, %69
  store float %add306, float* %arrayidx305, align 4, !tbaa !3
  %indvars.iv.next600 = add i64 %indvars.iv599, 1
  %indvars.iv.next602 = add i64 %indvars.iv601, 3
  %inc313 = add nsw i32 %s.1585, 1
  %exitcond605 = icmp eq i32 %inc313, %1
  br i1 %exitcond605, label %for.end314, label %for.body171

for.end314:                                       ; preds = %for.end271, %for.end164
  %vnbtot.2.lcssa = phi float [ %vnbtot.0.lcssa, %for.end164 ], [ %vnbtot.3.lcssa, %for.end271 ]
  %arrayidx316 = getelementptr inbounds i32* %gid, i64 %indvars.iv606
  %70 = load i32* %arrayidx316, align 4, !tbaa !0
  %idxprom317 = sext i32 %70 to i64
  %arrayidx318 = getelementptr inbounds float* %Vnb, i64 %idxprom317
  %71 = load float* %arrayidx318, align 4, !tbaa !3
  %add319 = fadd float %vnbtot.2.lcssa, %71
  store float %add319, float* %arrayidx318, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next607 to i32
  %exitcond608 = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond608, label %for.end324, label %for.body

for.end324:                                       ; preds = %for.end314, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl0300(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab) #0 {
entry:
  %cmp332 = icmp sgt i32 %nri, 0
  br i1 %cmp332, label %for.body.lr.ph, label %for.end192

for.body.lr.ph:                                   ; preds = %entry
  %mul27 = shl i32 %ntype, 1
  br label %for.body

for.body:                                         ; preds = %for.end, %for.body.lr.ph
  %indvars.iv334 = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next335, %for.end ]
  %arrayidx = getelementptr inbounds i32* %shift, i64 %indvars.iv334
  %0 = load i32* %arrayidx, align 4, !tbaa !0
  %mul = mul nsw i32 %0, 3
  %idxprom1 = sext i32 %mul to i64
  %arrayidx2 = getelementptr inbounds float* %shiftvec, i64 %idxprom1
  %1 = load float* %arrayidx2, align 4, !tbaa !3
  %add = add nsw i32 %mul, 1
  %idxprom3 = sext i32 %add to i64
  %arrayidx4 = getelementptr inbounds float* %shiftvec, i64 %idxprom3
  %2 = load float* %arrayidx4, align 4, !tbaa !3
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds float* %shiftvec, i64 %idxprom6
  %3 = load float* %arrayidx7, align 4, !tbaa !3
  %arrayidx9 = getelementptr inbounds i32* %iinr, i64 %indvars.iv334
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %arrayidx12 = getelementptr inbounds i32* %jindex, i64 %indvars.iv334
  %5 = load i32* %arrayidx12, align 4, !tbaa !0
  %indvars.iv.next335 = add i64 %indvars.iv334, 1
  %arrayidx15 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next335
  %6 = load i32* %arrayidx15, align 4, !tbaa !0
  %idxprom16 = sext i32 %mul10 to i64
  %arrayidx17 = getelementptr inbounds float* %pos, i64 %idxprom16
  %7 = load float* %arrayidx17, align 4, !tbaa !3
  %add18 = fadd float %1, %7
  %add19 = add nsw i32 %mul10, 1
  %idxprom20 = sext i32 %add19 to i64
  %arrayidx21 = getelementptr inbounds float* %pos, i64 %idxprom20
  %8 = load float* %arrayidx21, align 4, !tbaa !3
  %add22 = fadd float %2, %8
  %add23 = add nsw i32 %mul10, 2
  %idxprom24 = sext i32 %add23 to i64
  %arrayidx25 = getelementptr inbounds float* %pos, i64 %idxprom24
  %9 = load float* %arrayidx25, align 4, !tbaa !3
  %add26 = fadd float %3, %9
  %idxprom28 = sext i32 %4 to i64
  %arrayidx29 = getelementptr inbounds i32* %type, i64 %idxprom28
  %10 = load i32* %arrayidx29, align 4, !tbaa !0
  %mul30 = mul nsw i32 %mul27, %10
  %cmp32323 = icmp slt i32 %5, %6
  br i1 %cmp32323, label %for.body33.lr.ph, label %for.end

for.body33.lr.ph:                                 ; preds = %for.body
  %11 = sext i32 %5 to i64
  br label %for.body33

for.body33:                                       ; preds = %for.body33.lr.ph, %for.body33
  %indvars.iv = phi i64 [ %11, %for.body33.lr.ph ], [ %indvars.iv.next, %for.body33 ]
  %vnbtot.0327 = phi float [ 0.000000e+00, %for.body33.lr.ph ], [ %add115, %for.body33 ]
  %fix1.0326 = phi float [ 0.000000e+00, %for.body33.lr.ph ], [ %add123, %for.body33 ]
  %fiy1.0325 = phi float [ 0.000000e+00, %for.body33.lr.ph ], [ %add124, %for.body33 ]
  %fiz1.0324 = phi float [ 0.000000e+00, %for.body33.lr.ph ], [ %add125, %for.body33 ]
  %arrayidx35 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %12 = load i32* %arrayidx35, align 4, !tbaa !0
  %mul36 = mul nsw i32 %12, 3
  %idxprom37 = sext i32 %mul36 to i64
  %arrayidx38 = getelementptr inbounds float* %pos, i64 %idxprom37
  %13 = load float* %arrayidx38, align 4, !tbaa !3
  %add39 = add nsw i32 %mul36, 1
  %idxprom40 = sext i32 %add39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %14 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = add nsw i32 %mul36, 2
  %idxprom43 = sext i32 %add42 to i64
  %arrayidx44 = getelementptr inbounds float* %pos, i64 %idxprom43
  %15 = load float* %arrayidx44, align 4, !tbaa !3
  %sub = fsub float %add18, %13
  %sub45 = fsub float %add22, %14
  %sub46 = fsub float %add26, %15
  %mul47 = fmul float %sub, %sub
  %mul48 = fmul float %sub45, %sub45
  %add49 = fadd float %mul47, %mul48
  %mul50 = fmul float %sub46, %sub46
  %add51 = fadd float %add49, %mul50
  %conv = fpext float %add51 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv52 = fptrunc double %div to float
  %mul53 = fmul float %add51, %conv52
  %mul54 = fmul float %mul53, %tabscale
  %conv55 = fptosi float %mul54 to i32
  %conv56 = sitofp i32 %conv55 to float
  %sub57 = fsub float %mul54, %conv56
  %mul58 = fmul float %sub57, %sub57
  %mul59 = shl nsw i32 %conv55, 3
  %idxprom60 = sext i32 %12 to i64
  %arrayidx61 = getelementptr inbounds i32* %type, i64 %idxprom60
  %16 = load i32* %arrayidx61, align 4, !tbaa !0
  %mul62 = shl nsw i32 %16, 1
  %add63 = add nsw i32 %mul62, %mul30
  %idxprom64 = sext i32 %add63 to i64
  %arrayidx65 = getelementptr inbounds float* %nbfp, i64 %idxprom64
  %17 = load float* %arrayidx65, align 4, !tbaa !3
  %add66315 = or i32 %add63, 1
  %idxprom67 = sext i32 %add66315 to i64
  %arrayidx68 = getelementptr inbounds float* %nbfp, i64 %idxprom67
  %18 = load float* %arrayidx68, align 4, !tbaa !3
  %idxprom69 = sext i32 %mul59 to i64
  %arrayidx70 = getelementptr inbounds float* %VFtab, i64 %idxprom69
  %19 = load float* %arrayidx70, align 4, !tbaa !3
  %add71316 = or i32 %mul59, 1
  %idxprom72 = sext i32 %add71316 to i64
  %arrayidx73 = getelementptr inbounds float* %VFtab, i64 %idxprom72
  %20 = load float* %arrayidx73, align 4, !tbaa !3
  %add74317 = or i32 %mul59, 2
  %idxprom75 = sext i32 %add74317 to i64
  %arrayidx76 = getelementptr inbounds float* %VFtab, i64 %idxprom75
  %21 = load float* %arrayidx76, align 4, !tbaa !3
  %mul77 = fmul float %sub57, %21
  %add78318 = or i32 %mul59, 3
  %idxprom79 = sext i32 %add78318 to i64
  %arrayidx80 = getelementptr inbounds float* %VFtab, i64 %idxprom79
  %22 = load float* %arrayidx80, align 4, !tbaa !3
  %mul81 = fmul float %mul58, %22
  %add82 = fadd float %20, %mul77
  %add83 = fadd float %add82, %mul81
  %mul84 = fmul float %sub57, %add83
  %add85 = fadd float %19, %mul84
  %add86 = fadd float %mul77, %add83
  %mul87 = fmul float %mul81, 2.000000e+00
  %add88 = fadd float %mul87, %add86
  %mul89 = fmul float %17, %add85
  %mul90 = fmul float %17, %add88
  %add91319 = or i32 %mul59, 4
  %idxprom92 = sext i32 %add91319 to i64
  %arrayidx93 = getelementptr inbounds float* %VFtab, i64 %idxprom92
  %23 = load float* %arrayidx93, align 4, !tbaa !3
  %add94320 = or i32 %mul59, 5
  %idxprom95 = sext i32 %add94320 to i64
  %arrayidx96 = getelementptr inbounds float* %VFtab, i64 %idxprom95
  %24 = load float* %arrayidx96, align 4, !tbaa !3
  %add97321 = or i32 %mul59, 6
  %idxprom98 = sext i32 %add97321 to i64
  %arrayidx99 = getelementptr inbounds float* %VFtab, i64 %idxprom98
  %25 = load float* %arrayidx99, align 4, !tbaa !3
  %mul100 = fmul float %sub57, %25
  %add101322 = or i32 %mul59, 7
  %idxprom102 = sext i32 %add101322 to i64
  %arrayidx103 = getelementptr inbounds float* %VFtab, i64 %idxprom102
  %26 = load float* %arrayidx103, align 4, !tbaa !3
  %mul104 = fmul float %mul58, %26
  %add105 = fadd float %24, %mul100
  %add106 = fadd float %add105, %mul104
  %mul107 = fmul float %sub57, %add106
  %add108 = fadd float %23, %mul107
  %add109 = fadd float %mul100, %add106
  %mul110 = fmul float %mul104, 2.000000e+00
  %add111 = fadd float %mul110, %add109
  %mul112 = fmul float %18, %add108
  %mul113 = fmul float %18, %add111
  %add114 = fadd float %vnbtot.0327, %mul89
  %add115 = fadd float %add114, %mul112
  %add116 = fadd float %mul90, %mul113
  %mul117 = fmul float %add116, %tabscale
  %27 = fmul float %conv52, %mul117
  %mul119 = fsub float -0.000000e+00, %27
  %mul120 = fmul float %sub, %mul119
  %mul121 = fmul float %sub45, %mul119
  %mul122 = fmul float %sub46, %mul119
  %add123 = fadd float %fix1.0326, %mul120
  %add124 = fadd float %fiy1.0325, %mul121
  %add125 = fadd float %fiz1.0324, %mul122
  %arrayidx127 = getelementptr inbounds float* %faction, i64 %idxprom37
  %28 = load float* %arrayidx127, align 4, !tbaa !3
  %sub128 = fsub float %28, %mul120
  store float %sub128, float* %arrayidx127, align 4, !tbaa !3
  %arrayidx133 = getelementptr inbounds float* %faction, i64 %idxprom40
  %29 = load float* %arrayidx133, align 4, !tbaa !3
  %sub134 = fsub float %29, %mul121
  store float %sub134, float* %arrayidx133, align 4, !tbaa !3
  %arrayidx140 = getelementptr inbounds float* %faction, i64 %idxprom43
  %30 = load float* %arrayidx140, align 4, !tbaa !3
  %sub141 = fsub float %30, %mul122
  store float %sub141, float* %arrayidx140, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %31 = trunc i64 %indvars.iv.next to i32
  %cmp32 = icmp slt i32 %31, %6
  br i1 %cmp32, label %for.body33, label %for.end

for.end:                                          ; preds = %for.body33, %for.body
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add115, %for.body33 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add123, %for.body33 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add124, %for.body33 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add125, %for.body33 ]
  %arrayidx146 = getelementptr inbounds float* %faction, i64 %idxprom16
  %32 = load float* %arrayidx146, align 4, !tbaa !3
  %add147 = fadd float %fix1.0.lcssa, %32
  store float %add147, float* %arrayidx146, align 4, !tbaa !3
  %arrayidx152 = getelementptr inbounds float* %faction, i64 %idxprom20
  %33 = load float* %arrayidx152, align 4, !tbaa !3
  %add153 = fadd float %fiy1.0.lcssa, %33
  store float %add153, float* %arrayidx152, align 4, !tbaa !3
  %arrayidx159 = getelementptr inbounds float* %faction, i64 %idxprom24
  %34 = load float* %arrayidx159, align 4, !tbaa !3
  %add160 = fadd float %fiz1.0.lcssa, %34
  store float %add160, float* %arrayidx159, align 4, !tbaa !3
  %arrayidx165 = getelementptr inbounds float* %fshift, i64 %idxprom1
  %35 = load float* %arrayidx165, align 4, !tbaa !3
  %add166 = fadd float %fix1.0.lcssa, %35
  store float %add166, float* %arrayidx165, align 4, !tbaa !3
  %arrayidx171 = getelementptr inbounds float* %fshift, i64 %idxprom3
  %36 = load float* %arrayidx171, align 4, !tbaa !3
  %add172 = fadd float %fiy1.0.lcssa, %36
  store float %add172, float* %arrayidx171, align 4, !tbaa !3
  %arrayidx178 = getelementptr inbounds float* %fshift, i64 %idxprom6
  %37 = load float* %arrayidx178, align 4, !tbaa !3
  %add179 = fadd float %fiz1.0.lcssa, %37
  store float %add179, float* %arrayidx178, align 4, !tbaa !3
  %arrayidx184 = getelementptr inbounds i32* %gid, i64 %indvars.iv334
  %38 = load i32* %arrayidx184, align 4, !tbaa !0
  %idxprom185 = sext i32 %38 to i64
  %arrayidx186 = getelementptr inbounds float* %Vnb, i64 %idxprom185
  %39 = load float* %arrayidx186, align 4, !tbaa !3
  %add187 = fadd float %vnbtot.0.lcssa, %39
  store float %add187, float* %arrayidx186, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next335 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end192, label %for.body

for.end192:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl0301(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab, float %lambda, float* nocapture %dvdlambda, i32* nocapture %typeB) #0 {
entry:
  %sub = fsub float 1.000000e+00, %lambda
  %cmp381 = icmp sgt i32 %nri, 0
  br i1 %cmp381, label %for.body.lr.ph, label %for.end218

for.body.lr.ph:                                   ; preds = %entry
  %mul27 = shl nsw i32 %ntype, 1
  br label %for.body

for.body:                                         ; preds = %for.end, %for.body.lr.ph
  %indvars.iv385 = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next386, %for.end ]
  %dvdl.0382 = phi float [ 0.000000e+00, %for.body.lr.ph ], [ %dvdl.1.lcssa, %for.end ]
  %arrayidx = getelementptr inbounds i32* %shift, i64 %indvars.iv385
  %0 = load i32* %arrayidx, align 4, !tbaa !0
  %mul = mul nsw i32 %0, 3
  %idxprom1 = sext i32 %mul to i64
  %arrayidx2 = getelementptr inbounds float* %shiftvec, i64 %idxprom1
  %1 = load float* %arrayidx2, align 4, !tbaa !3
  %add = add nsw i32 %mul, 1
  %idxprom3 = sext i32 %add to i64
  %arrayidx4 = getelementptr inbounds float* %shiftvec, i64 %idxprom3
  %2 = load float* %arrayidx4, align 4, !tbaa !3
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds float* %shiftvec, i64 %idxprom6
  %3 = load float* %arrayidx7, align 4, !tbaa !3
  %arrayidx9 = getelementptr inbounds i32* %iinr, i64 %indvars.iv385
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %arrayidx12 = getelementptr inbounds i32* %jindex, i64 %indvars.iv385
  %5 = load i32* %arrayidx12, align 4, !tbaa !0
  %indvars.iv.next386 = add i64 %indvars.iv385, 1
  %arrayidx15 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next386
  %6 = load i32* %arrayidx15, align 4, !tbaa !0
  %idxprom16 = sext i32 %mul10 to i64
  %arrayidx17 = getelementptr inbounds float* %pos, i64 %idxprom16
  %7 = load float* %arrayidx17, align 4, !tbaa !3
  %add18 = fadd float %1, %7
  %add19 = add nsw i32 %mul10, 1
  %idxprom20 = sext i32 %add19 to i64
  %arrayidx21 = getelementptr inbounds float* %pos, i64 %idxprom20
  %8 = load float* %arrayidx21, align 4, !tbaa !3
  %add22 = fadd float %2, %8
  %add23 = add nsw i32 %mul10, 2
  %idxprom24 = sext i32 %add23 to i64
  %arrayidx25 = getelementptr inbounds float* %pos, i64 %idxprom24
  %9 = load float* %arrayidx25, align 4, !tbaa !3
  %add26 = fadd float %3, %9
  %idxprom28 = sext i32 %4 to i64
  %arrayidx29 = getelementptr inbounds i32* %type, i64 %idxprom28
  %10 = load i32* %arrayidx29, align 4, !tbaa !0
  %mul30 = mul nsw i32 %10, %mul27
  %arrayidx33 = getelementptr inbounds i32* %typeB, i64 %idxprom28
  %11 = load i32* %arrayidx33, align 4, !tbaa !0
  %mul34 = mul nsw i32 %11, %mul27
  %cmp36370 = icmp slt i32 %5, %6
  br i1 %cmp36370, label %for.body37.lr.ph, label %for.end

for.body37.lr.ph:                                 ; preds = %for.body
  %12 = sext i32 %5 to i64
  br label %for.body37

for.body37:                                       ; preds = %for.body37.lr.ph, %for.body37
  %indvars.iv = phi i64 [ %12, %for.body37.lr.ph ], [ %indvars.iv.next, %for.body37 ]
  %dvdl.1375 = phi float [ %dvdl.0382, %for.body37.lr.ph ], [ %add141, %for.body37 ]
  %vnbtot.0374 = phi float [ 0.000000e+00, %for.body37.lr.ph ], [ %add138, %for.body37 ]
  %fix1.0373 = phi float [ 0.000000e+00, %for.body37.lr.ph ], [ %add149, %for.body37 ]
  %fiy1.0372 = phi float [ 0.000000e+00, %for.body37.lr.ph ], [ %add150, %for.body37 ]
  %fiz1.0371 = phi float [ 0.000000e+00, %for.body37.lr.ph ], [ %add151, %for.body37 ]
  %arrayidx39 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %13 = load i32* %arrayidx39, align 4, !tbaa !0
  %mul40 = mul nsw i32 %13, 3
  %idxprom41 = sext i32 %mul40 to i64
  %arrayidx42 = getelementptr inbounds float* %pos, i64 %idxprom41
  %14 = load float* %arrayidx42, align 4, !tbaa !3
  %add43 = add nsw i32 %mul40, 1
  %idxprom44 = sext i32 %add43 to i64
  %arrayidx45 = getelementptr inbounds float* %pos, i64 %idxprom44
  %15 = load float* %arrayidx45, align 4, !tbaa !3
  %add46 = add nsw i32 %mul40, 2
  %idxprom47 = sext i32 %add46 to i64
  %arrayidx48 = getelementptr inbounds float* %pos, i64 %idxprom47
  %16 = load float* %arrayidx48, align 4, !tbaa !3
  %sub49 = fsub float %add18, %14
  %sub50 = fsub float %add22, %15
  %sub51 = fsub float %add26, %16
  %mul52 = fmul float %sub49, %sub49
  %mul53 = fmul float %sub50, %sub50
  %add54 = fadd float %mul52, %mul53
  %mul55 = fmul float %sub51, %sub51
  %add56 = fadd float %add54, %mul55
  %conv = fpext float %add56 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv57 = fptrunc double %div to float
  %mul58 = fmul float %add56, %conv57
  %mul59 = fmul float %mul58, %tabscale
  %conv60 = fptosi float %mul59 to i32
  %conv61 = sitofp i32 %conv60 to float
  %sub62 = fsub float %mul59, %conv61
  %mul63 = fmul float %sub62, %sub62
  %mul64 = shl nsw i32 %conv60, 3
  %idxprom65 = sext i32 %13 to i64
  %arrayidx66 = getelementptr inbounds i32* %type, i64 %idxprom65
  %17 = load i32* %arrayidx66, align 4, !tbaa !0
  %mul67 = shl nsw i32 %17, 1
  %add68 = add nsw i32 %mul67, %mul30
  %arrayidx70 = getelementptr inbounds i32* %typeB, i64 %idxprom65
  %18 = load i32* %arrayidx70, align 4, !tbaa !0
  %mul71 = shl nsw i32 %18, 1
  %add72 = add nsw i32 %mul71, %mul34
  %idxprom73 = sext i32 %add68 to i64
  %arrayidx74 = getelementptr inbounds float* %nbfp, i64 %idxprom73
  %19 = load float* %arrayidx74, align 4, !tbaa !3
  %idxprom75 = sext i32 %add72 to i64
  %arrayidx76 = getelementptr inbounds float* %nbfp, i64 %idxprom75
  %20 = load float* %arrayidx76, align 4, !tbaa !3
  %mul77 = fmul float %sub, %19
  %mul78 = fmul float %20, %lambda
  %add79 = fadd float %mul77, %mul78
  %add80361 = or i32 %add68, 1
  %idxprom81 = sext i32 %add80361 to i64
  %arrayidx82 = getelementptr inbounds float* %nbfp, i64 %idxprom81
  %21 = load float* %arrayidx82, align 4, !tbaa !3
  %add83362 = or i32 %add72, 1
  %idxprom84 = sext i32 %add83362 to i64
  %arrayidx85 = getelementptr inbounds float* %nbfp, i64 %idxprom84
  %22 = load float* %arrayidx85, align 4, !tbaa !3
  %mul86 = fmul float %sub, %21
  %mul87 = fmul float %22, %lambda
  %add88 = fadd float %mul86, %mul87
  %idxprom89 = sext i32 %mul64 to i64
  %arrayidx90 = getelementptr inbounds float* %VFtab, i64 %idxprom89
  %23 = load float* %arrayidx90, align 4, !tbaa !3
  %add91363 = or i32 %mul64, 1
  %idxprom92 = sext i32 %add91363 to i64
  %arrayidx93 = getelementptr inbounds float* %VFtab, i64 %idxprom92
  %24 = load float* %arrayidx93, align 4, !tbaa !3
  %add94364 = or i32 %mul64, 2
  %idxprom95 = sext i32 %add94364 to i64
  %arrayidx96 = getelementptr inbounds float* %VFtab, i64 %idxprom95
  %25 = load float* %arrayidx96, align 4, !tbaa !3
  %mul97 = fmul float %sub62, %25
  %add98365 = or i32 %mul64, 3
  %idxprom99 = sext i32 %add98365 to i64
  %arrayidx100 = getelementptr inbounds float* %VFtab, i64 %idxprom99
  %26 = load float* %arrayidx100, align 4, !tbaa !3
  %mul101 = fmul float %mul63, %26
  %add102 = fadd float %24, %mul97
  %add103 = fadd float %add102, %mul101
  %mul104 = fmul float %sub62, %add103
  %add105 = fadd float %23, %mul104
  %add106 = fadd float %mul97, %add103
  %mul107 = fmul float %mul101, 2.000000e+00
  %add108 = fadd float %mul107, %add106
  %mul109 = fmul float %add79, %add105
  %mul110 = fmul float %add79, %add108
  %sub111 = fsub float %20, %19
  %mul112 = fmul float %sub111, %add105
  %add113 = fadd float %dvdl.1375, %mul112
  %add114366 = or i32 %mul64, 4
  %idxprom115 = sext i32 %add114366 to i64
  %arrayidx116 = getelementptr inbounds float* %VFtab, i64 %idxprom115
  %27 = load float* %arrayidx116, align 4, !tbaa !3
  %add117367 = or i32 %mul64, 5
  %idxprom118 = sext i32 %add117367 to i64
  %arrayidx119 = getelementptr inbounds float* %VFtab, i64 %idxprom118
  %28 = load float* %arrayidx119, align 4, !tbaa !3
  %add120368 = or i32 %mul64, 6
  %idxprom121 = sext i32 %add120368 to i64
  %arrayidx122 = getelementptr inbounds float* %VFtab, i64 %idxprom121
  %29 = load float* %arrayidx122, align 4, !tbaa !3
  %mul123 = fmul float %sub62, %29
  %add124369 = or i32 %mul64, 7
  %idxprom125 = sext i32 %add124369 to i64
  %arrayidx126 = getelementptr inbounds float* %VFtab, i64 %idxprom125
  %30 = load float* %arrayidx126, align 4, !tbaa !3
  %mul127 = fmul float %mul63, %30
  %add128 = fadd float %28, %mul123
  %add129 = fadd float %add128, %mul127
  %mul130 = fmul float %sub62, %add129
  %add131 = fadd float %27, %mul130
  %add132 = fadd float %mul123, %add129
  %mul133 = fmul float %mul127, 2.000000e+00
  %add134 = fadd float %mul133, %add132
  %mul135 = fmul float %add88, %add131
  %mul136 = fmul float %add88, %add134
  %add137 = fadd float %vnbtot.0374, %mul109
  %add138 = fadd float %add137, %mul135
  %sub139 = fsub float %22, %21
  %mul140 = fmul float %sub139, %add131
  %add141 = fadd float %add113, %mul140
  %add142 = fadd float %mul110, %mul136
  %mul143 = fmul float %add142, %tabscale
  %31 = fmul float %conv57, %mul143
  %mul145 = fsub float -0.000000e+00, %31
  %mul146 = fmul float %sub49, %mul145
  %mul147 = fmul float %sub50, %mul145
  %mul148 = fmul float %sub51, %mul145
  %add149 = fadd float %fix1.0373, %mul146
  %add150 = fadd float %fiy1.0372, %mul147
  %add151 = fadd float %fiz1.0371, %mul148
  %arrayidx153 = getelementptr inbounds float* %faction, i64 %idxprom41
  %32 = load float* %arrayidx153, align 4, !tbaa !3
  %sub154 = fsub float %32, %mul146
  store float %sub154, float* %arrayidx153, align 4, !tbaa !3
  %arrayidx159 = getelementptr inbounds float* %faction, i64 %idxprom44
  %33 = load float* %arrayidx159, align 4, !tbaa !3
  %sub160 = fsub float %33, %mul147
  store float %sub160, float* %arrayidx159, align 4, !tbaa !3
  %arrayidx166 = getelementptr inbounds float* %faction, i64 %idxprom47
  %34 = load float* %arrayidx166, align 4, !tbaa !3
  %sub167 = fsub float %34, %mul148
  store float %sub167, float* %arrayidx166, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %35 = trunc i64 %indvars.iv.next to i32
  %cmp36 = icmp slt i32 %35, %6
  br i1 %cmp36, label %for.body37, label %for.end

for.end:                                          ; preds = %for.body37, %for.body
  %dvdl.1.lcssa = phi float [ %dvdl.0382, %for.body ], [ %add141, %for.body37 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add138, %for.body37 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add149, %for.body37 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add150, %for.body37 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add151, %for.body37 ]
  %arrayidx172 = getelementptr inbounds float* %faction, i64 %idxprom16
  %36 = load float* %arrayidx172, align 4, !tbaa !3
  %add173 = fadd float %fix1.0.lcssa, %36
  store float %add173, float* %arrayidx172, align 4, !tbaa !3
  %arrayidx178 = getelementptr inbounds float* %faction, i64 %idxprom20
  %37 = load float* %arrayidx178, align 4, !tbaa !3
  %add179 = fadd float %fiy1.0.lcssa, %37
  store float %add179, float* %arrayidx178, align 4, !tbaa !3
  %arrayidx185 = getelementptr inbounds float* %faction, i64 %idxprom24
  %38 = load float* %arrayidx185, align 4, !tbaa !3
  %add186 = fadd float %fiz1.0.lcssa, %38
  store float %add186, float* %arrayidx185, align 4, !tbaa !3
  %arrayidx191 = getelementptr inbounds float* %fshift, i64 %idxprom1
  %39 = load float* %arrayidx191, align 4, !tbaa !3
  %add192 = fadd float %fix1.0.lcssa, %39
  store float %add192, float* %arrayidx191, align 4, !tbaa !3
  %arrayidx197 = getelementptr inbounds float* %fshift, i64 %idxprom3
  %40 = load float* %arrayidx197, align 4, !tbaa !3
  %add198 = fadd float %fiy1.0.lcssa, %40
  store float %add198, float* %arrayidx197, align 4, !tbaa !3
  %arrayidx204 = getelementptr inbounds float* %fshift, i64 %idxprom6
  %41 = load float* %arrayidx204, align 4, !tbaa !3
  %add205 = fadd float %fiz1.0.lcssa, %41
  store float %add205, float* %arrayidx204, align 4, !tbaa !3
  %arrayidx210 = getelementptr inbounds i32* %gid, i64 %indvars.iv385
  %42 = load i32* %arrayidx210, align 4, !tbaa !0
  %idxprom211 = sext i32 %42 to i64
  %arrayidx212 = getelementptr inbounds float* %Vnb, i64 %idxprom211
  %43 = load float* %arrayidx212, align 4, !tbaa !3
  %add213 = fadd float %vnbtot.0.lcssa, %43
  store float %add213, float* %arrayidx212, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next386 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end218, label %for.body

for.end218:                                       ; preds = %for.end, %entry
  %dvdl.0.lcssa = phi float [ 0.000000e+00, %entry ], [ %dvdl.1.lcssa, %for.end ]
  %44 = load float* %dvdlambda, align 4, !tbaa !3
  %add219 = fadd float %dvdl.0.lcssa, %44
  store float %add219, float* %dvdlambda, align 4, !tbaa !3
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl0302(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab, float %lambda, float* nocapture %dvdlambda, i32* nocapture %typeB, float %Alpha, float %defsigma6) #0 {
entry:
  %sub = fsub float 1.000000e+00, %lambda
  %mul = fmul float %lambda, %lambda
  %mul1 = fmul float %sub, %sub
  %cmp609 = icmp sgt i32 %nri, 0
  br i1 %cmp609, label %for.body.lr.ph, label %for.end342

for.body.lr.ph:                                   ; preds = %entry
  %mul29 = shl nsw i32 %ntype, 1
  %mul260 = fmul float %Alpha, 0x3FD5555560000000
  %mul261 = fmul float %mul260, %lambda
  %mul262 = fmul float %sub, %mul261
  br label %for.body

for.body:                                         ; preds = %for.end, %for.body.lr.ph
  %indvars.iv613 = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next614, %for.end ]
  %dvdl.0610 = phi float [ 0.000000e+00, %for.body.lr.ph ], [ %dvdl.1.lcssa, %for.end ]
  %arrayidx = getelementptr inbounds i32* %shift, i64 %indvars.iv613
  %0 = load i32* %arrayidx, align 4, !tbaa !0
  %mul2 = mul nsw i32 %0, 3
  %idxprom3 = sext i32 %mul2 to i64
  %arrayidx4 = getelementptr inbounds float* %shiftvec, i64 %idxprom3
  %1 = load float* %arrayidx4, align 4, !tbaa !3
  %add = add nsw i32 %mul2, 1
  %idxprom5 = sext i32 %add to i64
  %arrayidx6 = getelementptr inbounds float* %shiftvec, i64 %idxprom5
  %2 = load float* %arrayidx6, align 4, !tbaa !3
  %add7 = add nsw i32 %mul2, 2
  %idxprom8 = sext i32 %add7 to i64
  %arrayidx9 = getelementptr inbounds float* %shiftvec, i64 %idxprom8
  %3 = load float* %arrayidx9, align 4, !tbaa !3
  %arrayidx11 = getelementptr inbounds i32* %iinr, i64 %indvars.iv613
  %4 = load i32* %arrayidx11, align 4, !tbaa !0
  %mul12 = mul nsw i32 %4, 3
  %arrayidx14 = getelementptr inbounds i32* %jindex, i64 %indvars.iv613
  %5 = load i32* %arrayidx14, align 4, !tbaa !0
  %indvars.iv.next614 = add i64 %indvars.iv613, 1
  %arrayidx17 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next614
  %6 = load i32* %arrayidx17, align 4, !tbaa !0
  %idxprom18 = sext i32 %mul12 to i64
  %arrayidx19 = getelementptr inbounds float* %pos, i64 %idxprom18
  %7 = load float* %arrayidx19, align 4, !tbaa !3
  %add20 = fadd float %1, %7
  %add21 = add nsw i32 %mul12, 1
  %idxprom22 = sext i32 %add21 to i64
  %arrayidx23 = getelementptr inbounds float* %pos, i64 %idxprom22
  %8 = load float* %arrayidx23, align 4, !tbaa !3
  %add24 = fadd float %2, %8
  %add25 = add nsw i32 %mul12, 2
  %idxprom26 = sext i32 %add25 to i64
  %arrayidx27 = getelementptr inbounds float* %pos, i64 %idxprom26
  %9 = load float* %arrayidx27, align 4, !tbaa !3
  %add28 = fadd float %3, %9
  %idxprom30 = sext i32 %4 to i64
  %arrayidx31 = getelementptr inbounds i32* %type, i64 %idxprom30
  %10 = load i32* %arrayidx31, align 4, !tbaa !0
  %mul32 = mul nsw i32 %10, %mul29
  %arrayidx35 = getelementptr inbounds i32* %typeB, i64 %idxprom30
  %11 = load i32* %arrayidx35, align 4, !tbaa !0
  %mul36 = mul nsw i32 %11, %mul29
  %cmp38598 = icmp slt i32 %5, %6
  br i1 %cmp38598, label %for.body39.lr.ph, label %for.end

for.body39.lr.ph:                                 ; preds = %for.body
  %12 = sext i32 %5 to i64
  br label %for.body39

for.body39:                                       ; preds = %for.body39.lr.ph, %if.end239
  %indvars.iv = phi i64 [ %12, %for.body39.lr.ph ], [ %indvars.iv.next, %if.end239 ]
  %fiz1.0603 = phi float [ 0.000000e+00, %for.body39.lr.ph ], [ %add275, %if.end239 ]
  %fiy1.0602 = phi float [ 0.000000e+00, %for.body39.lr.ph ], [ %add274, %if.end239 ]
  %fix1.0601 = phi float [ 0.000000e+00, %for.body39.lr.ph ], [ %add273, %if.end239 ]
  %dvdl.1600 = phi float [ %dvdl.0610, %for.body39.lr.ph ], [ %add269, %if.end239 ]
  %vnbtot.0599 = phi float [ 0.000000e+00, %for.body39.lr.ph ], [ %add245, %if.end239 ]
  %arrayidx41 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %13 = load i32* %arrayidx41, align 4, !tbaa !0
  %mul42 = mul nsw i32 %13, 3
  %idxprom43 = sext i32 %mul42 to i64
  %arrayidx44 = getelementptr inbounds float* %pos, i64 %idxprom43
  %14 = load float* %arrayidx44, align 4, !tbaa !3
  %add45 = add nsw i32 %mul42, 1
  %idxprom46 = sext i32 %add45 to i64
  %arrayidx47 = getelementptr inbounds float* %pos, i64 %idxprom46
  %15 = load float* %arrayidx47, align 4, !tbaa !3
  %add48 = add nsw i32 %mul42, 2
  %idxprom49 = sext i32 %add48 to i64
  %arrayidx50 = getelementptr inbounds float* %pos, i64 %idxprom49
  %16 = load float* %arrayidx50, align 4, !tbaa !3
  %sub51 = fsub float %add20, %14
  %sub52 = fsub float %add24, %15
  %sub53 = fsub float %add28, %16
  %mul54 = fmul float %sub51, %sub51
  %mul55 = fmul float %sub52, %sub52
  %add56 = fadd float %mul54, %mul55
  %mul57 = fmul float %sub53, %sub53
  %add58 = fadd float %add56, %mul57
  %conv = fpext float %add58 to double
  %call = tail call double @sqrt(double %conv) #2
  %idxprom61 = sext i32 %13 to i64
  %arrayidx62 = getelementptr inbounds i32* %type, i64 %idxprom61
  %17 = load i32* %arrayidx62, align 4, !tbaa !0
  %mul63 = shl nsw i32 %17, 1
  %add64 = add nsw i32 %mul63, %mul32
  %arrayidx66 = getelementptr inbounds i32* %typeB, i64 %idxprom61
  %18 = load i32* %arrayidx66, align 4, !tbaa !0
  %mul67 = shl nsw i32 %18, 1
  %add68 = add nsw i32 %mul67, %mul36
  %idxprom69 = sext i32 %add64 to i64
  %arrayidx70 = getelementptr inbounds float* %nbfp, i64 %idxprom69
  %19 = load float* %arrayidx70, align 4, !tbaa !3
  %idxprom71 = sext i32 %add68 to i64
  %arrayidx72 = getelementptr inbounds float* %nbfp, i64 %idxprom71
  %20 = load float* %arrayidx72, align 4, !tbaa !3
  %add73579 = or i32 %add64, 1
  %idxprom74 = sext i32 %add73579 to i64
  %arrayidx75 = getelementptr inbounds float* %nbfp, i64 %idxprom74
  %21 = load float* %arrayidx75, align 4, !tbaa !3
  %add76580 = or i32 %add68, 1
  %idxprom77 = sext i32 %add76580 to i64
  %arrayidx78 = getelementptr inbounds float* %nbfp, i64 %idxprom77
  %22 = load float* %arrayidx78, align 4, !tbaa !3
  %cmp79 = fcmp ogt float %19, 0.000000e+00
  %cmp81 = fcmp ogt float %21, 0.000000e+00
  %or.cond = and i1 %cmp79, %cmp81
  br i1 %or.cond, label %if.then, label %if.end

if.then:                                          ; preds = %for.body39
  %div83 = fdiv float %21, %19
  br label %if.end

if.end:                                           ; preds = %for.body39, %if.then
  %sigma6a.0 = phi float [ %div83, %if.then ], [ %defsigma6, %for.body39 ]
  %cmp84 = fcmp ogt float %20, 0.000000e+00
  %cmp87 = fcmp ogt float %22, 0.000000e+00
  %or.cond595 = and i1 %cmp84, %cmp87
  br i1 %or.cond595, label %if.then89, label %if.end92

if.then89:                                        ; preds = %if.end
  %div90 = fdiv float %22, %20
  br label %if.end92

if.end92:                                         ; preds = %if.end, %if.then89
  %sigma6b.0 = phi float [ %div90, %if.then89 ], [ %defsigma6, %if.end ]
  %mul93 = fmul float %add58, %add58
  %mul94 = fmul float %add58, %mul93
  %or.cond596 = or i1 %cmp79, %cmp81
  br i1 %or.cond596, label %if.then99, label %if.end166

if.then99:                                        ; preds = %if.end92
  %mul100 = fmul float %sigma6a.0, %Alpha
  %mul101 = fmul float %mul, %mul100
  %add102 = fadd float %mul94, %mul101
  %conv103 = fpext float %add102 to double
  %call104 = tail call double @pow(double %conv103, double 0x3FC5555560000000) #2
  %conv105 = fptrunc double %call104 to float
  %conv108 = fdiv float 1.000000e+00, %conv105
  %mul109 = fmul float %conv108, %conv108
  %mul110 = fmul float %mul109, %mul109
  %mul111 = fmul float %conv108, %mul110
  %mul112 = fmul float %conv105, %tabscale
  %conv113 = fptosi float %mul112 to i32
  %conv114 = sitofp i32 %conv113 to float
  %sub115 = fsub float %mul112, %conv114
  %mul116 = fmul float %sub115, %sub115
  %mul117 = shl nsw i32 %conv113, 3
  %idxprom118 = sext i32 %mul117 to i64
  %arrayidx119 = getelementptr inbounds float* %VFtab, i64 %idxprom118
  %23 = load float* %arrayidx119, align 4, !tbaa !3
  %add120588 = or i32 %mul117, 1
  %idxprom121 = sext i32 %add120588 to i64
  %arrayidx122 = getelementptr inbounds float* %VFtab, i64 %idxprom121
  %24 = load float* %arrayidx122, align 4, !tbaa !3
  %add123589 = or i32 %mul117, 2
  %idxprom124 = sext i32 %add123589 to i64
  %arrayidx125 = getelementptr inbounds float* %VFtab, i64 %idxprom124
  %25 = load float* %arrayidx125, align 4, !tbaa !3
  %mul126 = fmul float %25, %sub115
  %add127590 = or i32 %mul117, 3
  %idxprom128 = sext i32 %add127590 to i64
  %arrayidx129 = getelementptr inbounds float* %VFtab, i64 %idxprom128
  %26 = load float* %arrayidx129, align 4, !tbaa !3
  %mul130 = fmul float %26, %mul116
  %add131 = fadd float %24, %mul126
  %add132 = fadd float %add131, %mul130
  %mul133 = fmul float %sub115, %add132
  %add134 = fadd float %23, %mul133
  %add135 = fadd float %mul126, %add132
  %mul136 = fmul float %mul130, 2.000000e+00
  %add137 = fadd float %mul136, %add135
  %mul138 = fmul float %19, %add134
  %mul139 = fmul float %19, %tabscale
  %mul140 = fmul float %mul139, %add137
  %add141591 = or i32 %mul117, 4
  %idxprom142 = sext i32 %add141591 to i64
  %arrayidx143 = getelementptr inbounds float* %VFtab, i64 %idxprom142
  %27 = load float* %arrayidx143, align 4, !tbaa !3
  %add144592 = or i32 %mul117, 5
  %idxprom145 = sext i32 %add144592 to i64
  %arrayidx146 = getelementptr inbounds float* %VFtab, i64 %idxprom145
  %28 = load float* %arrayidx146, align 4, !tbaa !3
  %add147593 = or i32 %mul117, 6
  %idxprom148 = sext i32 %add147593 to i64
  %arrayidx149 = getelementptr inbounds float* %VFtab, i64 %idxprom148
  %29 = load float* %arrayidx149, align 4, !tbaa !3
  %mul150 = fmul float %sub115, %29
  %add151594 = or i32 %mul117, 7
  %idxprom152 = sext i32 %add151594 to i64
  %arrayidx153 = getelementptr inbounds float* %VFtab, i64 %idxprom152
  %30 = load float* %arrayidx153, align 4, !tbaa !3
  %mul154 = fmul float %mul116, %30
  %add155 = fadd float %28, %mul150
  %add156 = fadd float %add155, %mul154
  %mul157 = fmul float %sub115, %add156
  %add158 = fadd float %27, %mul157
  %add159 = fadd float %mul150, %add156
  %mul160 = fmul float %mul154, 2.000000e+00
  %add161 = fadd float %mul160, %add159
  %mul162 = fmul float %21, %add158
  %mul163 = fmul float %21, %tabscale
  %mul164 = fmul float %mul163, %add161
  br label %if.end166

if.end166:                                        ; preds = %if.end92, %if.then99
  %FFRa.0 = phi float [ %mul164, %if.then99 ], [ 0.000000e+00, %if.end92 ]
  %VVRa.0 = phi float [ %mul162, %if.then99 ], [ 0.000000e+00, %if.end92 ]
  %FFDa.0 = phi float [ %mul140, %if.then99 ], [ 0.000000e+00, %if.end92 ]
  %VVDa.0 = phi float [ %mul138, %if.then99 ], [ 0.000000e+00, %if.end92 ]
  %rinv5a.0 = phi float [ %mul111, %if.then99 ], [ 0.000000e+00, %if.end92 ]
  %or.cond597 = or i1 %cmp84, %cmp87
  br i1 %or.cond597, label %if.then172, label %if.end239

if.then172:                                       ; preds = %if.end166
  %mul173 = fmul float %sigma6b.0, %Alpha
  %mul174 = fmul float %mul1, %mul173
  %add175 = fadd float %mul94, %mul174
  %conv176 = fpext float %add175 to double
  %call177 = tail call double @pow(double %conv176, double 0x3FC5555560000000) #2
  %conv178 = fptrunc double %call177 to float
  %conv181 = fdiv float 1.000000e+00, %conv178
  %mul182 = fmul float %conv181, %conv181
  %mul183 = fmul float %mul182, %mul182
  %mul184 = fmul float %conv181, %mul183
  %mul185 = fmul float %conv178, %tabscale
  %conv186 = fptosi float %mul185 to i32
  %conv187 = sitofp i32 %conv186 to float
  %sub188 = fsub float %mul185, %conv187
  %mul189 = fmul float %sub188, %sub188
  %mul190 = shl nsw i32 %conv186, 3
  %idxprom191 = sext i32 %mul190 to i64
  %arrayidx192 = getelementptr inbounds float* %VFtab, i64 %idxprom191
  %31 = load float* %arrayidx192, align 4, !tbaa !3
  %add193581 = or i32 %mul190, 1
  %idxprom194 = sext i32 %add193581 to i64
  %arrayidx195 = getelementptr inbounds float* %VFtab, i64 %idxprom194
  %32 = load float* %arrayidx195, align 4, !tbaa !3
  %add196582 = or i32 %mul190, 2
  %idxprom197 = sext i32 %add196582 to i64
  %arrayidx198 = getelementptr inbounds float* %VFtab, i64 %idxprom197
  %33 = load float* %arrayidx198, align 4, !tbaa !3
  %mul199 = fmul float %33, %sub188
  %add200583 = or i32 %mul190, 3
  %idxprom201 = sext i32 %add200583 to i64
  %arrayidx202 = getelementptr inbounds float* %VFtab, i64 %idxprom201
  %34 = load float* %arrayidx202, align 4, !tbaa !3
  %mul203 = fmul float %34, %mul189
  %add204 = fadd float %32, %mul199
  %add205 = fadd float %add204, %mul203
  %mul206 = fmul float %sub188, %add205
  %add207 = fadd float %31, %mul206
  %add208 = fadd float %mul199, %add205
  %mul209 = fmul float %mul203, 2.000000e+00
  %add210 = fadd float %mul209, %add208
  %mul211 = fmul float %20, %add207
  %mul212 = fmul float %20, %tabscale
  %mul213 = fmul float %mul212, %add210
  %add214584 = or i32 %mul190, 4
  %idxprom215 = sext i32 %add214584 to i64
  %arrayidx216 = getelementptr inbounds float* %VFtab, i64 %idxprom215
  %35 = load float* %arrayidx216, align 4, !tbaa !3
  %add217585 = or i32 %mul190, 5
  %idxprom218 = sext i32 %add217585 to i64
  %arrayidx219 = getelementptr inbounds float* %VFtab, i64 %idxprom218
  %36 = load float* %arrayidx219, align 4, !tbaa !3
  %add220586 = or i32 %mul190, 6
  %idxprom221 = sext i32 %add220586 to i64
  %arrayidx222 = getelementptr inbounds float* %VFtab, i64 %idxprom221
  %37 = load float* %arrayidx222, align 4, !tbaa !3
  %mul223 = fmul float %sub188, %37
  %add224587 = or i32 %mul190, 7
  %idxprom225 = sext i32 %add224587 to i64
  %arrayidx226 = getelementptr inbounds float* %VFtab, i64 %idxprom225
  %38 = load float* %arrayidx226, align 4, !tbaa !3
  %mul227 = fmul float %mul189, %38
  %add228 = fadd float %36, %mul223
  %add229 = fadd float %add228, %mul227
  %mul230 = fmul float %sub188, %add229
  %add231 = fadd float %35, %mul230
  %add232 = fadd float %mul223, %add229
  %mul233 = fmul float %mul227, 2.000000e+00
  %add234 = fadd float %mul233, %add232
  %mul235 = fmul float %22, %add231
  %mul236 = fmul float %22, %tabscale
  %mul237 = fmul float %mul236, %add234
  br label %if.end239

if.end239:                                        ; preds = %if.end166, %if.then172
  %FFRb.0 = phi float [ %mul237, %if.then172 ], [ 0.000000e+00, %if.end166 ]
  %VVRb.0 = phi float [ %mul235, %if.then172 ], [ 0.000000e+00, %if.end166 ]
  %FFDb.0 = phi float [ %mul213, %if.then172 ], [ 0.000000e+00, %if.end166 ]
  %VVDb.0 = phi float [ %mul211, %if.then172 ], [ 0.000000e+00, %if.end166 ]
  %rinv5b.0 = phi float [ %mul184, %if.then172 ], [ 0.000000e+00, %if.end166 ]
  %add240 = fadd float %VVRb.0, %VVDb.0
  %mul241 = fmul float %add240, %lambda
  %add242 = fadd float %vnbtot.0599, %mul241
  %add243 = fadd float %VVRa.0, %VVDa.0
  %mul244 = fmul float %sub, %add243
  %add245 = fadd float %mul244, %add242
  %add246 = fadd float %FFRa.0, %FFDa.0
  %sub247 = fsub float -0.000000e+00, %add246
  %add248 = fadd float %FFRb.0, %FFDb.0
  %sub249 = fsub float -0.000000e+00, %add248
  %mul250 = fmul float %sub, %sub247
  %mul251 = fmul float %rinv5a.0, %mul250
  %mul252 = fmul float %lambda, %sub249
  %mul253 = fmul float %rinv5b.0, %mul252
  %add254 = fadd float %mul251, %mul253
  %mul255 = fmul float %mul93, %add254
  %add256 = fadd float %dvdl.1600, %VVDb.0
  %add257 = fadd float %VVRb.0, %add256
  %sub258 = fsub float %add257, %VVDa.0
  %sub259 = fsub float %sub258, %VVRa.0
  %mul263 = fmul float %sigma6b.0, %sub249
  %mul264 = fmul float %rinv5b.0, %mul263
  %mul265 = fmul float %sigma6a.0, %sub247
  %mul266 = fmul float %rinv5a.0, %mul265
  %sub267 = fsub float %mul264, %mul266
  %mul268 = fmul float %mul262, %sub267
  %add269 = fadd float %sub259, %mul268
  %mul270 = fmul float %sub51, %mul255
  %mul271 = fmul float %sub52, %mul255
  %mul272 = fmul float %sub53, %mul255
  %add273 = fadd float %fix1.0601, %mul270
  %add274 = fadd float %fiy1.0602, %mul271
  %add275 = fadd float %fiz1.0603, %mul272
  %arrayidx277 = getelementptr inbounds float* %faction, i64 %idxprom43
  %39 = load float* %arrayidx277, align 4, !tbaa !3
  %sub278 = fsub float %39, %mul270
  store float %sub278, float* %arrayidx277, align 4, !tbaa !3
  %arrayidx283 = getelementptr inbounds float* %faction, i64 %idxprom46
  %40 = load float* %arrayidx283, align 4, !tbaa !3
  %sub284 = fsub float %40, %mul271
  store float %sub284, float* %arrayidx283, align 4, !tbaa !3
  %arrayidx290 = getelementptr inbounds float* %faction, i64 %idxprom49
  %41 = load float* %arrayidx290, align 4, !tbaa !3
  %sub291 = fsub float %41, %mul272
  store float %sub291, float* %arrayidx290, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %42 = trunc i64 %indvars.iv.next to i32
  %cmp38 = icmp slt i32 %42, %6
  br i1 %cmp38, label %for.body39, label %for.end

for.end:                                          ; preds = %if.end239, %for.body
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add275, %if.end239 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add274, %if.end239 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add273, %if.end239 ]
  %dvdl.1.lcssa = phi float [ %dvdl.0610, %for.body ], [ %add269, %if.end239 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add245, %if.end239 ]
  %arrayidx296 = getelementptr inbounds float* %faction, i64 %idxprom18
  %43 = load float* %arrayidx296, align 4, !tbaa !3
  %add297 = fadd float %fix1.0.lcssa, %43
  store float %add297, float* %arrayidx296, align 4, !tbaa !3
  %arrayidx302 = getelementptr inbounds float* %faction, i64 %idxprom22
  %44 = load float* %arrayidx302, align 4, !tbaa !3
  %add303 = fadd float %fiy1.0.lcssa, %44
  store float %add303, float* %arrayidx302, align 4, !tbaa !3
  %arrayidx309 = getelementptr inbounds float* %faction, i64 %idxprom26
  %45 = load float* %arrayidx309, align 4, !tbaa !3
  %add310 = fadd float %fiz1.0.lcssa, %45
  store float %add310, float* %arrayidx309, align 4, !tbaa !3
  %arrayidx315 = getelementptr inbounds float* %fshift, i64 %idxprom3
  %46 = load float* %arrayidx315, align 4, !tbaa !3
  %add316 = fadd float %fix1.0.lcssa, %46
  store float %add316, float* %arrayidx315, align 4, !tbaa !3
  %arrayidx321 = getelementptr inbounds float* %fshift, i64 %idxprom5
  %47 = load float* %arrayidx321, align 4, !tbaa !3
  %add322 = fadd float %fiy1.0.lcssa, %47
  store float %add322, float* %arrayidx321, align 4, !tbaa !3
  %arrayidx328 = getelementptr inbounds float* %fshift, i64 %idxprom8
  %48 = load float* %arrayidx328, align 4, !tbaa !3
  %add329 = fadd float %fiz1.0.lcssa, %48
  store float %add329, float* %arrayidx328, align 4, !tbaa !3
  %arrayidx334 = getelementptr inbounds i32* %gid, i64 %indvars.iv613
  %49 = load i32* %arrayidx334, align 4, !tbaa !0
  %idxprom335 = sext i32 %49 to i64
  %arrayidx336 = getelementptr inbounds float* %Vnb, i64 %idxprom335
  %50 = load float* %arrayidx336, align 4, !tbaa !3
  %add337 = fadd float %vnbtot.0.lcssa, %50
  store float %add337, float* %arrayidx336, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next614 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end342, label %for.body

for.end342:                                       ; preds = %for.end, %entry
  %dvdl.0.lcssa = phi float [ 0.000000e+00, %entry ], [ %dvdl.1.lcssa, %for.end ]
  %51 = load float* %dvdlambda, align 4, !tbaa !3
  %add343 = fadd float %dvdl.0.lcssa, %51
  store float %add343, float* %dvdlambda, align 4, !tbaa !3
  ret void
}

; Function Attrs: nounwind optsize
declare double @pow(double, double) #1

; Function Attrs: nounwind optsize uwtable
define void @inl0310(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab, i32* nocapture %nsatoms) #0 {
entry:
  %cmp752 = icmp sgt i32 %nri, 0
  br i1 %cmp752, label %for.body.lr.ph, label %for.end398

for.body.lr.ph:                                   ; preds = %entry
  %mul220 = shl i32 %ntype, 1
  br label %for.body

for.body:                                         ; preds = %for.end388, %for.body.lr.ph
  %indvars.iv769 = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next770, %for.end388 ]
  %0 = trunc i64 %indvars.iv769 to i32
  %mul = mul nsw i32 %0, 3
  %idxprom = sext i32 %mul to i64
  %arrayidx = getelementptr inbounds i32* %nsatoms, i64 %idxprom
  %1 = load i32* %arrayidx, align 4, !tbaa !0
  %add = add nsw i32 %mul, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds i32* %nsatoms, i64 %idxprom2
  %2 = load i32* %arrayidx3, align 4, !tbaa !0
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds i32* %nsatoms, i64 %idxprom6
  %3 = load i32* %arrayidx7, align 4, !tbaa !0
  %arrayidx9 = getelementptr inbounds i32* %shift, i64 %indvars.iv769
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %idxprom11 = sext i32 %mul10 to i64
  %arrayidx12 = getelementptr inbounds float* %shiftvec, i64 %idxprom11
  %5 = load float* %arrayidx12, align 4, !tbaa !3
  %add13 = add nsw i32 %mul10, 1
  %idxprom14 = sext i32 %add13 to i64
  %arrayidx15 = getelementptr inbounds float* %shiftvec, i64 %idxprom14
  %6 = load float* %arrayidx15, align 4, !tbaa !3
  %add16 = add nsw i32 %mul10, 2
  %idxprom17 = sext i32 %add16 to i64
  %arrayidx18 = getelementptr inbounds float* %shiftvec, i64 %idxprom17
  %7 = load float* %arrayidx18, align 4, !tbaa !3
  %arrayidx20 = getelementptr inbounds i32* %iinr, i64 %indvars.iv769
  %8 = load i32* %arrayidx20, align 4, !tbaa !0
  %arrayidx23 = getelementptr inbounds i32* %jindex, i64 %indvars.iv769
  %9 = load i32* %arrayidx23, align 4, !tbaa !0
  %indvars.iv.next770 = add i64 %indvars.iv769, 1
  %arrayidx26 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next770
  %10 = load i32* %arrayidx26, align 4, !tbaa !0
  %cmp28729 = icmp sgt i32 %2, 0
  br i1 %cmp28729, label %for.body29.lr.ph, label %for.end201

for.body29.lr.ph:                                 ; preds = %for.body
  %cmp46720 = icmp slt i32 %9, %10
  %arrayidx179 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx185 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx192 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %11 = sext i32 %9 to i64
  %12 = sext i32 %8 to i64
  %13 = mul i32 %8, 3
  %14 = sext i32 %13 to i64
  br label %for.body29

for.body29:                                       ; preds = %for.end, %for.body29.lr.ph
  %indvars.iv756 = phi i64 [ %14, %for.body29.lr.ph ], [ %indvars.iv.next757, %for.end ]
  %indvars.iv754 = phi i64 [ %12, %for.body29.lr.ph ], [ %indvars.iv.next755, %for.end ]
  %s.0731 = phi i32 [ 0, %for.body29.lr.ph ], [ %inc200, %for.end ]
  %vnbtot.0730 = phi float [ 0.000000e+00, %for.body29.lr.ph ], [ %vnbtot.1.lcssa, %for.end ]
  %arrayidx31 = getelementptr inbounds float* %pos, i64 %indvars.iv756
  %15 = load float* %arrayidx31, align 4, !tbaa !3
  %add32 = fadd float %5, %15
  %16 = add nsw i64 %indvars.iv756, 1
  %arrayidx35 = getelementptr inbounds float* %pos, i64 %16
  %17 = load float* %arrayidx35, align 4, !tbaa !3
  %add36 = fadd float %6, %17
  %18 = add nsw i64 %indvars.iv756, 2
  %arrayidx39 = getelementptr inbounds float* %pos, i64 %18
  %19 = load float* %arrayidx39, align 4, !tbaa !3
  %add40 = fadd float %7, %19
  %arrayidx43 = getelementptr inbounds i32* %type, i64 %indvars.iv754
  %20 = load i32* %arrayidx43, align 4, !tbaa !0
  %mul44 = mul nsw i32 %mul220, %20
  br i1 %cmp46720, label %for.body47, label %for.end

for.body47:                                       ; preds = %for.body29, %for.body47
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body47 ], [ %11, %for.body29 ]
  %fiz1.0724 = phi float [ %add139, %for.body47 ], [ 0.000000e+00, %for.body29 ]
  %fiy1.0723 = phi float [ %add138, %for.body47 ], [ 0.000000e+00, %for.body29 ]
  %fix1.0722 = phi float [ %add137, %for.body47 ], [ 0.000000e+00, %for.body29 ]
  %vnbtot.1721 = phi float [ %add129, %for.body47 ], [ %vnbtot.0730, %for.body29 ]
  %arrayidx49 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %21 = load i32* %arrayidx49, align 4, !tbaa !0
  %mul50 = mul nsw i32 %21, 3
  %idxprom51 = sext i32 %mul50 to i64
  %arrayidx52 = getelementptr inbounds float* %pos, i64 %idxprom51
  %22 = load float* %arrayidx52, align 4, !tbaa !3
  %add53 = add nsw i32 %mul50, 1
  %idxprom54 = sext i32 %add53 to i64
  %arrayidx55 = getelementptr inbounds float* %pos, i64 %idxprom54
  %23 = load float* %arrayidx55, align 4, !tbaa !3
  %add56 = add nsw i32 %mul50, 2
  %idxprom57 = sext i32 %add56 to i64
  %arrayidx58 = getelementptr inbounds float* %pos, i64 %idxprom57
  %24 = load float* %arrayidx58, align 4, !tbaa !3
  %sub = fsub float %add32, %22
  %sub59 = fsub float %add36, %23
  %sub60 = fsub float %add40, %24
  %mul61 = fmul float %sub, %sub
  %mul62 = fmul float %sub59, %sub59
  %add63 = fadd float %mul61, %mul62
  %mul64 = fmul float %sub60, %sub60
  %add65 = fadd float %add63, %mul64
  %conv = fpext float %add65 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv66 = fptrunc double %div to float
  %mul67 = fmul float %add65, %conv66
  %mul68 = fmul float %mul67, %tabscale
  %conv69 = fptosi float %mul68 to i32
  %conv70 = sitofp i32 %conv69 to float
  %sub71 = fsub float %mul68, %conv70
  %mul72 = fmul float %sub71, %sub71
  %mul73 = shl nsw i32 %conv69, 3
  %idxprom74 = sext i32 %21 to i64
  %arrayidx75 = getelementptr inbounds i32* %type, i64 %idxprom74
  %25 = load i32* %arrayidx75, align 4, !tbaa !0
  %mul76 = shl nsw i32 %25, 1
  %add77 = add nsw i32 %mul76, %mul44
  %idxprom78 = sext i32 %add77 to i64
  %arrayidx79 = getelementptr inbounds float* %nbfp, i64 %idxprom78
  %26 = load float* %arrayidx79, align 4, !tbaa !3
  %add80712 = or i32 %add77, 1
  %idxprom81 = sext i32 %add80712 to i64
  %arrayidx82 = getelementptr inbounds float* %nbfp, i64 %idxprom81
  %27 = load float* %arrayidx82, align 4, !tbaa !3
  %idxprom83 = sext i32 %mul73 to i64
  %arrayidx84 = getelementptr inbounds float* %VFtab, i64 %idxprom83
  %28 = load float* %arrayidx84, align 4, !tbaa !3
  %add85713 = or i32 %mul73, 1
  %idxprom86 = sext i32 %add85713 to i64
  %arrayidx87 = getelementptr inbounds float* %VFtab, i64 %idxprom86
  %29 = load float* %arrayidx87, align 4, !tbaa !3
  %add88714 = or i32 %mul73, 2
  %idxprom89 = sext i32 %add88714 to i64
  %arrayidx90 = getelementptr inbounds float* %VFtab, i64 %idxprom89
  %30 = load float* %arrayidx90, align 4, !tbaa !3
  %mul91 = fmul float %sub71, %30
  %add92715 = or i32 %mul73, 3
  %idxprom93 = sext i32 %add92715 to i64
  %arrayidx94 = getelementptr inbounds float* %VFtab, i64 %idxprom93
  %31 = load float* %arrayidx94, align 4, !tbaa !3
  %mul95 = fmul float %mul72, %31
  %add96 = fadd float %29, %mul91
  %add97 = fadd float %add96, %mul95
  %mul98 = fmul float %sub71, %add97
  %add99 = fadd float %28, %mul98
  %add100 = fadd float %mul91, %add97
  %mul101 = fmul float %mul95, 2.000000e+00
  %add102 = fadd float %mul101, %add100
  %mul103 = fmul float %26, %add99
  %mul104 = fmul float %26, %add102
  %add105716 = or i32 %mul73, 4
  %idxprom106 = sext i32 %add105716 to i64
  %arrayidx107 = getelementptr inbounds float* %VFtab, i64 %idxprom106
  %32 = load float* %arrayidx107, align 4, !tbaa !3
  %add108717 = or i32 %mul73, 5
  %idxprom109 = sext i32 %add108717 to i64
  %arrayidx110 = getelementptr inbounds float* %VFtab, i64 %idxprom109
  %33 = load float* %arrayidx110, align 4, !tbaa !3
  %add111718 = or i32 %mul73, 6
  %idxprom112 = sext i32 %add111718 to i64
  %arrayidx113 = getelementptr inbounds float* %VFtab, i64 %idxprom112
  %34 = load float* %arrayidx113, align 4, !tbaa !3
  %mul114 = fmul float %sub71, %34
  %add115719 = or i32 %mul73, 7
  %idxprom116 = sext i32 %add115719 to i64
  %arrayidx117 = getelementptr inbounds float* %VFtab, i64 %idxprom116
  %35 = load float* %arrayidx117, align 4, !tbaa !3
  %mul118 = fmul float %mul72, %35
  %add119 = fadd float %33, %mul114
  %add120 = fadd float %add119, %mul118
  %mul121 = fmul float %sub71, %add120
  %add122 = fadd float %32, %mul121
  %add123 = fadd float %mul114, %add120
  %mul124 = fmul float %mul118, 2.000000e+00
  %add125 = fadd float %mul124, %add123
  %mul126 = fmul float %27, %add122
  %mul127 = fmul float %27, %add125
  %add128 = fadd float %vnbtot.1721, %mul103
  %add129 = fadd float %add128, %mul126
  %add130 = fadd float %mul104, %mul127
  %mul131 = fmul float %add130, %tabscale
  %36 = fmul float %conv66, %mul131
  %mul133 = fsub float -0.000000e+00, %36
  %mul134 = fmul float %sub, %mul133
  %mul135 = fmul float %sub59, %mul133
  %mul136 = fmul float %sub60, %mul133
  %add137 = fadd float %fix1.0722, %mul134
  %add138 = fadd float %fiy1.0723, %mul135
  %add139 = fadd float %fiz1.0724, %mul136
  %arrayidx141 = getelementptr inbounds float* %faction, i64 %idxprom51
  %37 = load float* %arrayidx141, align 4, !tbaa !3
  %sub142 = fsub float %37, %mul134
  store float %sub142, float* %arrayidx141, align 4, !tbaa !3
  %arrayidx147 = getelementptr inbounds float* %faction, i64 %idxprom54
  %38 = load float* %arrayidx147, align 4, !tbaa !3
  %sub148 = fsub float %38, %mul135
  store float %sub148, float* %arrayidx147, align 4, !tbaa !3
  %arrayidx154 = getelementptr inbounds float* %faction, i64 %idxprom57
  %39 = load float* %arrayidx154, align 4, !tbaa !3
  %sub155 = fsub float %39, %mul136
  store float %sub155, float* %arrayidx154, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %40 = trunc i64 %indvars.iv.next to i32
  %cmp46 = icmp slt i32 %40, %10
  br i1 %cmp46, label %for.body47, label %for.end

for.end:                                          ; preds = %for.body47, %for.body29
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add139, %for.body47 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add138, %for.body47 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add137, %for.body47 ]
  %vnbtot.1.lcssa = phi float [ %vnbtot.0730, %for.body29 ], [ %add129, %for.body47 ]
  %arrayidx160 = getelementptr inbounds float* %faction, i64 %indvars.iv756
  %41 = load float* %arrayidx160, align 4, !tbaa !3
  %add161 = fadd float %fix1.0.lcssa, %41
  store float %add161, float* %arrayidx160, align 4, !tbaa !3
  %arrayidx166 = getelementptr inbounds float* %faction, i64 %16
  %42 = load float* %arrayidx166, align 4, !tbaa !3
  %add167 = fadd float %fiy1.0.lcssa, %42
  store float %add167, float* %arrayidx166, align 4, !tbaa !3
  %arrayidx173 = getelementptr inbounds float* %faction, i64 %18
  %43 = load float* %arrayidx173, align 4, !tbaa !3
  %add174 = fadd float %fiz1.0.lcssa, %43
  store float %add174, float* %arrayidx173, align 4, !tbaa !3
  %44 = load float* %arrayidx179, align 4, !tbaa !3
  %add180 = fadd float %fix1.0.lcssa, %44
  store float %add180, float* %arrayidx179, align 4, !tbaa !3
  %45 = load float* %arrayidx185, align 4, !tbaa !3
  %add186 = fadd float %fiy1.0.lcssa, %45
  store float %add186, float* %arrayidx185, align 4, !tbaa !3
  %46 = load float* %arrayidx192, align 4, !tbaa !3
  %add193 = fadd float %fiz1.0.lcssa, %46
  store float %add193, float* %arrayidx192, align 4, !tbaa !3
  %indvars.iv.next755 = add i64 %indvars.iv754, 1
  %indvars.iv.next757 = add i64 %indvars.iv756, 3
  %inc200 = add nsw i32 %s.0731, 1
  %exitcond = icmp eq i32 %inc200, %2
  br i1 %exitcond, label %for.cond27.for.end201_crit_edge, label %for.body29

for.cond27.for.end201_crit_edge:                  ; preds = %for.end
  %47 = add i32 %2, %8
  br label %for.end201

for.end201:                                       ; preds = %for.cond27.for.end201_crit_edge, %for.body
  %ii.0.lcssa = phi i32 [ %47, %for.cond27.for.end201_crit_edge ], [ %8, %for.body ]
  %vnbtot.0.lcssa = phi float [ %vnbtot.1.lcssa, %for.cond27.for.end201_crit_edge ], [ 0.000000e+00, %for.body ]
  %cmp206746 = icmp slt i32 %3, %1
  br i1 %cmp206746, label %for.body208.lr.ph, label %for.end388

for.body208.lr.ph:                                ; preds = %for.end201
  %cmp225736 = icmp slt i32 %9, %10
  %arrayidx366 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx372 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx379 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %48 = sext i32 %9 to i64
  %49 = add i32 %ii.0.lcssa, %3
  %50 = sub i32 %49, %2
  %51 = sext i32 %50 to i64
  %52 = mul i32 %50, 3
  %53 = sext i32 %52 to i64
  br label %for.body208

for.body208:                                      ; preds = %for.end345, %for.body208.lr.ph
  %indvars.iv764 = phi i64 [ %53, %for.body208.lr.ph ], [ %indvars.iv.next765, %for.end345 ]
  %indvars.iv762 = phi i64 [ %51, %for.body208.lr.ph ], [ %indvars.iv.next763, %for.end345 ]
  %s.1748 = phi i32 [ %3, %for.body208.lr.ph ], [ %inc387, %for.end345 ]
  %vnbtot.2747 = phi float [ %vnbtot.0.lcssa, %for.body208.lr.ph ], [ %vnbtot.3.lcssa, %for.end345 ]
  %arrayidx210 = getelementptr inbounds float* %pos, i64 %indvars.iv764
  %54 = load float* %arrayidx210, align 4, !tbaa !3
  %add211 = fadd float %5, %54
  %55 = add nsw i64 %indvars.iv764, 1
  %arrayidx214 = getelementptr inbounds float* %pos, i64 %55
  %56 = load float* %arrayidx214, align 4, !tbaa !3
  %add215 = fadd float %6, %56
  %57 = add nsw i64 %indvars.iv764, 2
  %arrayidx218 = getelementptr inbounds float* %pos, i64 %57
  %58 = load float* %arrayidx218, align 4, !tbaa !3
  %add219 = fadd float %7, %58
  %arrayidx222 = getelementptr inbounds i32* %type, i64 %indvars.iv762
  %59 = load i32* %arrayidx222, align 4, !tbaa !0
  %mul223 = mul nsw i32 %mul220, %59
  br i1 %cmp225736, label %for.body227, label %for.end345

for.body227:                                      ; preds = %for.body208, %for.body227
  %indvars.iv760 = phi i64 [ %indvars.iv.next761, %for.body227 ], [ %48, %for.body208 ]
  %fiz1.1740 = phi float [ %add323, %for.body227 ], [ 0.000000e+00, %for.body208 ]
  %fiy1.1739 = phi float [ %add322, %for.body227 ], [ 0.000000e+00, %for.body208 ]
  %fix1.1738 = phi float [ %add321, %for.body227 ], [ 0.000000e+00, %for.body208 ]
  %vnbtot.3737 = phi float [ %add313, %for.body227 ], [ %vnbtot.2747, %for.body208 ]
  %arrayidx229 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv760
  %60 = load i32* %arrayidx229, align 4, !tbaa !0
  %mul230 = mul nsw i32 %60, 3
  %idxprom231 = sext i32 %mul230 to i64
  %arrayidx232 = getelementptr inbounds float* %pos, i64 %idxprom231
  %61 = load float* %arrayidx232, align 4, !tbaa !3
  %add233 = add nsw i32 %mul230, 1
  %idxprom234 = sext i32 %add233 to i64
  %arrayidx235 = getelementptr inbounds float* %pos, i64 %idxprom234
  %62 = load float* %arrayidx235, align 4, !tbaa !3
  %add236 = add nsw i32 %mul230, 2
  %idxprom237 = sext i32 %add236 to i64
  %arrayidx238 = getelementptr inbounds float* %pos, i64 %idxprom237
  %63 = load float* %arrayidx238, align 4, !tbaa !3
  %sub239 = fsub float %add211, %61
  %sub240 = fsub float %add215, %62
  %sub241 = fsub float %add219, %63
  %mul242 = fmul float %sub239, %sub239
  %mul243 = fmul float %sub240, %sub240
  %add244 = fadd float %mul242, %mul243
  %mul245 = fmul float %sub241, %sub241
  %add246 = fadd float %add244, %mul245
  %conv247 = fpext float %add246 to double
  %call248 = tail call double @sqrt(double %conv247) #2
  %div249 = fdiv double 1.000000e+00, %call248
  %conv250 = fptrunc double %div249 to float
  %mul251 = fmul float %add246, %conv250
  %mul252 = fmul float %mul251, %tabscale
  %conv253 = fptosi float %mul252 to i32
  %conv254 = sitofp i32 %conv253 to float
  %sub255 = fsub float %mul252, %conv254
  %mul256 = fmul float %sub255, %sub255
  %mul257 = shl nsw i32 %conv253, 3
  %idxprom258 = sext i32 %60 to i64
  %arrayidx259 = getelementptr inbounds i32* %type, i64 %idxprom258
  %64 = load i32* %arrayidx259, align 4, !tbaa !0
  %mul260 = shl nsw i32 %64, 1
  %add261 = add nsw i32 %mul260, %mul223
  %idxprom262 = sext i32 %add261 to i64
  %arrayidx263 = getelementptr inbounds float* %nbfp, i64 %idxprom262
  %65 = load float* %arrayidx263, align 4, !tbaa !3
  %add264704 = or i32 %add261, 1
  %idxprom265 = sext i32 %add264704 to i64
  %arrayidx266 = getelementptr inbounds float* %nbfp, i64 %idxprom265
  %66 = load float* %arrayidx266, align 4, !tbaa !3
  %idxprom267 = sext i32 %mul257 to i64
  %arrayidx268 = getelementptr inbounds float* %VFtab, i64 %idxprom267
  %67 = load float* %arrayidx268, align 4, !tbaa !3
  %add269705 = or i32 %mul257, 1
  %idxprom270 = sext i32 %add269705 to i64
  %arrayidx271 = getelementptr inbounds float* %VFtab, i64 %idxprom270
  %68 = load float* %arrayidx271, align 4, !tbaa !3
  %add272706 = or i32 %mul257, 2
  %idxprom273 = sext i32 %add272706 to i64
  %arrayidx274 = getelementptr inbounds float* %VFtab, i64 %idxprom273
  %69 = load float* %arrayidx274, align 4, !tbaa !3
  %mul275 = fmul float %sub255, %69
  %add276707 = or i32 %mul257, 3
  %idxprom277 = sext i32 %add276707 to i64
  %arrayidx278 = getelementptr inbounds float* %VFtab, i64 %idxprom277
  %70 = load float* %arrayidx278, align 4, !tbaa !3
  %mul279 = fmul float %mul256, %70
  %add280 = fadd float %68, %mul275
  %add281 = fadd float %add280, %mul279
  %mul282 = fmul float %sub255, %add281
  %add283 = fadd float %67, %mul282
  %add284 = fadd float %mul275, %add281
  %mul285 = fmul float %mul279, 2.000000e+00
  %add286 = fadd float %mul285, %add284
  %mul287 = fmul float %65, %add283
  %mul288 = fmul float %65, %add286
  %add289708 = or i32 %mul257, 4
  %idxprom290 = sext i32 %add289708 to i64
  %arrayidx291 = getelementptr inbounds float* %VFtab, i64 %idxprom290
  %71 = load float* %arrayidx291, align 4, !tbaa !3
  %add292709 = or i32 %mul257, 5
  %idxprom293 = sext i32 %add292709 to i64
  %arrayidx294 = getelementptr inbounds float* %VFtab, i64 %idxprom293
  %72 = load float* %arrayidx294, align 4, !tbaa !3
  %add295710 = or i32 %mul257, 6
  %idxprom296 = sext i32 %add295710 to i64
  %arrayidx297 = getelementptr inbounds float* %VFtab, i64 %idxprom296
  %73 = load float* %arrayidx297, align 4, !tbaa !3
  %mul298 = fmul float %sub255, %73
  %add299711 = or i32 %mul257, 7
  %idxprom300 = sext i32 %add299711 to i64
  %arrayidx301 = getelementptr inbounds float* %VFtab, i64 %idxprom300
  %74 = load float* %arrayidx301, align 4, !tbaa !3
  %mul302 = fmul float %mul256, %74
  %add303 = fadd float %72, %mul298
  %add304 = fadd float %add303, %mul302
  %mul305 = fmul float %sub255, %add304
  %add306 = fadd float %71, %mul305
  %add307 = fadd float %mul298, %add304
  %mul308 = fmul float %mul302, 2.000000e+00
  %add309 = fadd float %mul308, %add307
  %mul310 = fmul float %66, %add306
  %mul311 = fmul float %66, %add309
  %add312 = fadd float %vnbtot.3737, %mul287
  %add313 = fadd float %add312, %mul310
  %add314 = fadd float %mul288, %mul311
  %mul315 = fmul float %add314, %tabscale
  %75 = fmul float %conv250, %mul315
  %mul317 = fsub float -0.000000e+00, %75
  %mul318 = fmul float %sub239, %mul317
  %mul319 = fmul float %sub240, %mul317
  %mul320 = fmul float %sub241, %mul317
  %add321 = fadd float %fix1.1738, %mul318
  %add322 = fadd float %fiy1.1739, %mul319
  %add323 = fadd float %fiz1.1740, %mul320
  %arrayidx325 = getelementptr inbounds float* %faction, i64 %idxprom231
  %76 = load float* %arrayidx325, align 4, !tbaa !3
  %sub326 = fsub float %76, %mul318
  store float %sub326, float* %arrayidx325, align 4, !tbaa !3
  %arrayidx331 = getelementptr inbounds float* %faction, i64 %idxprom234
  %77 = load float* %arrayidx331, align 4, !tbaa !3
  %sub332 = fsub float %77, %mul319
  store float %sub332, float* %arrayidx331, align 4, !tbaa !3
  %arrayidx338 = getelementptr inbounds float* %faction, i64 %idxprom237
  %78 = load float* %arrayidx338, align 4, !tbaa !3
  %sub339 = fsub float %78, %mul320
  store float %sub339, float* %arrayidx338, align 4, !tbaa !3
  %indvars.iv.next761 = add i64 %indvars.iv760, 1
  %79 = trunc i64 %indvars.iv.next761 to i32
  %cmp225 = icmp slt i32 %79, %10
  br i1 %cmp225, label %for.body227, label %for.end345

for.end345:                                       ; preds = %for.body227, %for.body208
  %fiz1.1.lcssa = phi float [ 0.000000e+00, %for.body208 ], [ %add323, %for.body227 ]
  %fiy1.1.lcssa = phi float [ 0.000000e+00, %for.body208 ], [ %add322, %for.body227 ]
  %fix1.1.lcssa = phi float [ 0.000000e+00, %for.body208 ], [ %add321, %for.body227 ]
  %vnbtot.3.lcssa = phi float [ %vnbtot.2747, %for.body208 ], [ %add313, %for.body227 ]
  %arrayidx347 = getelementptr inbounds float* %faction, i64 %indvars.iv764
  %80 = load float* %arrayidx347, align 4, !tbaa !3
  %add348 = fadd float %fix1.1.lcssa, %80
  store float %add348, float* %arrayidx347, align 4, !tbaa !3
  %arrayidx353 = getelementptr inbounds float* %faction, i64 %55
  %81 = load float* %arrayidx353, align 4, !tbaa !3
  %add354 = fadd float %fiy1.1.lcssa, %81
  store float %add354, float* %arrayidx353, align 4, !tbaa !3
  %arrayidx360 = getelementptr inbounds float* %faction, i64 %57
  %82 = load float* %arrayidx360, align 4, !tbaa !3
  %add361 = fadd float %fiz1.1.lcssa, %82
  store float %add361, float* %arrayidx360, align 4, !tbaa !3
  %83 = load float* %arrayidx366, align 4, !tbaa !3
  %add367 = fadd float %fix1.1.lcssa, %83
  store float %add367, float* %arrayidx366, align 4, !tbaa !3
  %84 = load float* %arrayidx372, align 4, !tbaa !3
  %add373 = fadd float %fiy1.1.lcssa, %84
  store float %add373, float* %arrayidx372, align 4, !tbaa !3
  %85 = load float* %arrayidx379, align 4, !tbaa !3
  %add380 = fadd float %fiz1.1.lcssa, %85
  store float %add380, float* %arrayidx379, align 4, !tbaa !3
  %indvars.iv.next763 = add i64 %indvars.iv762, 1
  %indvars.iv.next765 = add i64 %indvars.iv764, 3
  %inc387 = add nsw i32 %s.1748, 1
  %exitcond768 = icmp eq i32 %inc387, %1
  br i1 %exitcond768, label %for.end388, label %for.body208

for.end388:                                       ; preds = %for.end345, %for.end201
  %vnbtot.2.lcssa = phi float [ %vnbtot.0.lcssa, %for.end201 ], [ %vnbtot.3.lcssa, %for.end345 ]
  %arrayidx390 = getelementptr inbounds i32* %gid, i64 %indvars.iv769
  %86 = load i32* %arrayidx390, align 4, !tbaa !0
  %idxprom391 = sext i32 %86 to i64
  %arrayidx392 = getelementptr inbounds float* %Vnb, i64 %idxprom391
  %87 = load float* %arrayidx392, align 4, !tbaa !3
  %add393 = fadd float %vnbtot.2.lcssa, %87
  store float %add393, float* %arrayidx392, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next770 to i32
  %exitcond771 = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond771, label %for.end398, label %for.body

for.end398:                                       ; preds = %for.end388, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl0400(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab, float %exptabscale) #0 {
entry:
  %cmp355 = icmp sgt i32 %nri, 0
  br i1 %cmp355, label %for.body, label %for.end204

for.body:                                         ; preds = %for.end, %entry
  %indvars.iv357 = phi i64 [ 0, %entry ], [ %indvars.iv.next358, %for.end ]
  %arrayidx = getelementptr inbounds i32* %shift, i64 %indvars.iv357
  %0 = load i32* %arrayidx, align 4, !tbaa !0
  %mul = mul nsw i32 %0, 3
  %idxprom1 = sext i32 %mul to i64
  %arrayidx2 = getelementptr inbounds float* %shiftvec, i64 %idxprom1
  %1 = load float* %arrayidx2, align 4, !tbaa !3
  %add = add nsw i32 %mul, 1
  %idxprom3 = sext i32 %add to i64
  %arrayidx4 = getelementptr inbounds float* %shiftvec, i64 %idxprom3
  %2 = load float* %arrayidx4, align 4, !tbaa !3
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds float* %shiftvec, i64 %idxprom6
  %3 = load float* %arrayidx7, align 4, !tbaa !3
  %arrayidx9 = getelementptr inbounds i32* %iinr, i64 %indvars.iv357
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %arrayidx12 = getelementptr inbounds i32* %jindex, i64 %indvars.iv357
  %5 = load i32* %arrayidx12, align 4, !tbaa !0
  %indvars.iv.next358 = add i64 %indvars.iv357, 1
  %arrayidx15 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next358
  %6 = load i32* %arrayidx15, align 4, !tbaa !0
  %idxprom16 = sext i32 %mul10 to i64
  %arrayidx17 = getelementptr inbounds float* %pos, i64 %idxprom16
  %7 = load float* %arrayidx17, align 4, !tbaa !3
  %add18 = fadd float %1, %7
  %add19 = add nsw i32 %mul10, 1
  %idxprom20 = sext i32 %add19 to i64
  %arrayidx21 = getelementptr inbounds float* %pos, i64 %idxprom20
  %8 = load float* %arrayidx21, align 4, !tbaa !3
  %add22 = fadd float %2, %8
  %add23 = add nsw i32 %mul10, 2
  %idxprom24 = sext i32 %add23 to i64
  %arrayidx25 = getelementptr inbounds float* %pos, i64 %idxprom24
  %9 = load float* %arrayidx25, align 4, !tbaa !3
  %add26 = fadd float %3, %9
  %idxprom28 = sext i32 %4 to i64
  %arrayidx29 = getelementptr inbounds i32* %type, i64 %idxprom28
  %10 = load i32* %arrayidx29, align 4, !tbaa !0
  %mul30 = mul i32 %10, %ntype
  %cmp32346 = icmp slt i32 %5, %6
  br i1 %cmp32346, label %for.body33.lr.ph, label %for.end

for.body33.lr.ph:                                 ; preds = %for.body
  %11 = sext i32 %5 to i64
  br label %for.body33

for.body33:                                       ; preds = %for.body33.lr.ph, %for.body33
  %indvars.iv = phi i64 [ %11, %for.body33.lr.ph ], [ %indvars.iv.next, %for.body33 ]
  %vnbtot.0350 = phi float [ 0.000000e+00, %for.body33.lr.ph ], [ %add126, %for.body33 ]
  %fix1.0349 = phi float [ 0.000000e+00, %for.body33.lr.ph ], [ %add135, %for.body33 ]
  %fiy1.0348 = phi float [ 0.000000e+00, %for.body33.lr.ph ], [ %add136, %for.body33 ]
  %fiz1.0347 = phi float [ 0.000000e+00, %for.body33.lr.ph ], [ %add137, %for.body33 ]
  %arrayidx35 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %12 = load i32* %arrayidx35, align 4, !tbaa !0
  %mul36 = mul nsw i32 %12, 3
  %idxprom37 = sext i32 %mul36 to i64
  %arrayidx38 = getelementptr inbounds float* %pos, i64 %idxprom37
  %13 = load float* %arrayidx38, align 4, !tbaa !3
  %add39 = add nsw i32 %mul36, 1
  %idxprom40 = sext i32 %add39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %14 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = add nsw i32 %mul36, 2
  %idxprom43 = sext i32 %add42 to i64
  %arrayidx44 = getelementptr inbounds float* %pos, i64 %idxprom43
  %15 = load float* %arrayidx44, align 4, !tbaa !3
  %sub = fsub float %add18, %13
  %sub45 = fsub float %add22, %14
  %sub46 = fsub float %add26, %15
  %mul47 = fmul float %sub, %sub
  %mul48 = fmul float %sub45, %sub45
  %add49 = fadd float %mul47, %mul48
  %mul50 = fmul float %sub46, %sub46
  %add51 = fadd float %add49, %mul50
  %conv = fpext float %add51 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv52 = fptrunc double %div to float
  %mul53 = fmul float %add51, %conv52
  %mul54 = fmul float %mul53, %tabscale
  %conv55 = fptosi float %mul54 to i32
  %conv56 = sitofp i32 %conv55 to float
  %sub57 = fsub float %mul54, %conv56
  %mul58 = fmul float %sub57, %sub57
  %mul59 = shl nsw i32 %conv55, 3
  %idxprom60 = sext i32 %12 to i64
  %arrayidx61 = getelementptr inbounds i32* %type, i64 %idxprom60
  %16 = load i32* %arrayidx61, align 4, !tbaa !0
  %tmp = add i32 %16, %mul30
  %tmp345 = mul i32 %tmp, 3
  %idxprom64 = sext i32 %tmp345 to i64
  %arrayidx65 = getelementptr inbounds float* %nbfp, i64 %idxprom64
  %17 = load float* %arrayidx65, align 4, !tbaa !3
  %add66 = add nsw i32 %tmp345, 1
  %idxprom67 = sext i32 %add66 to i64
  %arrayidx68 = getelementptr inbounds float* %nbfp, i64 %idxprom67
  %18 = load float* %arrayidx68, align 4, !tbaa !3
  %add69 = add nsw i32 %tmp345, 2
  %idxprom70 = sext i32 %add69 to i64
  %arrayidx71 = getelementptr inbounds float* %nbfp, i64 %idxprom70
  %19 = load float* %arrayidx71, align 4, !tbaa !3
  %idxprom72 = sext i32 %mul59 to i64
  %arrayidx73 = getelementptr inbounds float* %VFtab, i64 %idxprom72
  %20 = load float* %arrayidx73, align 4, !tbaa !3
  %add74338 = or i32 %mul59, 1
  %idxprom75 = sext i32 %add74338 to i64
  %arrayidx76 = getelementptr inbounds float* %VFtab, i64 %idxprom75
  %21 = load float* %arrayidx76, align 4, !tbaa !3
  %add77339 = or i32 %mul59, 2
  %idxprom78 = sext i32 %add77339 to i64
  %arrayidx79 = getelementptr inbounds float* %VFtab, i64 %idxprom78
  %22 = load float* %arrayidx79, align 4, !tbaa !3
  %mul80 = fmul float %sub57, %22
  %add81340 = or i32 %mul59, 3
  %idxprom82 = sext i32 %add81340 to i64
  %arrayidx83 = getelementptr inbounds float* %VFtab, i64 %idxprom82
  %23 = load float* %arrayidx83, align 4, !tbaa !3
  %mul84 = fmul float %mul58, %23
  %add85 = fadd float %21, %mul80
  %add86 = fadd float %add85, %mul84
  %mul87 = fmul float %sub57, %add86
  %add88 = fadd float %20, %mul87
  %add89 = fadd float %mul80, %add86
  %mul90 = fmul float %mul84, 2.000000e+00
  %add91 = fadd float %mul90, %add89
  %mul92 = fmul float %17, %add88
  %mul93 = fmul float %17, %add91
  %mul94 = fmul float %mul53, %19
  %mul95 = fmul float %mul94, %exptabscale
  %conv96 = fptosi float %mul95 to i32
  %conv97 = sitofp i32 %conv96 to float
  %sub98 = fsub float %mul95, %conv97
  %mul99 = fmul float %sub98, %sub98
  %mul100 = shl nsw i32 %conv96, 3
  %add101341 = or i32 %mul100, 4
  %idxprom102 = sext i32 %add101341 to i64
  %arrayidx103 = getelementptr inbounds float* %VFtab, i64 %idxprom102
  %24 = load float* %arrayidx103, align 4, !tbaa !3
  %add104342 = or i32 %mul100, 5
  %idxprom105 = sext i32 %add104342 to i64
  %arrayidx106 = getelementptr inbounds float* %VFtab, i64 %idxprom105
  %25 = load float* %arrayidx106, align 4, !tbaa !3
  %add107343 = or i32 %mul100, 6
  %idxprom108 = sext i32 %add107343 to i64
  %arrayidx109 = getelementptr inbounds float* %VFtab, i64 %idxprom108
  %26 = load float* %arrayidx109, align 4, !tbaa !3
  %mul110 = fmul float %sub98, %26
  %add111344 = or i32 %mul100, 7
  %idxprom112 = sext i32 %add111344 to i64
  %arrayidx113 = getelementptr inbounds float* %VFtab, i64 %idxprom112
  %27 = load float* %arrayidx113, align 4, !tbaa !3
  %mul114 = fmul float %mul99, %27
  %add115 = fadd float %25, %mul110
  %add116 = fadd float %add115, %mul114
  %mul117 = fmul float %sub98, %add116
  %add118 = fadd float %24, %mul117
  %add119 = fadd float %mul110, %add116
  %mul120 = fmul float %mul114, 2.000000e+00
  %add121 = fadd float %mul120, %add119
  %mul122 = fmul float %18, %add118
  %mul123 = fmul float %18, %19
  %mul124 = fmul float %mul123, %add121
  %add125 = fadd float %vnbtot.0350, %mul92
  %add126 = fadd float %add125, %mul122
  %mul127 = fmul float %mul93, %tabscale
  %mul128 = fmul float %mul124, %exptabscale
  %add129 = fadd float %mul127, %mul128
  %28 = fmul float %conv52, %add129
  %mul131 = fsub float -0.000000e+00, %28
  %mul132 = fmul float %sub, %mul131
  %mul133 = fmul float %sub45, %mul131
  %mul134 = fmul float %sub46, %mul131
  %add135 = fadd float %fix1.0349, %mul132
  %add136 = fadd float %fiy1.0348, %mul133
  %add137 = fadd float %fiz1.0347, %mul134
  %arrayidx139 = getelementptr inbounds float* %faction, i64 %idxprom37
  %29 = load float* %arrayidx139, align 4, !tbaa !3
  %sub140 = fsub float %29, %mul132
  store float %sub140, float* %arrayidx139, align 4, !tbaa !3
  %arrayidx145 = getelementptr inbounds float* %faction, i64 %idxprom40
  %30 = load float* %arrayidx145, align 4, !tbaa !3
  %sub146 = fsub float %30, %mul133
  store float %sub146, float* %arrayidx145, align 4, !tbaa !3
  %arrayidx152 = getelementptr inbounds float* %faction, i64 %idxprom43
  %31 = load float* %arrayidx152, align 4, !tbaa !3
  %sub153 = fsub float %31, %mul134
  store float %sub153, float* %arrayidx152, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %32 = trunc i64 %indvars.iv.next to i32
  %cmp32 = icmp slt i32 %32, %6
  br i1 %cmp32, label %for.body33, label %for.end

for.end:                                          ; preds = %for.body33, %for.body
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add126, %for.body33 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add135, %for.body33 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add136, %for.body33 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add137, %for.body33 ]
  %arrayidx158 = getelementptr inbounds float* %faction, i64 %idxprom16
  %33 = load float* %arrayidx158, align 4, !tbaa !3
  %add159 = fadd float %fix1.0.lcssa, %33
  store float %add159, float* %arrayidx158, align 4, !tbaa !3
  %arrayidx164 = getelementptr inbounds float* %faction, i64 %idxprom20
  %34 = load float* %arrayidx164, align 4, !tbaa !3
  %add165 = fadd float %fiy1.0.lcssa, %34
  store float %add165, float* %arrayidx164, align 4, !tbaa !3
  %arrayidx171 = getelementptr inbounds float* %faction, i64 %idxprom24
  %35 = load float* %arrayidx171, align 4, !tbaa !3
  %add172 = fadd float %fiz1.0.lcssa, %35
  store float %add172, float* %arrayidx171, align 4, !tbaa !3
  %arrayidx177 = getelementptr inbounds float* %fshift, i64 %idxprom1
  %36 = load float* %arrayidx177, align 4, !tbaa !3
  %add178 = fadd float %fix1.0.lcssa, %36
  store float %add178, float* %arrayidx177, align 4, !tbaa !3
  %arrayidx183 = getelementptr inbounds float* %fshift, i64 %idxprom3
  %37 = load float* %arrayidx183, align 4, !tbaa !3
  %add184 = fadd float %fiy1.0.lcssa, %37
  store float %add184, float* %arrayidx183, align 4, !tbaa !3
  %arrayidx190 = getelementptr inbounds float* %fshift, i64 %idxprom6
  %38 = load float* %arrayidx190, align 4, !tbaa !3
  %add191 = fadd float %fiz1.0.lcssa, %38
  store float %add191, float* %arrayidx190, align 4, !tbaa !3
  %arrayidx196 = getelementptr inbounds i32* %gid, i64 %indvars.iv357
  %39 = load i32* %arrayidx196, align 4, !tbaa !0
  %idxprom197 = sext i32 %39 to i64
  %arrayidx198 = getelementptr inbounds float* %Vnb, i64 %idxprom197
  %40 = load float* %arrayidx198, align 4, !tbaa !3
  %add199 = fadd float %vnbtot.0.lcssa, %40
  store float %add199, float* %arrayidx198, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next358 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end204, label %for.body

for.end204:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl0401(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab, float %exptabscale, float %lambda, float* nocapture %dvdlambda, i32* nocapture %typeB) #0 {
entry:
  %sub = fsub float 1.000000e+00, %lambda
  %cmp477 = icmp sgt i32 %nri, 0
  br i1 %cmp477, label %for.body.lr.ph, label %for.end266

for.body.lr.ph:                                   ; preds = %entry
  %mul27 = mul nsw i32 %ntype, 3
  br label %for.body

for.body:                                         ; preds = %for.end, %for.body.lr.ph
  %indvars.iv481 = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next482, %for.end ]
  %dvdl.0478 = phi float [ 0.000000e+00, %for.body.lr.ph ], [ %dvdl.1.lcssa, %for.end ]
  %arrayidx = getelementptr inbounds i32* %shift, i64 %indvars.iv481
  %0 = load i32* %arrayidx, align 4, !tbaa !0
  %mul = mul nsw i32 %0, 3
  %idxprom1 = sext i32 %mul to i64
  %arrayidx2 = getelementptr inbounds float* %shiftvec, i64 %idxprom1
  %1 = load float* %arrayidx2, align 4, !tbaa !3
  %add = add nsw i32 %mul, 1
  %idxprom3 = sext i32 %add to i64
  %arrayidx4 = getelementptr inbounds float* %shiftvec, i64 %idxprom3
  %2 = load float* %arrayidx4, align 4, !tbaa !3
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds float* %shiftvec, i64 %idxprom6
  %3 = load float* %arrayidx7, align 4, !tbaa !3
  %arrayidx9 = getelementptr inbounds i32* %iinr, i64 %indvars.iv481
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %arrayidx12 = getelementptr inbounds i32* %jindex, i64 %indvars.iv481
  %5 = load i32* %arrayidx12, align 4, !tbaa !0
  %indvars.iv.next482 = add i64 %indvars.iv481, 1
  %arrayidx15 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next482
  %6 = load i32* %arrayidx15, align 4, !tbaa !0
  %idxprom16 = sext i32 %mul10 to i64
  %arrayidx17 = getelementptr inbounds float* %pos, i64 %idxprom16
  %7 = load float* %arrayidx17, align 4, !tbaa !3
  %add18 = fadd float %1, %7
  %add19 = add nsw i32 %mul10, 1
  %idxprom20 = sext i32 %add19 to i64
  %arrayidx21 = getelementptr inbounds float* %pos, i64 %idxprom20
  %8 = load float* %arrayidx21, align 4, !tbaa !3
  %add22 = fadd float %2, %8
  %add23 = add nsw i32 %mul10, 2
  %idxprom24 = sext i32 %add23 to i64
  %arrayidx25 = getelementptr inbounds float* %pos, i64 %idxprom24
  %9 = load float* %arrayidx25, align 4, !tbaa !3
  %add26 = fadd float %3, %9
  %idxprom28 = sext i32 %4 to i64
  %arrayidx29 = getelementptr inbounds i32* %type, i64 %idxprom28
  %10 = load i32* %arrayidx29, align 4, !tbaa !0
  %mul30 = mul nsw i32 %10, %mul27
  %arrayidx33 = getelementptr inbounds i32* %typeB, i64 %idxprom28
  %11 = load i32* %arrayidx33, align 4, !tbaa !0
  %mul34 = mul nsw i32 %11, %mul27
  %cmp36466 = icmp slt i32 %5, %6
  br i1 %cmp36466, label %for.body37.lr.ph, label %for.end

for.body37.lr.ph:                                 ; preds = %for.body
  %12 = sext i32 %5 to i64
  br label %for.body37

for.body37:                                       ; preds = %for.body37.lr.ph, %for.body37
  %indvars.iv = phi i64 [ %12, %for.body37.lr.ph ], [ %indvars.iv.next, %for.body37 ]
  %dvdl.1471 = phi float [ %dvdl.0478, %for.body37.lr.ph ], [ %sub188, %for.body37 ]
  %vnbtot.0470 = phi float [ 0.000000e+00, %for.body37.lr.ph ], [ %add186, %for.body37 ]
  %fix1.0469 = phi float [ 0.000000e+00, %for.body37.lr.ph ], [ %add197, %for.body37 ]
  %fiy1.0468 = phi float [ 0.000000e+00, %for.body37.lr.ph ], [ %add198, %for.body37 ]
  %fiz1.0467 = phi float [ 0.000000e+00, %for.body37.lr.ph ], [ %add199, %for.body37 ]
  %arrayidx39 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %13 = load i32* %arrayidx39, align 4, !tbaa !0
  %mul40 = mul nsw i32 %13, 3
  %idxprom41 = sext i32 %mul40 to i64
  %arrayidx42 = getelementptr inbounds float* %pos, i64 %idxprom41
  %14 = load float* %arrayidx42, align 4, !tbaa !3
  %add43 = add nsw i32 %mul40, 1
  %idxprom44 = sext i32 %add43 to i64
  %arrayidx45 = getelementptr inbounds float* %pos, i64 %idxprom44
  %15 = load float* %arrayidx45, align 4, !tbaa !3
  %add46 = add nsw i32 %mul40, 2
  %idxprom47 = sext i32 %add46 to i64
  %arrayidx48 = getelementptr inbounds float* %pos, i64 %idxprom47
  %16 = load float* %arrayidx48, align 4, !tbaa !3
  %sub49 = fsub float %add18, %14
  %sub50 = fsub float %add22, %15
  %sub51 = fsub float %add26, %16
  %mul52 = fmul float %sub49, %sub49
  %mul53 = fmul float %sub50, %sub50
  %add54 = fadd float %mul52, %mul53
  %mul55 = fmul float %sub51, %sub51
  %add56 = fadd float %add54, %mul55
  %conv = fpext float %add56 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv57 = fptrunc double %div to float
  %mul58 = fmul float %add56, %conv57
  %mul59 = fmul float %mul58, %tabscale
  %conv60 = fptosi float %mul59 to i32
  %conv61 = sitofp i32 %conv60 to float
  %sub62 = fsub float %mul59, %conv61
  %mul63 = fmul float %sub62, %sub62
  %mul64 = shl nsw i32 %conv60, 3
  %idxprom65 = sext i32 %13 to i64
  %arrayidx66 = getelementptr inbounds i32* %type, i64 %idxprom65
  %17 = load i32* %arrayidx66, align 4, !tbaa !0
  %mul67 = mul nsw i32 %17, 3
  %add68 = add nsw i32 %mul67, %mul30
  %arrayidx70 = getelementptr inbounds i32* %typeB, i64 %idxprom65
  %18 = load i32* %arrayidx70, align 4, !tbaa !0
  %mul71 = mul nsw i32 %18, 3
  %add72 = add nsw i32 %mul71, %mul34
  %idxprom73 = sext i32 %add68 to i64
  %arrayidx74 = getelementptr inbounds float* %nbfp, i64 %idxprom73
  %19 = load float* %arrayidx74, align 4, !tbaa !3
  %idxprom75 = sext i32 %add72 to i64
  %arrayidx76 = getelementptr inbounds float* %nbfp, i64 %idxprom75
  %20 = load float* %arrayidx76, align 4, !tbaa !3
  %mul77 = fmul float %sub, %19
  %mul78 = fmul float %20, %lambda
  %add79 = fadd float %mul77, %mul78
  %add80 = add nsw i32 %add68, 1
  %idxprom81 = sext i32 %add80 to i64
  %arrayidx82 = getelementptr inbounds float* %nbfp, i64 %idxprom81
  %21 = load float* %arrayidx82, align 4, !tbaa !3
  %add83 = add nsw i32 %add72, 1
  %idxprom84 = sext i32 %add83 to i64
  %arrayidx85 = getelementptr inbounds float* %nbfp, i64 %idxprom84
  %22 = load float* %arrayidx85, align 4, !tbaa !3
  %add86 = add nsw i32 %add68, 2
  %idxprom87 = sext i32 %add86 to i64
  %arrayidx88 = getelementptr inbounds float* %nbfp, i64 %idxprom87
  %23 = load float* %arrayidx88, align 4, !tbaa !3
  %add89 = add nsw i32 %add72, 2
  %idxprom90 = sext i32 %add89 to i64
  %arrayidx91 = getelementptr inbounds float* %nbfp, i64 %idxprom90
  %24 = load float* %arrayidx91, align 4, !tbaa !3
  %idxprom92 = sext i32 %mul64 to i64
  %arrayidx93 = getelementptr inbounds float* %VFtab, i64 %idxprom92
  %25 = load float* %arrayidx93, align 4, !tbaa !3
  %add94455 = or i32 %mul64, 1
  %idxprom95 = sext i32 %add94455 to i64
  %arrayidx96 = getelementptr inbounds float* %VFtab, i64 %idxprom95
  %26 = load float* %arrayidx96, align 4, !tbaa !3
  %add97456 = or i32 %mul64, 2
  %idxprom98 = sext i32 %add97456 to i64
  %arrayidx99 = getelementptr inbounds float* %VFtab, i64 %idxprom98
  %27 = load float* %arrayidx99, align 4, !tbaa !3
  %mul100 = fmul float %sub62, %27
  %add101457 = or i32 %mul64, 3
  %idxprom102 = sext i32 %add101457 to i64
  %arrayidx103 = getelementptr inbounds float* %VFtab, i64 %idxprom102
  %28 = load float* %arrayidx103, align 4, !tbaa !3
  %mul104 = fmul float %mul63, %28
  %add105 = fadd float %26, %mul100
  %add106 = fadd float %add105, %mul104
  %mul107 = fmul float %sub62, %add106
  %add108 = fadd float %25, %mul107
  %add109 = fadd float %mul100, %add106
  %mul110 = fmul float %mul104, 2.000000e+00
  %add111 = fadd float %mul110, %add109
  %mul112 = fmul float %add79, %add108
  %mul113 = fmul float %add79, %add111
  %sub114 = fsub float %20, %19
  %mul115 = fmul float %sub114, %add108
  %add116 = fadd float %dvdl.1471, %mul115
  %mul117 = fmul float %mul58, %23
  %mul118 = fmul float %mul117, %exptabscale
  %conv119 = fptosi float %mul118 to i32
  %conv120 = sitofp i32 %conv119 to float
  %sub121 = fsub float %mul118, %conv120
  %mul122 = fmul float %sub121, %sub121
  %mul123 = shl nsw i32 %conv119, 3
  %add124458 = or i32 %mul123, 4
  %idxprom125 = sext i32 %add124458 to i64
  %arrayidx126 = getelementptr inbounds float* %VFtab, i64 %idxprom125
  %29 = load float* %arrayidx126, align 4, !tbaa !3
  %add127459 = or i32 %mul123, 5
  %idxprom128 = sext i32 %add127459 to i64
  %arrayidx129 = getelementptr inbounds float* %VFtab, i64 %idxprom128
  %30 = load float* %arrayidx129, align 4, !tbaa !3
  %add130460 = or i32 %mul123, 6
  %idxprom131 = sext i32 %add130460 to i64
  %arrayidx132 = getelementptr inbounds float* %VFtab, i64 %idxprom131
  %31 = load float* %arrayidx132, align 4, !tbaa !3
  %mul133 = fmul float %sub121, %31
  %add134461 = or i32 %mul123, 7
  %idxprom135 = sext i32 %add134461 to i64
  %arrayidx136 = getelementptr inbounds float* %VFtab, i64 %idxprom135
  %32 = load float* %arrayidx136, align 4, !tbaa !3
  %mul137 = fmul float %mul122, %32
  %add138 = fadd float %30, %mul133
  %add139 = fadd float %add138, %mul137
  %mul140 = fmul float %sub121, %add139
  %add141 = fadd float %29, %mul140
  %add142 = fadd float %mul133, %add139
  %mul143 = fmul float %mul137, 2.000000e+00
  %add144 = fadd float %mul143, %add142
  %mul145 = fmul float %21, %add141
  %mul146 = fmul float %21, %23
  %mul147 = fmul float %mul146, %add144
  %mul148 = fmul float %mul58, %24
  %mul149 = fmul float %mul148, %exptabscale
  %conv150 = fptosi float %mul149 to i32
  %conv151 = sitofp i32 %conv150 to float
  %sub152 = fsub float %mul149, %conv151
  %mul153 = fmul float %sub152, %sub152
  %mul154 = shl nsw i32 %conv150, 3
  %add155462 = or i32 %mul154, 4
  %idxprom156 = sext i32 %add155462 to i64
  %arrayidx157 = getelementptr inbounds float* %VFtab, i64 %idxprom156
  %33 = load float* %arrayidx157, align 4, !tbaa !3
  %add158463 = or i32 %mul154, 5
  %idxprom159 = sext i32 %add158463 to i64
  %arrayidx160 = getelementptr inbounds float* %VFtab, i64 %idxprom159
  %34 = load float* %arrayidx160, align 4, !tbaa !3
  %add161464 = or i32 %mul154, 6
  %idxprom162 = sext i32 %add161464 to i64
  %arrayidx163 = getelementptr inbounds float* %VFtab, i64 %idxprom162
  %35 = load float* %arrayidx163, align 4, !tbaa !3
  %mul164 = fmul float %sub152, %35
  %add165465 = or i32 %mul154, 7
  %idxprom166 = sext i32 %add165465 to i64
  %arrayidx167 = getelementptr inbounds float* %VFtab, i64 %idxprom166
  %36 = load float* %arrayidx167, align 4, !tbaa !3
  %mul168 = fmul float %mul153, %36
  %add169 = fadd float %34, %mul164
  %add170 = fadd float %add169, %mul168
  %mul171 = fmul float %sub152, %add170
  %add172 = fadd float %33, %mul171
  %add173 = fadd float %mul164, %add170
  %mul174 = fmul float %mul168, 2.000000e+00
  %add175 = fadd float %mul174, %add173
  %mul176 = fmul float %22, %add172
  %mul177 = fmul float %22, %24
  %mul178 = fmul float %mul177, %add175
  %mul179 = fmul float %sub, %mul147
  %mul180 = fmul float %mul178, %lambda
  %add181 = fadd float %mul179, %mul180
  %add182 = fadd float %vnbtot.0470, %mul112
  %mul183 = fmul float %sub, %mul145
  %add184 = fadd float %add182, %mul183
  %mul185 = fmul float %mul176, %lambda
  %add186 = fadd float %add184, %mul185
  %add187 = fadd float %add116, %mul176
  %sub188 = fsub float %add187, %mul145
  %mul189 = fmul float %mul113, %tabscale
  %mul190 = fmul float %add181, %exptabscale
  %add191 = fadd float %mul189, %mul190
  %37 = fmul float %conv57, %add191
  %mul193 = fsub float -0.000000e+00, %37
  %mul194 = fmul float %sub49, %mul193
  %mul195 = fmul float %sub50, %mul193
  %mul196 = fmul float %sub51, %mul193
  %add197 = fadd float %fix1.0469, %mul194
  %add198 = fadd float %fiy1.0468, %mul195
  %add199 = fadd float %fiz1.0467, %mul196
  %arrayidx201 = getelementptr inbounds float* %faction, i64 %idxprom41
  %38 = load float* %arrayidx201, align 4, !tbaa !3
  %sub202 = fsub float %38, %mul194
  store float %sub202, float* %arrayidx201, align 4, !tbaa !3
  %arrayidx207 = getelementptr inbounds float* %faction, i64 %idxprom44
  %39 = load float* %arrayidx207, align 4, !tbaa !3
  %sub208 = fsub float %39, %mul195
  store float %sub208, float* %arrayidx207, align 4, !tbaa !3
  %arrayidx214 = getelementptr inbounds float* %faction, i64 %idxprom47
  %40 = load float* %arrayidx214, align 4, !tbaa !3
  %sub215 = fsub float %40, %mul196
  store float %sub215, float* %arrayidx214, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %41 = trunc i64 %indvars.iv.next to i32
  %cmp36 = icmp slt i32 %41, %6
  br i1 %cmp36, label %for.body37, label %for.end

for.end:                                          ; preds = %for.body37, %for.body
  %dvdl.1.lcssa = phi float [ %dvdl.0478, %for.body ], [ %sub188, %for.body37 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add186, %for.body37 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add197, %for.body37 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add198, %for.body37 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add199, %for.body37 ]
  %arrayidx220 = getelementptr inbounds float* %faction, i64 %idxprom16
  %42 = load float* %arrayidx220, align 4, !tbaa !3
  %add221 = fadd float %fix1.0.lcssa, %42
  store float %add221, float* %arrayidx220, align 4, !tbaa !3
  %arrayidx226 = getelementptr inbounds float* %faction, i64 %idxprom20
  %43 = load float* %arrayidx226, align 4, !tbaa !3
  %add227 = fadd float %fiy1.0.lcssa, %43
  store float %add227, float* %arrayidx226, align 4, !tbaa !3
  %arrayidx233 = getelementptr inbounds float* %faction, i64 %idxprom24
  %44 = load float* %arrayidx233, align 4, !tbaa !3
  %add234 = fadd float %fiz1.0.lcssa, %44
  store float %add234, float* %arrayidx233, align 4, !tbaa !3
  %arrayidx239 = getelementptr inbounds float* %fshift, i64 %idxprom1
  %45 = load float* %arrayidx239, align 4, !tbaa !3
  %add240 = fadd float %fix1.0.lcssa, %45
  store float %add240, float* %arrayidx239, align 4, !tbaa !3
  %arrayidx245 = getelementptr inbounds float* %fshift, i64 %idxprom3
  %46 = load float* %arrayidx245, align 4, !tbaa !3
  %add246 = fadd float %fiy1.0.lcssa, %46
  store float %add246, float* %arrayidx245, align 4, !tbaa !3
  %arrayidx252 = getelementptr inbounds float* %fshift, i64 %idxprom6
  %47 = load float* %arrayidx252, align 4, !tbaa !3
  %add253 = fadd float %fiz1.0.lcssa, %47
  store float %add253, float* %arrayidx252, align 4, !tbaa !3
  %arrayidx258 = getelementptr inbounds i32* %gid, i64 %indvars.iv481
  %48 = load i32* %arrayidx258, align 4, !tbaa !0
  %idxprom259 = sext i32 %48 to i64
  %arrayidx260 = getelementptr inbounds float* %Vnb, i64 %idxprom259
  %49 = load float* %arrayidx260, align 4, !tbaa !3
  %add261 = fadd float %vnbtot.0.lcssa, %49
  store float %add261, float* %arrayidx260, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next482 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end266, label %for.body

for.end266:                                       ; preds = %for.end, %entry
  %dvdl.0.lcssa = phi float [ 0.000000e+00, %entry ], [ %dvdl.1.lcssa, %for.end ]
  %50 = load float* %dvdlambda, align 4, !tbaa !3
  %add267 = fadd float %dvdl.0.lcssa, %50
  store float %add267, float* %dvdlambda, align 4, !tbaa !3
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl0402(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab, float %exptabscale, float %lambda, float* nocapture %dvdlambda, i32* nocapture %typeB, float %Alpha, float %defsigma6) #0 {
entry:
  %sub = fsub float 1.000000e+00, %lambda
  %cmp625 = icmp sgt i32 %nri, 0
  br i1 %cmp625, label %for.body.lr.ph, label %for.end347

for.body.lr.ph:                                   ; preds = %entry
  %mul1 = fmul float %sub, %sub
  %mul = fmul float %lambda, %lambda
  %mul29 = mul nsw i32 %ntype, 3
  %mul91 = fmul float %Alpha, %defsigma6
  %mul92 = fmul float %mul, %mul91
  %mul171 = fmul float %mul1, %mul91
  %mul265 = fmul float %Alpha, 0x3FD5555560000000
  %mul266 = fmul float %mul265, %lambda
  %mul267 = fmul float %sub, %mul266
  br label %for.body

for.body:                                         ; preds = %for.end, %for.body.lr.ph
  %indvars.iv629 = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next630, %for.end ]
  %dvdl.0626 = phi float [ 0.000000e+00, %for.body.lr.ph ], [ %dvdl.1.lcssa, %for.end ]
  %arrayidx = getelementptr inbounds i32* %shift, i64 %indvars.iv629
  %0 = load i32* %arrayidx, align 4, !tbaa !0
  %mul2 = mul nsw i32 %0, 3
  %idxprom3 = sext i32 %mul2 to i64
  %arrayidx4 = getelementptr inbounds float* %shiftvec, i64 %idxprom3
  %1 = load float* %arrayidx4, align 4, !tbaa !3
  %add = add nsw i32 %mul2, 1
  %idxprom5 = sext i32 %add to i64
  %arrayidx6 = getelementptr inbounds float* %shiftvec, i64 %idxprom5
  %2 = load float* %arrayidx6, align 4, !tbaa !3
  %add7 = add nsw i32 %mul2, 2
  %idxprom8 = sext i32 %add7 to i64
  %arrayidx9 = getelementptr inbounds float* %shiftvec, i64 %idxprom8
  %3 = load float* %arrayidx9, align 4, !tbaa !3
  %arrayidx11 = getelementptr inbounds i32* %iinr, i64 %indvars.iv629
  %4 = load i32* %arrayidx11, align 4, !tbaa !0
  %mul12 = mul nsw i32 %4, 3
  %arrayidx14 = getelementptr inbounds i32* %jindex, i64 %indvars.iv629
  %5 = load i32* %arrayidx14, align 4, !tbaa !0
  %indvars.iv.next630 = add i64 %indvars.iv629, 1
  %arrayidx17 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next630
  %6 = load i32* %arrayidx17, align 4, !tbaa !0
  %idxprom18 = sext i32 %mul12 to i64
  %arrayidx19 = getelementptr inbounds float* %pos, i64 %idxprom18
  %7 = load float* %arrayidx19, align 4, !tbaa !3
  %add20 = fadd float %1, %7
  %add21 = add nsw i32 %mul12, 1
  %idxprom22 = sext i32 %add21 to i64
  %arrayidx23 = getelementptr inbounds float* %pos, i64 %idxprom22
  %8 = load float* %arrayidx23, align 4, !tbaa !3
  %add24 = fadd float %2, %8
  %add25 = add nsw i32 %mul12, 2
  %idxprom26 = sext i32 %add25 to i64
  %arrayidx27 = getelementptr inbounds float* %pos, i64 %idxprom26
  %9 = load float* %arrayidx27, align 4, !tbaa !3
  %add28 = fadd float %3, %9
  %idxprom30 = sext i32 %4 to i64
  %arrayidx31 = getelementptr inbounds i32* %type, i64 %idxprom30
  %10 = load i32* %arrayidx31, align 4, !tbaa !0
  %mul32 = mul nsw i32 %10, %mul29
  %arrayidx35 = getelementptr inbounds i32* %typeB, i64 %idxprom30
  %11 = load i32* %arrayidx35, align 4, !tbaa !0
  %mul36 = mul nsw i32 %11, %mul29
  %cmp38614 = icmp slt i32 %5, %6
  br i1 %cmp38614, label %for.body39.lr.ph, label %for.end

for.body39.lr.ph:                                 ; preds = %for.body
  %12 = sext i32 %5 to i64
  br label %for.body39

for.body39:                                       ; preds = %for.body39.lr.ph, %if.end244
  %indvars.iv = phi i64 [ %12, %for.body39.lr.ph ], [ %indvars.iv.next, %if.end244 ]
  %fiz1.0619 = phi float [ 0.000000e+00, %for.body39.lr.ph ], [ %add280, %if.end244 ]
  %fiy1.0618 = phi float [ 0.000000e+00, %for.body39.lr.ph ], [ %add279, %if.end244 ]
  %fix1.0617 = phi float [ 0.000000e+00, %for.body39.lr.ph ], [ %add278, %if.end244 ]
  %dvdl.1616 = phi float [ %dvdl.0626, %for.body39.lr.ph ], [ %add274, %if.end244 ]
  %vnbtot.0615 = phi float [ 0.000000e+00, %for.body39.lr.ph ], [ %add250, %if.end244 ]
  %arrayidx41 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %13 = load i32* %arrayidx41, align 4, !tbaa !0
  %mul42 = mul nsw i32 %13, 3
  %idxprom43 = sext i32 %mul42 to i64
  %arrayidx44 = getelementptr inbounds float* %pos, i64 %idxprom43
  %14 = load float* %arrayidx44, align 4, !tbaa !3
  %add45 = add nsw i32 %mul42, 1
  %idxprom46 = sext i32 %add45 to i64
  %arrayidx47 = getelementptr inbounds float* %pos, i64 %idxprom46
  %15 = load float* %arrayidx47, align 4, !tbaa !3
  %add48 = add nsw i32 %mul42, 2
  %idxprom49 = sext i32 %add48 to i64
  %arrayidx50 = getelementptr inbounds float* %pos, i64 %idxprom49
  %16 = load float* %arrayidx50, align 4, !tbaa !3
  %sub51 = fsub float %add20, %14
  %sub52 = fsub float %add24, %15
  %sub53 = fsub float %add28, %16
  %mul54 = fmul float %sub51, %sub51
  %mul55 = fmul float %sub52, %sub52
  %add56 = fadd float %mul54, %mul55
  %mul57 = fmul float %sub53, %sub53
  %add58 = fadd float %add56, %mul57
  %conv = fpext float %add58 to double
  %call = tail call double @sqrt(double %conv) #2
  %idxprom61 = sext i32 %13 to i64
  %arrayidx62 = getelementptr inbounds i32* %type, i64 %idxprom61
  %17 = load i32* %arrayidx62, align 4, !tbaa !0
  %mul63 = mul nsw i32 %17, 3
  %add64 = add nsw i32 %mul63, %mul32
  %arrayidx66 = getelementptr inbounds i32* %typeB, i64 %idxprom61
  %18 = load i32* %arrayidx66, align 4, !tbaa !0
  %mul67 = mul nsw i32 %18, 3
  %add68 = add nsw i32 %mul67, %mul36
  %idxprom69 = sext i32 %add64 to i64
  %arrayidx70 = getelementptr inbounds float* %nbfp, i64 %idxprom69
  %19 = load float* %arrayidx70, align 4, !tbaa !3
  %idxprom71 = sext i32 %add68 to i64
  %arrayidx72 = getelementptr inbounds float* %nbfp, i64 %idxprom71
  %20 = load float* %arrayidx72, align 4, !tbaa !3
  %add73 = add nsw i32 %add64, 1
  %idxprom74 = sext i32 %add73 to i64
  %arrayidx75 = getelementptr inbounds float* %nbfp, i64 %idxprom74
  %21 = load float* %arrayidx75, align 4, !tbaa !3
  %add76 = add nsw i32 %add68, 1
  %idxprom77 = sext i32 %add76 to i64
  %arrayidx78 = getelementptr inbounds float* %nbfp, i64 %idxprom77
  %22 = load float* %arrayidx78, align 4, !tbaa !3
  %add79 = add nsw i32 %add64, 2
  %idxprom80 = sext i32 %add79 to i64
  %arrayidx81 = getelementptr inbounds float* %nbfp, i64 %idxprom80
  %23 = load float* %arrayidx81, align 4, !tbaa !3
  %add82 = add nsw i32 %add68, 2
  %idxprom83 = sext i32 %add82 to i64
  %arrayidx84 = getelementptr inbounds float* %nbfp, i64 %idxprom83
  %24 = load float* %arrayidx84, align 4, !tbaa !3
  %mul85 = fmul float %add58, %add58
  %mul86 = fmul float %add58, %mul85
  %cmp87 = fcmp ogt float %19, 0.000000e+00
  %cmp89 = fcmp ogt float %21, 0.000000e+00
  %or.cond = or i1 %cmp87, %cmp89
  br i1 %or.cond, label %if.then, label %if.end

if.then:                                          ; preds = %for.body39
  %add93 = fadd float %mul92, %mul86
  %conv94 = fpext float %add93 to double
  %call95 = tail call double @pow(double %conv94, double 0x3FC5555560000000) #2
  %conv96 = fptrunc double %call95 to float
  %conv99 = fdiv float 1.000000e+00, %conv96
  %mul100 = fmul float %conv99, %conv99
  %mul101 = fmul float %mul100, %mul100
  %mul102 = fmul float %conv99, %mul101
  %mul103 = fmul float %conv96, %tabscale
  %conv104 = fptosi float %mul103 to i32
  %conv105 = sitofp i32 %conv104 to float
  %sub106 = fsub float %mul103, %conv105
  %mul107 = fmul float %sub106, %sub106
  %mul108 = shl nsw i32 %conv104, 3
  %idxprom109 = sext i32 %mul108 to i64
  %arrayidx110 = getelementptr inbounds float* %VFtab, i64 %idxprom109
  %25 = load float* %arrayidx110, align 4, !tbaa !3
  %add111606 = or i32 %mul108, 1
  %idxprom112 = sext i32 %add111606 to i64
  %arrayidx113 = getelementptr inbounds float* %VFtab, i64 %idxprom112
  %26 = load float* %arrayidx113, align 4, !tbaa !3
  %add114607 = or i32 %mul108, 2
  %idxprom115 = sext i32 %add114607 to i64
  %arrayidx116 = getelementptr inbounds float* %VFtab, i64 %idxprom115
  %27 = load float* %arrayidx116, align 4, !tbaa !3
  %mul117 = fmul float %27, %sub106
  %add118608 = or i32 %mul108, 3
  %idxprom119 = sext i32 %add118608 to i64
  %arrayidx120 = getelementptr inbounds float* %VFtab, i64 %idxprom119
  %28 = load float* %arrayidx120, align 4, !tbaa !3
  %mul121 = fmul float %28, %mul107
  %add122 = fadd float %26, %mul117
  %add123 = fadd float %add122, %mul121
  %mul124 = fmul float %sub106, %add123
  %add125 = fadd float %25, %mul124
  %add126 = fadd float %mul117, %add123
  %mul127 = fmul float %mul121, 2.000000e+00
  %add128 = fadd float %mul127, %add126
  %mul129 = fmul float %19, %add125
  %mul130 = fmul float %19, %tabscale
  %mul131 = fmul float %mul130, %add128
  %mul132 = fmul float %23, %conv96
  %mul133 = fmul float %mul132, %tabscale
  %conv134 = fptosi float %mul133 to i32
  %conv135 = sitofp i32 %conv134 to float
  %sub136 = fsub float %mul133, %conv135
  %mul137 = fmul float %sub136, %sub136
  %mul138 = shl nsw i32 %conv134, 3
  %add139609 = or i32 %mul138, 4
  %idxprom140 = sext i32 %add139609 to i64
  %arrayidx141 = getelementptr inbounds float* %VFtab, i64 %idxprom140
  %29 = load float* %arrayidx141, align 4, !tbaa !3
  %add142610 = or i32 %mul138, 5
  %idxprom143 = sext i32 %add142610 to i64
  %arrayidx144 = getelementptr inbounds float* %VFtab, i64 %idxprom143
  %30 = load float* %arrayidx144, align 4, !tbaa !3
  %add145611 = or i32 %mul138, 6
  %idxprom146 = sext i32 %add145611 to i64
  %arrayidx147 = getelementptr inbounds float* %VFtab, i64 %idxprom146
  %31 = load float* %arrayidx147, align 4, !tbaa !3
  %mul148 = fmul float %sub136, %31
  %add149612 = or i32 %mul138, 7
  %idxprom150 = sext i32 %add149612 to i64
  %arrayidx151 = getelementptr inbounds float* %VFtab, i64 %idxprom150
  %32 = load float* %arrayidx151, align 4, !tbaa !3
  %mul152 = fmul float %mul137, %32
  %add153 = fadd float %30, %mul148
  %add154 = fadd float %add153, %mul152
  %mul155 = fmul float %sub136, %add154
  %add156 = fadd float %29, %mul155
  %add157 = fadd float %mul148, %add154
  %mul158 = fmul float %mul152, 2.000000e+00
  %add159 = fadd float %mul158, %add157
  %mul160 = fmul float %21, %add156
  %mul161 = fmul float %21, %23
  %mul162 = fmul float %mul161, %exptabscale
  %mul163 = fmul float %mul162, %add159
  br label %if.end

if.end:                                           ; preds = %for.body39, %if.then
  %FFRa.0 = phi float [ %mul163, %if.then ], [ 0.000000e+00, %for.body39 ]
  %VVRa.0 = phi float [ %mul160, %if.then ], [ 0.000000e+00, %for.body39 ]
  %FFDa.0 = phi float [ %mul131, %if.then ], [ 0.000000e+00, %for.body39 ]
  %VVDa.0 = phi float [ %mul129, %if.then ], [ 0.000000e+00, %for.body39 ]
  %rinv5a.0 = phi float [ %mul102, %if.then ], [ 0.000000e+00, %for.body39 ]
  %cmp164 = fcmp ogt float %20, 0.000000e+00
  %cmp167 = fcmp ogt float %22, 0.000000e+00
  %or.cond613 = or i1 %cmp164, %cmp167
  br i1 %or.cond613, label %if.then169, label %if.end244

if.then169:                                       ; preds = %if.end
  %add172 = fadd float %mul171, %mul86
  %conv173 = fpext float %add172 to double
  %call174 = tail call double @pow(double %conv173, double 0x3FC5555560000000) #2
  %conv175 = fptrunc double %call174 to float
  %conv178 = fdiv float 1.000000e+00, %conv175
  %mul179 = fmul float %conv178, %conv178
  %mul180 = fmul float %mul179, %mul179
  %mul181 = fmul float %conv178, %mul180
  %mul182 = fmul float %conv175, %tabscale
  %conv183 = fptosi float %mul182 to i32
  %conv184 = sitofp i32 %conv183 to float
  %sub185 = fsub float %mul182, %conv184
  %mul186 = fmul float %sub185, %sub185
  %mul187 = shl nsw i32 %conv183, 3
  %idxprom188 = sext i32 %mul187 to i64
  %arrayidx189 = getelementptr inbounds float* %VFtab, i64 %idxprom188
  %33 = load float* %arrayidx189, align 4, !tbaa !3
  %add190599 = or i32 %mul187, 1
  %idxprom191 = sext i32 %add190599 to i64
  %arrayidx192 = getelementptr inbounds float* %VFtab, i64 %idxprom191
  %34 = load float* %arrayidx192, align 4, !tbaa !3
  %add193600 = or i32 %mul187, 2
  %idxprom194 = sext i32 %add193600 to i64
  %arrayidx195 = getelementptr inbounds float* %VFtab, i64 %idxprom194
  %35 = load float* %arrayidx195, align 4, !tbaa !3
  %mul196 = fmul float %35, %sub185
  %add197601 = or i32 %mul187, 3
  %idxprom198 = sext i32 %add197601 to i64
  %arrayidx199 = getelementptr inbounds float* %VFtab, i64 %idxprom198
  %36 = load float* %arrayidx199, align 4, !tbaa !3
  %mul200 = fmul float %36, %mul186
  %add201 = fadd float %34, %mul196
  %add202 = fadd float %add201, %mul200
  %mul203 = fmul float %sub185, %add202
  %add204 = fadd float %33, %mul203
  %add205 = fadd float %mul196, %add202
  %mul206 = fmul float %mul200, 2.000000e+00
  %add207 = fadd float %mul206, %add205
  %mul208 = fmul float %20, %add204
  %mul209 = fmul float %20, %tabscale
  %mul210 = fmul float %mul209, %add207
  %mul211 = fmul float %24, %conv175
  %mul212 = fmul float %mul211, %tabscale
  %conv213 = fptosi float %mul212 to i32
  %conv214 = sitofp i32 %conv213 to float
  %sub215 = fsub float %mul212, %conv214
  %mul216 = fmul float %sub215, %sub215
  %mul217 = shl nsw i32 %conv213, 3
  %add218602 = or i32 %mul217, 4
  %idxprom219 = sext i32 %add218602 to i64
  %arrayidx220 = getelementptr inbounds float* %VFtab, i64 %idxprom219
  %37 = load float* %arrayidx220, align 4, !tbaa !3
  %add221603 = or i32 %mul217, 5
  %idxprom222 = sext i32 %add221603 to i64
  %arrayidx223 = getelementptr inbounds float* %VFtab, i64 %idxprom222
  %38 = load float* %arrayidx223, align 4, !tbaa !3
  %add224604 = or i32 %mul217, 6
  %idxprom225 = sext i32 %add224604 to i64
  %arrayidx226 = getelementptr inbounds float* %VFtab, i64 %idxprom225
  %39 = load float* %arrayidx226, align 4, !tbaa !3
  %mul227 = fmul float %sub215, %39
  %add228605 = or i32 %mul217, 7
  %idxprom229 = sext i32 %add228605 to i64
  %arrayidx230 = getelementptr inbounds float* %VFtab, i64 %idxprom229
  %40 = load float* %arrayidx230, align 4, !tbaa !3
  %mul231 = fmul float %mul216, %40
  %add232 = fadd float %38, %mul227
  %add233 = fadd float %add232, %mul231
  %mul234 = fmul float %sub215, %add233
  %add235 = fadd float %37, %mul234
  %add236 = fadd float %mul227, %add233
  %mul237 = fmul float %mul231, 2.000000e+00
  %add238 = fadd float %mul237, %add236
  %mul239 = fmul float %22, %add235
  %mul240 = fmul float %22, %24
  %mul241 = fmul float %mul240, %exptabscale
  %mul242 = fmul float %mul241, %add238
  br label %if.end244

if.end244:                                        ; preds = %if.end, %if.then169
  %FFRb.0 = phi float [ %mul242, %if.then169 ], [ 0.000000e+00, %if.end ]
  %VVRb.0 = phi float [ %mul239, %if.then169 ], [ 0.000000e+00, %if.end ]
  %FFDb.0 = phi float [ %mul210, %if.then169 ], [ 0.000000e+00, %if.end ]
  %VVDb.0 = phi float [ %mul208, %if.then169 ], [ 0.000000e+00, %if.end ]
  %rinv5b.0 = phi float [ %mul181, %if.then169 ], [ 0.000000e+00, %if.end ]
  %add245 = fadd float %VVRb.0, %VVDb.0
  %mul246 = fmul float %add245, %lambda
  %add247 = fadd float %vnbtot.0615, %mul246
  %add248 = fadd float %VVRa.0, %VVDa.0
  %mul249 = fmul float %sub, %add248
  %add250 = fadd float %mul249, %add247
  %add251 = fadd float %FFRa.0, %FFDa.0
  %sub252 = fsub float -0.000000e+00, %add251
  %add253 = fadd float %FFRb.0, %FFDb.0
  %sub254 = fsub float -0.000000e+00, %add253
  %mul255 = fmul float %sub, %sub252
  %mul256 = fmul float %rinv5a.0, %mul255
  %mul257 = fmul float %lambda, %sub254
  %mul258 = fmul float %rinv5b.0, %mul257
  %add259 = fadd float %mul256, %mul258
  %mul260 = fmul float %mul85, %add259
  %add261 = fadd float %dvdl.1616, %VVDb.0
  %add262 = fadd float %VVRb.0, %add261
  %sub263 = fsub float %add262, %VVDa.0
  %sub264 = fsub float %sub263, %VVRa.0
  %mul268 = fmul float %defsigma6, %sub254
  %mul269 = fmul float %rinv5b.0, %mul268
  %mul270 = fmul float %defsigma6, %sub252
  %mul271 = fmul float %rinv5a.0, %mul270
  %sub272 = fsub float %mul269, %mul271
  %mul273 = fmul float %mul267, %sub272
  %add274 = fadd float %sub264, %mul273
  %mul275 = fmul float %sub51, %mul260
  %mul276 = fmul float %sub52, %mul260
  %mul277 = fmul float %sub53, %mul260
  %add278 = fadd float %fix1.0617, %mul275
  %add279 = fadd float %fiy1.0618, %mul276
  %add280 = fadd float %fiz1.0619, %mul277
  %arrayidx282 = getelementptr inbounds float* %faction, i64 %idxprom43
  %41 = load float* %arrayidx282, align 4, !tbaa !3
  %sub283 = fsub float %41, %mul275
  store float %sub283, float* %arrayidx282, align 4, !tbaa !3
  %arrayidx288 = getelementptr inbounds float* %faction, i64 %idxprom46
  %42 = load float* %arrayidx288, align 4, !tbaa !3
  %sub289 = fsub float %42, %mul276
  store float %sub289, float* %arrayidx288, align 4, !tbaa !3
  %arrayidx295 = getelementptr inbounds float* %faction, i64 %idxprom49
  %43 = load float* %arrayidx295, align 4, !tbaa !3
  %sub296 = fsub float %43, %mul277
  store float %sub296, float* %arrayidx295, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %44 = trunc i64 %indvars.iv.next to i32
  %cmp38 = icmp slt i32 %44, %6
  br i1 %cmp38, label %for.body39, label %for.end

for.end:                                          ; preds = %if.end244, %for.body
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add280, %if.end244 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add279, %if.end244 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add278, %if.end244 ]
  %dvdl.1.lcssa = phi float [ %dvdl.0626, %for.body ], [ %add274, %if.end244 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add250, %if.end244 ]
  %arrayidx301 = getelementptr inbounds float* %faction, i64 %idxprom18
  %45 = load float* %arrayidx301, align 4, !tbaa !3
  %add302 = fadd float %fix1.0.lcssa, %45
  store float %add302, float* %arrayidx301, align 4, !tbaa !3
  %arrayidx307 = getelementptr inbounds float* %faction, i64 %idxprom22
  %46 = load float* %arrayidx307, align 4, !tbaa !3
  %add308 = fadd float %fiy1.0.lcssa, %46
  store float %add308, float* %arrayidx307, align 4, !tbaa !3
  %arrayidx314 = getelementptr inbounds float* %faction, i64 %idxprom26
  %47 = load float* %arrayidx314, align 4, !tbaa !3
  %add315 = fadd float %fiz1.0.lcssa, %47
  store float %add315, float* %arrayidx314, align 4, !tbaa !3
  %arrayidx320 = getelementptr inbounds float* %fshift, i64 %idxprom3
  %48 = load float* %arrayidx320, align 4, !tbaa !3
  %add321 = fadd float %fix1.0.lcssa, %48
  store float %add321, float* %arrayidx320, align 4, !tbaa !3
  %arrayidx326 = getelementptr inbounds float* %fshift, i64 %idxprom5
  %49 = load float* %arrayidx326, align 4, !tbaa !3
  %add327 = fadd float %fiy1.0.lcssa, %49
  store float %add327, float* %arrayidx326, align 4, !tbaa !3
  %arrayidx333 = getelementptr inbounds float* %fshift, i64 %idxprom8
  %50 = load float* %arrayidx333, align 4, !tbaa !3
  %add334 = fadd float %fiz1.0.lcssa, %50
  store float %add334, float* %arrayidx333, align 4, !tbaa !3
  %arrayidx339 = getelementptr inbounds i32* %gid, i64 %indvars.iv629
  %51 = load i32* %arrayidx339, align 4, !tbaa !0
  %idxprom340 = sext i32 %51 to i64
  %arrayidx341 = getelementptr inbounds float* %Vnb, i64 %idxprom340
  %52 = load float* %arrayidx341, align 4, !tbaa !3
  %add342 = fadd float %vnbtot.0.lcssa, %52
  store float %add342, float* %arrayidx341, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next630 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end347, label %for.body

for.end347:                                       ; preds = %for.end, %entry
  %dvdl.0.lcssa = phi float [ 0.000000e+00, %entry ], [ %dvdl.1.lcssa, %for.end ]
  %53 = load float* %dvdlambda, align 4, !tbaa !3
  %add348 = fadd float %dvdl.0.lcssa, %53
  store float %add348, float* %dvdlambda, align 4, !tbaa !3
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl0410(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab, float %exptabscale, i32* nocapture %nsatoms) #0 {
entry:
  %cmp801 = icmp sgt i32 %nri, 0
  br i1 %cmp801, label %for.body, label %for.end422

for.body:                                         ; preds = %for.end412, %entry
  %indvars.iv818 = phi i64 [ 0, %entry ], [ %indvars.iv.next819, %for.end412 ]
  %0 = trunc i64 %indvars.iv818 to i32
  %mul = mul nsw i32 %0, 3
  %idxprom = sext i32 %mul to i64
  %arrayidx = getelementptr inbounds i32* %nsatoms, i64 %idxprom
  %1 = load i32* %arrayidx, align 4, !tbaa !0
  %add = add nsw i32 %mul, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds i32* %nsatoms, i64 %idxprom2
  %2 = load i32* %arrayidx3, align 4, !tbaa !0
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds i32* %nsatoms, i64 %idxprom6
  %3 = load i32* %arrayidx7, align 4, !tbaa !0
  %arrayidx9 = getelementptr inbounds i32* %shift, i64 %indvars.iv818
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %idxprom11 = sext i32 %mul10 to i64
  %arrayidx12 = getelementptr inbounds float* %shiftvec, i64 %idxprom11
  %5 = load float* %arrayidx12, align 4, !tbaa !3
  %add13 = add nsw i32 %mul10, 1
  %idxprom14 = sext i32 %add13 to i64
  %arrayidx15 = getelementptr inbounds float* %shiftvec, i64 %idxprom14
  %6 = load float* %arrayidx15, align 4, !tbaa !3
  %add16 = add nsw i32 %mul10, 2
  %idxprom17 = sext i32 %add16 to i64
  %arrayidx18 = getelementptr inbounds float* %shiftvec, i64 %idxprom17
  %7 = load float* %arrayidx18, align 4, !tbaa !3
  %arrayidx20 = getelementptr inbounds i32* %iinr, i64 %indvars.iv818
  %8 = load i32* %arrayidx20, align 4, !tbaa !0
  %arrayidx23 = getelementptr inbounds i32* %jindex, i64 %indvars.iv818
  %9 = load i32* %arrayidx23, align 4, !tbaa !0
  %indvars.iv.next819 = add i64 %indvars.iv818, 1
  %arrayidx26 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next819
  %10 = load i32* %arrayidx26, align 4, !tbaa !0
  %cmp28778 = icmp sgt i32 %2, 0
  br i1 %cmp28778, label %for.body29.lr.ph, label %for.end213

for.body29.lr.ph:                                 ; preds = %for.body
  %cmp46769 = icmp slt i32 %9, %10
  %arrayidx191 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx197 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx204 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %11 = sext i32 %9 to i64
  %12 = sext i32 %8 to i64
  %13 = mul i32 %8, 3
  %14 = sext i32 %13 to i64
  br label %for.body29

for.body29:                                       ; preds = %for.end, %for.body29.lr.ph
  %indvars.iv805 = phi i64 [ %14, %for.body29.lr.ph ], [ %indvars.iv.next806, %for.end ]
  %indvars.iv803 = phi i64 [ %12, %for.body29.lr.ph ], [ %indvars.iv.next804, %for.end ]
  %s.0780 = phi i32 [ 0, %for.body29.lr.ph ], [ %inc212, %for.end ]
  %vnbtot.0779 = phi float [ 0.000000e+00, %for.body29.lr.ph ], [ %vnbtot.1.lcssa, %for.end ]
  %arrayidx31 = getelementptr inbounds float* %pos, i64 %indvars.iv805
  %15 = load float* %arrayidx31, align 4, !tbaa !3
  %add32 = fadd float %5, %15
  %16 = add nsw i64 %indvars.iv805, 1
  %arrayidx35 = getelementptr inbounds float* %pos, i64 %16
  %17 = load float* %arrayidx35, align 4, !tbaa !3
  %add36 = fadd float %6, %17
  %18 = add nsw i64 %indvars.iv805, 2
  %arrayidx39 = getelementptr inbounds float* %pos, i64 %18
  %19 = load float* %arrayidx39, align 4, !tbaa !3
  %add40 = fadd float %7, %19
  %arrayidx43 = getelementptr inbounds i32* %type, i64 %indvars.iv803
  %20 = load i32* %arrayidx43, align 4, !tbaa !0
  %mul44 = mul i32 %20, %ntype
  br i1 %cmp46769, label %for.body47, label %for.end

for.body47:                                       ; preds = %for.body29, %for.body47
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body47 ], [ %11, %for.body29 ]
  %fiz1.0773 = phi float [ %add151, %for.body47 ], [ 0.000000e+00, %for.body29 ]
  %fiy1.0772 = phi float [ %add150, %for.body47 ], [ 0.000000e+00, %for.body29 ]
  %fix1.0771 = phi float [ %add149, %for.body47 ], [ 0.000000e+00, %for.body29 ]
  %vnbtot.1770 = phi float [ %add140, %for.body47 ], [ %vnbtot.0779, %for.body29 ]
  %arrayidx49 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %21 = load i32* %arrayidx49, align 4, !tbaa !0
  %mul50 = mul nsw i32 %21, 3
  %idxprom51 = sext i32 %mul50 to i64
  %arrayidx52 = getelementptr inbounds float* %pos, i64 %idxprom51
  %22 = load float* %arrayidx52, align 4, !tbaa !3
  %add53 = add nsw i32 %mul50, 1
  %idxprom54 = sext i32 %add53 to i64
  %arrayidx55 = getelementptr inbounds float* %pos, i64 %idxprom54
  %23 = load float* %arrayidx55, align 4, !tbaa !3
  %add56 = add nsw i32 %mul50, 2
  %idxprom57 = sext i32 %add56 to i64
  %arrayidx58 = getelementptr inbounds float* %pos, i64 %idxprom57
  %24 = load float* %arrayidx58, align 4, !tbaa !3
  %sub = fsub float %add32, %22
  %sub59 = fsub float %add36, %23
  %sub60 = fsub float %add40, %24
  %mul61 = fmul float %sub, %sub
  %mul62 = fmul float %sub59, %sub59
  %add63 = fadd float %mul61, %mul62
  %mul64 = fmul float %sub60, %sub60
  %add65 = fadd float %add63, %mul64
  %conv = fpext float %add65 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv66 = fptrunc double %div to float
  %mul67 = fmul float %add65, %conv66
  %mul68 = fmul float %mul67, %tabscale
  %conv69 = fptosi float %mul68 to i32
  %conv70 = sitofp i32 %conv69 to float
  %sub71 = fsub float %mul68, %conv70
  %mul72 = fmul float %sub71, %sub71
  %mul73 = shl nsw i32 %conv69, 3
  %idxprom74 = sext i32 %21 to i64
  %arrayidx75 = getelementptr inbounds i32* %type, i64 %idxprom74
  %25 = load i32* %arrayidx75, align 4, !tbaa !0
  %tmp = add i32 %25, %mul44
  %tmp766 = mul i32 %tmp, 3
  %idxprom78 = sext i32 %tmp766 to i64
  %arrayidx79 = getelementptr inbounds float* %nbfp, i64 %idxprom78
  %26 = load float* %arrayidx79, align 4, !tbaa !3
  %add80 = add nsw i32 %tmp766, 1
  %idxprom81 = sext i32 %add80 to i64
  %arrayidx82 = getelementptr inbounds float* %nbfp, i64 %idxprom81
  %27 = load float* %arrayidx82, align 4, !tbaa !3
  %add83 = add nsw i32 %tmp766, 2
  %idxprom84 = sext i32 %add83 to i64
  %arrayidx85 = getelementptr inbounds float* %nbfp, i64 %idxprom84
  %28 = load float* %arrayidx85, align 4, !tbaa !3
  %idxprom86 = sext i32 %mul73 to i64
  %arrayidx87 = getelementptr inbounds float* %VFtab, i64 %idxprom86
  %29 = load float* %arrayidx87, align 4, !tbaa !3
  %add88759 = or i32 %mul73, 1
  %idxprom89 = sext i32 %add88759 to i64
  %arrayidx90 = getelementptr inbounds float* %VFtab, i64 %idxprom89
  %30 = load float* %arrayidx90, align 4, !tbaa !3
  %add91760 = or i32 %mul73, 2
  %idxprom92 = sext i32 %add91760 to i64
  %arrayidx93 = getelementptr inbounds float* %VFtab, i64 %idxprom92
  %31 = load float* %arrayidx93, align 4, !tbaa !3
  %mul94 = fmul float %sub71, %31
  %add95761 = or i32 %mul73, 3
  %idxprom96 = sext i32 %add95761 to i64
  %arrayidx97 = getelementptr inbounds float* %VFtab, i64 %idxprom96
  %32 = load float* %arrayidx97, align 4, !tbaa !3
  %mul98 = fmul float %mul72, %32
  %add99 = fadd float %30, %mul94
  %add100 = fadd float %add99, %mul98
  %mul101 = fmul float %sub71, %add100
  %add102 = fadd float %29, %mul101
  %add103 = fadd float %mul94, %add100
  %mul104 = fmul float %mul98, 2.000000e+00
  %add105 = fadd float %mul104, %add103
  %mul106 = fmul float %26, %add102
  %mul107 = fmul float %26, %add105
  %mul108 = fmul float %mul67, %28
  %mul109 = fmul float %mul108, %exptabscale
  %conv110 = fptosi float %mul109 to i32
  %conv111 = sitofp i32 %conv110 to float
  %sub112 = fsub float %mul109, %conv111
  %mul113 = fmul float %sub112, %sub112
  %mul114 = shl nsw i32 %conv110, 3
  %add115762 = or i32 %mul114, 4
  %idxprom116 = sext i32 %add115762 to i64
  %arrayidx117 = getelementptr inbounds float* %VFtab, i64 %idxprom116
  %33 = load float* %arrayidx117, align 4, !tbaa !3
  %add118763 = or i32 %mul114, 5
  %idxprom119 = sext i32 %add118763 to i64
  %arrayidx120 = getelementptr inbounds float* %VFtab, i64 %idxprom119
  %34 = load float* %arrayidx120, align 4, !tbaa !3
  %add121764 = or i32 %mul114, 6
  %idxprom122 = sext i32 %add121764 to i64
  %arrayidx123 = getelementptr inbounds float* %VFtab, i64 %idxprom122
  %35 = load float* %arrayidx123, align 4, !tbaa !3
  %mul124 = fmul float %sub112, %35
  %add125765 = or i32 %mul114, 7
  %idxprom126 = sext i32 %add125765 to i64
  %arrayidx127 = getelementptr inbounds float* %VFtab, i64 %idxprom126
  %36 = load float* %arrayidx127, align 4, !tbaa !3
  %mul128 = fmul float %mul113, %36
  %add129 = fadd float %34, %mul124
  %add130 = fadd float %add129, %mul128
  %mul131 = fmul float %sub112, %add130
  %add132 = fadd float %33, %mul131
  %add133 = fadd float %mul124, %add130
  %mul134 = fmul float %mul128, 2.000000e+00
  %add135 = fadd float %mul134, %add133
  %mul136 = fmul float %27, %add132
  %mul137 = fmul float %27, %28
  %mul138 = fmul float %mul137, %add135
  %add139 = fadd float %vnbtot.1770, %mul106
  %add140 = fadd float %add139, %mul136
  %mul141 = fmul float %mul107, %tabscale
  %mul142 = fmul float %mul138, %exptabscale
  %add143 = fadd float %mul141, %mul142
  %37 = fmul float %conv66, %add143
  %mul145 = fsub float -0.000000e+00, %37
  %mul146 = fmul float %sub, %mul145
  %mul147 = fmul float %sub59, %mul145
  %mul148 = fmul float %sub60, %mul145
  %add149 = fadd float %fix1.0771, %mul146
  %add150 = fadd float %fiy1.0772, %mul147
  %add151 = fadd float %fiz1.0773, %mul148
  %arrayidx153 = getelementptr inbounds float* %faction, i64 %idxprom51
  %38 = load float* %arrayidx153, align 4, !tbaa !3
  %sub154 = fsub float %38, %mul146
  store float %sub154, float* %arrayidx153, align 4, !tbaa !3
  %arrayidx159 = getelementptr inbounds float* %faction, i64 %idxprom54
  %39 = load float* %arrayidx159, align 4, !tbaa !3
  %sub160 = fsub float %39, %mul147
  store float %sub160, float* %arrayidx159, align 4, !tbaa !3
  %arrayidx166 = getelementptr inbounds float* %faction, i64 %idxprom57
  %40 = load float* %arrayidx166, align 4, !tbaa !3
  %sub167 = fsub float %40, %mul148
  store float %sub167, float* %arrayidx166, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %41 = trunc i64 %indvars.iv.next to i32
  %cmp46 = icmp slt i32 %41, %10
  br i1 %cmp46, label %for.body47, label %for.end

for.end:                                          ; preds = %for.body47, %for.body29
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add151, %for.body47 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add150, %for.body47 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add149, %for.body47 ]
  %vnbtot.1.lcssa = phi float [ %vnbtot.0779, %for.body29 ], [ %add140, %for.body47 ]
  %arrayidx172 = getelementptr inbounds float* %faction, i64 %indvars.iv805
  %42 = load float* %arrayidx172, align 4, !tbaa !3
  %add173 = fadd float %fix1.0.lcssa, %42
  store float %add173, float* %arrayidx172, align 4, !tbaa !3
  %arrayidx178 = getelementptr inbounds float* %faction, i64 %16
  %43 = load float* %arrayidx178, align 4, !tbaa !3
  %add179 = fadd float %fiy1.0.lcssa, %43
  store float %add179, float* %arrayidx178, align 4, !tbaa !3
  %arrayidx185 = getelementptr inbounds float* %faction, i64 %18
  %44 = load float* %arrayidx185, align 4, !tbaa !3
  %add186 = fadd float %fiz1.0.lcssa, %44
  store float %add186, float* %arrayidx185, align 4, !tbaa !3
  %45 = load float* %arrayidx191, align 4, !tbaa !3
  %add192 = fadd float %fix1.0.lcssa, %45
  store float %add192, float* %arrayidx191, align 4, !tbaa !3
  %46 = load float* %arrayidx197, align 4, !tbaa !3
  %add198 = fadd float %fiy1.0.lcssa, %46
  store float %add198, float* %arrayidx197, align 4, !tbaa !3
  %47 = load float* %arrayidx204, align 4, !tbaa !3
  %add205 = fadd float %fiz1.0.lcssa, %47
  store float %add205, float* %arrayidx204, align 4, !tbaa !3
  %indvars.iv.next804 = add i64 %indvars.iv803, 1
  %indvars.iv.next806 = add i64 %indvars.iv805, 3
  %inc212 = add nsw i32 %s.0780, 1
  %exitcond = icmp eq i32 %inc212, %2
  br i1 %exitcond, label %for.cond27.for.end213_crit_edge, label %for.body29

for.cond27.for.end213_crit_edge:                  ; preds = %for.end
  %48 = add i32 %2, %8
  br label %for.end213

for.end213:                                       ; preds = %for.cond27.for.end213_crit_edge, %for.body
  %ii.0.lcssa = phi i32 [ %48, %for.cond27.for.end213_crit_edge ], [ %8, %for.body ]
  %vnbtot.0.lcssa = phi float [ %vnbtot.1.lcssa, %for.cond27.for.end213_crit_edge ], [ 0.000000e+00, %for.body ]
  %cmp218795 = icmp slt i32 %3, %1
  br i1 %cmp218795, label %for.body220.lr.ph, label %for.end412

for.body220.lr.ph:                                ; preds = %for.end213
  %cmp237785 = icmp slt i32 %9, %10
  %arrayidx390 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx396 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx403 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %49 = sext i32 %9 to i64
  %50 = add i32 %ii.0.lcssa, %3
  %51 = sub i32 %50, %2
  %52 = sext i32 %51 to i64
  %53 = mul i32 %51, 3
  %54 = sext i32 %53 to i64
  br label %for.body220

for.body220:                                      ; preds = %for.end369, %for.body220.lr.ph
  %indvars.iv813 = phi i64 [ %54, %for.body220.lr.ph ], [ %indvars.iv.next814, %for.end369 ]
  %indvars.iv811 = phi i64 [ %52, %for.body220.lr.ph ], [ %indvars.iv.next812, %for.end369 ]
  %s.1797 = phi i32 [ %3, %for.body220.lr.ph ], [ %inc411, %for.end369 ]
  %vnbtot.2796 = phi float [ %vnbtot.0.lcssa, %for.body220.lr.ph ], [ %vnbtot.3.lcssa, %for.end369 ]
  %arrayidx222 = getelementptr inbounds float* %pos, i64 %indvars.iv813
  %55 = load float* %arrayidx222, align 4, !tbaa !3
  %add223 = fadd float %5, %55
  %56 = add nsw i64 %indvars.iv813, 1
  %arrayidx226 = getelementptr inbounds float* %pos, i64 %56
  %57 = load float* %arrayidx226, align 4, !tbaa !3
  %add227 = fadd float %6, %57
  %58 = add nsw i64 %indvars.iv813, 2
  %arrayidx230 = getelementptr inbounds float* %pos, i64 %58
  %59 = load float* %arrayidx230, align 4, !tbaa !3
  %add231 = fadd float %7, %59
  %arrayidx234 = getelementptr inbounds i32* %type, i64 %indvars.iv811
  %60 = load i32* %arrayidx234, align 4, !tbaa !0
  %mul235 = mul i32 %60, %ntype
  br i1 %cmp237785, label %for.body239, label %for.end369

for.body239:                                      ; preds = %for.body220, %for.body239
  %indvars.iv809 = phi i64 [ %indvars.iv.next810, %for.body239 ], [ %49, %for.body220 ]
  %fiz1.1789 = phi float [ %add347, %for.body239 ], [ 0.000000e+00, %for.body220 ]
  %fiy1.1788 = phi float [ %add346, %for.body239 ], [ 0.000000e+00, %for.body220 ]
  %fix1.1787 = phi float [ %add345, %for.body239 ], [ 0.000000e+00, %for.body220 ]
  %vnbtot.3786 = phi float [ %add336, %for.body239 ], [ %vnbtot.2796, %for.body220 ]
  %arrayidx241 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv809
  %61 = load i32* %arrayidx241, align 4, !tbaa !0
  %mul242 = mul nsw i32 %61, 3
  %idxprom243 = sext i32 %mul242 to i64
  %arrayidx244 = getelementptr inbounds float* %pos, i64 %idxprom243
  %62 = load float* %arrayidx244, align 4, !tbaa !3
  %add245 = add nsw i32 %mul242, 1
  %idxprom246 = sext i32 %add245 to i64
  %arrayidx247 = getelementptr inbounds float* %pos, i64 %idxprom246
  %63 = load float* %arrayidx247, align 4, !tbaa !3
  %add248 = add nsw i32 %mul242, 2
  %idxprom249 = sext i32 %add248 to i64
  %arrayidx250 = getelementptr inbounds float* %pos, i64 %idxprom249
  %64 = load float* %arrayidx250, align 4, !tbaa !3
  %sub251 = fsub float %add223, %62
  %sub252 = fsub float %add227, %63
  %sub253 = fsub float %add231, %64
  %mul254 = fmul float %sub251, %sub251
  %mul255 = fmul float %sub252, %sub252
  %add256 = fadd float %mul254, %mul255
  %mul257 = fmul float %sub253, %sub253
  %add258 = fadd float %add256, %mul257
  %conv259 = fpext float %add258 to double
  %call260 = tail call double @sqrt(double %conv259) #2
  %div261 = fdiv double 1.000000e+00, %call260
  %conv262 = fptrunc double %div261 to float
  %mul263 = fmul float %add258, %conv262
  %mul264 = fmul float %mul263, %tabscale
  %conv265 = fptosi float %mul264 to i32
  %conv266 = sitofp i32 %conv265 to float
  %sub267 = fsub float %mul264, %conv266
  %mul268 = fmul float %sub267, %sub267
  %mul269 = shl nsw i32 %conv265, 3
  %idxprom270 = sext i32 %61 to i64
  %arrayidx271 = getelementptr inbounds i32* %type, i64 %idxprom270
  %65 = load i32* %arrayidx271, align 4, !tbaa !0
  %tmp767 = add i32 %65, %mul235
  %tmp768 = mul i32 %tmp767, 3
  %idxprom274 = sext i32 %tmp768 to i64
  %arrayidx275 = getelementptr inbounds float* %nbfp, i64 %idxprom274
  %66 = load float* %arrayidx275, align 4, !tbaa !3
  %add276 = add nsw i32 %tmp768, 1
  %idxprom277 = sext i32 %add276 to i64
  %arrayidx278 = getelementptr inbounds float* %nbfp, i64 %idxprom277
  %67 = load float* %arrayidx278, align 4, !tbaa !3
  %add279 = add nsw i32 %tmp768, 2
  %idxprom280 = sext i32 %add279 to i64
  %arrayidx281 = getelementptr inbounds float* %nbfp, i64 %idxprom280
  %68 = load float* %arrayidx281, align 4, !tbaa !3
  %idxprom282 = sext i32 %mul269 to i64
  %arrayidx283 = getelementptr inbounds float* %VFtab, i64 %idxprom282
  %69 = load float* %arrayidx283, align 4, !tbaa !3
  %add284752 = or i32 %mul269, 1
  %idxprom285 = sext i32 %add284752 to i64
  %arrayidx286 = getelementptr inbounds float* %VFtab, i64 %idxprom285
  %70 = load float* %arrayidx286, align 4, !tbaa !3
  %add287753 = or i32 %mul269, 2
  %idxprom288 = sext i32 %add287753 to i64
  %arrayidx289 = getelementptr inbounds float* %VFtab, i64 %idxprom288
  %71 = load float* %arrayidx289, align 4, !tbaa !3
  %mul290 = fmul float %sub267, %71
  %add291754 = or i32 %mul269, 3
  %idxprom292 = sext i32 %add291754 to i64
  %arrayidx293 = getelementptr inbounds float* %VFtab, i64 %idxprom292
  %72 = load float* %arrayidx293, align 4, !tbaa !3
  %mul294 = fmul float %mul268, %72
  %add295 = fadd float %70, %mul290
  %add296 = fadd float %add295, %mul294
  %mul297 = fmul float %sub267, %add296
  %add298 = fadd float %69, %mul297
  %add299 = fadd float %mul290, %add296
  %mul300 = fmul float %mul294, 2.000000e+00
  %add301 = fadd float %mul300, %add299
  %mul302 = fmul float %66, %add298
  %mul303 = fmul float %66, %add301
  %mul304 = fmul float %mul263, %68
  %mul305 = fmul float %mul304, %exptabscale
  %conv306 = fptosi float %mul305 to i32
  %conv307 = sitofp i32 %conv306 to float
  %sub308 = fsub float %mul305, %conv307
  %mul309 = fmul float %sub308, %sub308
  %mul310 = shl nsw i32 %conv306, 3
  %add311755 = or i32 %mul310, 4
  %idxprom312 = sext i32 %add311755 to i64
  %arrayidx313 = getelementptr inbounds float* %VFtab, i64 %idxprom312
  %73 = load float* %arrayidx313, align 4, !tbaa !3
  %add314756 = or i32 %mul310, 5
  %idxprom315 = sext i32 %add314756 to i64
  %arrayidx316 = getelementptr inbounds float* %VFtab, i64 %idxprom315
  %74 = load float* %arrayidx316, align 4, !tbaa !3
  %add317757 = or i32 %mul310, 6
  %idxprom318 = sext i32 %add317757 to i64
  %arrayidx319 = getelementptr inbounds float* %VFtab, i64 %idxprom318
  %75 = load float* %arrayidx319, align 4, !tbaa !3
  %mul320 = fmul float %sub308, %75
  %add321758 = or i32 %mul310, 7
  %idxprom322 = sext i32 %add321758 to i64
  %arrayidx323 = getelementptr inbounds float* %VFtab, i64 %idxprom322
  %76 = load float* %arrayidx323, align 4, !tbaa !3
  %mul324 = fmul float %mul309, %76
  %add325 = fadd float %74, %mul320
  %add326 = fadd float %add325, %mul324
  %mul327 = fmul float %sub308, %add326
  %add328 = fadd float %73, %mul327
  %add329 = fadd float %mul320, %add326
  %mul330 = fmul float %mul324, 2.000000e+00
  %add331 = fadd float %mul330, %add329
  %mul332 = fmul float %67, %add328
  %mul333 = fmul float %67, %68
  %mul334 = fmul float %mul333, %add331
  %add335 = fadd float %vnbtot.3786, %mul302
  %add336 = fadd float %add335, %mul332
  %mul337 = fmul float %mul303, %tabscale
  %mul338 = fmul float %mul334, %exptabscale
  %add339 = fadd float %mul337, %mul338
  %77 = fmul float %conv262, %add339
  %mul341 = fsub float -0.000000e+00, %77
  %mul342 = fmul float %sub251, %mul341
  %mul343 = fmul float %sub252, %mul341
  %mul344 = fmul float %sub253, %mul341
  %add345 = fadd float %fix1.1787, %mul342
  %add346 = fadd float %fiy1.1788, %mul343
  %add347 = fadd float %fiz1.1789, %mul344
  %arrayidx349 = getelementptr inbounds float* %faction, i64 %idxprom243
  %78 = load float* %arrayidx349, align 4, !tbaa !3
  %sub350 = fsub float %78, %mul342
  store float %sub350, float* %arrayidx349, align 4, !tbaa !3
  %arrayidx355 = getelementptr inbounds float* %faction, i64 %idxprom246
  %79 = load float* %arrayidx355, align 4, !tbaa !3
  %sub356 = fsub float %79, %mul343
  store float %sub356, float* %arrayidx355, align 4, !tbaa !3
  %arrayidx362 = getelementptr inbounds float* %faction, i64 %idxprom249
  %80 = load float* %arrayidx362, align 4, !tbaa !3
  %sub363 = fsub float %80, %mul344
  store float %sub363, float* %arrayidx362, align 4, !tbaa !3
  %indvars.iv.next810 = add i64 %indvars.iv809, 1
  %81 = trunc i64 %indvars.iv.next810 to i32
  %cmp237 = icmp slt i32 %81, %10
  br i1 %cmp237, label %for.body239, label %for.end369

for.end369:                                       ; preds = %for.body239, %for.body220
  %fiz1.1.lcssa = phi float [ 0.000000e+00, %for.body220 ], [ %add347, %for.body239 ]
  %fiy1.1.lcssa = phi float [ 0.000000e+00, %for.body220 ], [ %add346, %for.body239 ]
  %fix1.1.lcssa = phi float [ 0.000000e+00, %for.body220 ], [ %add345, %for.body239 ]
  %vnbtot.3.lcssa = phi float [ %vnbtot.2796, %for.body220 ], [ %add336, %for.body239 ]
  %arrayidx371 = getelementptr inbounds float* %faction, i64 %indvars.iv813
  %82 = load float* %arrayidx371, align 4, !tbaa !3
  %add372 = fadd float %fix1.1.lcssa, %82
  store float %add372, float* %arrayidx371, align 4, !tbaa !3
  %arrayidx377 = getelementptr inbounds float* %faction, i64 %56
  %83 = load float* %arrayidx377, align 4, !tbaa !3
  %add378 = fadd float %fiy1.1.lcssa, %83
  store float %add378, float* %arrayidx377, align 4, !tbaa !3
  %arrayidx384 = getelementptr inbounds float* %faction, i64 %58
  %84 = load float* %arrayidx384, align 4, !tbaa !3
  %add385 = fadd float %fiz1.1.lcssa, %84
  store float %add385, float* %arrayidx384, align 4, !tbaa !3
  %85 = load float* %arrayidx390, align 4, !tbaa !3
  %add391 = fadd float %fix1.1.lcssa, %85
  store float %add391, float* %arrayidx390, align 4, !tbaa !3
  %86 = load float* %arrayidx396, align 4, !tbaa !3
  %add397 = fadd float %fiy1.1.lcssa, %86
  store float %add397, float* %arrayidx396, align 4, !tbaa !3
  %87 = load float* %arrayidx403, align 4, !tbaa !3
  %add404 = fadd float %fiz1.1.lcssa, %87
  store float %add404, float* %arrayidx403, align 4, !tbaa !3
  %indvars.iv.next812 = add i64 %indvars.iv811, 1
  %indvars.iv.next814 = add i64 %indvars.iv813, 3
  %inc411 = add nsw i32 %s.1797, 1
  %exitcond817 = icmp eq i32 %inc411, %1
  br i1 %exitcond817, label %for.end412, label %for.body220

for.end412:                                       ; preds = %for.end369, %for.end213
  %vnbtot.2.lcssa = phi float [ %vnbtot.0.lcssa, %for.end213 ], [ %vnbtot.3.lcssa, %for.end369 ]
  %arrayidx414 = getelementptr inbounds i32* %gid, i64 %indvars.iv818
  %88 = load i32* %arrayidx414, align 4, !tbaa !0
  %idxprom415 = sext i32 %88 to i64
  %arrayidx416 = getelementptr inbounds float* %Vnb, i64 %idxprom415
  %89 = load float* %arrayidx416, align 4, !tbaa !3
  %add417 = fadd float %vnbtot.2.lcssa, %89
  store float %add417, float* %arrayidx416, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next819 to i32
  %exitcond820 = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond820, label %for.end422, label %for.body

for.end422:                                       ; preds = %for.end412, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl1000(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc) #0 {
entry:
  %cmp223 = icmp sgt i32 %nri, 0
  br i1 %cmp223, label %for.body, label %for.end131

for.body:                                         ; preds = %for.end, %entry
  %indvars.iv225 = phi i64 [ 0, %entry ], [ %indvars.iv.next226, %for.end ]
  %arrayidx = getelementptr inbounds i32* %shift, i64 %indvars.iv225
  %0 = load i32* %arrayidx, align 4, !tbaa !0
  %mul = mul nsw i32 %0, 3
  %idxprom1 = sext i32 %mul to i64
  %arrayidx2 = getelementptr inbounds float* %shiftvec, i64 %idxprom1
  %1 = load float* %arrayidx2, align 4, !tbaa !3
  %add = add nsw i32 %mul, 1
  %idxprom3 = sext i32 %add to i64
  %arrayidx4 = getelementptr inbounds float* %shiftvec, i64 %idxprom3
  %2 = load float* %arrayidx4, align 4, !tbaa !3
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds float* %shiftvec, i64 %idxprom6
  %3 = load float* %arrayidx7, align 4, !tbaa !3
  %arrayidx9 = getelementptr inbounds i32* %iinr, i64 %indvars.iv225
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %arrayidx12 = getelementptr inbounds i32* %jindex, i64 %indvars.iv225
  %5 = load i32* %arrayidx12, align 4, !tbaa !0
  %indvars.iv.next226 = add i64 %indvars.iv225, 1
  %arrayidx15 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next226
  %6 = load i32* %arrayidx15, align 4, !tbaa !0
  %idxprom16 = sext i32 %mul10 to i64
  %arrayidx17 = getelementptr inbounds float* %pos, i64 %idxprom16
  %7 = load float* %arrayidx17, align 4, !tbaa !3
  %add18 = fadd float %1, %7
  %add19 = add nsw i32 %mul10, 1
  %idxprom20 = sext i32 %add19 to i64
  %arrayidx21 = getelementptr inbounds float* %pos, i64 %idxprom20
  %8 = load float* %arrayidx21, align 4, !tbaa !3
  %add22 = fadd float %2, %8
  %add23 = add nsw i32 %mul10, 2
  %idxprom24 = sext i32 %add23 to i64
  %arrayidx25 = getelementptr inbounds float* %pos, i64 %idxprom24
  %9 = load float* %arrayidx25, align 4, !tbaa !3
  %add26 = fadd float %3, %9
  %idxprom27 = sext i32 %4 to i64
  %arrayidx28 = getelementptr inbounds float* %charge, i64 %idxprom27
  %10 = load float* %arrayidx28, align 4, !tbaa !3
  %mul29 = fmul float %10, %facel
  %cmp31214 = icmp slt i32 %5, %6
  br i1 %cmp31214, label %for.body32.lr.ph, label %for.end

for.body32.lr.ph:                                 ; preds = %for.body
  %11 = sext i32 %5 to i64
  br label %for.body32

for.body32:                                       ; preds = %for.body32.lr.ph, %for.body32
  %indvars.iv = phi i64 [ %11, %for.body32.lr.ph ], [ %indvars.iv.next, %for.body32 ]
  %vctot.0218 = phi float [ 0.000000e+00, %for.body32.lr.ph ], [ %add58, %for.body32 ]
  %fix1.0217 = phi float [ 0.000000e+00, %for.body32.lr.ph ], [ %add62, %for.body32 ]
  %fiy1.0216 = phi float [ 0.000000e+00, %for.body32.lr.ph ], [ %add63, %for.body32 ]
  %fiz1.0215 = phi float [ 0.000000e+00, %for.body32.lr.ph ], [ %add64, %for.body32 ]
  %arrayidx34 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %12 = load i32* %arrayidx34, align 4, !tbaa !0
  %mul35 = mul nsw i32 %12, 3
  %idxprom36 = sext i32 %mul35 to i64
  %arrayidx37 = getelementptr inbounds float* %pos, i64 %idxprom36
  %13 = load float* %arrayidx37, align 4, !tbaa !3
  %add38 = add nsw i32 %mul35, 1
  %idxprom39 = sext i32 %add38 to i64
  %arrayidx40 = getelementptr inbounds float* %pos, i64 %idxprom39
  %14 = load float* %arrayidx40, align 4, !tbaa !3
  %add41 = add nsw i32 %mul35, 2
  %idxprom42 = sext i32 %add41 to i64
  %arrayidx43 = getelementptr inbounds float* %pos, i64 %idxprom42
  %15 = load float* %arrayidx43, align 4, !tbaa !3
  %sub = fsub float %add18, %13
  %sub44 = fsub float %add22, %14
  %sub45 = fsub float %add26, %15
  %mul46 = fmul float %sub, %sub
  %mul47 = fmul float %sub44, %sub44
  %add48 = fadd float %mul46, %mul47
  %mul49 = fmul float %sub45, %sub45
  %add50 = fadd float %add48, %mul49
  %conv = fpext float %add50 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv51 = fptrunc double %div to float
  %mul52 = fmul float %conv51, %conv51
  %idxprom53 = sext i32 %12 to i64
  %arrayidx54 = getelementptr inbounds float* %charge, i64 %idxprom53
  %16 = load float* %arrayidx54, align 4, !tbaa !3
  %mul55 = fmul float %mul29, %16
  %mul56 = fmul float %conv51, %mul55
  %mul57 = fmul float %mul52, %mul56
  %add58 = fadd float %vctot.0218, %mul56
  %mul59 = fmul float %sub, %mul57
  %mul60 = fmul float %sub44, %mul57
  %mul61 = fmul float %sub45, %mul57
  %add62 = fadd float %fix1.0217, %mul59
  %add63 = fadd float %fiy1.0216, %mul60
  %add64 = fadd float %fiz1.0215, %mul61
  %arrayidx66 = getelementptr inbounds float* %faction, i64 %idxprom36
  %17 = load float* %arrayidx66, align 4, !tbaa !3
  %sub67 = fsub float %17, %mul59
  store float %sub67, float* %arrayidx66, align 4, !tbaa !3
  %arrayidx72 = getelementptr inbounds float* %faction, i64 %idxprom39
  %18 = load float* %arrayidx72, align 4, !tbaa !3
  %sub73 = fsub float %18, %mul60
  store float %sub73, float* %arrayidx72, align 4, !tbaa !3
  %arrayidx79 = getelementptr inbounds float* %faction, i64 %idxprom42
  %19 = load float* %arrayidx79, align 4, !tbaa !3
  %sub80 = fsub float %19, %mul61
  store float %sub80, float* %arrayidx79, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %20 = trunc i64 %indvars.iv.next to i32
  %cmp31 = icmp slt i32 %20, %6
  br i1 %cmp31, label %for.body32, label %for.end

for.end:                                          ; preds = %for.body32, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add58, %for.body32 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add62, %for.body32 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add63, %for.body32 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add64, %for.body32 ]
  %arrayidx85 = getelementptr inbounds float* %faction, i64 %idxprom16
  %21 = load float* %arrayidx85, align 4, !tbaa !3
  %add86 = fadd float %fix1.0.lcssa, %21
  store float %add86, float* %arrayidx85, align 4, !tbaa !3
  %arrayidx91 = getelementptr inbounds float* %faction, i64 %idxprom20
  %22 = load float* %arrayidx91, align 4, !tbaa !3
  %add92 = fadd float %fiy1.0.lcssa, %22
  store float %add92, float* %arrayidx91, align 4, !tbaa !3
  %arrayidx98 = getelementptr inbounds float* %faction, i64 %idxprom24
  %23 = load float* %arrayidx98, align 4, !tbaa !3
  %add99 = fadd float %fiz1.0.lcssa, %23
  store float %add99, float* %arrayidx98, align 4, !tbaa !3
  %arrayidx104 = getelementptr inbounds float* %fshift, i64 %idxprom1
  %24 = load float* %arrayidx104, align 4, !tbaa !3
  %add105 = fadd float %fix1.0.lcssa, %24
  store float %add105, float* %arrayidx104, align 4, !tbaa !3
  %arrayidx110 = getelementptr inbounds float* %fshift, i64 %idxprom3
  %25 = load float* %arrayidx110, align 4, !tbaa !3
  %add111 = fadd float %fiy1.0.lcssa, %25
  store float %add111, float* %arrayidx110, align 4, !tbaa !3
  %arrayidx117 = getelementptr inbounds float* %fshift, i64 %idxprom6
  %26 = load float* %arrayidx117, align 4, !tbaa !3
  %add118 = fadd float %fiz1.0.lcssa, %26
  store float %add118, float* %arrayidx117, align 4, !tbaa !3
  %arrayidx123 = getelementptr inbounds i32* %gid, i64 %indvars.iv225
  %27 = load i32* %arrayidx123, align 4, !tbaa !0
  %idxprom124 = sext i32 %27 to i64
  %arrayidx125 = getelementptr inbounds float* %Vc, i64 %idxprom124
  %28 = load float* %arrayidx125, align 4, !tbaa !3
  %add126 = fadd float %vctot.0.lcssa, %28
  store float %add126, float* %arrayidx125, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next226 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end131, label %for.body

for.end131:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl1010(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %nsatoms) #0 {
entry:
  %cmp256 = icmp sgt i32 %nri, 0
  br i1 %cmp256, label %for.body, label %for.end150

for.body:                                         ; preds = %for.end140, %entry
  %indvars.iv264 = phi i64 [ 0, %entry ], [ %indvars.iv.next265, %for.end140 ]
  %add5 = mul i64 %indvars.iv264, 12884901888
  %sext = add i64 %add5, 8589934592
  %idxprom6 = ashr exact i64 %sext, 32
  %arrayidx7 = getelementptr inbounds i32* %nsatoms, i64 %idxprom6
  %0 = load i32* %arrayidx7, align 4, !tbaa !0
  %arrayidx9 = getelementptr inbounds i32* %shift, i64 %indvars.iv264
  %1 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %1, 3
  %idxprom11 = sext i32 %mul10 to i64
  %arrayidx12 = getelementptr inbounds float* %shiftvec, i64 %idxprom11
  %2 = load float* %arrayidx12, align 4, !tbaa !3
  %add13 = add nsw i32 %mul10, 1
  %idxprom14 = sext i32 %add13 to i64
  %arrayidx15 = getelementptr inbounds float* %shiftvec, i64 %idxprom14
  %3 = load float* %arrayidx15, align 4, !tbaa !3
  %add16 = add nsw i32 %mul10, 2
  %idxprom17 = sext i32 %add16 to i64
  %arrayidx18 = getelementptr inbounds float* %shiftvec, i64 %idxprom17
  %4 = load float* %arrayidx18, align 4, !tbaa !3
  %arrayidx20 = getelementptr inbounds i32* %iinr, i64 %indvars.iv264
  %5 = load i32* %arrayidx20, align 4, !tbaa !0
  %arrayidx23 = getelementptr inbounds i32* %jindex, i64 %indvars.iv264
  %6 = load i32* %arrayidx23, align 4, !tbaa !0
  %indvars.iv.next265 = add i64 %indvars.iv264, 1
  %arrayidx26 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next265
  %7 = load i32* %arrayidx26, align 4, !tbaa !0
  %cmp28250 = icmp sgt i32 %0, 0
  br i1 %cmp28250, label %for.body29.lr.ph, label %for.end140

for.body29.lr.ph:                                 ; preds = %for.body
  %cmp45241 = icmp slt i32 %6, %7
  %arrayidx118 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx124 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx131 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %8 = sext i32 %6 to i64
  %9 = sext i32 %5 to i64
  %10 = mul i32 %5, 3
  %11 = sext i32 %10 to i64
  br label %for.body29

for.body29:                                       ; preds = %for.end, %for.body29.lr.ph
  %indvars.iv260 = phi i64 [ %11, %for.body29.lr.ph ], [ %indvars.iv.next261, %for.end ]
  %indvars.iv258 = phi i64 [ %9, %for.body29.lr.ph ], [ %indvars.iv.next259, %for.end ]
  %s.0252 = phi i32 [ 0, %for.body29.lr.ph ], [ %inc139, %for.end ]
  %vctot.0251 = phi float [ 0.000000e+00, %for.body29.lr.ph ], [ %vctot.1.lcssa, %for.end ]
  %arrayidx31 = getelementptr inbounds float* %pos, i64 %indvars.iv260
  %12 = load float* %arrayidx31, align 4, !tbaa !3
  %add32 = fadd float %2, %12
  %13 = add nsw i64 %indvars.iv260, 1
  %arrayidx35 = getelementptr inbounds float* %pos, i64 %13
  %14 = load float* %arrayidx35, align 4, !tbaa !3
  %add36 = fadd float %3, %14
  %15 = add nsw i64 %indvars.iv260, 2
  %arrayidx39 = getelementptr inbounds float* %pos, i64 %15
  %16 = load float* %arrayidx39, align 4, !tbaa !3
  %add40 = fadd float %4, %16
  %arrayidx42 = getelementptr inbounds float* %charge, i64 %indvars.iv258
  %17 = load float* %arrayidx42, align 4, !tbaa !3
  %mul43 = fmul float %17, %facel
  br i1 %cmp45241, label %for.body46, label %for.end

for.body46:                                       ; preds = %for.body29, %for.body46
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body46 ], [ %8, %for.body29 ]
  %vctot.1245 = phi float [ %add72, %for.body46 ], [ %vctot.0251, %for.body29 ]
  %fix1.0244 = phi float [ %add76, %for.body46 ], [ 0.000000e+00, %for.body29 ]
  %fiy1.0243 = phi float [ %add77, %for.body46 ], [ 0.000000e+00, %for.body29 ]
  %fiz1.0242 = phi float [ %add78, %for.body46 ], [ 0.000000e+00, %for.body29 ]
  %arrayidx48 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %18 = load i32* %arrayidx48, align 4, !tbaa !0
  %mul49 = mul nsw i32 %18, 3
  %idxprom50 = sext i32 %mul49 to i64
  %arrayidx51 = getelementptr inbounds float* %pos, i64 %idxprom50
  %19 = load float* %arrayidx51, align 4, !tbaa !3
  %add52 = add nsw i32 %mul49, 1
  %idxprom53 = sext i32 %add52 to i64
  %arrayidx54 = getelementptr inbounds float* %pos, i64 %idxprom53
  %20 = load float* %arrayidx54, align 4, !tbaa !3
  %add55 = add nsw i32 %mul49, 2
  %idxprom56 = sext i32 %add55 to i64
  %arrayidx57 = getelementptr inbounds float* %pos, i64 %idxprom56
  %21 = load float* %arrayidx57, align 4, !tbaa !3
  %sub = fsub float %add32, %19
  %sub58 = fsub float %add36, %20
  %sub59 = fsub float %add40, %21
  %mul60 = fmul float %sub, %sub
  %mul61 = fmul float %sub58, %sub58
  %add62 = fadd float %mul60, %mul61
  %mul63 = fmul float %sub59, %sub59
  %add64 = fadd float %add62, %mul63
  %conv = fpext float %add64 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv65 = fptrunc double %div to float
  %mul66 = fmul float %conv65, %conv65
  %idxprom67 = sext i32 %18 to i64
  %arrayidx68 = getelementptr inbounds float* %charge, i64 %idxprom67
  %22 = load float* %arrayidx68, align 4, !tbaa !3
  %mul69 = fmul float %mul43, %22
  %mul70 = fmul float %conv65, %mul69
  %mul71 = fmul float %mul66, %mul70
  %add72 = fadd float %vctot.1245, %mul70
  %mul73 = fmul float %sub, %mul71
  %mul74 = fmul float %sub58, %mul71
  %mul75 = fmul float %sub59, %mul71
  %add76 = fadd float %fix1.0244, %mul73
  %add77 = fadd float %fiy1.0243, %mul74
  %add78 = fadd float %fiz1.0242, %mul75
  %arrayidx80 = getelementptr inbounds float* %faction, i64 %idxprom50
  %23 = load float* %arrayidx80, align 4, !tbaa !3
  %sub81 = fsub float %23, %mul73
  store float %sub81, float* %arrayidx80, align 4, !tbaa !3
  %arrayidx86 = getelementptr inbounds float* %faction, i64 %idxprom53
  %24 = load float* %arrayidx86, align 4, !tbaa !3
  %sub87 = fsub float %24, %mul74
  store float %sub87, float* %arrayidx86, align 4, !tbaa !3
  %arrayidx93 = getelementptr inbounds float* %faction, i64 %idxprom56
  %25 = load float* %arrayidx93, align 4, !tbaa !3
  %sub94 = fsub float %25, %mul75
  store float %sub94, float* %arrayidx93, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %26 = trunc i64 %indvars.iv.next to i32
  %cmp45 = icmp slt i32 %26, %7
  br i1 %cmp45, label %for.body46, label %for.end

for.end:                                          ; preds = %for.body46, %for.body29
  %vctot.1.lcssa = phi float [ %vctot.0251, %for.body29 ], [ %add72, %for.body46 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add76, %for.body46 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add77, %for.body46 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add78, %for.body46 ]
  %arrayidx99 = getelementptr inbounds float* %faction, i64 %indvars.iv260
  %27 = load float* %arrayidx99, align 4, !tbaa !3
  %add100 = fadd float %fix1.0.lcssa, %27
  store float %add100, float* %arrayidx99, align 4, !tbaa !3
  %arrayidx105 = getelementptr inbounds float* %faction, i64 %13
  %28 = load float* %arrayidx105, align 4, !tbaa !3
  %add106 = fadd float %fiy1.0.lcssa, %28
  store float %add106, float* %arrayidx105, align 4, !tbaa !3
  %arrayidx112 = getelementptr inbounds float* %faction, i64 %15
  %29 = load float* %arrayidx112, align 4, !tbaa !3
  %add113 = fadd float %fiz1.0.lcssa, %29
  store float %add113, float* %arrayidx112, align 4, !tbaa !3
  %30 = load float* %arrayidx118, align 4, !tbaa !3
  %add119 = fadd float %fix1.0.lcssa, %30
  store float %add119, float* %arrayidx118, align 4, !tbaa !3
  %31 = load float* %arrayidx124, align 4, !tbaa !3
  %add125 = fadd float %fiy1.0.lcssa, %31
  store float %add125, float* %arrayidx124, align 4, !tbaa !3
  %32 = load float* %arrayidx131, align 4, !tbaa !3
  %add132 = fadd float %fiz1.0.lcssa, %32
  store float %add132, float* %arrayidx131, align 4, !tbaa !3
  %indvars.iv.next259 = add i64 %indvars.iv258, 1
  %indvars.iv.next261 = add i64 %indvars.iv260, 3
  %inc139 = add nsw i32 %s.0252, 1
  %exitcond = icmp eq i32 %inc139, %0
  br i1 %exitcond, label %for.end140, label %for.body29

for.end140:                                       ; preds = %for.end, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %vctot.1.lcssa, %for.end ]
  %arrayidx142 = getelementptr inbounds i32* %gid, i64 %indvars.iv264
  %33 = load i32* %arrayidx142, align 4, !tbaa !0
  %idxprom143 = sext i32 %33 to i64
  %arrayidx144 = getelementptr inbounds float* %Vc, i64 %idxprom143
  %34 = load float* %arrayidx144, align 4, !tbaa !3
  %add145 = fadd float %vctot.0.lcssa, %34
  store float %add145, float* %arrayidx144, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next265 to i32
  %exitcond266 = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond266, label %for.end150, label %for.body

for.end150:                                       ; preds = %for.end140, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl1020(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc) #0 {
entry:
  %0 = load i32* %iinr, align 4, !tbaa !0
  %idxprom = sext i32 %0 to i64
  %arrayidx1 = getelementptr inbounds float* %charge, i64 %idxprom
  %1 = load float* %arrayidx1, align 4, !tbaa !3
  %add = add nsw i32 %0, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds float* %charge, i64 %idxprom2
  %2 = load float* %arrayidx3, align 4, !tbaa !3
  %mul = fmul float %1, %facel
  %mul4 = fmul float %2, %facel
  %cmp476 = icmp sgt i32 %nri, 0
  br i1 %cmp476, label %for.body, label %for.end264

for.body:                                         ; preds = %entry, %for.end.for.body_crit_edge
  %3 = phi i32 [ %.pre, %for.end.for.body_crit_edge ], [ %0, %entry ]
  %indvars.iv478 = phi i64 [ %indvars.iv.next479, %for.end.for.body_crit_edge ], [ 0, %entry ]
  %arrayidx6 = getelementptr inbounds i32* %shift, i64 %indvars.iv478
  %4 = load i32* %arrayidx6, align 4, !tbaa !0
  %mul7 = mul nsw i32 %4, 3
  %idxprom8 = sext i32 %mul7 to i64
  %arrayidx9 = getelementptr inbounds float* %shiftvec, i64 %idxprom8
  %5 = load float* %arrayidx9, align 4, !tbaa !3
  %add10 = add nsw i32 %mul7, 1
  %idxprom11 = sext i32 %add10 to i64
  %arrayidx12 = getelementptr inbounds float* %shiftvec, i64 %idxprom11
  %6 = load float* %arrayidx12, align 4, !tbaa !3
  %add13 = add nsw i32 %mul7, 2
  %idxprom14 = sext i32 %add13 to i64
  %arrayidx15 = getelementptr inbounds float* %shiftvec, i64 %idxprom14
  %7 = load float* %arrayidx15, align 4, !tbaa !3
  %mul18 = mul nsw i32 %3, 3
  %arrayidx20 = getelementptr inbounds i32* %jindex, i64 %indvars.iv478
  %8 = load i32* %arrayidx20, align 4, !tbaa !0
  %indvars.iv.next479 = add i64 %indvars.iv478, 1
  %arrayidx23 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next479
  %9 = load i32* %arrayidx23, align 4, !tbaa !0
  %idxprom24 = sext i32 %mul18 to i64
  %arrayidx25 = getelementptr inbounds float* %pos, i64 %idxprom24
  %10 = load float* %arrayidx25, align 4, !tbaa !3
  %add26 = fadd float %5, %10
  %add27 = add nsw i32 %mul18, 1
  %idxprom28 = sext i32 %add27 to i64
  %arrayidx29 = getelementptr inbounds float* %pos, i64 %idxprom28
  %11 = load float* %arrayidx29, align 4, !tbaa !3
  %add30 = fadd float %6, %11
  %add31 = add nsw i32 %mul18, 2
  %idxprom32 = sext i32 %add31 to i64
  %arrayidx33 = getelementptr inbounds float* %pos, i64 %idxprom32
  %12 = load float* %arrayidx33, align 4, !tbaa !3
  %add34 = fadd float %7, %12
  %add35 = add nsw i32 %mul18, 3
  %idxprom36 = sext i32 %add35 to i64
  %arrayidx37 = getelementptr inbounds float* %pos, i64 %idxprom36
  %13 = load float* %arrayidx37, align 4, !tbaa !3
  %add38 = fadd float %5, %13
  %add39 = add nsw i32 %mul18, 4
  %idxprom40 = sext i32 %add39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %14 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = fadd float %6, %14
  %add43 = add nsw i32 %mul18, 5
  %idxprom44 = sext i32 %add43 to i64
  %arrayidx45 = getelementptr inbounds float* %pos, i64 %idxprom44
  %15 = load float* %arrayidx45, align 4, !tbaa !3
  %add46 = fadd float %7, %15
  %add47 = add nsw i32 %mul18, 6
  %idxprom48 = sext i32 %add47 to i64
  %arrayidx49 = getelementptr inbounds float* %pos, i64 %idxprom48
  %16 = load float* %arrayidx49, align 4, !tbaa !3
  %add50 = fadd float %5, %16
  %add51 = add nsw i32 %mul18, 7
  %idxprom52 = sext i32 %add51 to i64
  %arrayidx53 = getelementptr inbounds float* %pos, i64 %idxprom52
  %17 = load float* %arrayidx53, align 4, !tbaa !3
  %add54 = fadd float %6, %17
  %add55 = add nsw i32 %mul18, 8
  %idxprom56 = sext i32 %add55 to i64
  %arrayidx57 = getelementptr inbounds float* %pos, i64 %idxprom56
  %18 = load float* %arrayidx57, align 4, !tbaa !3
  %add58 = fadd float %7, %18
  %cmp60455 = icmp slt i32 %8, %9
  br i1 %cmp60455, label %for.body61.lr.ph, label %for.end

for.body61.lr.ph:                                 ; preds = %for.body
  %19 = sext i32 %8 to i64
  br label %for.body61

for.body61:                                       ; preds = %for.body61.lr.ph, %for.body61
  %indvars.iv = phi i64 [ %19, %for.body61.lr.ph ], [ %indvars.iv.next, %for.body61 ]
  %vctot.0465 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add151, %for.body61 ]
  %fix1.0464 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add115, %for.body61 ]
  %fiy1.0463 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add116, %for.body61 ]
  %fiz1.0462 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add117, %for.body61 ]
  %fix2.0461 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add139, %for.body61 ]
  %fiy2.0460 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add140, %for.body61 ]
  %fiz2.0459 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add141, %for.body61 ]
  %fix3.0458 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add155, %for.body61 ]
  %fiy3.0457 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add156, %for.body61 ]
  %fiz3.0456 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add157, %for.body61 ]
  %arrayidx63 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %20 = load i32* %arrayidx63, align 4, !tbaa !0
  %mul64 = mul nsw i32 %20, 3
  %idxprom65 = sext i32 %mul64 to i64
  %arrayidx66 = getelementptr inbounds float* %pos, i64 %idxprom65
  %21 = load float* %arrayidx66, align 4, !tbaa !3
  %add67 = add nsw i32 %mul64, 1
  %idxprom68 = sext i32 %add67 to i64
  %arrayidx69 = getelementptr inbounds float* %pos, i64 %idxprom68
  %22 = load float* %arrayidx69, align 4, !tbaa !3
  %add70 = add nsw i32 %mul64, 2
  %idxprom71 = sext i32 %add70 to i64
  %arrayidx72 = getelementptr inbounds float* %pos, i64 %idxprom71
  %23 = load float* %arrayidx72, align 4, !tbaa !3
  %sub = fsub float %add26, %21
  %sub73 = fsub float %add30, %22
  %sub74 = fsub float %add34, %23
  %mul75 = fmul float %sub, %sub
  %mul76 = fmul float %sub73, %sub73
  %add77 = fadd float %mul75, %mul76
  %mul78 = fmul float %sub74, %sub74
  %add79 = fadd float %add77, %mul78
  %sub80 = fsub float %add38, %21
  %sub81 = fsub float %add42, %22
  %sub82 = fsub float %add46, %23
  %mul83 = fmul float %sub80, %sub80
  %mul84 = fmul float %sub81, %sub81
  %add85 = fadd float %mul83, %mul84
  %mul86 = fmul float %sub82, %sub82
  %add87 = fadd float %add85, %mul86
  %sub88 = fsub float %add50, %21
  %sub89 = fsub float %add54, %22
  %sub90 = fsub float %add58, %23
  %mul91 = fmul float %sub88, %sub88
  %mul92 = fmul float %sub89, %sub89
  %add93 = fadd float %mul91, %mul92
  %mul94 = fmul float %sub90, %sub90
  %add95 = fadd float %add93, %mul94
  %conv = fpext float %add79 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv96 = fptrunc double %div to float
  %conv97 = fpext float %add87 to double
  %call98 = tail call double @sqrt(double %conv97) #2
  %div99 = fdiv double 1.000000e+00, %call98
  %conv100 = fptrunc double %div99 to float
  %conv101 = fpext float %add95 to double
  %call102 = tail call double @sqrt(double %conv101) #2
  %div103 = fdiv double 1.000000e+00, %call102
  %conv104 = fptrunc double %div103 to float
  %mul105 = fmul float %conv96, %conv96
  %idxprom106 = sext i32 %20 to i64
  %arrayidx107 = getelementptr inbounds float* %charge, i64 %idxprom106
  %24 = load float* %arrayidx107, align 4, !tbaa !3
  %mul108 = fmul float %mul, %24
  %mul109 = fmul float %conv96, %mul108
  %mul110 = fmul float %mul105, %mul109
  %add111 = fadd float %vctot.0465, %mul109
  %mul112 = fmul float %sub, %mul110
  %mul113 = fmul float %sub73, %mul110
  %mul114 = fmul float %sub74, %mul110
  %add115 = fadd float %fix1.0464, %mul112
  %add116 = fadd float %fiy1.0463, %mul113
  %add117 = fadd float %fiz1.0462, %mul114
  %arrayidx119 = getelementptr inbounds float* %faction, i64 %idxprom65
  %25 = load float* %arrayidx119, align 4, !tbaa !3
  %sub120 = fsub float %25, %mul112
  %arrayidx123 = getelementptr inbounds float* %faction, i64 %idxprom68
  %26 = load float* %arrayidx123, align 4, !tbaa !3
  %sub124 = fsub float %26, %mul113
  %arrayidx127 = getelementptr inbounds float* %faction, i64 %idxprom71
  %27 = load float* %arrayidx127, align 4, !tbaa !3
  %sub128 = fsub float %27, %mul114
  %mul129 = fmul float %conv100, %conv100
  %mul132 = fmul float %mul4, %24
  %mul133 = fmul float %conv100, %mul132
  %mul134 = fmul float %mul129, %mul133
  %add135 = fadd float %mul133, %add111
  %mul136 = fmul float %sub80, %mul134
  %mul137 = fmul float %sub81, %mul134
  %mul138 = fmul float %sub82, %mul134
  %add139 = fadd float %fix2.0461, %mul136
  %add140 = fadd float %fiy2.0460, %mul137
  %add141 = fadd float %fiz2.0459, %mul138
  %sub142 = fsub float %sub120, %mul136
  %sub143 = fsub float %sub124, %mul137
  %sub144 = fsub float %sub128, %mul138
  %mul145 = fmul float %conv104, %conv104
  %mul149 = fmul float %conv104, %mul132
  %mul150 = fmul float %mul145, %mul149
  %add151 = fadd float %mul149, %add135
  %mul152 = fmul float %sub88, %mul150
  %mul153 = fmul float %sub89, %mul150
  %mul154 = fmul float %sub90, %mul150
  %add155 = fadd float %fix3.0458, %mul152
  %add156 = fadd float %fiy3.0457, %mul153
  %add157 = fadd float %fiz3.0456, %mul154
  %sub158 = fsub float %sub142, %mul152
  store float %sub158, float* %arrayidx119, align 4, !tbaa !3
  %sub161 = fsub float %sub143, %mul153
  store float %sub161, float* %arrayidx123, align 4, !tbaa !3
  %sub165 = fsub float %sub144, %mul154
  store float %sub165, float* %arrayidx127, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %28 = trunc i64 %indvars.iv.next to i32
  %cmp60 = icmp slt i32 %28, %9
  br i1 %cmp60, label %for.body61, label %for.end

for.end:                                          ; preds = %for.body61, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add151, %for.body61 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add115, %for.body61 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add116, %for.body61 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add117, %for.body61 ]
  %fix2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add139, %for.body61 ]
  %fiy2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add140, %for.body61 ]
  %fiz2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add141, %for.body61 ]
  %fix3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add155, %for.body61 ]
  %fiy3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add156, %for.body61 ]
  %fiz3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add157, %for.body61 ]
  %arrayidx170 = getelementptr inbounds float* %faction, i64 %idxprom24
  %29 = load float* %arrayidx170, align 4, !tbaa !3
  %add171 = fadd float %fix1.0.lcssa, %29
  store float %add171, float* %arrayidx170, align 4, !tbaa !3
  %arrayidx176 = getelementptr inbounds float* %faction, i64 %idxprom28
  %30 = load float* %arrayidx176, align 4, !tbaa !3
  %add177 = fadd float %fiy1.0.lcssa, %30
  store float %add177, float* %arrayidx176, align 4, !tbaa !3
  %arrayidx183 = getelementptr inbounds float* %faction, i64 %idxprom32
  %31 = load float* %arrayidx183, align 4, !tbaa !3
  %add184 = fadd float %fiz1.0.lcssa, %31
  store float %add184, float* %arrayidx183, align 4, !tbaa !3
  %arrayidx190 = getelementptr inbounds float* %faction, i64 %idxprom36
  %32 = load float* %arrayidx190, align 4, !tbaa !3
  %add191 = fadd float %fix2.0.lcssa, %32
  store float %add191, float* %arrayidx190, align 4, !tbaa !3
  %arrayidx197 = getelementptr inbounds float* %faction, i64 %idxprom40
  %33 = load float* %arrayidx197, align 4, !tbaa !3
  %add198 = fadd float %fiy2.0.lcssa, %33
  store float %add198, float* %arrayidx197, align 4, !tbaa !3
  %arrayidx204 = getelementptr inbounds float* %faction, i64 %idxprom44
  %34 = load float* %arrayidx204, align 4, !tbaa !3
  %add205 = fadd float %fiz2.0.lcssa, %34
  store float %add205, float* %arrayidx204, align 4, !tbaa !3
  %arrayidx211 = getelementptr inbounds float* %faction, i64 %idxprom48
  %35 = load float* %arrayidx211, align 4, !tbaa !3
  %add212 = fadd float %fix3.0.lcssa, %35
  store float %add212, float* %arrayidx211, align 4, !tbaa !3
  %arrayidx218 = getelementptr inbounds float* %faction, i64 %idxprom52
  %36 = load float* %arrayidx218, align 4, !tbaa !3
  %add219 = fadd float %fiy3.0.lcssa, %36
  store float %add219, float* %arrayidx218, align 4, !tbaa !3
  %arrayidx225 = getelementptr inbounds float* %faction, i64 %idxprom56
  %37 = load float* %arrayidx225, align 4, !tbaa !3
  %add226 = fadd float %fiz3.0.lcssa, %37
  store float %add226, float* %arrayidx225, align 4, !tbaa !3
  %arrayidx231 = getelementptr inbounds float* %fshift, i64 %idxprom8
  %38 = load float* %arrayidx231, align 4, !tbaa !3
  %add232 = fadd float %fix1.0.lcssa, %38
  %add233 = fadd float %fix2.0.lcssa, %add232
  %add234 = fadd float %fix3.0.lcssa, %add233
  store float %add234, float* %arrayidx231, align 4, !tbaa !3
  %arrayidx239 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %39 = load float* %arrayidx239, align 4, !tbaa !3
  %add240 = fadd float %fiy1.0.lcssa, %39
  %add241 = fadd float %fiy2.0.lcssa, %add240
  %add242 = fadd float %fiy3.0.lcssa, %add241
  store float %add242, float* %arrayidx239, align 4, !tbaa !3
  %arrayidx248 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %40 = load float* %arrayidx248, align 4, !tbaa !3
  %add249 = fadd float %fiz1.0.lcssa, %40
  %add250 = fadd float %fiz2.0.lcssa, %add249
  %add251 = fadd float %fiz3.0.lcssa, %add250
  store float %add251, float* %arrayidx248, align 4, !tbaa !3
  %arrayidx256 = getelementptr inbounds i32* %gid, i64 %indvars.iv478
  %41 = load i32* %arrayidx256, align 4, !tbaa !0
  %idxprom257 = sext i32 %41 to i64
  %arrayidx258 = getelementptr inbounds float* %Vc, i64 %idxprom257
  %42 = load float* %arrayidx258, align 4, !tbaa !3
  %add259 = fadd float %vctot.0.lcssa, %42
  store float %add259, float* %arrayidx258, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next479 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end264, label %for.end.for.body_crit_edge

for.end.for.body_crit_edge:                       ; preds = %for.end
  %arrayidx17.phi.trans.insert = getelementptr inbounds i32* %iinr, i64 %indvars.iv.next479
  %.pre = load i32* %arrayidx17.phi.trans.insert, align 4, !tbaa !0
  br label %for.body

for.end264:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl1030(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc) #0 {
entry:
  %0 = load i32* %iinr, align 4, !tbaa !0
  %idxprom = sext i32 %0 to i64
  %arrayidx1 = getelementptr inbounds float* %charge, i64 %idxprom
  %1 = load float* %arrayidx1, align 4, !tbaa !3
  %add = add nsw i32 %0, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds float* %charge, i64 %idxprom2
  %2 = load float* %arrayidx3, align 4, !tbaa !3
  %mul = fmul float %1, %facel
  %mul4 = fmul float %1, %mul
  %mul6 = fmul float %mul, %2
  %mul7 = fmul float %2, %facel
  %mul8 = fmul float %2, %mul7
  %cmp861 = icmp sgt i32 %nri, 0
  br i1 %cmp861, label %for.body, label %for.end463

for.body:                                         ; preds = %entry, %for.end.for.body_crit_edge
  %3 = phi i32 [ %.pre, %for.end.for.body_crit_edge ], [ %0, %entry ]
  %indvars.iv863 = phi i64 [ %indvars.iv.next864, %for.end.for.body_crit_edge ], [ 0, %entry ]
  %arrayidx10 = getelementptr inbounds i32* %shift, i64 %indvars.iv863
  %4 = load i32* %arrayidx10, align 4, !tbaa !0
  %mul11 = mul nsw i32 %4, 3
  %idxprom12 = sext i32 %mul11 to i64
  %arrayidx13 = getelementptr inbounds float* %shiftvec, i64 %idxprom12
  %5 = load float* %arrayidx13, align 4, !tbaa !3
  %add14 = add nsw i32 %mul11, 1
  %idxprom15 = sext i32 %add14 to i64
  %arrayidx16 = getelementptr inbounds float* %shiftvec, i64 %idxprom15
  %6 = load float* %arrayidx16, align 4, !tbaa !3
  %add17 = add nsw i32 %mul11, 2
  %idxprom18 = sext i32 %add17 to i64
  %arrayidx19 = getelementptr inbounds float* %shiftvec, i64 %idxprom18
  %7 = load float* %arrayidx19, align 4, !tbaa !3
  %mul22 = mul nsw i32 %3, 3
  %arrayidx24 = getelementptr inbounds i32* %jindex, i64 %indvars.iv863
  %8 = load i32* %arrayidx24, align 4, !tbaa !0
  %indvars.iv.next864 = add i64 %indvars.iv863, 1
  %arrayidx27 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next864
  %9 = load i32* %arrayidx27, align 4, !tbaa !0
  %idxprom28 = sext i32 %mul22 to i64
  %arrayidx29 = getelementptr inbounds float* %pos, i64 %idxprom28
  %10 = load float* %arrayidx29, align 4, !tbaa !3
  %add30 = fadd float %5, %10
  %add31 = add nsw i32 %mul22, 1
  %idxprom32 = sext i32 %add31 to i64
  %arrayidx33 = getelementptr inbounds float* %pos, i64 %idxprom32
  %11 = load float* %arrayidx33, align 4, !tbaa !3
  %add34 = fadd float %6, %11
  %add35 = add nsw i32 %mul22, 2
  %idxprom36 = sext i32 %add35 to i64
  %arrayidx37 = getelementptr inbounds float* %pos, i64 %idxprom36
  %12 = load float* %arrayidx37, align 4, !tbaa !3
  %add38 = fadd float %7, %12
  %add39 = add nsw i32 %mul22, 3
  %idxprom40 = sext i32 %add39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %13 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = fadd float %5, %13
  %add43 = add nsw i32 %mul22, 4
  %idxprom44 = sext i32 %add43 to i64
  %arrayidx45 = getelementptr inbounds float* %pos, i64 %idxprom44
  %14 = load float* %arrayidx45, align 4, !tbaa !3
  %add46 = fadd float %6, %14
  %add47 = add nsw i32 %mul22, 5
  %idxprom48 = sext i32 %add47 to i64
  %arrayidx49 = getelementptr inbounds float* %pos, i64 %idxprom48
  %15 = load float* %arrayidx49, align 4, !tbaa !3
  %add50 = fadd float %7, %15
  %add51 = add nsw i32 %mul22, 6
  %idxprom52 = sext i32 %add51 to i64
  %arrayidx53 = getelementptr inbounds float* %pos, i64 %idxprom52
  %16 = load float* %arrayidx53, align 4, !tbaa !3
  %add54 = fadd float %5, %16
  %add55 = add nsw i32 %mul22, 7
  %idxprom56 = sext i32 %add55 to i64
  %arrayidx57 = getelementptr inbounds float* %pos, i64 %idxprom56
  %17 = load float* %arrayidx57, align 4, !tbaa !3
  %add58 = fadd float %6, %17
  %add59 = add nsw i32 %mul22, 8
  %idxprom60 = sext i32 %add59 to i64
  %arrayidx61 = getelementptr inbounds float* %pos, i64 %idxprom60
  %18 = load float* %arrayidx61, align 4, !tbaa !3
  %add62 = fadd float %7, %18
  %cmp64840 = icmp slt i32 %8, %9
  br i1 %cmp64840, label %for.body65.lr.ph, label %for.end

for.body65.lr.ph:                                 ; preds = %for.body
  %19 = sext i32 %8 to i64
  br label %for.body65

for.body65:                                       ; preds = %for.body65.lr.ph, %for.body65
  %indvars.iv = phi i64 [ %19, %for.body65.lr.ph ], [ %indvars.iv.next, %for.body65 ]
  %vctot.0850 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add349, %for.body65 ]
  %fix1.0849 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add249, %for.body65 ]
  %fiy1.0848 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add250, %for.body65 ]
  %fiz1.0847 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add251, %for.body65 ]
  %fix2.0846 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add297, %for.body65 ]
  %fiy2.0845 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add298, %for.body65 ]
  %fiz2.0844 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add299, %for.body65 ]
  %fix3.0843 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add353, %for.body65 ]
  %fiy3.0842 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add354, %for.body65 ]
  %fiz3.0841 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add355, %for.body65 ]
  %arrayidx67 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %20 = load i32* %arrayidx67, align 4, !tbaa !0
  %mul68 = mul nsw i32 %20, 3
  %idxprom69 = sext i32 %mul68 to i64
  %arrayidx70 = getelementptr inbounds float* %pos, i64 %idxprom69
  %21 = load float* %arrayidx70, align 4, !tbaa !3
  %add71 = add nsw i32 %mul68, 1
  %idxprom72 = sext i32 %add71 to i64
  %arrayidx73 = getelementptr inbounds float* %pos, i64 %idxprom72
  %22 = load float* %arrayidx73, align 4, !tbaa !3
  %add74 = add nsw i32 %mul68, 2
  %idxprom75 = sext i32 %add74 to i64
  %arrayidx76 = getelementptr inbounds float* %pos, i64 %idxprom75
  %23 = load float* %arrayidx76, align 4, !tbaa !3
  %add77 = add nsw i32 %mul68, 3
  %idxprom78 = sext i32 %add77 to i64
  %arrayidx79 = getelementptr inbounds float* %pos, i64 %idxprom78
  %24 = load float* %arrayidx79, align 4, !tbaa !3
  %add80 = add nsw i32 %mul68, 4
  %idxprom81 = sext i32 %add80 to i64
  %arrayidx82 = getelementptr inbounds float* %pos, i64 %idxprom81
  %25 = load float* %arrayidx82, align 4, !tbaa !3
  %add83 = add nsw i32 %mul68, 5
  %idxprom84 = sext i32 %add83 to i64
  %arrayidx85 = getelementptr inbounds float* %pos, i64 %idxprom84
  %26 = load float* %arrayidx85, align 4, !tbaa !3
  %add86 = add nsw i32 %mul68, 6
  %idxprom87 = sext i32 %add86 to i64
  %arrayidx88 = getelementptr inbounds float* %pos, i64 %idxprom87
  %27 = load float* %arrayidx88, align 4, !tbaa !3
  %add89 = add nsw i32 %mul68, 7
  %idxprom90 = sext i32 %add89 to i64
  %arrayidx91 = getelementptr inbounds float* %pos, i64 %idxprom90
  %28 = load float* %arrayidx91, align 4, !tbaa !3
  %add92 = add nsw i32 %mul68, 8
  %idxprom93 = sext i32 %add92 to i64
  %arrayidx94 = getelementptr inbounds float* %pos, i64 %idxprom93
  %29 = load float* %arrayidx94, align 4, !tbaa !3
  %sub = fsub float %add30, %21
  %sub95 = fsub float %add34, %22
  %sub96 = fsub float %add38, %23
  %mul97 = fmul float %sub, %sub
  %mul98 = fmul float %sub95, %sub95
  %add99 = fadd float %mul97, %mul98
  %mul100 = fmul float %sub96, %sub96
  %add101 = fadd float %add99, %mul100
  %sub102 = fsub float %add30, %24
  %sub103 = fsub float %add34, %25
  %sub104 = fsub float %add38, %26
  %mul105 = fmul float %sub102, %sub102
  %mul106 = fmul float %sub103, %sub103
  %add107 = fadd float %mul105, %mul106
  %mul108 = fmul float %sub104, %sub104
  %add109 = fadd float %add107, %mul108
  %sub110 = fsub float %add30, %27
  %sub111 = fsub float %add34, %28
  %sub112 = fsub float %add38, %29
  %mul113 = fmul float %sub110, %sub110
  %mul114 = fmul float %sub111, %sub111
  %add115 = fadd float %mul113, %mul114
  %mul116 = fmul float %sub112, %sub112
  %add117 = fadd float %add115, %mul116
  %sub118 = fsub float %add42, %21
  %sub119 = fsub float %add46, %22
  %sub120 = fsub float %add50, %23
  %mul121 = fmul float %sub118, %sub118
  %mul122 = fmul float %sub119, %sub119
  %add123 = fadd float %mul121, %mul122
  %mul124 = fmul float %sub120, %sub120
  %add125 = fadd float %add123, %mul124
  %sub126 = fsub float %add42, %24
  %sub127 = fsub float %add46, %25
  %sub128 = fsub float %add50, %26
  %mul129 = fmul float %sub126, %sub126
  %mul130 = fmul float %sub127, %sub127
  %add131 = fadd float %mul129, %mul130
  %mul132 = fmul float %sub128, %sub128
  %add133 = fadd float %add131, %mul132
  %sub134 = fsub float %add42, %27
  %sub135 = fsub float %add46, %28
  %sub136 = fsub float %add50, %29
  %mul137 = fmul float %sub134, %sub134
  %mul138 = fmul float %sub135, %sub135
  %add139 = fadd float %mul137, %mul138
  %mul140 = fmul float %sub136, %sub136
  %add141 = fadd float %add139, %mul140
  %sub142 = fsub float %add54, %21
  %sub143 = fsub float %add58, %22
  %sub144 = fsub float %add62, %23
  %mul145 = fmul float %sub142, %sub142
  %mul146 = fmul float %sub143, %sub143
  %add147 = fadd float %mul145, %mul146
  %mul148 = fmul float %sub144, %sub144
  %add149 = fadd float %add147, %mul148
  %sub150 = fsub float %add54, %24
  %sub151 = fsub float %add58, %25
  %sub152 = fsub float %add62, %26
  %mul153 = fmul float %sub150, %sub150
  %mul154 = fmul float %sub151, %sub151
  %add155 = fadd float %mul153, %mul154
  %mul156 = fmul float %sub152, %sub152
  %add157 = fadd float %add155, %mul156
  %sub158 = fsub float %add54, %27
  %sub159 = fsub float %add58, %28
  %sub160 = fsub float %add62, %29
  %mul161 = fmul float %sub158, %sub158
  %mul162 = fmul float %sub159, %sub159
  %add163 = fadd float %mul161, %mul162
  %mul164 = fmul float %sub160, %sub160
  %add165 = fadd float %add163, %mul164
  %conv = fpext float %add101 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv166 = fptrunc double %div to float
  %conv167 = fpext float %add125 to double
  %call168 = tail call double @sqrt(double %conv167) #2
  %div169 = fdiv double 1.000000e+00, %call168
  %conv170 = fptrunc double %div169 to float
  %conv171 = fpext float %add149 to double
  %call172 = tail call double @sqrt(double %conv171) #2
  %div173 = fdiv double 1.000000e+00, %call172
  %conv174 = fptrunc double %div173 to float
  %conv175 = fpext float %add109 to double
  %call176 = tail call double @sqrt(double %conv175) #2
  %div177 = fdiv double 1.000000e+00, %call176
  %conv178 = fptrunc double %div177 to float
  %conv179 = fpext float %add133 to double
  %call180 = tail call double @sqrt(double %conv179) #2
  %div181 = fdiv double 1.000000e+00, %call180
  %conv182 = fptrunc double %div181 to float
  %conv183 = fpext float %add157 to double
  %call184 = tail call double @sqrt(double %conv183) #2
  %div185 = fdiv double 1.000000e+00, %call184
  %conv186 = fptrunc double %div185 to float
  %conv187 = fpext float %add117 to double
  %call188 = tail call double @sqrt(double %conv187) #2
  %div189 = fdiv double 1.000000e+00, %call188
  %conv190 = fptrunc double %div189 to float
  %conv191 = fpext float %add141 to double
  %call192 = tail call double @sqrt(double %conv191) #2
  %div193 = fdiv double 1.000000e+00, %call192
  %conv194 = fptrunc double %div193 to float
  %conv195 = fpext float %add165 to double
  %call196 = tail call double @sqrt(double %conv195) #2
  %div197 = fdiv double 1.000000e+00, %call196
  %conv198 = fptrunc double %div197 to float
  %mul199 = fmul float %conv166, %conv166
  %mul200 = fmul float %mul4, %conv166
  %mul201 = fmul float %mul200, %mul199
  %add202 = fadd float %vctot.0850, %mul200
  %mul203 = fmul float %sub, %mul201
  %mul204 = fmul float %sub95, %mul201
  %mul205 = fmul float %sub96, %mul201
  %add206 = fadd float %fix1.0849, %mul203
  %add207 = fadd float %fiy1.0848, %mul204
  %add208 = fadd float %fiz1.0847, %mul205
  %arrayidx210 = getelementptr inbounds float* %faction, i64 %idxprom69
  %30 = load float* %arrayidx210, align 4, !tbaa !3
  %sub211 = fsub float %30, %mul203
  %arrayidx214 = getelementptr inbounds float* %faction, i64 %idxprom72
  %31 = load float* %arrayidx214, align 4, !tbaa !3
  %sub215 = fsub float %31, %mul204
  %arrayidx218 = getelementptr inbounds float* %faction, i64 %idxprom75
  %32 = load float* %arrayidx218, align 4, !tbaa !3
  %sub219 = fsub float %32, %mul205
  %mul220 = fmul float %conv178, %conv178
  %mul221 = fmul float %mul6, %conv178
  %mul222 = fmul float %mul221, %mul220
  %add223 = fadd float %add202, %mul221
  %mul224 = fmul float %sub102, %mul222
  %mul225 = fmul float %sub103, %mul222
  %mul226 = fmul float %sub104, %mul222
  %add227 = fadd float %add206, %mul224
  %add228 = fadd float %add207, %mul225
  %add229 = fadd float %add208, %mul226
  %arrayidx232 = getelementptr inbounds float* %faction, i64 %idxprom78
  %33 = load float* %arrayidx232, align 4, !tbaa !3
  %sub233 = fsub float %33, %mul224
  %arrayidx236 = getelementptr inbounds float* %faction, i64 %idxprom81
  %34 = load float* %arrayidx236, align 4, !tbaa !3
  %sub237 = fsub float %34, %mul225
  %arrayidx240 = getelementptr inbounds float* %faction, i64 %idxprom84
  %35 = load float* %arrayidx240, align 4, !tbaa !3
  %sub241 = fsub float %35, %mul226
  %mul242 = fmul float %conv190, %conv190
  %mul243 = fmul float %mul6, %conv190
  %mul244 = fmul float %mul243, %mul242
  %add245 = fadd float %add223, %mul243
  %mul246 = fmul float %sub110, %mul244
  %mul247 = fmul float %sub111, %mul244
  %mul248 = fmul float %sub112, %mul244
  %add249 = fadd float %add227, %mul246
  %add250 = fadd float %add228, %mul247
  %add251 = fadd float %add229, %mul248
  %arrayidx254 = getelementptr inbounds float* %faction, i64 %idxprom87
  %36 = load float* %arrayidx254, align 4, !tbaa !3
  %sub255 = fsub float %36, %mul246
  %arrayidx258 = getelementptr inbounds float* %faction, i64 %idxprom90
  %37 = load float* %arrayidx258, align 4, !tbaa !3
  %sub259 = fsub float %37, %mul247
  %arrayidx262 = getelementptr inbounds float* %faction, i64 %idxprom93
  %38 = load float* %arrayidx262, align 4, !tbaa !3
  %sub263 = fsub float %38, %mul248
  %mul264 = fmul float %conv170, %conv170
  %mul265 = fmul float %mul6, %conv170
  %mul266 = fmul float %mul265, %mul264
  %add267 = fadd float %mul265, %add245
  %mul268 = fmul float %sub118, %mul266
  %mul269 = fmul float %sub119, %mul266
  %mul270 = fmul float %sub120, %mul266
  %add271 = fadd float %fix2.0846, %mul268
  %add272 = fadd float %fiy2.0845, %mul269
  %add273 = fadd float %fiz2.0844, %mul270
  %sub274 = fsub float %sub211, %mul268
  %sub275 = fsub float %sub215, %mul269
  %sub276 = fsub float %sub219, %mul270
  %mul277 = fmul float %conv182, %conv182
  %mul278 = fmul float %mul8, %conv182
  %mul279 = fmul float %mul278, %mul277
  %add280 = fadd float %mul278, %add267
  %mul281 = fmul float %sub126, %mul279
  %mul282 = fmul float %sub127, %mul279
  %mul283 = fmul float %sub128, %mul279
  %add284 = fadd float %add271, %mul281
  %add285 = fadd float %add272, %mul282
  %add286 = fadd float %add273, %mul283
  %sub287 = fsub float %sub233, %mul281
  %sub288 = fsub float %sub237, %mul282
  %sub289 = fsub float %sub241, %mul283
  %mul290 = fmul float %conv194, %conv194
  %mul291 = fmul float %mul8, %conv194
  %mul292 = fmul float %mul291, %mul290
  %add293 = fadd float %mul291, %add280
  %mul294 = fmul float %sub134, %mul292
  %mul295 = fmul float %sub135, %mul292
  %mul296 = fmul float %sub136, %mul292
  %add297 = fadd float %add284, %mul294
  %add298 = fadd float %add285, %mul295
  %add299 = fadd float %add286, %mul296
  %sub300 = fsub float %sub255, %mul294
  %sub301 = fsub float %sub259, %mul295
  %sub302 = fsub float %sub263, %mul296
  %mul303 = fmul float %conv174, %conv174
  %mul304 = fmul float %mul6, %conv174
  %mul305 = fmul float %mul304, %mul303
  %add306 = fadd float %mul304, %add293
  %mul307 = fmul float %sub142, %mul305
  %mul308 = fmul float %sub143, %mul305
  %mul309 = fmul float %sub144, %mul305
  %add310 = fadd float %fix3.0843, %mul307
  %add311 = fadd float %fiy3.0842, %mul308
  %add312 = fadd float %fiz3.0841, %mul309
  %sub313 = fsub float %sub274, %mul307
  store float %sub313, float* %arrayidx210, align 4, !tbaa !3
  %sub316 = fsub float %sub275, %mul308
  store float %sub316, float* %arrayidx214, align 4, !tbaa !3
  %sub320 = fsub float %sub276, %mul309
  store float %sub320, float* %arrayidx218, align 4, !tbaa !3
  %mul324 = fmul float %conv186, %conv186
  %mul325 = fmul float %mul8, %conv186
  %mul326 = fmul float %mul325, %mul324
  %add327 = fadd float %mul325, %add306
  %mul328 = fmul float %sub150, %mul326
  %mul329 = fmul float %sub151, %mul326
  %mul330 = fmul float %sub152, %mul326
  %add331 = fadd float %add310, %mul328
  %add332 = fadd float %add311, %mul329
  %add333 = fadd float %add312, %mul330
  %sub334 = fsub float %sub287, %mul328
  store float %sub334, float* %arrayidx232, align 4, !tbaa !3
  %sub338 = fsub float %sub288, %mul329
  store float %sub338, float* %arrayidx236, align 4, !tbaa !3
  %sub342 = fsub float %sub289, %mul330
  store float %sub342, float* %arrayidx240, align 4, !tbaa !3
  %mul346 = fmul float %conv198, %conv198
  %mul347 = fmul float %mul8, %conv198
  %mul348 = fmul float %mul347, %mul346
  %add349 = fadd float %mul347, %add327
  %mul350 = fmul float %sub158, %mul348
  %mul351 = fmul float %sub159, %mul348
  %mul352 = fmul float %sub160, %mul348
  %add353 = fadd float %add331, %mul350
  %add354 = fadd float %add332, %mul351
  %add355 = fadd float %add333, %mul352
  %sub356 = fsub float %sub300, %mul350
  store float %sub356, float* %arrayidx254, align 4, !tbaa !3
  %sub360 = fsub float %sub301, %mul351
  store float %sub360, float* %arrayidx258, align 4, !tbaa !3
  %sub364 = fsub float %sub302, %mul352
  store float %sub364, float* %arrayidx262, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %39 = trunc i64 %indvars.iv.next to i32
  %cmp64 = icmp slt i32 %39, %9
  br i1 %cmp64, label %for.body65, label %for.end

for.end:                                          ; preds = %for.body65, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add349, %for.body65 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add249, %for.body65 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add250, %for.body65 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add251, %for.body65 ]
  %fix2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add297, %for.body65 ]
  %fiy2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add298, %for.body65 ]
  %fiz2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add299, %for.body65 ]
  %fix3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add353, %for.body65 ]
  %fiy3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add354, %for.body65 ]
  %fiz3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add355, %for.body65 ]
  %arrayidx369 = getelementptr inbounds float* %faction, i64 %idxprom28
  %40 = load float* %arrayidx369, align 4, !tbaa !3
  %add370 = fadd float %fix1.0.lcssa, %40
  store float %add370, float* %arrayidx369, align 4, !tbaa !3
  %arrayidx375 = getelementptr inbounds float* %faction, i64 %idxprom32
  %41 = load float* %arrayidx375, align 4, !tbaa !3
  %add376 = fadd float %fiy1.0.lcssa, %41
  store float %add376, float* %arrayidx375, align 4, !tbaa !3
  %arrayidx382 = getelementptr inbounds float* %faction, i64 %idxprom36
  %42 = load float* %arrayidx382, align 4, !tbaa !3
  %add383 = fadd float %fiz1.0.lcssa, %42
  store float %add383, float* %arrayidx382, align 4, !tbaa !3
  %arrayidx389 = getelementptr inbounds float* %faction, i64 %idxprom40
  %43 = load float* %arrayidx389, align 4, !tbaa !3
  %add390 = fadd float %fix2.0.lcssa, %43
  store float %add390, float* %arrayidx389, align 4, !tbaa !3
  %arrayidx396 = getelementptr inbounds float* %faction, i64 %idxprom44
  %44 = load float* %arrayidx396, align 4, !tbaa !3
  %add397 = fadd float %fiy2.0.lcssa, %44
  store float %add397, float* %arrayidx396, align 4, !tbaa !3
  %arrayidx403 = getelementptr inbounds float* %faction, i64 %idxprom48
  %45 = load float* %arrayidx403, align 4, !tbaa !3
  %add404 = fadd float %fiz2.0.lcssa, %45
  store float %add404, float* %arrayidx403, align 4, !tbaa !3
  %arrayidx410 = getelementptr inbounds float* %faction, i64 %idxprom52
  %46 = load float* %arrayidx410, align 4, !tbaa !3
  %add411 = fadd float %fix3.0.lcssa, %46
  store float %add411, float* %arrayidx410, align 4, !tbaa !3
  %arrayidx417 = getelementptr inbounds float* %faction, i64 %idxprom56
  %47 = load float* %arrayidx417, align 4, !tbaa !3
  %add418 = fadd float %fiy3.0.lcssa, %47
  store float %add418, float* %arrayidx417, align 4, !tbaa !3
  %arrayidx424 = getelementptr inbounds float* %faction, i64 %idxprom60
  %48 = load float* %arrayidx424, align 4, !tbaa !3
  %add425 = fadd float %fiz3.0.lcssa, %48
  store float %add425, float* %arrayidx424, align 4, !tbaa !3
  %arrayidx430 = getelementptr inbounds float* %fshift, i64 %idxprom12
  %49 = load float* %arrayidx430, align 4, !tbaa !3
  %add431 = fadd float %fix1.0.lcssa, %49
  %add432 = fadd float %fix2.0.lcssa, %add431
  %add433 = fadd float %fix3.0.lcssa, %add432
  store float %add433, float* %arrayidx430, align 4, !tbaa !3
  %arrayidx438 = getelementptr inbounds float* %fshift, i64 %idxprom15
  %50 = load float* %arrayidx438, align 4, !tbaa !3
  %add439 = fadd float %fiy1.0.lcssa, %50
  %add440 = fadd float %fiy2.0.lcssa, %add439
  %add441 = fadd float %fiy3.0.lcssa, %add440
  store float %add441, float* %arrayidx438, align 4, !tbaa !3
  %arrayidx447 = getelementptr inbounds float* %fshift, i64 %idxprom18
  %51 = load float* %arrayidx447, align 4, !tbaa !3
  %add448 = fadd float %fiz1.0.lcssa, %51
  %add449 = fadd float %fiz2.0.lcssa, %add448
  %add450 = fadd float %fiz3.0.lcssa, %add449
  store float %add450, float* %arrayidx447, align 4, !tbaa !3
  %arrayidx455 = getelementptr inbounds i32* %gid, i64 %indvars.iv863
  %52 = load i32* %arrayidx455, align 4, !tbaa !0
  %idxprom456 = sext i32 %52 to i64
  %arrayidx457 = getelementptr inbounds float* %Vc, i64 %idxprom456
  %53 = load float* %arrayidx457, align 4, !tbaa !3
  %add458 = fadd float %vctot.0.lcssa, %53
  store float %add458, float* %arrayidx457, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next864 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end463, label %for.end.for.body_crit_edge

for.end.for.body_crit_edge:                       ; preds = %for.end
  %arrayidx21.phi.trans.insert = getelementptr inbounds i32* %iinr, i64 %indvars.iv.next864
  %.pre = load i32* %arrayidx21.phi.trans.insert, align 4, !tbaa !0
  br label %for.body

for.end463:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl1100(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb) #0 {
entry:
  %cmp271 = icmp sgt i32 %nri, 0
  br i1 %cmp271, label %for.body.lr.ph, label %for.end160

for.body.lr.ph:                                   ; preds = %entry
  %mul30 = shl i32 %ntype, 1
  br label %for.body

for.body:                                         ; preds = %for.end, %for.body.lr.ph
  %indvars.iv273 = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next274, %for.end ]
  %arrayidx = getelementptr inbounds i32* %shift, i64 %indvars.iv273
  %0 = load i32* %arrayidx, align 4, !tbaa !0
  %mul = mul nsw i32 %0, 3
  %idxprom1 = sext i32 %mul to i64
  %arrayidx2 = getelementptr inbounds float* %shiftvec, i64 %idxprom1
  %1 = load float* %arrayidx2, align 4, !tbaa !3
  %add = add nsw i32 %mul, 1
  %idxprom3 = sext i32 %add to i64
  %arrayidx4 = getelementptr inbounds float* %shiftvec, i64 %idxprom3
  %2 = load float* %arrayidx4, align 4, !tbaa !3
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds float* %shiftvec, i64 %idxprom6
  %3 = load float* %arrayidx7, align 4, !tbaa !3
  %arrayidx9 = getelementptr inbounds i32* %iinr, i64 %indvars.iv273
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %arrayidx12 = getelementptr inbounds i32* %jindex, i64 %indvars.iv273
  %5 = load i32* %arrayidx12, align 4, !tbaa !0
  %indvars.iv.next274 = add i64 %indvars.iv273, 1
  %arrayidx15 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next274
  %6 = load i32* %arrayidx15, align 4, !tbaa !0
  %idxprom16 = sext i32 %mul10 to i64
  %arrayidx17 = getelementptr inbounds float* %pos, i64 %idxprom16
  %7 = load float* %arrayidx17, align 4, !tbaa !3
  %add18 = fadd float %1, %7
  %add19 = add nsw i32 %mul10, 1
  %idxprom20 = sext i32 %add19 to i64
  %arrayidx21 = getelementptr inbounds float* %pos, i64 %idxprom20
  %8 = load float* %arrayidx21, align 4, !tbaa !3
  %add22 = fadd float %2, %8
  %add23 = add nsw i32 %mul10, 2
  %idxprom24 = sext i32 %add23 to i64
  %arrayidx25 = getelementptr inbounds float* %pos, i64 %idxprom24
  %9 = load float* %arrayidx25, align 4, !tbaa !3
  %add26 = fadd float %3, %9
  %idxprom27 = sext i32 %4 to i64
  %arrayidx28 = getelementptr inbounds float* %charge, i64 %idxprom27
  %10 = load float* %arrayidx28, align 4, !tbaa !3
  %mul29 = fmul float %10, %facel
  %arrayidx32 = getelementptr inbounds i32* %type, i64 %idxprom27
  %11 = load i32* %arrayidx32, align 4, !tbaa !0
  %mul33 = mul nsw i32 %mul30, %11
  %cmp35260 = icmp slt i32 %5, %6
  br i1 %cmp35260, label %for.body36.lr.ph, label %for.end

for.body36.lr.ph:                                 ; preds = %for.body
  %12 = sext i32 %5 to i64
  br label %for.body36

for.body36:                                       ; preds = %for.body36.lr.ph, %for.body36
  %indvars.iv = phi i64 [ %12, %for.body36.lr.ph ], [ %indvars.iv.next, %for.body36 ]
  %vctot.0265 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add82, %for.body36 ]
  %vnbtot.0264 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %sub72, %for.body36 ]
  %fix1.0263 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add86, %for.body36 ]
  %fiy1.0262 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add87, %for.body36 ]
  %fiz1.0261 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add88, %for.body36 ]
  %arrayidx38 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %13 = load i32* %arrayidx38, align 4, !tbaa !0
  %mul39 = mul nsw i32 %13, 3
  %idxprom40 = sext i32 %mul39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %14 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = add nsw i32 %mul39, 1
  %idxprom43 = sext i32 %add42 to i64
  %arrayidx44 = getelementptr inbounds float* %pos, i64 %idxprom43
  %15 = load float* %arrayidx44, align 4, !tbaa !3
  %add45 = add nsw i32 %mul39, 2
  %idxprom46 = sext i32 %add45 to i64
  %arrayidx47 = getelementptr inbounds float* %pos, i64 %idxprom46
  %16 = load float* %arrayidx47, align 4, !tbaa !3
  %sub = fsub float %add18, %14
  %sub48 = fsub float %add22, %15
  %sub49 = fsub float %add26, %16
  %mul50 = fmul float %sub, %sub
  %mul51 = fmul float %sub48, %sub48
  %add52 = fadd float %mul50, %mul51
  %mul53 = fmul float %sub49, %sub49
  %add54 = fadd float %add52, %mul53
  %conv = fpext float %add54 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv55 = fptrunc double %div to float
  %mul56 = fmul float %conv55, %conv55
  %mul57 = fmul float %mul56, %mul56
  %mul58 = fmul float %mul56, %mul57
  %idxprom59 = sext i32 %13 to i64
  %arrayidx60 = getelementptr inbounds i32* %type, i64 %idxprom59
  %17 = load i32* %arrayidx60, align 4, !tbaa !0
  %mul61 = shl nsw i32 %17, 1
  %add62 = add nsw i32 %mul61, %mul33
  %idxprom63 = sext i32 %add62 to i64
  %arrayidx64 = getelementptr inbounds float* %nbfp, i64 %idxprom63
  %18 = load float* %arrayidx64, align 4, !tbaa !3
  %mul65 = fmul float %18, %mul58
  %mul66 = fmul float %mul58, %mul58
  %add67259 = or i32 %add62, 1
  %idxprom68 = sext i32 %add67259 to i64
  %arrayidx69 = getelementptr inbounds float* %nbfp, i64 %idxprom68
  %19 = load float* %arrayidx69, align 4, !tbaa !3
  %mul70 = fmul float %19, %mul66
  %add71 = fadd float %vnbtot.0264, %mul70
  %sub72 = fsub float %add71, %mul65
  %arrayidx74 = getelementptr inbounds float* %charge, i64 %idxprom59
  %20 = load float* %arrayidx74, align 4, !tbaa !3
  %mul75 = fmul float %mul29, %20
  %mul76 = fmul float %conv55, %mul75
  %mul77 = fmul float %mul70, 1.200000e+01
  %mul78 = fmul float %mul65, 6.000000e+00
  %sub79 = fsub float %mul77, %mul78
  %add80 = fadd float %mul76, %sub79
  %mul81 = fmul float %mul56, %add80
  %add82 = fadd float %vctot.0265, %mul76
  %mul83 = fmul float %sub, %mul81
  %mul84 = fmul float %sub48, %mul81
  %mul85 = fmul float %sub49, %mul81
  %add86 = fadd float %fix1.0263, %mul83
  %add87 = fadd float %fiy1.0262, %mul84
  %add88 = fadd float %fiz1.0261, %mul85
  %arrayidx90 = getelementptr inbounds float* %faction, i64 %idxprom40
  %21 = load float* %arrayidx90, align 4, !tbaa !3
  %sub91 = fsub float %21, %mul83
  store float %sub91, float* %arrayidx90, align 4, !tbaa !3
  %arrayidx96 = getelementptr inbounds float* %faction, i64 %idxprom43
  %22 = load float* %arrayidx96, align 4, !tbaa !3
  %sub97 = fsub float %22, %mul84
  store float %sub97, float* %arrayidx96, align 4, !tbaa !3
  %arrayidx103 = getelementptr inbounds float* %faction, i64 %idxprom46
  %23 = load float* %arrayidx103, align 4, !tbaa !3
  %sub104 = fsub float %23, %mul85
  store float %sub104, float* %arrayidx103, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %24 = trunc i64 %indvars.iv.next to i32
  %cmp35 = icmp slt i32 %24, %6
  br i1 %cmp35, label %for.body36, label %for.end

for.end:                                          ; preds = %for.body36, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add82, %for.body36 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %sub72, %for.body36 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add86, %for.body36 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add87, %for.body36 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add88, %for.body36 ]
  %arrayidx109 = getelementptr inbounds float* %faction, i64 %idxprom16
  %25 = load float* %arrayidx109, align 4, !tbaa !3
  %add110 = fadd float %fix1.0.lcssa, %25
  store float %add110, float* %arrayidx109, align 4, !tbaa !3
  %arrayidx115 = getelementptr inbounds float* %faction, i64 %idxprom20
  %26 = load float* %arrayidx115, align 4, !tbaa !3
  %add116 = fadd float %fiy1.0.lcssa, %26
  store float %add116, float* %arrayidx115, align 4, !tbaa !3
  %arrayidx122 = getelementptr inbounds float* %faction, i64 %idxprom24
  %27 = load float* %arrayidx122, align 4, !tbaa !3
  %add123 = fadd float %fiz1.0.lcssa, %27
  store float %add123, float* %arrayidx122, align 4, !tbaa !3
  %arrayidx128 = getelementptr inbounds float* %fshift, i64 %idxprom1
  %28 = load float* %arrayidx128, align 4, !tbaa !3
  %add129 = fadd float %fix1.0.lcssa, %28
  store float %add129, float* %arrayidx128, align 4, !tbaa !3
  %arrayidx134 = getelementptr inbounds float* %fshift, i64 %idxprom3
  %29 = load float* %arrayidx134, align 4, !tbaa !3
  %add135 = fadd float %fiy1.0.lcssa, %29
  store float %add135, float* %arrayidx134, align 4, !tbaa !3
  %arrayidx141 = getelementptr inbounds float* %fshift, i64 %idxprom6
  %30 = load float* %arrayidx141, align 4, !tbaa !3
  %add142 = fadd float %fiz1.0.lcssa, %30
  store float %add142, float* %arrayidx141, align 4, !tbaa !3
  %arrayidx147 = getelementptr inbounds i32* %gid, i64 %indvars.iv273
  %31 = load i32* %arrayidx147, align 4, !tbaa !0
  %idxprom148 = sext i32 %31 to i64
  %arrayidx149 = getelementptr inbounds float* %Vc, i64 %idxprom148
  %32 = load float* %arrayidx149, align 4, !tbaa !3
  %add150 = fadd float %vctot.0.lcssa, %32
  store float %add150, float* %arrayidx149, align 4, !tbaa !3
  %arrayidx154 = getelementptr inbounds float* %Vnb, i64 %idxprom148
  %33 = load float* %arrayidx154, align 4, !tbaa !3
  %add155 = fadd float %vnbtot.0.lcssa, %33
  store float %add155, float* %arrayidx154, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next274 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end160, label %for.body

for.end160:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl1110(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, i32* nocapture %nsatoms) #0 {
entry:
  %cmp832 = icmp sgt i32 %nri, 0
  br i1 %cmp832, label %for.body.lr.ph, label %for.end438

for.body.lr.ph:                                   ; preds = %entry
  %mul303 = shl i32 %ntype, 1
  br label %for.body

for.body:                                         ; preds = %for.end423, %for.body.lr.ph
  %indvars.iv858 = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next859, %for.end423 ]
  %0 = trunc i64 %indvars.iv858 to i32
  %mul = mul nsw i32 %0, 3
  %idxprom = sext i32 %mul to i64
  %arrayidx = getelementptr inbounds i32* %nsatoms, i64 %idxprom
  %1 = load i32* %arrayidx, align 4, !tbaa !0
  %add = add nsw i32 %mul, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds i32* %nsatoms, i64 %idxprom2
  %2 = load i32* %arrayidx3, align 4, !tbaa !0
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds i32* %nsatoms, i64 %idxprom6
  %3 = load i32* %arrayidx7, align 4, !tbaa !0
  %arrayidx9 = getelementptr inbounds i32* %shift, i64 %indvars.iv858
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %idxprom11 = sext i32 %mul10 to i64
  %arrayidx12 = getelementptr inbounds float* %shiftvec, i64 %idxprom11
  %5 = load float* %arrayidx12, align 4, !tbaa !3
  %add13 = add nsw i32 %mul10, 1
  %idxprom14 = sext i32 %add13 to i64
  %arrayidx15 = getelementptr inbounds float* %shiftvec, i64 %idxprom14
  %6 = load float* %arrayidx15, align 4, !tbaa !3
  %add16 = add nsw i32 %mul10, 2
  %idxprom17 = sext i32 %add16 to i64
  %arrayidx18 = getelementptr inbounds float* %shiftvec, i64 %idxprom17
  %7 = load float* %arrayidx18, align 4, !tbaa !3
  %arrayidx20 = getelementptr inbounds i32* %iinr, i64 %indvars.iv858
  %8 = load i32* %arrayidx20, align 4, !tbaa !0
  %mul21 = mul i32 %8, 3
  %arrayidx23 = getelementptr inbounds i32* %jindex, i64 %indvars.iv858
  %9 = load i32* %arrayidx23, align 4, !tbaa !0
  %indvars.iv.next859 = add i64 %indvars.iv858, 1
  %arrayidx26 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next859
  %10 = load i32* %arrayidx26, align 4, !tbaa !0
  %cmp28788 = icmp sgt i32 %2, 0
  br i1 %cmp28788, label %for.body29.lr.ph, label %for.cond165.loopexit

for.body29.lr.ph:                                 ; preds = %for.body
  %cmp49777 = icmp slt i32 %9, %10
  %arrayidx142 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx148 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx155 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %11 = sext i32 %9 to i64
  %12 = sext i32 %8 to i64
  %13 = sext i32 %mul21 to i64
  %14 = add i32 %2, %8
  %15 = mul i32 %14, 3
  br label %for.body29

for.body29:                                       ; preds = %for.end, %for.body29.lr.ph
  %indvars.iv836 = phi i64 [ %13, %for.body29.lr.ph ], [ %indvars.iv.next837, %for.end ]
  %indvars.iv834 = phi i64 [ %12, %for.body29.lr.ph ], [ %indvars.iv.next835, %for.end ]
  %s.0791 = phi i32 [ 0, %for.body29.lr.ph ], [ %inc163, %for.end ]
  %vctot.0790 = phi float [ 0.000000e+00, %for.body29.lr.ph ], [ %vctot.1.lcssa, %for.end ]
  %vnbtot.0789 = phi float [ 0.000000e+00, %for.body29.lr.ph ], [ %vnbtot.1.lcssa, %for.end ]
  %arrayidx31 = getelementptr inbounds float* %pos, i64 %indvars.iv836
  %16 = load float* %arrayidx31, align 4, !tbaa !3
  %add32 = fadd float %5, %16
  %17 = add nsw i64 %indvars.iv836, 1
  %arrayidx35 = getelementptr inbounds float* %pos, i64 %17
  %18 = load float* %arrayidx35, align 4, !tbaa !3
  %add36 = fadd float %6, %18
  %19 = add nsw i64 %indvars.iv836, 2
  %arrayidx39 = getelementptr inbounds float* %pos, i64 %19
  %20 = load float* %arrayidx39, align 4, !tbaa !3
  %add40 = fadd float %7, %20
  %arrayidx42 = getelementptr inbounds float* %charge, i64 %indvars.iv834
  %21 = load float* %arrayidx42, align 4, !tbaa !3
  %mul43 = fmul float %21, %facel
  %arrayidx46 = getelementptr inbounds i32* %type, i64 %indvars.iv834
  %22 = load i32* %arrayidx46, align 4, !tbaa !0
  %mul47 = mul nsw i32 %mul303, %22
  br i1 %cmp49777, label %for.body50, label %for.end

for.body50:                                       ; preds = %for.body29, %for.body50
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body50 ], [ %11, %for.body29 ]
  %fiz1.0782 = phi float [ %add102, %for.body50 ], [ 0.000000e+00, %for.body29 ]
  %fiy1.0781 = phi float [ %add101, %for.body50 ], [ 0.000000e+00, %for.body29 ]
  %fix1.0780 = phi float [ %add100, %for.body50 ], [ 0.000000e+00, %for.body29 ]
  %vctot.1779 = phi float [ %add96, %for.body50 ], [ %vctot.0790, %for.body29 ]
  %vnbtot.1778 = phi float [ %sub86, %for.body50 ], [ %vnbtot.0789, %for.body29 ]
  %arrayidx52 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %23 = load i32* %arrayidx52, align 4, !tbaa !0
  %mul53 = mul nsw i32 %23, 3
  %idxprom54 = sext i32 %mul53 to i64
  %arrayidx55 = getelementptr inbounds float* %pos, i64 %idxprom54
  %24 = load float* %arrayidx55, align 4, !tbaa !3
  %add56 = add nsw i32 %mul53, 1
  %idxprom57 = sext i32 %add56 to i64
  %arrayidx58 = getelementptr inbounds float* %pos, i64 %idxprom57
  %25 = load float* %arrayidx58, align 4, !tbaa !3
  %add59 = add nsw i32 %mul53, 2
  %idxprom60 = sext i32 %add59 to i64
  %arrayidx61 = getelementptr inbounds float* %pos, i64 %idxprom60
  %26 = load float* %arrayidx61, align 4, !tbaa !3
  %sub = fsub float %add32, %24
  %sub62 = fsub float %add36, %25
  %sub63 = fsub float %add40, %26
  %mul64 = fmul float %sub, %sub
  %mul65 = fmul float %sub62, %sub62
  %add66 = fadd float %mul64, %mul65
  %mul67 = fmul float %sub63, %sub63
  %add68 = fadd float %add66, %mul67
  %conv = fpext float %add68 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv69 = fptrunc double %div to float
  %mul70 = fmul float %conv69, %conv69
  %mul71 = fmul float %mul70, %mul70
  %mul72 = fmul float %mul70, %mul71
  %idxprom73 = sext i32 %23 to i64
  %arrayidx74 = getelementptr inbounds i32* %type, i64 %idxprom73
  %27 = load i32* %arrayidx74, align 4, !tbaa !0
  %mul75 = shl nsw i32 %27, 1
  %add76 = add nsw i32 %mul75, %mul47
  %idxprom77 = sext i32 %add76 to i64
  %arrayidx78 = getelementptr inbounds float* %nbfp, i64 %idxprom77
  %28 = load float* %arrayidx78, align 4, !tbaa !3
  %mul79 = fmul float %28, %mul72
  %mul80 = fmul float %mul72, %mul72
  %add81776 = or i32 %add76, 1
  %idxprom82 = sext i32 %add81776 to i64
  %arrayidx83 = getelementptr inbounds float* %nbfp, i64 %idxprom82
  %29 = load float* %arrayidx83, align 4, !tbaa !3
  %mul84 = fmul float %29, %mul80
  %add85 = fadd float %vnbtot.1778, %mul84
  %sub86 = fsub float %add85, %mul79
  %arrayidx88 = getelementptr inbounds float* %charge, i64 %idxprom73
  %30 = load float* %arrayidx88, align 4, !tbaa !3
  %mul89 = fmul float %mul43, %30
  %mul90 = fmul float %conv69, %mul89
  %mul91 = fmul float %mul84, 1.200000e+01
  %mul92 = fmul float %mul79, 6.000000e+00
  %sub93 = fsub float %mul91, %mul92
  %add94 = fadd float %mul90, %sub93
  %mul95 = fmul float %mul70, %add94
  %add96 = fadd float %vctot.1779, %mul90
  %mul97 = fmul float %sub, %mul95
  %mul98 = fmul float %sub62, %mul95
  %mul99 = fmul float %sub63, %mul95
  %add100 = fadd float %fix1.0780, %mul97
  %add101 = fadd float %fiy1.0781, %mul98
  %add102 = fadd float %fiz1.0782, %mul99
  %arrayidx104 = getelementptr inbounds float* %faction, i64 %idxprom54
  %31 = load float* %arrayidx104, align 4, !tbaa !3
  %sub105 = fsub float %31, %mul97
  store float %sub105, float* %arrayidx104, align 4, !tbaa !3
  %arrayidx110 = getelementptr inbounds float* %faction, i64 %idxprom57
  %32 = load float* %arrayidx110, align 4, !tbaa !3
  %sub111 = fsub float %32, %mul98
  store float %sub111, float* %arrayidx110, align 4, !tbaa !3
  %arrayidx117 = getelementptr inbounds float* %faction, i64 %idxprom60
  %33 = load float* %arrayidx117, align 4, !tbaa !3
  %sub118 = fsub float %33, %mul99
  store float %sub118, float* %arrayidx117, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %34 = trunc i64 %indvars.iv.next to i32
  %cmp49 = icmp slt i32 %34, %10
  br i1 %cmp49, label %for.body50, label %for.end

for.end:                                          ; preds = %for.body50, %for.body29
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add102, %for.body50 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add101, %for.body50 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add100, %for.body50 ]
  %vctot.1.lcssa = phi float [ %vctot.0790, %for.body29 ], [ %add96, %for.body50 ]
  %vnbtot.1.lcssa = phi float [ %vnbtot.0789, %for.body29 ], [ %sub86, %for.body50 ]
  %arrayidx123 = getelementptr inbounds float* %faction, i64 %indvars.iv836
  %35 = load float* %arrayidx123, align 4, !tbaa !3
  %add124 = fadd float %fix1.0.lcssa, %35
  store float %add124, float* %arrayidx123, align 4, !tbaa !3
  %arrayidx129 = getelementptr inbounds float* %faction, i64 %17
  %36 = load float* %arrayidx129, align 4, !tbaa !3
  %add130 = fadd float %fiy1.0.lcssa, %36
  store float %add130, float* %arrayidx129, align 4, !tbaa !3
  %arrayidx136 = getelementptr inbounds float* %faction, i64 %19
  %37 = load float* %arrayidx136, align 4, !tbaa !3
  %add137 = fadd float %fiz1.0.lcssa, %37
  store float %add137, float* %arrayidx136, align 4, !tbaa !3
  %38 = load float* %arrayidx142, align 4, !tbaa !3
  %add143 = fadd float %fix1.0.lcssa, %38
  store float %add143, float* %arrayidx142, align 4, !tbaa !3
  %39 = load float* %arrayidx148, align 4, !tbaa !3
  %add149 = fadd float %fiy1.0.lcssa, %39
  store float %add149, float* %arrayidx148, align 4, !tbaa !3
  %40 = load float* %arrayidx155, align 4, !tbaa !3
  %add156 = fadd float %fiz1.0.lcssa, %40
  store float %add156, float* %arrayidx155, align 4, !tbaa !3
  %indvars.iv.next835 = add i64 %indvars.iv834, 1
  %indvars.iv.next837 = add i64 %indvars.iv836, 3
  %inc163 = add nsw i32 %s.0791, 1
  %exitcond = icmp eq i32 %inc163, %2
  br i1 %exitcond, label %for.cond27.for.cond165.loopexit_crit_edge, label %for.body29

for.cond27.for.cond165.loopexit_crit_edge:        ; preds = %for.end
  %41 = add i32 %2, %8
  br label %for.cond165.loopexit

for.cond165.loopexit:                             ; preds = %for.cond27.for.cond165.loopexit_crit_edge, %for.body
  %ii.0.lcssa = phi i32 [ %41, %for.cond27.for.cond165.loopexit_crit_edge ], [ %8, %for.body ]
  %ii3.0.lcssa = phi i32 [ %15, %for.cond27.for.cond165.loopexit_crit_edge ], [ %mul21, %for.body ]
  %vctot.0.lcssa = phi float [ %vctot.1.lcssa, %for.cond27.for.cond165.loopexit_crit_edge ], [ 0.000000e+00, %for.body ]
  %vnbtot.0.lcssa = phi float [ %vnbtot.1.lcssa, %for.cond27.for.cond165.loopexit_crit_edge ], [ 0.000000e+00, %for.body ]
  %cmp166808 = icmp slt i32 %2, %3
  br i1 %cmp166808, label %for.body168.lr.ph, label %for.cond288.loopexit

for.body168.lr.ph:                                ; preds = %for.cond165.loopexit
  %cmp184798 = icmp slt i32 %9, %10
  %arrayidx265 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx271 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx278 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %42 = sext i32 %9 to i64
  %43 = sext i32 %ii.0.lcssa to i64
  %44 = sext i32 %ii3.0.lcssa to i64
  %45 = mul i32 %3, 3
  %46 = add i32 %ii.0.lcssa, %3
  br label %for.body168

for.body168:                                      ; preds = %for.end244, %for.body168.lr.ph
  %indvars.iv844 = phi i64 [ %44, %for.body168.lr.ph ], [ %indvars.iv.next845, %for.end244 ]
  %indvars.iv842 = phi i64 [ %43, %for.body168.lr.ph ], [ %indvars.iv.next843, %for.end244 ]
  %s.1810 = phi i32 [ %2, %for.body168.lr.ph ], [ %inc286, %for.end244 ]
  %vctot.2809 = phi float [ %vctot.0.lcssa, %for.body168.lr.ph ], [ %vctot.3.lcssa, %for.end244 ]
  %arrayidx170 = getelementptr inbounds float* %pos, i64 %indvars.iv844
  %47 = load float* %arrayidx170, align 4, !tbaa !3
  %add171 = fadd float %5, %47
  %48 = add nsw i64 %indvars.iv844, 1
  %arrayidx174 = getelementptr inbounds float* %pos, i64 %48
  %49 = load float* %arrayidx174, align 4, !tbaa !3
  %add175 = fadd float %6, %49
  %50 = add nsw i64 %indvars.iv844, 2
  %arrayidx178 = getelementptr inbounds float* %pos, i64 %50
  %51 = load float* %arrayidx178, align 4, !tbaa !3
  %add179 = fadd float %7, %51
  %arrayidx181 = getelementptr inbounds float* %charge, i64 %indvars.iv842
  %52 = load float* %arrayidx181, align 4, !tbaa !3
  %mul182 = fmul float %52, %facel
  br i1 %cmp184798, label %for.body186, label %for.end244

for.body186:                                      ; preds = %for.body168, %for.body186
  %indvars.iv840 = phi i64 [ %indvars.iv.next841, %for.body186 ], [ %42, %for.body168 ]
  %fiz1.1802 = phi float [ %add222, %for.body186 ], [ 0.000000e+00, %for.body168 ]
  %fiy1.1801 = phi float [ %add221, %for.body186 ], [ 0.000000e+00, %for.body168 ]
  %fix1.1800 = phi float [ %add220, %for.body186 ], [ 0.000000e+00, %for.body168 ]
  %vctot.3799 = phi float [ %add216, %for.body186 ], [ %vctot.2809, %for.body168 ]
  %arrayidx188 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv840
  %53 = load i32* %arrayidx188, align 4, !tbaa !0
  %mul189 = mul nsw i32 %53, 3
  %idxprom190 = sext i32 %mul189 to i64
  %arrayidx191 = getelementptr inbounds float* %pos, i64 %idxprom190
  %54 = load float* %arrayidx191, align 4, !tbaa !3
  %add192 = add nsw i32 %mul189, 1
  %idxprom193 = sext i32 %add192 to i64
  %arrayidx194 = getelementptr inbounds float* %pos, i64 %idxprom193
  %55 = load float* %arrayidx194, align 4, !tbaa !3
  %add195 = add nsw i32 %mul189, 2
  %idxprom196 = sext i32 %add195 to i64
  %arrayidx197 = getelementptr inbounds float* %pos, i64 %idxprom196
  %56 = load float* %arrayidx197, align 4, !tbaa !3
  %sub198 = fsub float %add171, %54
  %sub199 = fsub float %add175, %55
  %sub200 = fsub float %add179, %56
  %mul201 = fmul float %sub198, %sub198
  %mul202 = fmul float %sub199, %sub199
  %add203 = fadd float %mul201, %mul202
  %mul204 = fmul float %sub200, %sub200
  %add205 = fadd float %add203, %mul204
  %conv206 = fpext float %add205 to double
  %call207 = tail call double @sqrt(double %conv206) #2
  %div208 = fdiv double 1.000000e+00, %call207
  %conv209 = fptrunc double %div208 to float
  %mul210 = fmul float %conv209, %conv209
  %idxprom211 = sext i32 %53 to i64
  %arrayidx212 = getelementptr inbounds float* %charge, i64 %idxprom211
  %57 = load float* %arrayidx212, align 4, !tbaa !3
  %mul213 = fmul float %mul182, %57
  %mul214 = fmul float %conv209, %mul213
  %mul215 = fmul float %mul210, %mul214
  %add216 = fadd float %vctot.3799, %mul214
  %mul217 = fmul float %sub198, %mul215
  %mul218 = fmul float %sub199, %mul215
  %mul219 = fmul float %sub200, %mul215
  %add220 = fadd float %fix1.1800, %mul217
  %add221 = fadd float %fiy1.1801, %mul218
  %add222 = fadd float %fiz1.1802, %mul219
  %arrayidx224 = getelementptr inbounds float* %faction, i64 %idxprom190
  %58 = load float* %arrayidx224, align 4, !tbaa !3
  %sub225 = fsub float %58, %mul217
  store float %sub225, float* %arrayidx224, align 4, !tbaa !3
  %arrayidx230 = getelementptr inbounds float* %faction, i64 %idxprom193
  %59 = load float* %arrayidx230, align 4, !tbaa !3
  %sub231 = fsub float %59, %mul218
  store float %sub231, float* %arrayidx230, align 4, !tbaa !3
  %arrayidx237 = getelementptr inbounds float* %faction, i64 %idxprom196
  %60 = load float* %arrayidx237, align 4, !tbaa !3
  %sub238 = fsub float %60, %mul219
  store float %sub238, float* %arrayidx237, align 4, !tbaa !3
  %indvars.iv.next841 = add i64 %indvars.iv840, 1
  %61 = trunc i64 %indvars.iv.next841 to i32
  %cmp184 = icmp slt i32 %61, %10
  br i1 %cmp184, label %for.body186, label %for.end244

for.end244:                                       ; preds = %for.body186, %for.body168
  %fiz1.1.lcssa = phi float [ 0.000000e+00, %for.body168 ], [ %add222, %for.body186 ]
  %fiy1.1.lcssa = phi float [ 0.000000e+00, %for.body168 ], [ %add221, %for.body186 ]
  %fix1.1.lcssa = phi float [ 0.000000e+00, %for.body168 ], [ %add220, %for.body186 ]
  %vctot.3.lcssa = phi float [ %vctot.2809, %for.body168 ], [ %add216, %for.body186 ]
  %arrayidx246 = getelementptr inbounds float* %faction, i64 %indvars.iv844
  %62 = load float* %arrayidx246, align 4, !tbaa !3
  %add247 = fadd float %fix1.1.lcssa, %62
  store float %add247, float* %arrayidx246, align 4, !tbaa !3
  %arrayidx252 = getelementptr inbounds float* %faction, i64 %48
  %63 = load float* %arrayidx252, align 4, !tbaa !3
  %add253 = fadd float %fiy1.1.lcssa, %63
  store float %add253, float* %arrayidx252, align 4, !tbaa !3
  %arrayidx259 = getelementptr inbounds float* %faction, i64 %50
  %64 = load float* %arrayidx259, align 4, !tbaa !3
  %add260 = fadd float %fiz1.1.lcssa, %64
  store float %add260, float* %arrayidx259, align 4, !tbaa !3
  %65 = load float* %arrayidx265, align 4, !tbaa !3
  %add266 = fadd float %fix1.1.lcssa, %65
  store float %add266, float* %arrayidx265, align 4, !tbaa !3
  %66 = load float* %arrayidx271, align 4, !tbaa !3
  %add272 = fadd float %fiy1.1.lcssa, %66
  store float %add272, float* %arrayidx271, align 4, !tbaa !3
  %67 = load float* %arrayidx278, align 4, !tbaa !3
  %add279 = fadd float %fiz1.1.lcssa, %67
  store float %add279, float* %arrayidx278, align 4, !tbaa !3
  %indvars.iv.next843 = add i64 %indvars.iv842, 1
  %indvars.iv.next845 = add i64 %indvars.iv844, 3
  %inc286 = add nsw i32 %s.1810, 1
  %exitcond848 = icmp eq i32 %inc286, %3
  br i1 %exitcond848, label %for.cond165.for.cond288.loopexit_crit_edge, label %for.body168

for.cond165.for.cond288.loopexit_crit_edge:       ; preds = %for.end244
  %68 = add i32 %ii3.0.lcssa, %45
  %69 = mul i32 %2, -3
  %70 = add i32 %68, %69
  %71 = sub i32 %46, %2
  br label %for.cond288.loopexit

for.cond288.loopexit:                             ; preds = %for.cond165.for.cond288.loopexit_crit_edge, %for.cond165.loopexit
  %ii.1.lcssa = phi i32 [ %71, %for.cond165.for.cond288.loopexit_crit_edge ], [ %ii.0.lcssa, %for.cond165.loopexit ]
  %ii3.1.lcssa = phi i32 [ %70, %for.cond165.for.cond288.loopexit_crit_edge ], [ %ii3.0.lcssa, %for.cond165.loopexit ]
  %vctot.2.lcssa = phi float [ %vctot.3.lcssa, %for.cond165.for.cond288.loopexit_crit_edge ], [ %vctot.0.lcssa, %for.cond165.loopexit ]
  %cmp289826 = icmp slt i32 %3, %1
  br i1 %cmp289826, label %for.body291.lr.ph, label %for.end423

for.body291.lr.ph:                                ; preds = %for.cond288.loopexit
  %cmp308816 = icmp slt i32 %9, %10
  %arrayidx401 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx407 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx414 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %72 = sext i32 %9 to i64
  %73 = sext i32 %ii.1.lcssa to i64
  %74 = sext i32 %ii3.1.lcssa to i64
  br label %for.body291

for.body291:                                      ; preds = %for.end380, %for.body291.lr.ph
  %indvars.iv853 = phi i64 [ %74, %for.body291.lr.ph ], [ %indvars.iv.next854, %for.end380 ]
  %indvars.iv851 = phi i64 [ %73, %for.body291.lr.ph ], [ %indvars.iv.next852, %for.end380 ]
  %s.2828 = phi i32 [ %3, %for.body291.lr.ph ], [ %inc422, %for.end380 ]
  %vnbtot.2827 = phi float [ %vnbtot.0.lcssa, %for.body291.lr.ph ], [ %vnbtot.3.lcssa, %for.end380 ]
  %arrayidx293 = getelementptr inbounds float* %pos, i64 %indvars.iv853
  %75 = load float* %arrayidx293, align 4, !tbaa !3
  %add294 = fadd float %5, %75
  %76 = add nsw i64 %indvars.iv853, 1
  %arrayidx297 = getelementptr inbounds float* %pos, i64 %76
  %77 = load float* %arrayidx297, align 4, !tbaa !3
  %add298 = fadd float %6, %77
  %78 = add nsw i64 %indvars.iv853, 2
  %arrayidx301 = getelementptr inbounds float* %pos, i64 %78
  %79 = load float* %arrayidx301, align 4, !tbaa !3
  %add302 = fadd float %7, %79
  %arrayidx305 = getelementptr inbounds i32* %type, i64 %indvars.iv851
  %80 = load i32* %arrayidx305, align 4, !tbaa !0
  %mul306 = mul nsw i32 %mul303, %80
  br i1 %cmp308816, label %for.body310, label %for.end380

for.body310:                                      ; preds = %for.body291, %for.body310
  %indvars.iv849 = phi i64 [ %indvars.iv.next850, %for.body310 ], [ %72, %for.body291 ]
  %fiz1.2820 = phi float [ %add358, %for.body310 ], [ 0.000000e+00, %for.body291 ]
  %fiy1.2819 = phi float [ %add357, %for.body310 ], [ 0.000000e+00, %for.body291 ]
  %fix1.2818 = phi float [ %add356, %for.body310 ], [ 0.000000e+00, %for.body291 ]
  %vnbtot.3817 = phi float [ %sub348, %for.body310 ], [ %vnbtot.2827, %for.body291 ]
  %arrayidx312 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv849
  %81 = load i32* %arrayidx312, align 4, !tbaa !0
  %mul313 = mul nsw i32 %81, 3
  %idxprom314 = sext i32 %mul313 to i64
  %arrayidx315 = getelementptr inbounds float* %pos, i64 %idxprom314
  %82 = load float* %arrayidx315, align 4, !tbaa !3
  %add316 = add nsw i32 %mul313, 1
  %idxprom317 = sext i32 %add316 to i64
  %arrayidx318 = getelementptr inbounds float* %pos, i64 %idxprom317
  %83 = load float* %arrayidx318, align 4, !tbaa !3
  %add319 = add nsw i32 %mul313, 2
  %idxprom320 = sext i32 %add319 to i64
  %arrayidx321 = getelementptr inbounds float* %pos, i64 %idxprom320
  %84 = load float* %arrayidx321, align 4, !tbaa !3
  %sub322 = fsub float %add294, %82
  %sub323 = fsub float %add298, %83
  %sub324 = fsub float %add302, %84
  %mul325 = fmul float %sub322, %sub322
  %mul326 = fmul float %sub323, %sub323
  %add327 = fadd float %mul325, %mul326
  %mul328 = fmul float %sub324, %sub324
  %add329 = fadd float %add327, %mul328
  %conv332 = fdiv float 1.000000e+00, %add329
  %mul333 = fmul float %conv332, %conv332
  %mul334 = fmul float %conv332, %mul333
  %idxprom335 = sext i32 %81 to i64
  %arrayidx336 = getelementptr inbounds i32* %type, i64 %idxprom335
  %85 = load i32* %arrayidx336, align 4, !tbaa !0
  %mul337 = shl nsw i32 %85, 1
  %add338 = add nsw i32 %mul337, %mul306
  %idxprom339 = sext i32 %add338 to i64
  %arrayidx340 = getelementptr inbounds float* %nbfp, i64 %idxprom339
  %86 = load float* %arrayidx340, align 4, !tbaa !3
  %mul341 = fmul float %mul334, %86
  %mul342 = fmul float %mul334, %mul334
  %add343775 = or i32 %add338, 1
  %idxprom344 = sext i32 %add343775 to i64
  %arrayidx345 = getelementptr inbounds float* %nbfp, i64 %idxprom344
  %87 = load float* %arrayidx345, align 4, !tbaa !3
  %mul346 = fmul float %mul342, %87
  %add347 = fadd float %vnbtot.3817, %mul346
  %sub348 = fsub float %add347, %mul341
  %mul349 = fmul float %mul346, 1.200000e+01
  %mul350 = fmul float %mul341, 6.000000e+00
  %sub351 = fsub float %mul349, %mul350
  %mul352 = fmul float %conv332, %sub351
  %mul353 = fmul float %sub322, %mul352
  %mul354 = fmul float %sub323, %mul352
  %mul355 = fmul float %sub324, %mul352
  %add356 = fadd float %fix1.2818, %mul353
  %add357 = fadd float %fiy1.2819, %mul354
  %add358 = fadd float %fiz1.2820, %mul355
  %arrayidx360 = getelementptr inbounds float* %faction, i64 %idxprom314
  %88 = load float* %arrayidx360, align 4, !tbaa !3
  %sub361 = fsub float %88, %mul353
  store float %sub361, float* %arrayidx360, align 4, !tbaa !3
  %arrayidx366 = getelementptr inbounds float* %faction, i64 %idxprom317
  %89 = load float* %arrayidx366, align 4, !tbaa !3
  %sub367 = fsub float %89, %mul354
  store float %sub367, float* %arrayidx366, align 4, !tbaa !3
  %arrayidx373 = getelementptr inbounds float* %faction, i64 %idxprom320
  %90 = load float* %arrayidx373, align 4, !tbaa !3
  %sub374 = fsub float %90, %mul355
  store float %sub374, float* %arrayidx373, align 4, !tbaa !3
  %indvars.iv.next850 = add i64 %indvars.iv849, 1
  %91 = trunc i64 %indvars.iv.next850 to i32
  %cmp308 = icmp slt i32 %91, %10
  br i1 %cmp308, label %for.body310, label %for.end380

for.end380:                                       ; preds = %for.body310, %for.body291
  %fiz1.2.lcssa = phi float [ 0.000000e+00, %for.body291 ], [ %add358, %for.body310 ]
  %fiy1.2.lcssa = phi float [ 0.000000e+00, %for.body291 ], [ %add357, %for.body310 ]
  %fix1.2.lcssa = phi float [ 0.000000e+00, %for.body291 ], [ %add356, %for.body310 ]
  %vnbtot.3.lcssa = phi float [ %vnbtot.2827, %for.body291 ], [ %sub348, %for.body310 ]
  %arrayidx382 = getelementptr inbounds float* %faction, i64 %indvars.iv853
  %92 = load float* %arrayidx382, align 4, !tbaa !3
  %add383 = fadd float %fix1.2.lcssa, %92
  store float %add383, float* %arrayidx382, align 4, !tbaa !3
  %arrayidx388 = getelementptr inbounds float* %faction, i64 %76
  %93 = load float* %arrayidx388, align 4, !tbaa !3
  %add389 = fadd float %fiy1.2.lcssa, %93
  store float %add389, float* %arrayidx388, align 4, !tbaa !3
  %arrayidx395 = getelementptr inbounds float* %faction, i64 %78
  %94 = load float* %arrayidx395, align 4, !tbaa !3
  %add396 = fadd float %fiz1.2.lcssa, %94
  store float %add396, float* %arrayidx395, align 4, !tbaa !3
  %95 = load float* %arrayidx401, align 4, !tbaa !3
  %add402 = fadd float %fix1.2.lcssa, %95
  store float %add402, float* %arrayidx401, align 4, !tbaa !3
  %96 = load float* %arrayidx407, align 4, !tbaa !3
  %add408 = fadd float %fiy1.2.lcssa, %96
  store float %add408, float* %arrayidx407, align 4, !tbaa !3
  %97 = load float* %arrayidx414, align 4, !tbaa !3
  %add415 = fadd float %fiz1.2.lcssa, %97
  store float %add415, float* %arrayidx414, align 4, !tbaa !3
  %indvars.iv.next852 = add i64 %indvars.iv851, 1
  %indvars.iv.next854 = add i64 %indvars.iv853, 3
  %inc422 = add nsw i32 %s.2828, 1
  %exitcond857 = icmp eq i32 %inc422, %1
  br i1 %exitcond857, label %for.end423, label %for.body291

for.end423:                                       ; preds = %for.end380, %for.cond288.loopexit
  %vnbtot.2.lcssa = phi float [ %vnbtot.0.lcssa, %for.cond288.loopexit ], [ %vnbtot.3.lcssa, %for.end380 ]
  %arrayidx425 = getelementptr inbounds i32* %gid, i64 %indvars.iv858
  %98 = load i32* %arrayidx425, align 4, !tbaa !0
  %idxprom426 = sext i32 %98 to i64
  %arrayidx427 = getelementptr inbounds float* %Vc, i64 %idxprom426
  %99 = load float* %arrayidx427, align 4, !tbaa !3
  %add428 = fadd float %vctot.2.lcssa, %99
  store float %add428, float* %arrayidx427, align 4, !tbaa !3
  %arrayidx432 = getelementptr inbounds float* %Vnb, i64 %idxprom426
  %100 = load float* %arrayidx432, align 4, !tbaa !3
  %add433 = fadd float %vnbtot.2.lcssa, %100
  store float %add433, float* %arrayidx432, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next859 to i32
  %exitcond860 = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond860, label %for.end438, label %for.body

for.end438:                                       ; preds = %for.end423, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl1120(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb) #0 {
entry:
  %0 = load i32* %iinr, align 4, !tbaa !0
  %idxprom = sext i32 %0 to i64
  %arrayidx1 = getelementptr inbounds float* %charge, i64 %idxprom
  %1 = load float* %arrayidx1, align 4, !tbaa !3
  %add = add nsw i32 %0, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds float* %charge, i64 %idxprom2
  %2 = load float* %arrayidx3, align 4, !tbaa !3
  %mul = fmul float %1, %facel
  %mul4 = fmul float %2, %facel
  %mul5 = shl i32 %ntype, 1
  %arrayidx7 = getelementptr inbounds i32* %type, i64 %idxprom
  %3 = load i32* %arrayidx7, align 4, !tbaa !0
  %mul8 = mul nsw i32 %mul5, %3
  %cmp524 = icmp sgt i32 %nri, 0
  br i1 %cmp524, label %for.body, label %for.end293

for.body:                                         ; preds = %entry, %for.end.for.body_crit_edge
  %4 = phi i32 [ %.pre, %for.end.for.body_crit_edge ], [ %0, %entry ]
  %indvars.iv526 = phi i64 [ %indvars.iv.next527, %for.end.for.body_crit_edge ], [ 0, %entry ]
  %arrayidx10 = getelementptr inbounds i32* %shift, i64 %indvars.iv526
  %5 = load i32* %arrayidx10, align 4, !tbaa !0
  %mul11 = mul nsw i32 %5, 3
  %idxprom12 = sext i32 %mul11 to i64
  %arrayidx13 = getelementptr inbounds float* %shiftvec, i64 %idxprom12
  %6 = load float* %arrayidx13, align 4, !tbaa !3
  %add14 = add nsw i32 %mul11, 1
  %idxprom15 = sext i32 %add14 to i64
  %arrayidx16 = getelementptr inbounds float* %shiftvec, i64 %idxprom15
  %7 = load float* %arrayidx16, align 4, !tbaa !3
  %add17 = add nsw i32 %mul11, 2
  %idxprom18 = sext i32 %add17 to i64
  %arrayidx19 = getelementptr inbounds float* %shiftvec, i64 %idxprom18
  %8 = load float* %arrayidx19, align 4, !tbaa !3
  %mul22 = mul nsw i32 %4, 3
  %arrayidx24 = getelementptr inbounds i32* %jindex, i64 %indvars.iv526
  %9 = load i32* %arrayidx24, align 4, !tbaa !0
  %indvars.iv.next527 = add i64 %indvars.iv526, 1
  %arrayidx27 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next527
  %10 = load i32* %arrayidx27, align 4, !tbaa !0
  %idxprom28 = sext i32 %mul22 to i64
  %arrayidx29 = getelementptr inbounds float* %pos, i64 %idxprom28
  %11 = load float* %arrayidx29, align 4, !tbaa !3
  %add30 = fadd float %6, %11
  %add31 = add nsw i32 %mul22, 1
  %idxprom32 = sext i32 %add31 to i64
  %arrayidx33 = getelementptr inbounds float* %pos, i64 %idxprom32
  %12 = load float* %arrayidx33, align 4, !tbaa !3
  %add34 = fadd float %7, %12
  %add35 = add nsw i32 %mul22, 2
  %idxprom36 = sext i32 %add35 to i64
  %arrayidx37 = getelementptr inbounds float* %pos, i64 %idxprom36
  %13 = load float* %arrayidx37, align 4, !tbaa !3
  %add38 = fadd float %8, %13
  %add39 = add nsw i32 %mul22, 3
  %idxprom40 = sext i32 %add39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %14 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = fadd float %6, %14
  %add43 = add nsw i32 %mul22, 4
  %idxprom44 = sext i32 %add43 to i64
  %arrayidx45 = getelementptr inbounds float* %pos, i64 %idxprom44
  %15 = load float* %arrayidx45, align 4, !tbaa !3
  %add46 = fadd float %7, %15
  %add47 = add nsw i32 %mul22, 5
  %idxprom48 = sext i32 %add47 to i64
  %arrayidx49 = getelementptr inbounds float* %pos, i64 %idxprom48
  %16 = load float* %arrayidx49, align 4, !tbaa !3
  %add50 = fadd float %8, %16
  %add51 = add nsw i32 %mul22, 6
  %idxprom52 = sext i32 %add51 to i64
  %arrayidx53 = getelementptr inbounds float* %pos, i64 %idxprom52
  %17 = load float* %arrayidx53, align 4, !tbaa !3
  %add54 = fadd float %6, %17
  %add55 = add nsw i32 %mul22, 7
  %idxprom56 = sext i32 %add55 to i64
  %arrayidx57 = getelementptr inbounds float* %pos, i64 %idxprom56
  %18 = load float* %arrayidx57, align 4, !tbaa !3
  %add58 = fadd float %7, %18
  %add59 = add nsw i32 %mul22, 8
  %idxprom60 = sext i32 %add59 to i64
  %arrayidx61 = getelementptr inbounds float* %pos, i64 %idxprom60
  %19 = load float* %arrayidx61, align 4, !tbaa !3
  %add62 = fadd float %8, %19
  %cmp64501 = icmp slt i32 %9, %10
  br i1 %cmp64501, label %for.body65.lr.ph, label %for.end

for.body65.lr.ph:                                 ; preds = %for.body
  %20 = sext i32 %9 to i64
  br label %for.body65

for.body65:                                       ; preds = %for.body65.lr.ph, %for.body65
  %indvars.iv = phi i64 [ %20, %for.body65.lr.ph ], [ %indvars.iv.next, %for.body65 ]
  %vctot.0512 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add175, %for.body65 ]
  %vnbtot.0511 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %sub125, %for.body65 ]
  %fix1.0510 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add139, %for.body65 ]
  %fiy1.0509 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add140, %for.body65 ]
  %fiz1.0508 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add141, %for.body65 ]
  %fix2.0507 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add163, %for.body65 ]
  %fiy2.0506 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add164, %for.body65 ]
  %fiz2.0505 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add165, %for.body65 ]
  %fix3.0504 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add179, %for.body65 ]
  %fiy3.0503 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add180, %for.body65 ]
  %fiz3.0502 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add181, %for.body65 ]
  %arrayidx67 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %21 = load i32* %arrayidx67, align 4, !tbaa !0
  %mul68 = mul nsw i32 %21, 3
  %idxprom69 = sext i32 %mul68 to i64
  %arrayidx70 = getelementptr inbounds float* %pos, i64 %idxprom69
  %22 = load float* %arrayidx70, align 4, !tbaa !3
  %add71 = add nsw i32 %mul68, 1
  %idxprom72 = sext i32 %add71 to i64
  %arrayidx73 = getelementptr inbounds float* %pos, i64 %idxprom72
  %23 = load float* %arrayidx73, align 4, !tbaa !3
  %add74 = add nsw i32 %mul68, 2
  %idxprom75 = sext i32 %add74 to i64
  %arrayidx76 = getelementptr inbounds float* %pos, i64 %idxprom75
  %24 = load float* %arrayidx76, align 4, !tbaa !3
  %sub = fsub float %add30, %22
  %sub77 = fsub float %add34, %23
  %sub78 = fsub float %add38, %24
  %mul79 = fmul float %sub, %sub
  %mul80 = fmul float %sub77, %sub77
  %add81 = fadd float %mul79, %mul80
  %mul82 = fmul float %sub78, %sub78
  %add83 = fadd float %add81, %mul82
  %sub84 = fsub float %add42, %22
  %sub85 = fsub float %add46, %23
  %sub86 = fsub float %add50, %24
  %mul87 = fmul float %sub84, %sub84
  %mul88 = fmul float %sub85, %sub85
  %add89 = fadd float %mul87, %mul88
  %mul90 = fmul float %sub86, %sub86
  %add91 = fadd float %add89, %mul90
  %sub92 = fsub float %add54, %22
  %sub93 = fsub float %add58, %23
  %sub94 = fsub float %add62, %24
  %mul95 = fmul float %sub92, %sub92
  %mul96 = fmul float %sub93, %sub93
  %add97 = fadd float %mul95, %mul96
  %mul98 = fmul float %sub94, %sub94
  %add99 = fadd float %add97, %mul98
  %conv = fpext float %add83 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv100 = fptrunc double %div to float
  %conv101 = fpext float %add91 to double
  %call102 = tail call double @sqrt(double %conv101) #2
  %div103 = fdiv double 1.000000e+00, %call102
  %conv104 = fptrunc double %div103 to float
  %conv105 = fpext float %add99 to double
  %call106 = tail call double @sqrt(double %conv105) #2
  %div107 = fdiv double 1.000000e+00, %call106
  %conv108 = fptrunc double %div107 to float
  %mul109 = fmul float %conv100, %conv100
  %mul110 = fmul float %mul109, %mul109
  %mul111 = fmul float %mul109, %mul110
  %idxprom112 = sext i32 %21 to i64
  %arrayidx113 = getelementptr inbounds i32* %type, i64 %idxprom112
  %25 = load i32* %arrayidx113, align 4, !tbaa !0
  %mul114 = shl nsw i32 %25, 1
  %add115 = add nsw i32 %mul114, %mul8
  %idxprom116 = sext i32 %add115 to i64
  %arrayidx117 = getelementptr inbounds float* %nbfp, i64 %idxprom116
  %26 = load float* %arrayidx117, align 4, !tbaa !3
  %mul118 = fmul float %mul111, %26
  %mul119 = fmul float %mul111, %mul111
  %add120500 = or i32 %add115, 1
  %idxprom121 = sext i32 %add120500 to i64
  %arrayidx122 = getelementptr inbounds float* %nbfp, i64 %idxprom121
  %27 = load float* %arrayidx122, align 4, !tbaa !3
  %mul123 = fmul float %mul119, %27
  %add124 = fadd float %vnbtot.0511, %mul123
  %sub125 = fsub float %add124, %mul118
  %arrayidx127 = getelementptr inbounds float* %charge, i64 %idxprom112
  %28 = load float* %arrayidx127, align 4, !tbaa !3
  %mul128 = fmul float %mul, %28
  %mul129 = fmul float %conv100, %mul128
  %mul130 = fmul float %mul123, 1.200000e+01
  %mul131 = fmul float %mul118, 6.000000e+00
  %sub132 = fsub float %mul130, %mul131
  %add133 = fadd float %sub132, %mul129
  %mul134 = fmul float %mul109, %add133
  %add135 = fadd float %vctot.0512, %mul129
  %mul136 = fmul float %sub, %mul134
  %mul137 = fmul float %sub77, %mul134
  %mul138 = fmul float %sub78, %mul134
  %add139 = fadd float %fix1.0510, %mul136
  %add140 = fadd float %fiy1.0509, %mul137
  %add141 = fadd float %fiz1.0508, %mul138
  %arrayidx143 = getelementptr inbounds float* %faction, i64 %idxprom69
  %29 = load float* %arrayidx143, align 4, !tbaa !3
  %sub144 = fsub float %29, %mul136
  %arrayidx147 = getelementptr inbounds float* %faction, i64 %idxprom72
  %30 = load float* %arrayidx147, align 4, !tbaa !3
  %sub148 = fsub float %30, %mul137
  %arrayidx151 = getelementptr inbounds float* %faction, i64 %idxprom75
  %31 = load float* %arrayidx151, align 4, !tbaa !3
  %sub152 = fsub float %31, %mul138
  %mul153 = fmul float %conv104, %conv104
  %mul156 = fmul float %mul4, %28
  %mul157 = fmul float %conv104, %mul156
  %mul158 = fmul float %mul153, %mul157
  %add159 = fadd float %mul157, %add135
  %mul160 = fmul float %sub84, %mul158
  %mul161 = fmul float %sub85, %mul158
  %mul162 = fmul float %sub86, %mul158
  %add163 = fadd float %fix2.0507, %mul160
  %add164 = fadd float %fiy2.0506, %mul161
  %add165 = fadd float %fiz2.0505, %mul162
  %sub166 = fsub float %sub144, %mul160
  %sub167 = fsub float %sub148, %mul161
  %sub168 = fsub float %sub152, %mul162
  %mul169 = fmul float %conv108, %conv108
  %mul173 = fmul float %conv108, %mul156
  %mul174 = fmul float %mul169, %mul173
  %add175 = fadd float %mul173, %add159
  %mul176 = fmul float %sub92, %mul174
  %mul177 = fmul float %sub93, %mul174
  %mul178 = fmul float %sub94, %mul174
  %add179 = fadd float %fix3.0504, %mul176
  %add180 = fadd float %fiy3.0503, %mul177
  %add181 = fadd float %fiz3.0502, %mul178
  %sub182 = fsub float %sub166, %mul176
  store float %sub182, float* %arrayidx143, align 4, !tbaa !3
  %sub185 = fsub float %sub167, %mul177
  store float %sub185, float* %arrayidx147, align 4, !tbaa !3
  %sub189 = fsub float %sub168, %mul178
  store float %sub189, float* %arrayidx151, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %32 = trunc i64 %indvars.iv.next to i32
  %cmp64 = icmp slt i32 %32, %10
  br i1 %cmp64, label %for.body65, label %for.end

for.end:                                          ; preds = %for.body65, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add175, %for.body65 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %sub125, %for.body65 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add139, %for.body65 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add140, %for.body65 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add141, %for.body65 ]
  %fix2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add163, %for.body65 ]
  %fiy2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add164, %for.body65 ]
  %fiz2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add165, %for.body65 ]
  %fix3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add179, %for.body65 ]
  %fiy3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add180, %for.body65 ]
  %fiz3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add181, %for.body65 ]
  %arrayidx194 = getelementptr inbounds float* %faction, i64 %idxprom28
  %33 = load float* %arrayidx194, align 4, !tbaa !3
  %add195 = fadd float %fix1.0.lcssa, %33
  store float %add195, float* %arrayidx194, align 4, !tbaa !3
  %arrayidx200 = getelementptr inbounds float* %faction, i64 %idxprom32
  %34 = load float* %arrayidx200, align 4, !tbaa !3
  %add201 = fadd float %fiy1.0.lcssa, %34
  store float %add201, float* %arrayidx200, align 4, !tbaa !3
  %arrayidx207 = getelementptr inbounds float* %faction, i64 %idxprom36
  %35 = load float* %arrayidx207, align 4, !tbaa !3
  %add208 = fadd float %fiz1.0.lcssa, %35
  store float %add208, float* %arrayidx207, align 4, !tbaa !3
  %arrayidx214 = getelementptr inbounds float* %faction, i64 %idxprom40
  %36 = load float* %arrayidx214, align 4, !tbaa !3
  %add215 = fadd float %fix2.0.lcssa, %36
  store float %add215, float* %arrayidx214, align 4, !tbaa !3
  %arrayidx221 = getelementptr inbounds float* %faction, i64 %idxprom44
  %37 = load float* %arrayidx221, align 4, !tbaa !3
  %add222 = fadd float %fiy2.0.lcssa, %37
  store float %add222, float* %arrayidx221, align 4, !tbaa !3
  %arrayidx228 = getelementptr inbounds float* %faction, i64 %idxprom48
  %38 = load float* %arrayidx228, align 4, !tbaa !3
  %add229 = fadd float %fiz2.0.lcssa, %38
  store float %add229, float* %arrayidx228, align 4, !tbaa !3
  %arrayidx235 = getelementptr inbounds float* %faction, i64 %idxprom52
  %39 = load float* %arrayidx235, align 4, !tbaa !3
  %add236 = fadd float %fix3.0.lcssa, %39
  store float %add236, float* %arrayidx235, align 4, !tbaa !3
  %arrayidx242 = getelementptr inbounds float* %faction, i64 %idxprom56
  %40 = load float* %arrayidx242, align 4, !tbaa !3
  %add243 = fadd float %fiy3.0.lcssa, %40
  store float %add243, float* %arrayidx242, align 4, !tbaa !3
  %arrayidx249 = getelementptr inbounds float* %faction, i64 %idxprom60
  %41 = load float* %arrayidx249, align 4, !tbaa !3
  %add250 = fadd float %fiz3.0.lcssa, %41
  store float %add250, float* %arrayidx249, align 4, !tbaa !3
  %arrayidx255 = getelementptr inbounds float* %fshift, i64 %idxprom12
  %42 = load float* %arrayidx255, align 4, !tbaa !3
  %add256 = fadd float %fix1.0.lcssa, %42
  %add257 = fadd float %fix2.0.lcssa, %add256
  %add258 = fadd float %fix3.0.lcssa, %add257
  store float %add258, float* %arrayidx255, align 4, !tbaa !3
  %arrayidx263 = getelementptr inbounds float* %fshift, i64 %idxprom15
  %43 = load float* %arrayidx263, align 4, !tbaa !3
  %add264 = fadd float %fiy1.0.lcssa, %43
  %add265 = fadd float %fiy2.0.lcssa, %add264
  %add266 = fadd float %fiy3.0.lcssa, %add265
  store float %add266, float* %arrayidx263, align 4, !tbaa !3
  %arrayidx272 = getelementptr inbounds float* %fshift, i64 %idxprom18
  %44 = load float* %arrayidx272, align 4, !tbaa !3
  %add273 = fadd float %fiz1.0.lcssa, %44
  %add274 = fadd float %fiz2.0.lcssa, %add273
  %add275 = fadd float %fiz3.0.lcssa, %add274
  store float %add275, float* %arrayidx272, align 4, !tbaa !3
  %arrayidx280 = getelementptr inbounds i32* %gid, i64 %indvars.iv526
  %45 = load i32* %arrayidx280, align 4, !tbaa !0
  %idxprom281 = sext i32 %45 to i64
  %arrayidx282 = getelementptr inbounds float* %Vc, i64 %idxprom281
  %46 = load float* %arrayidx282, align 4, !tbaa !3
  %add283 = fadd float %vctot.0.lcssa, %46
  store float %add283, float* %arrayidx282, align 4, !tbaa !3
  %arrayidx287 = getelementptr inbounds float* %Vnb, i64 %idxprom281
  %47 = load float* %arrayidx287, align 4, !tbaa !3
  %add288 = fadd float %vnbtot.0.lcssa, %47
  store float %add288, float* %arrayidx287, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next527 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end293, label %for.end.for.body_crit_edge

for.end.for.body_crit_edge:                       ; preds = %for.end
  %arrayidx21.phi.trans.insert = getelementptr inbounds i32* %iinr, i64 %indvars.iv.next527
  %.pre = load i32* %arrayidx21.phi.trans.insert, align 4, !tbaa !0
  br label %for.body

for.end293:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl1130(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb) #0 {
entry:
  %0 = load i32* %iinr, align 4, !tbaa !0
  %idxprom = sext i32 %0 to i64
  %arrayidx1 = getelementptr inbounds float* %charge, i64 %idxprom
  %1 = load float* %arrayidx1, align 4, !tbaa !3
  %add = add nsw i32 %0, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds float* %charge, i64 %idxprom2
  %2 = load float* %arrayidx3, align 4, !tbaa !3
  %mul = fmul float %1, %facel
  %mul4 = fmul float %1, %mul
  %mul6 = fmul float %mul, %2
  %mul7 = fmul float %2, %facel
  %mul8 = fmul float %2, %mul7
  %mul9 = shl i32 %ntype, 1
  %arrayidx11 = getelementptr inbounds i32* %type, i64 %idxprom
  %3 = load i32* %arrayidx11, align 4, !tbaa !0
  %mul12 = mul nsw i32 %mul9, %3
  %mul15 = shl nsw i32 %3, 1
  %add16 = add nsw i32 %mul12, %mul15
  %idxprom17 = sext i32 %add16 to i64
  %arrayidx18 = getelementptr inbounds float* %nbfp, i64 %idxprom17
  %4 = load float* %arrayidx18, align 4, !tbaa !3
  %add19885 = or i32 %add16, 1
  %idxprom20 = sext i32 %add19885 to i64
  %arrayidx21 = getelementptr inbounds float* %nbfp, i64 %idxprom20
  %5 = load float* %arrayidx21, align 4, !tbaa !3
  %cmp909 = icmp sgt i32 %nri, 0
  br i1 %cmp909, label %for.body, label %for.end492

for.body:                                         ; preds = %entry, %for.end.for.body_crit_edge
  %6 = phi i32 [ %.pre, %for.end.for.body_crit_edge ], [ %0, %entry ]
  %indvars.iv911 = phi i64 [ %indvars.iv.next912, %for.end.for.body_crit_edge ], [ 0, %entry ]
  %arrayidx23 = getelementptr inbounds i32* %shift, i64 %indvars.iv911
  %7 = load i32* %arrayidx23, align 4, !tbaa !0
  %mul24 = mul nsw i32 %7, 3
  %idxprom25 = sext i32 %mul24 to i64
  %arrayidx26 = getelementptr inbounds float* %shiftvec, i64 %idxprom25
  %8 = load float* %arrayidx26, align 4, !tbaa !3
  %add27 = add nsw i32 %mul24, 1
  %idxprom28 = sext i32 %add27 to i64
  %arrayidx29 = getelementptr inbounds float* %shiftvec, i64 %idxprom28
  %9 = load float* %arrayidx29, align 4, !tbaa !3
  %add30 = add nsw i32 %mul24, 2
  %idxprom31 = sext i32 %add30 to i64
  %arrayidx32 = getelementptr inbounds float* %shiftvec, i64 %idxprom31
  %10 = load float* %arrayidx32, align 4, !tbaa !3
  %mul35 = mul nsw i32 %6, 3
  %arrayidx37 = getelementptr inbounds i32* %jindex, i64 %indvars.iv911
  %11 = load i32* %arrayidx37, align 4, !tbaa !0
  %indvars.iv.next912 = add i64 %indvars.iv911, 1
  %arrayidx40 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next912
  %12 = load i32* %arrayidx40, align 4, !tbaa !0
  %idxprom41 = sext i32 %mul35 to i64
  %arrayidx42 = getelementptr inbounds float* %pos, i64 %idxprom41
  %13 = load float* %arrayidx42, align 4, !tbaa !3
  %add43 = fadd float %8, %13
  %add44 = add nsw i32 %mul35, 1
  %idxprom45 = sext i32 %add44 to i64
  %arrayidx46 = getelementptr inbounds float* %pos, i64 %idxprom45
  %14 = load float* %arrayidx46, align 4, !tbaa !3
  %add47 = fadd float %9, %14
  %add48 = add nsw i32 %mul35, 2
  %idxprom49 = sext i32 %add48 to i64
  %arrayidx50 = getelementptr inbounds float* %pos, i64 %idxprom49
  %15 = load float* %arrayidx50, align 4, !tbaa !3
  %add51 = fadd float %10, %15
  %add52 = add nsw i32 %mul35, 3
  %idxprom53 = sext i32 %add52 to i64
  %arrayidx54 = getelementptr inbounds float* %pos, i64 %idxprom53
  %16 = load float* %arrayidx54, align 4, !tbaa !3
  %add55 = fadd float %8, %16
  %add56 = add nsw i32 %mul35, 4
  %idxprom57 = sext i32 %add56 to i64
  %arrayidx58 = getelementptr inbounds float* %pos, i64 %idxprom57
  %17 = load float* %arrayidx58, align 4, !tbaa !3
  %add59 = fadd float %9, %17
  %add60 = add nsw i32 %mul35, 5
  %idxprom61 = sext i32 %add60 to i64
  %arrayidx62 = getelementptr inbounds float* %pos, i64 %idxprom61
  %18 = load float* %arrayidx62, align 4, !tbaa !3
  %add63 = fadd float %10, %18
  %add64 = add nsw i32 %mul35, 6
  %idxprom65 = sext i32 %add64 to i64
  %arrayidx66 = getelementptr inbounds float* %pos, i64 %idxprom65
  %19 = load float* %arrayidx66, align 4, !tbaa !3
  %add67 = fadd float %8, %19
  %add68 = add nsw i32 %mul35, 7
  %idxprom69 = sext i32 %add68 to i64
  %arrayidx70 = getelementptr inbounds float* %pos, i64 %idxprom69
  %20 = load float* %arrayidx70, align 4, !tbaa !3
  %add71 = fadd float %9, %20
  %add72 = add nsw i32 %mul35, 8
  %idxprom73 = sext i32 %add72 to i64
  %arrayidx74 = getelementptr inbounds float* %pos, i64 %idxprom73
  %21 = load float* %arrayidx74, align 4, !tbaa !3
  %add75 = fadd float %10, %21
  %cmp77886 = icmp slt i32 %11, %12
  br i1 %cmp77886, label %for.body78.lr.ph, label %for.end

for.body78.lr.ph:                                 ; preds = %for.body
  %22 = sext i32 %11 to i64
  br label %for.body78

for.body78:                                       ; preds = %for.body78.lr.ph, %for.body78
  %indvars.iv = phi i64 [ %22, %for.body78.lr.ph ], [ %indvars.iv.next, %for.body78 ]
  %vctot.0897 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add373, %for.body78 ]
  %vnbtot.0896 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %sub219, %for.body78 ]
  %fix1.0895 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add273, %for.body78 ]
  %fiy1.0894 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add274, %for.body78 ]
  %fiz1.0893 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add275, %for.body78 ]
  %fix2.0892 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add321, %for.body78 ]
  %fiy2.0891 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add322, %for.body78 ]
  %fiz2.0890 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add323, %for.body78 ]
  %fix3.0889 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add377, %for.body78 ]
  %fiy3.0888 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add378, %for.body78 ]
  %fiz3.0887 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add379, %for.body78 ]
  %arrayidx80 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %23 = load i32* %arrayidx80, align 4, !tbaa !0
  %mul81 = mul nsw i32 %23, 3
  %idxprom82 = sext i32 %mul81 to i64
  %arrayidx83 = getelementptr inbounds float* %pos, i64 %idxprom82
  %24 = load float* %arrayidx83, align 4, !tbaa !3
  %add84 = add nsw i32 %mul81, 1
  %idxprom85 = sext i32 %add84 to i64
  %arrayidx86 = getelementptr inbounds float* %pos, i64 %idxprom85
  %25 = load float* %arrayidx86, align 4, !tbaa !3
  %add87 = add nsw i32 %mul81, 2
  %idxprom88 = sext i32 %add87 to i64
  %arrayidx89 = getelementptr inbounds float* %pos, i64 %idxprom88
  %26 = load float* %arrayidx89, align 4, !tbaa !3
  %add90 = add nsw i32 %mul81, 3
  %idxprom91 = sext i32 %add90 to i64
  %arrayidx92 = getelementptr inbounds float* %pos, i64 %idxprom91
  %27 = load float* %arrayidx92, align 4, !tbaa !3
  %add93 = add nsw i32 %mul81, 4
  %idxprom94 = sext i32 %add93 to i64
  %arrayidx95 = getelementptr inbounds float* %pos, i64 %idxprom94
  %28 = load float* %arrayidx95, align 4, !tbaa !3
  %add96 = add nsw i32 %mul81, 5
  %idxprom97 = sext i32 %add96 to i64
  %arrayidx98 = getelementptr inbounds float* %pos, i64 %idxprom97
  %29 = load float* %arrayidx98, align 4, !tbaa !3
  %add99 = add nsw i32 %mul81, 6
  %idxprom100 = sext i32 %add99 to i64
  %arrayidx101 = getelementptr inbounds float* %pos, i64 %idxprom100
  %30 = load float* %arrayidx101, align 4, !tbaa !3
  %add102 = add nsw i32 %mul81, 7
  %idxprom103 = sext i32 %add102 to i64
  %arrayidx104 = getelementptr inbounds float* %pos, i64 %idxprom103
  %31 = load float* %arrayidx104, align 4, !tbaa !3
  %add105 = add nsw i32 %mul81, 8
  %idxprom106 = sext i32 %add105 to i64
  %arrayidx107 = getelementptr inbounds float* %pos, i64 %idxprom106
  %32 = load float* %arrayidx107, align 4, !tbaa !3
  %sub = fsub float %add43, %24
  %sub108 = fsub float %add47, %25
  %sub109 = fsub float %add51, %26
  %mul110 = fmul float %sub, %sub
  %mul111 = fmul float %sub108, %sub108
  %add112 = fadd float %mul110, %mul111
  %mul113 = fmul float %sub109, %sub109
  %add114 = fadd float %add112, %mul113
  %sub115 = fsub float %add43, %27
  %sub116 = fsub float %add47, %28
  %sub117 = fsub float %add51, %29
  %mul118 = fmul float %sub115, %sub115
  %mul119 = fmul float %sub116, %sub116
  %add120 = fadd float %mul118, %mul119
  %mul121 = fmul float %sub117, %sub117
  %add122 = fadd float %add120, %mul121
  %sub123 = fsub float %add43, %30
  %sub124 = fsub float %add47, %31
  %sub125 = fsub float %add51, %32
  %mul126 = fmul float %sub123, %sub123
  %mul127 = fmul float %sub124, %sub124
  %add128 = fadd float %mul126, %mul127
  %mul129 = fmul float %sub125, %sub125
  %add130 = fadd float %add128, %mul129
  %sub131 = fsub float %add55, %24
  %sub132 = fsub float %add59, %25
  %sub133 = fsub float %add63, %26
  %mul134 = fmul float %sub131, %sub131
  %mul135 = fmul float %sub132, %sub132
  %add136 = fadd float %mul134, %mul135
  %mul137 = fmul float %sub133, %sub133
  %add138 = fadd float %add136, %mul137
  %sub139 = fsub float %add55, %27
  %sub140 = fsub float %add59, %28
  %sub141 = fsub float %add63, %29
  %mul142 = fmul float %sub139, %sub139
  %mul143 = fmul float %sub140, %sub140
  %add144 = fadd float %mul142, %mul143
  %mul145 = fmul float %sub141, %sub141
  %add146 = fadd float %add144, %mul145
  %sub147 = fsub float %add55, %30
  %sub148 = fsub float %add59, %31
  %sub149 = fsub float %add63, %32
  %mul150 = fmul float %sub147, %sub147
  %mul151 = fmul float %sub148, %sub148
  %add152 = fadd float %mul150, %mul151
  %mul153 = fmul float %sub149, %sub149
  %add154 = fadd float %add152, %mul153
  %sub155 = fsub float %add67, %24
  %sub156 = fsub float %add71, %25
  %sub157 = fsub float %add75, %26
  %mul158 = fmul float %sub155, %sub155
  %mul159 = fmul float %sub156, %sub156
  %add160 = fadd float %mul158, %mul159
  %mul161 = fmul float %sub157, %sub157
  %add162 = fadd float %add160, %mul161
  %sub163 = fsub float %add67, %27
  %sub164 = fsub float %add71, %28
  %sub165 = fsub float %add75, %29
  %mul166 = fmul float %sub163, %sub163
  %mul167 = fmul float %sub164, %sub164
  %add168 = fadd float %mul166, %mul167
  %mul169 = fmul float %sub165, %sub165
  %add170 = fadd float %add168, %mul169
  %sub171 = fsub float %add67, %30
  %sub172 = fsub float %add71, %31
  %sub173 = fsub float %add75, %32
  %mul174 = fmul float %sub171, %sub171
  %mul175 = fmul float %sub172, %sub172
  %add176 = fadd float %mul174, %mul175
  %mul177 = fmul float %sub173, %sub173
  %add178 = fadd float %add176, %mul177
  %conv = fpext float %add114 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv179 = fptrunc double %div to float
  %conv180 = fpext float %add138 to double
  %call181 = tail call double @sqrt(double %conv180) #2
  %div182 = fdiv double 1.000000e+00, %call181
  %conv183 = fptrunc double %div182 to float
  %conv184 = fpext float %add162 to double
  %call185 = tail call double @sqrt(double %conv184) #2
  %div186 = fdiv double 1.000000e+00, %call185
  %conv187 = fptrunc double %div186 to float
  %conv188 = fpext float %add122 to double
  %call189 = tail call double @sqrt(double %conv188) #2
  %div190 = fdiv double 1.000000e+00, %call189
  %conv191 = fptrunc double %div190 to float
  %conv192 = fpext float %add146 to double
  %call193 = tail call double @sqrt(double %conv192) #2
  %div194 = fdiv double 1.000000e+00, %call193
  %conv195 = fptrunc double %div194 to float
  %conv196 = fpext float %add170 to double
  %call197 = tail call double @sqrt(double %conv196) #2
  %div198 = fdiv double 1.000000e+00, %call197
  %conv199 = fptrunc double %div198 to float
  %conv200 = fpext float %add130 to double
  %call201 = tail call double @sqrt(double %conv200) #2
  %div202 = fdiv double 1.000000e+00, %call201
  %conv203 = fptrunc double %div202 to float
  %conv204 = fpext float %add154 to double
  %call205 = tail call double @sqrt(double %conv204) #2
  %div206 = fdiv double 1.000000e+00, %call205
  %conv207 = fptrunc double %div206 to float
  %conv208 = fpext float %add178 to double
  %call209 = tail call double @sqrt(double %conv208) #2
  %div210 = fdiv double 1.000000e+00, %call209
  %conv211 = fptrunc double %div210 to float
  %mul212 = fmul float %conv179, %conv179
  %mul213 = fmul float %mul212, %mul212
  %mul214 = fmul float %mul212, %mul213
  %mul215 = fmul float %4, %mul214
  %mul216 = fmul float %5, %mul214
  %mul217 = fmul float %mul214, %mul216
  %add218 = fadd float %vnbtot.0896, %mul217
  %sub219 = fsub float %add218, %mul215
  %mul220 = fmul float %mul4, %conv179
  %mul221 = fmul float %mul217, 1.200000e+01
  %mul222 = fmul float %mul215, 6.000000e+00
  %sub223 = fsub float %mul221, %mul222
  %add224 = fadd float %mul220, %sub223
  %mul225 = fmul float %mul212, %add224
  %add226 = fadd float %vctot.0897, %mul220
  %mul227 = fmul float %sub, %mul225
  %mul228 = fmul float %sub108, %mul225
  %mul229 = fmul float %sub109, %mul225
  %add230 = fadd float %fix1.0895, %mul227
  %add231 = fadd float %fiy1.0894, %mul228
  %add232 = fadd float %fiz1.0893, %mul229
  %arrayidx234 = getelementptr inbounds float* %faction, i64 %idxprom82
  %33 = load float* %arrayidx234, align 4, !tbaa !3
  %sub235 = fsub float %33, %mul227
  %arrayidx238 = getelementptr inbounds float* %faction, i64 %idxprom85
  %34 = load float* %arrayidx238, align 4, !tbaa !3
  %sub239 = fsub float %34, %mul228
  %arrayidx242 = getelementptr inbounds float* %faction, i64 %idxprom88
  %35 = load float* %arrayidx242, align 4, !tbaa !3
  %sub243 = fsub float %35, %mul229
  %mul244 = fmul float %conv191, %conv191
  %mul245 = fmul float %mul6, %conv191
  %mul246 = fmul float %mul245, %mul244
  %add247 = fadd float %add226, %mul245
  %mul248 = fmul float %sub115, %mul246
  %mul249 = fmul float %sub116, %mul246
  %mul250 = fmul float %sub117, %mul246
  %add251 = fadd float %mul248, %add230
  %add252 = fadd float %mul249, %add231
  %add253 = fadd float %mul250, %add232
  %arrayidx256 = getelementptr inbounds float* %faction, i64 %idxprom91
  %36 = load float* %arrayidx256, align 4, !tbaa !3
  %sub257 = fsub float %36, %mul248
  %arrayidx260 = getelementptr inbounds float* %faction, i64 %idxprom94
  %37 = load float* %arrayidx260, align 4, !tbaa !3
  %sub261 = fsub float %37, %mul249
  %arrayidx264 = getelementptr inbounds float* %faction, i64 %idxprom97
  %38 = load float* %arrayidx264, align 4, !tbaa !3
  %sub265 = fsub float %38, %mul250
  %mul266 = fmul float %conv203, %conv203
  %mul267 = fmul float %mul6, %conv203
  %mul268 = fmul float %mul267, %mul266
  %add269 = fadd float %add247, %mul267
  %mul270 = fmul float %sub123, %mul268
  %mul271 = fmul float %sub124, %mul268
  %mul272 = fmul float %sub125, %mul268
  %add273 = fadd float %add251, %mul270
  %add274 = fadd float %add252, %mul271
  %add275 = fadd float %add253, %mul272
  %arrayidx278 = getelementptr inbounds float* %faction, i64 %idxprom100
  %39 = load float* %arrayidx278, align 4, !tbaa !3
  %sub279 = fsub float %39, %mul270
  %arrayidx282 = getelementptr inbounds float* %faction, i64 %idxprom103
  %40 = load float* %arrayidx282, align 4, !tbaa !3
  %sub283 = fsub float %40, %mul271
  %arrayidx286 = getelementptr inbounds float* %faction, i64 %idxprom106
  %41 = load float* %arrayidx286, align 4, !tbaa !3
  %sub287 = fsub float %41, %mul272
  %mul288 = fmul float %conv183, %conv183
  %mul289 = fmul float %mul6, %conv183
  %mul290 = fmul float %mul289, %mul288
  %add291 = fadd float %mul289, %add269
  %mul292 = fmul float %sub131, %mul290
  %mul293 = fmul float %sub132, %mul290
  %mul294 = fmul float %sub133, %mul290
  %add295 = fadd float %fix2.0892, %mul292
  %add296 = fadd float %fiy2.0891, %mul293
  %add297 = fadd float %fiz2.0890, %mul294
  %sub298 = fsub float %sub235, %mul292
  %sub299 = fsub float %sub239, %mul293
  %sub300 = fsub float %sub243, %mul294
  %mul301 = fmul float %conv195, %conv195
  %mul302 = fmul float %mul8, %conv195
  %mul303 = fmul float %mul302, %mul301
  %add304 = fadd float %mul302, %add291
  %mul305 = fmul float %sub139, %mul303
  %mul306 = fmul float %sub140, %mul303
  %mul307 = fmul float %sub141, %mul303
  %add308 = fadd float %add295, %mul305
  %add309 = fadd float %add296, %mul306
  %add310 = fadd float %add297, %mul307
  %sub311 = fsub float %sub257, %mul305
  %sub312 = fsub float %sub261, %mul306
  %sub313 = fsub float %sub265, %mul307
  %mul314 = fmul float %conv207, %conv207
  %mul315 = fmul float %mul8, %conv207
  %mul316 = fmul float %mul315, %mul314
  %add317 = fadd float %mul315, %add304
  %mul318 = fmul float %sub147, %mul316
  %mul319 = fmul float %sub148, %mul316
  %mul320 = fmul float %sub149, %mul316
  %add321 = fadd float %add308, %mul318
  %add322 = fadd float %add309, %mul319
  %add323 = fadd float %add310, %mul320
  %sub324 = fsub float %sub279, %mul318
  %sub325 = fsub float %sub283, %mul319
  %sub326 = fsub float %sub287, %mul320
  %mul327 = fmul float %conv187, %conv187
  %mul328 = fmul float %mul6, %conv187
  %mul329 = fmul float %mul328, %mul327
  %add330 = fadd float %mul328, %add317
  %mul331 = fmul float %sub155, %mul329
  %mul332 = fmul float %sub156, %mul329
  %mul333 = fmul float %sub157, %mul329
  %add334 = fadd float %fix3.0889, %mul331
  %add335 = fadd float %fiy3.0888, %mul332
  %add336 = fadd float %fiz3.0887, %mul333
  %sub337 = fsub float %sub298, %mul331
  store float %sub337, float* %arrayidx234, align 4, !tbaa !3
  %sub340 = fsub float %sub299, %mul332
  store float %sub340, float* %arrayidx238, align 4, !tbaa !3
  %sub344 = fsub float %sub300, %mul333
  store float %sub344, float* %arrayidx242, align 4, !tbaa !3
  %mul348 = fmul float %conv199, %conv199
  %mul349 = fmul float %mul8, %conv199
  %mul350 = fmul float %mul349, %mul348
  %add351 = fadd float %mul349, %add330
  %mul352 = fmul float %sub163, %mul350
  %mul353 = fmul float %sub164, %mul350
  %mul354 = fmul float %sub165, %mul350
  %add355 = fadd float %add334, %mul352
  %add356 = fadd float %add335, %mul353
  %add357 = fadd float %add336, %mul354
  %sub358 = fsub float %sub311, %mul352
  store float %sub358, float* %arrayidx256, align 4, !tbaa !3
  %sub362 = fsub float %sub312, %mul353
  store float %sub362, float* %arrayidx260, align 4, !tbaa !3
  %sub366 = fsub float %sub313, %mul354
  store float %sub366, float* %arrayidx264, align 4, !tbaa !3
  %mul370 = fmul float %conv211, %conv211
  %mul371 = fmul float %mul8, %conv211
  %mul372 = fmul float %mul371, %mul370
  %add373 = fadd float %mul371, %add351
  %mul374 = fmul float %sub171, %mul372
  %mul375 = fmul float %sub172, %mul372
  %mul376 = fmul float %sub173, %mul372
  %add377 = fadd float %add355, %mul374
  %add378 = fadd float %add356, %mul375
  %add379 = fadd float %add357, %mul376
  %sub380 = fsub float %sub324, %mul374
  store float %sub380, float* %arrayidx278, align 4, !tbaa !3
  %sub384 = fsub float %sub325, %mul375
  store float %sub384, float* %arrayidx282, align 4, !tbaa !3
  %sub388 = fsub float %sub326, %mul376
  store float %sub388, float* %arrayidx286, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %42 = trunc i64 %indvars.iv.next to i32
  %cmp77 = icmp slt i32 %42, %12
  br i1 %cmp77, label %for.body78, label %for.end

for.end:                                          ; preds = %for.body78, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add373, %for.body78 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %sub219, %for.body78 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add273, %for.body78 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add274, %for.body78 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add275, %for.body78 ]
  %fix2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add321, %for.body78 ]
  %fiy2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add322, %for.body78 ]
  %fiz2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add323, %for.body78 ]
  %fix3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add377, %for.body78 ]
  %fiy3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add378, %for.body78 ]
  %fiz3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add379, %for.body78 ]
  %arrayidx393 = getelementptr inbounds float* %faction, i64 %idxprom41
  %43 = load float* %arrayidx393, align 4, !tbaa !3
  %add394 = fadd float %fix1.0.lcssa, %43
  store float %add394, float* %arrayidx393, align 4, !tbaa !3
  %arrayidx399 = getelementptr inbounds float* %faction, i64 %idxprom45
  %44 = load float* %arrayidx399, align 4, !tbaa !3
  %add400 = fadd float %fiy1.0.lcssa, %44
  store float %add400, float* %arrayidx399, align 4, !tbaa !3
  %arrayidx406 = getelementptr inbounds float* %faction, i64 %idxprom49
  %45 = load float* %arrayidx406, align 4, !tbaa !3
  %add407 = fadd float %fiz1.0.lcssa, %45
  store float %add407, float* %arrayidx406, align 4, !tbaa !3
  %arrayidx413 = getelementptr inbounds float* %faction, i64 %idxprom53
  %46 = load float* %arrayidx413, align 4, !tbaa !3
  %add414 = fadd float %fix2.0.lcssa, %46
  store float %add414, float* %arrayidx413, align 4, !tbaa !3
  %arrayidx420 = getelementptr inbounds float* %faction, i64 %idxprom57
  %47 = load float* %arrayidx420, align 4, !tbaa !3
  %add421 = fadd float %fiy2.0.lcssa, %47
  store float %add421, float* %arrayidx420, align 4, !tbaa !3
  %arrayidx427 = getelementptr inbounds float* %faction, i64 %idxprom61
  %48 = load float* %arrayidx427, align 4, !tbaa !3
  %add428 = fadd float %fiz2.0.lcssa, %48
  store float %add428, float* %arrayidx427, align 4, !tbaa !3
  %arrayidx434 = getelementptr inbounds float* %faction, i64 %idxprom65
  %49 = load float* %arrayidx434, align 4, !tbaa !3
  %add435 = fadd float %fix3.0.lcssa, %49
  store float %add435, float* %arrayidx434, align 4, !tbaa !3
  %arrayidx441 = getelementptr inbounds float* %faction, i64 %idxprom69
  %50 = load float* %arrayidx441, align 4, !tbaa !3
  %add442 = fadd float %fiy3.0.lcssa, %50
  store float %add442, float* %arrayidx441, align 4, !tbaa !3
  %arrayidx448 = getelementptr inbounds float* %faction, i64 %idxprom73
  %51 = load float* %arrayidx448, align 4, !tbaa !3
  %add449 = fadd float %fiz3.0.lcssa, %51
  store float %add449, float* %arrayidx448, align 4, !tbaa !3
  %arrayidx454 = getelementptr inbounds float* %fshift, i64 %idxprom25
  %52 = load float* %arrayidx454, align 4, !tbaa !3
  %add455 = fadd float %fix1.0.lcssa, %52
  %add456 = fadd float %fix2.0.lcssa, %add455
  %add457 = fadd float %fix3.0.lcssa, %add456
  store float %add457, float* %arrayidx454, align 4, !tbaa !3
  %arrayidx462 = getelementptr inbounds float* %fshift, i64 %idxprom28
  %53 = load float* %arrayidx462, align 4, !tbaa !3
  %add463 = fadd float %fiy1.0.lcssa, %53
  %add464 = fadd float %fiy2.0.lcssa, %add463
  %add465 = fadd float %fiy3.0.lcssa, %add464
  store float %add465, float* %arrayidx462, align 4, !tbaa !3
  %arrayidx471 = getelementptr inbounds float* %fshift, i64 %idxprom31
  %54 = load float* %arrayidx471, align 4, !tbaa !3
  %add472 = fadd float %fiz1.0.lcssa, %54
  %add473 = fadd float %fiz2.0.lcssa, %add472
  %add474 = fadd float %fiz3.0.lcssa, %add473
  store float %add474, float* %arrayidx471, align 4, !tbaa !3
  %arrayidx479 = getelementptr inbounds i32* %gid, i64 %indvars.iv911
  %55 = load i32* %arrayidx479, align 4, !tbaa !0
  %idxprom480 = sext i32 %55 to i64
  %arrayidx481 = getelementptr inbounds float* %Vc, i64 %idxprom480
  %56 = load float* %arrayidx481, align 4, !tbaa !3
  %add482 = fadd float %vctot.0.lcssa, %56
  store float %add482, float* %arrayidx481, align 4, !tbaa !3
  %arrayidx486 = getelementptr inbounds float* %Vnb, i64 %idxprom480
  %57 = load float* %arrayidx486, align 4, !tbaa !3
  %add487 = fadd float %vnbtot.0.lcssa, %57
  store float %add487, float* %arrayidx486, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next912 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end492, label %for.end.for.body_crit_edge

for.end.for.body_crit_edge:                       ; preds = %for.end
  %arrayidx34.phi.trans.insert = getelementptr inbounds i32* %iinr, i64 %indvars.iv.next912
  %.pre = load i32* %arrayidx34.phi.trans.insert, align 4, !tbaa !0
  br label %for.body

for.end492:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl1200(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb) #0 {
entry:
  %cmp283 = icmp sgt i32 %nri, 0
  br i1 %cmp283, label %for.body, label %for.end169

for.body:                                         ; preds = %for.end, %entry
  %indvars.iv285 = phi i64 [ 0, %entry ], [ %indvars.iv.next286, %for.end ]
  %arrayidx = getelementptr inbounds i32* %shift, i64 %indvars.iv285
  %0 = load i32* %arrayidx, align 4, !tbaa !0
  %mul = mul nsw i32 %0, 3
  %idxprom1 = sext i32 %mul to i64
  %arrayidx2 = getelementptr inbounds float* %shiftvec, i64 %idxprom1
  %1 = load float* %arrayidx2, align 4, !tbaa !3
  %add = add nsw i32 %mul, 1
  %idxprom3 = sext i32 %add to i64
  %arrayidx4 = getelementptr inbounds float* %shiftvec, i64 %idxprom3
  %2 = load float* %arrayidx4, align 4, !tbaa !3
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds float* %shiftvec, i64 %idxprom6
  %3 = load float* %arrayidx7, align 4, !tbaa !3
  %arrayidx9 = getelementptr inbounds i32* %iinr, i64 %indvars.iv285
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %arrayidx12 = getelementptr inbounds i32* %jindex, i64 %indvars.iv285
  %5 = load i32* %arrayidx12, align 4, !tbaa !0
  %indvars.iv.next286 = add i64 %indvars.iv285, 1
  %arrayidx15 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next286
  %6 = load i32* %arrayidx15, align 4, !tbaa !0
  %idxprom16 = sext i32 %mul10 to i64
  %arrayidx17 = getelementptr inbounds float* %pos, i64 %idxprom16
  %7 = load float* %arrayidx17, align 4, !tbaa !3
  %add18 = fadd float %1, %7
  %add19 = add nsw i32 %mul10, 1
  %idxprom20 = sext i32 %add19 to i64
  %arrayidx21 = getelementptr inbounds float* %pos, i64 %idxprom20
  %8 = load float* %arrayidx21, align 4, !tbaa !3
  %add22 = fadd float %2, %8
  %add23 = add nsw i32 %mul10, 2
  %idxprom24 = sext i32 %add23 to i64
  %arrayidx25 = getelementptr inbounds float* %pos, i64 %idxprom24
  %9 = load float* %arrayidx25, align 4, !tbaa !3
  %add26 = fadd float %3, %9
  %idxprom27 = sext i32 %4 to i64
  %arrayidx28 = getelementptr inbounds float* %charge, i64 %idxprom27
  %10 = load float* %arrayidx28, align 4, !tbaa !3
  %mul29 = fmul float %10, %facel
  %arrayidx32 = getelementptr inbounds i32* %type, i64 %idxprom27
  %11 = load i32* %arrayidx32, align 4, !tbaa !0
  %mul33 = mul i32 %11, %ntype
  %cmp35272 = icmp slt i32 %5, %6
  br i1 %cmp35272, label %for.body36.lr.ph, label %for.end

for.body36.lr.ph:                                 ; preds = %for.body
  %12 = sext i32 %5 to i64
  br label %for.body36

for.body36:                                       ; preds = %for.body36.lr.ph, %for.body36
  %indvars.iv = phi i64 [ %12, %for.body36.lr.ph ], [ %indvars.iv.next, %for.body36 ]
  %vctot.0277 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add91, %for.body36 ]
  %vnbtot.0276 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %sub81, %for.body36 ]
  %fix1.0275 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add95, %for.body36 ]
  %fiy1.0274 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add96, %for.body36 ]
  %fiz1.0273 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add97, %for.body36 ]
  %arrayidx38 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %13 = load i32* %arrayidx38, align 4, !tbaa !0
  %mul39 = mul nsw i32 %13, 3
  %idxprom40 = sext i32 %mul39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %14 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = add nsw i32 %mul39, 1
  %idxprom43 = sext i32 %add42 to i64
  %arrayidx44 = getelementptr inbounds float* %pos, i64 %idxprom43
  %15 = load float* %arrayidx44, align 4, !tbaa !3
  %add45 = add nsw i32 %mul39, 2
  %idxprom46 = sext i32 %add45 to i64
  %arrayidx47 = getelementptr inbounds float* %pos, i64 %idxprom46
  %16 = load float* %arrayidx47, align 4, !tbaa !3
  %sub = fsub float %add18, %14
  %sub48 = fsub float %add22, %15
  %sub49 = fsub float %add26, %16
  %mul50 = fmul float %sub, %sub
  %mul51 = fmul float %sub48, %sub48
  %add52 = fadd float %mul50, %mul51
  %mul53 = fmul float %sub49, %sub49
  %add54 = fadd float %add52, %mul53
  %conv = fpext float %add54 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv55 = fptrunc double %div to float
  %mul56 = fmul float %add54, %conv55
  %mul57 = fmul float %conv55, %conv55
  %mul58 = fmul float %mul57, %mul57
  %mul59 = fmul float %mul57, %mul58
  %idxprom60 = sext i32 %13 to i64
  %arrayidx61 = getelementptr inbounds i32* %type, i64 %idxprom60
  %17 = load i32* %arrayidx61, align 4, !tbaa !0
  %tmp = add i32 %17, %mul33
  %tmp271 = mul i32 %tmp, 3
  %idxprom64 = sext i32 %tmp271 to i64
  %arrayidx65 = getelementptr inbounds float* %nbfp, i64 %idxprom64
  %18 = load float* %arrayidx65, align 4, !tbaa !3
  %mul66 = fmul float %18, %mul59
  %add67 = add nsw i32 %tmp271, 2
  %idxprom68 = sext i32 %add67 to i64
  %arrayidx69 = getelementptr inbounds float* %nbfp, i64 %idxprom68
  %19 = load float* %arrayidx69, align 4, !tbaa !3
  %mul70 = fmul float %mul56, %19
  %sub71 = fsub float -0.000000e+00, %mul70
  %conv72 = fpext float %sub71 to double
  %call73 = tail call double @exp(double %conv72) #2
  %add74 = add nsw i32 %tmp271, 1
  %idxprom75 = sext i32 %add74 to i64
  %arrayidx76 = getelementptr inbounds float* %nbfp, i64 %idxprom75
  %20 = load float* %arrayidx76, align 4, !tbaa !3
  %conv77 = fpext float %20 to double
  %mul78 = fmul double %call73, %conv77
  %conv79 = fptrunc double %mul78 to float
  %add80 = fadd float %vnbtot.0276, %conv79
  %sub81 = fsub float %add80, %mul66
  %arrayidx83 = getelementptr inbounds float* %charge, i64 %idxprom60
  %21 = load float* %arrayidx83, align 4, !tbaa !3
  %mul84 = fmul float %mul29, %21
  %mul85 = fmul float %conv55, %mul84
  %mul86 = fmul float %mul70, %conv79
  %mul87 = fmul float %mul66, 6.000000e+00
  %sub88 = fsub float %mul86, %mul87
  %add89 = fadd float %mul85, %sub88
  %mul90 = fmul float %mul57, %add89
  %add91 = fadd float %vctot.0277, %mul85
  %mul92 = fmul float %sub, %mul90
  %mul93 = fmul float %sub48, %mul90
  %mul94 = fmul float %sub49, %mul90
  %add95 = fadd float %fix1.0275, %mul92
  %add96 = fadd float %fiy1.0274, %mul93
  %add97 = fadd float %fiz1.0273, %mul94
  %arrayidx99 = getelementptr inbounds float* %faction, i64 %idxprom40
  %22 = load float* %arrayidx99, align 4, !tbaa !3
  %sub100 = fsub float %22, %mul92
  store float %sub100, float* %arrayidx99, align 4, !tbaa !3
  %arrayidx105 = getelementptr inbounds float* %faction, i64 %idxprom43
  %23 = load float* %arrayidx105, align 4, !tbaa !3
  %sub106 = fsub float %23, %mul93
  store float %sub106, float* %arrayidx105, align 4, !tbaa !3
  %arrayidx112 = getelementptr inbounds float* %faction, i64 %idxprom46
  %24 = load float* %arrayidx112, align 4, !tbaa !3
  %sub113 = fsub float %24, %mul94
  store float %sub113, float* %arrayidx112, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %25 = trunc i64 %indvars.iv.next to i32
  %cmp35 = icmp slt i32 %25, %6
  br i1 %cmp35, label %for.body36, label %for.end

for.end:                                          ; preds = %for.body36, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add91, %for.body36 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %sub81, %for.body36 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add95, %for.body36 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add96, %for.body36 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add97, %for.body36 ]
  %arrayidx118 = getelementptr inbounds float* %faction, i64 %idxprom16
  %26 = load float* %arrayidx118, align 4, !tbaa !3
  %add119 = fadd float %fix1.0.lcssa, %26
  store float %add119, float* %arrayidx118, align 4, !tbaa !3
  %arrayidx124 = getelementptr inbounds float* %faction, i64 %idxprom20
  %27 = load float* %arrayidx124, align 4, !tbaa !3
  %add125 = fadd float %fiy1.0.lcssa, %27
  store float %add125, float* %arrayidx124, align 4, !tbaa !3
  %arrayidx131 = getelementptr inbounds float* %faction, i64 %idxprom24
  %28 = load float* %arrayidx131, align 4, !tbaa !3
  %add132 = fadd float %fiz1.0.lcssa, %28
  store float %add132, float* %arrayidx131, align 4, !tbaa !3
  %arrayidx137 = getelementptr inbounds float* %fshift, i64 %idxprom1
  %29 = load float* %arrayidx137, align 4, !tbaa !3
  %add138 = fadd float %fix1.0.lcssa, %29
  store float %add138, float* %arrayidx137, align 4, !tbaa !3
  %arrayidx143 = getelementptr inbounds float* %fshift, i64 %idxprom3
  %30 = load float* %arrayidx143, align 4, !tbaa !3
  %add144 = fadd float %fiy1.0.lcssa, %30
  store float %add144, float* %arrayidx143, align 4, !tbaa !3
  %arrayidx150 = getelementptr inbounds float* %fshift, i64 %idxprom6
  %31 = load float* %arrayidx150, align 4, !tbaa !3
  %add151 = fadd float %fiz1.0.lcssa, %31
  store float %add151, float* %arrayidx150, align 4, !tbaa !3
  %arrayidx156 = getelementptr inbounds i32* %gid, i64 %indvars.iv285
  %32 = load i32* %arrayidx156, align 4, !tbaa !0
  %idxprom157 = sext i32 %32 to i64
  %arrayidx158 = getelementptr inbounds float* %Vc, i64 %idxprom157
  %33 = load float* %arrayidx158, align 4, !tbaa !3
  %add159 = fadd float %vctot.0.lcssa, %33
  store float %add159, float* %arrayidx158, align 4, !tbaa !3
  %arrayidx163 = getelementptr inbounds float* %Vnb, i64 %idxprom157
  %34 = load float* %arrayidx163, align 4, !tbaa !3
  %add164 = fadd float %vnbtot.0.lcssa, %34
  store float %add164, float* %arrayidx163, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next286 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end169, label %for.body

for.end169:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl1210(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, i32* nocapture %nsatoms) #0 {
entry:
  %cmp863 = icmp sgt i32 %nri, 0
  br i1 %cmp863, label %for.body, label %for.end458

for.body:                                         ; preds = %for.end443, %entry
  %indvars.iv889 = phi i64 [ 0, %entry ], [ %indvars.iv.next890, %for.end443 ]
  %0 = trunc i64 %indvars.iv889 to i32
  %mul = mul nsw i32 %0, 3
  %idxprom = sext i32 %mul to i64
  %arrayidx = getelementptr inbounds i32* %nsatoms, i64 %idxprom
  %1 = load i32* %arrayidx, align 4, !tbaa !0
  %add = add nsw i32 %mul, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds i32* %nsatoms, i64 %idxprom2
  %2 = load i32* %arrayidx3, align 4, !tbaa !0
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds i32* %nsatoms, i64 %idxprom6
  %3 = load i32* %arrayidx7, align 4, !tbaa !0
  %arrayidx9 = getelementptr inbounds i32* %shift, i64 %indvars.iv889
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %idxprom11 = sext i32 %mul10 to i64
  %arrayidx12 = getelementptr inbounds float* %shiftvec, i64 %idxprom11
  %5 = load float* %arrayidx12, align 4, !tbaa !3
  %add13 = add nsw i32 %mul10, 1
  %idxprom14 = sext i32 %add13 to i64
  %arrayidx15 = getelementptr inbounds float* %shiftvec, i64 %idxprom14
  %6 = load float* %arrayidx15, align 4, !tbaa !3
  %add16 = add nsw i32 %mul10, 2
  %idxprom17 = sext i32 %add16 to i64
  %arrayidx18 = getelementptr inbounds float* %shiftvec, i64 %idxprom17
  %7 = load float* %arrayidx18, align 4, !tbaa !3
  %arrayidx20 = getelementptr inbounds i32* %iinr, i64 %indvars.iv889
  %8 = load i32* %arrayidx20, align 4, !tbaa !0
  %mul21 = mul i32 %8, 3
  %arrayidx23 = getelementptr inbounds i32* %jindex, i64 %indvars.iv889
  %9 = load i32* %arrayidx23, align 4, !tbaa !0
  %indvars.iv.next890 = add i64 %indvars.iv889, 1
  %arrayidx26 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next890
  %10 = load i32* %arrayidx26, align 4, !tbaa !0
  %cmp28819 = icmp sgt i32 %2, 0
  br i1 %cmp28819, label %for.body29.lr.ph, label %for.cond174.loopexit

for.body29.lr.ph:                                 ; preds = %for.body
  %cmp49808 = icmp slt i32 %9, %10
  %arrayidx151 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx157 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx164 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %11 = sext i32 %9 to i64
  %12 = sext i32 %8 to i64
  %13 = sext i32 %mul21 to i64
  %14 = add i32 %2, %8
  %15 = mul i32 %14, 3
  br label %for.body29

for.body29:                                       ; preds = %for.end, %for.body29.lr.ph
  %indvars.iv867 = phi i64 [ %13, %for.body29.lr.ph ], [ %indvars.iv.next868, %for.end ]
  %indvars.iv865 = phi i64 [ %12, %for.body29.lr.ph ], [ %indvars.iv.next866, %for.end ]
  %s.0822 = phi i32 [ 0, %for.body29.lr.ph ], [ %inc172, %for.end ]
  %vctot.0821 = phi float [ 0.000000e+00, %for.body29.lr.ph ], [ %vctot.1.lcssa, %for.end ]
  %vnbtot.0820 = phi float [ 0.000000e+00, %for.body29.lr.ph ], [ %vnbtot.1.lcssa, %for.end ]
  %arrayidx31 = getelementptr inbounds float* %pos, i64 %indvars.iv867
  %16 = load float* %arrayidx31, align 4, !tbaa !3
  %add32 = fadd float %5, %16
  %17 = add nsw i64 %indvars.iv867, 1
  %arrayidx35 = getelementptr inbounds float* %pos, i64 %17
  %18 = load float* %arrayidx35, align 4, !tbaa !3
  %add36 = fadd float %6, %18
  %19 = add nsw i64 %indvars.iv867, 2
  %arrayidx39 = getelementptr inbounds float* %pos, i64 %19
  %20 = load float* %arrayidx39, align 4, !tbaa !3
  %add40 = fadd float %7, %20
  %arrayidx42 = getelementptr inbounds float* %charge, i64 %indvars.iv865
  %21 = load float* %arrayidx42, align 4, !tbaa !3
  %mul43 = fmul float %21, %facel
  %arrayidx46 = getelementptr inbounds i32* %type, i64 %indvars.iv865
  %22 = load i32* %arrayidx46, align 4, !tbaa !0
  %mul47 = mul i32 %22, %ntype
  br i1 %cmp49808, label %for.body50, label %for.end

for.body50:                                       ; preds = %for.body29, %for.body50
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body50 ], [ %11, %for.body29 ]
  %fiz1.0813 = phi float [ %add111, %for.body50 ], [ 0.000000e+00, %for.body29 ]
  %fiy1.0812 = phi float [ %add110, %for.body50 ], [ 0.000000e+00, %for.body29 ]
  %fix1.0811 = phi float [ %add109, %for.body50 ], [ 0.000000e+00, %for.body29 ]
  %vctot.1810 = phi float [ %add105, %for.body50 ], [ %vctot.0821, %for.body29 ]
  %vnbtot.1809 = phi float [ %sub95, %for.body50 ], [ %vnbtot.0820, %for.body29 ]
  %arrayidx52 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %23 = load i32* %arrayidx52, align 4, !tbaa !0
  %mul53 = mul nsw i32 %23, 3
  %idxprom54 = sext i32 %mul53 to i64
  %arrayidx55 = getelementptr inbounds float* %pos, i64 %idxprom54
  %24 = load float* %arrayidx55, align 4, !tbaa !3
  %add56 = add nsw i32 %mul53, 1
  %idxprom57 = sext i32 %add56 to i64
  %arrayidx58 = getelementptr inbounds float* %pos, i64 %idxprom57
  %25 = load float* %arrayidx58, align 4, !tbaa !3
  %add59 = add nsw i32 %mul53, 2
  %idxprom60 = sext i32 %add59 to i64
  %arrayidx61 = getelementptr inbounds float* %pos, i64 %idxprom60
  %26 = load float* %arrayidx61, align 4, !tbaa !3
  %sub = fsub float %add32, %24
  %sub62 = fsub float %add36, %25
  %sub63 = fsub float %add40, %26
  %mul64 = fmul float %sub, %sub
  %mul65 = fmul float %sub62, %sub62
  %add66 = fadd float %mul64, %mul65
  %mul67 = fmul float %sub63, %sub63
  %add68 = fadd float %add66, %mul67
  %conv = fpext float %add68 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv69 = fptrunc double %div to float
  %mul70 = fmul float %add68, %conv69
  %mul71 = fmul float %conv69, %conv69
  %mul72 = fmul float %mul71, %mul71
  %mul73 = fmul float %mul71, %mul72
  %idxprom74 = sext i32 %23 to i64
  %arrayidx75 = getelementptr inbounds i32* %type, i64 %idxprom74
  %27 = load i32* %arrayidx75, align 4, !tbaa !0
  %tmp = add i32 %27, %mul47
  %tmp805 = mul i32 %tmp, 3
  %idxprom78 = sext i32 %tmp805 to i64
  %arrayidx79 = getelementptr inbounds float* %nbfp, i64 %idxprom78
  %28 = load float* %arrayidx79, align 4, !tbaa !3
  %mul80 = fmul float %28, %mul73
  %add81 = add nsw i32 %tmp805, 2
  %idxprom82 = sext i32 %add81 to i64
  %arrayidx83 = getelementptr inbounds float* %nbfp, i64 %idxprom82
  %29 = load float* %arrayidx83, align 4, !tbaa !3
  %mul84 = fmul float %mul70, %29
  %sub85 = fsub float -0.000000e+00, %mul84
  %conv86 = fpext float %sub85 to double
  %call87 = tail call double @exp(double %conv86) #2
  %add88 = add nsw i32 %tmp805, 1
  %idxprom89 = sext i32 %add88 to i64
  %arrayidx90 = getelementptr inbounds float* %nbfp, i64 %idxprom89
  %30 = load float* %arrayidx90, align 4, !tbaa !3
  %conv91 = fpext float %30 to double
  %mul92 = fmul double %call87, %conv91
  %conv93 = fptrunc double %mul92 to float
  %add94 = fadd float %vnbtot.1809, %conv93
  %sub95 = fsub float %add94, %mul80
  %arrayidx97 = getelementptr inbounds float* %charge, i64 %idxprom74
  %31 = load float* %arrayidx97, align 4, !tbaa !3
  %mul98 = fmul float %mul43, %31
  %mul99 = fmul float %conv69, %mul98
  %mul100 = fmul float %mul84, %conv93
  %mul101 = fmul float %mul80, 6.000000e+00
  %sub102 = fsub float %mul100, %mul101
  %add103 = fadd float %mul99, %sub102
  %mul104 = fmul float %mul71, %add103
  %add105 = fadd float %vctot.1810, %mul99
  %mul106 = fmul float %sub, %mul104
  %mul107 = fmul float %sub62, %mul104
  %mul108 = fmul float %sub63, %mul104
  %add109 = fadd float %fix1.0811, %mul106
  %add110 = fadd float %fiy1.0812, %mul107
  %add111 = fadd float %fiz1.0813, %mul108
  %arrayidx113 = getelementptr inbounds float* %faction, i64 %idxprom54
  %32 = load float* %arrayidx113, align 4, !tbaa !3
  %sub114 = fsub float %32, %mul106
  store float %sub114, float* %arrayidx113, align 4, !tbaa !3
  %arrayidx119 = getelementptr inbounds float* %faction, i64 %idxprom57
  %33 = load float* %arrayidx119, align 4, !tbaa !3
  %sub120 = fsub float %33, %mul107
  store float %sub120, float* %arrayidx119, align 4, !tbaa !3
  %arrayidx126 = getelementptr inbounds float* %faction, i64 %idxprom60
  %34 = load float* %arrayidx126, align 4, !tbaa !3
  %sub127 = fsub float %34, %mul108
  store float %sub127, float* %arrayidx126, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %35 = trunc i64 %indvars.iv.next to i32
  %cmp49 = icmp slt i32 %35, %10
  br i1 %cmp49, label %for.body50, label %for.end

for.end:                                          ; preds = %for.body50, %for.body29
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add111, %for.body50 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add110, %for.body50 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add109, %for.body50 ]
  %vctot.1.lcssa = phi float [ %vctot.0821, %for.body29 ], [ %add105, %for.body50 ]
  %vnbtot.1.lcssa = phi float [ %vnbtot.0820, %for.body29 ], [ %sub95, %for.body50 ]
  %arrayidx132 = getelementptr inbounds float* %faction, i64 %indvars.iv867
  %36 = load float* %arrayidx132, align 4, !tbaa !3
  %add133 = fadd float %fix1.0.lcssa, %36
  store float %add133, float* %arrayidx132, align 4, !tbaa !3
  %arrayidx138 = getelementptr inbounds float* %faction, i64 %17
  %37 = load float* %arrayidx138, align 4, !tbaa !3
  %add139 = fadd float %fiy1.0.lcssa, %37
  store float %add139, float* %arrayidx138, align 4, !tbaa !3
  %arrayidx145 = getelementptr inbounds float* %faction, i64 %19
  %38 = load float* %arrayidx145, align 4, !tbaa !3
  %add146 = fadd float %fiz1.0.lcssa, %38
  store float %add146, float* %arrayidx145, align 4, !tbaa !3
  %39 = load float* %arrayidx151, align 4, !tbaa !3
  %add152 = fadd float %fix1.0.lcssa, %39
  store float %add152, float* %arrayidx151, align 4, !tbaa !3
  %40 = load float* %arrayidx157, align 4, !tbaa !3
  %add158 = fadd float %fiy1.0.lcssa, %40
  store float %add158, float* %arrayidx157, align 4, !tbaa !3
  %41 = load float* %arrayidx164, align 4, !tbaa !3
  %add165 = fadd float %fiz1.0.lcssa, %41
  store float %add165, float* %arrayidx164, align 4, !tbaa !3
  %indvars.iv.next866 = add i64 %indvars.iv865, 1
  %indvars.iv.next868 = add i64 %indvars.iv867, 3
  %inc172 = add nsw i32 %s.0822, 1
  %exitcond = icmp eq i32 %inc172, %2
  br i1 %exitcond, label %for.cond27.for.cond174.loopexit_crit_edge, label %for.body29

for.cond27.for.cond174.loopexit_crit_edge:        ; preds = %for.end
  %42 = add i32 %2, %8
  br label %for.cond174.loopexit

for.cond174.loopexit:                             ; preds = %for.cond27.for.cond174.loopexit_crit_edge, %for.body
  %ii.0.lcssa = phi i32 [ %42, %for.cond27.for.cond174.loopexit_crit_edge ], [ %8, %for.body ]
  %ii3.0.lcssa = phi i32 [ %15, %for.cond27.for.cond174.loopexit_crit_edge ], [ %mul21, %for.body ]
  %vctot.0.lcssa = phi float [ %vctot.1.lcssa, %for.cond27.for.cond174.loopexit_crit_edge ], [ 0.000000e+00, %for.body ]
  %vnbtot.0.lcssa = phi float [ %vnbtot.1.lcssa, %for.cond27.for.cond174.loopexit_crit_edge ], [ 0.000000e+00, %for.body ]
  %cmp175839 = icmp slt i32 %2, %3
  br i1 %cmp175839, label %for.body177.lr.ph, label %for.cond297.loopexit

for.body177.lr.ph:                                ; preds = %for.cond174.loopexit
  %cmp193829 = icmp slt i32 %9, %10
  %arrayidx274 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx280 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx287 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %43 = sext i32 %9 to i64
  %44 = sext i32 %ii.0.lcssa to i64
  %45 = sext i32 %ii3.0.lcssa to i64
  %46 = mul i32 %3, 3
  %47 = add i32 %ii.0.lcssa, %3
  br label %for.body177

for.body177:                                      ; preds = %for.end253, %for.body177.lr.ph
  %indvars.iv875 = phi i64 [ %45, %for.body177.lr.ph ], [ %indvars.iv.next876, %for.end253 ]
  %indvars.iv873 = phi i64 [ %44, %for.body177.lr.ph ], [ %indvars.iv.next874, %for.end253 ]
  %s.1841 = phi i32 [ %2, %for.body177.lr.ph ], [ %inc295, %for.end253 ]
  %vctot.2840 = phi float [ %vctot.0.lcssa, %for.body177.lr.ph ], [ %vctot.3.lcssa, %for.end253 ]
  %arrayidx179 = getelementptr inbounds float* %pos, i64 %indvars.iv875
  %48 = load float* %arrayidx179, align 4, !tbaa !3
  %add180 = fadd float %5, %48
  %49 = add nsw i64 %indvars.iv875, 1
  %arrayidx183 = getelementptr inbounds float* %pos, i64 %49
  %50 = load float* %arrayidx183, align 4, !tbaa !3
  %add184 = fadd float %6, %50
  %51 = add nsw i64 %indvars.iv875, 2
  %arrayidx187 = getelementptr inbounds float* %pos, i64 %51
  %52 = load float* %arrayidx187, align 4, !tbaa !3
  %add188 = fadd float %7, %52
  %arrayidx190 = getelementptr inbounds float* %charge, i64 %indvars.iv873
  %53 = load float* %arrayidx190, align 4, !tbaa !3
  %mul191 = fmul float %53, %facel
  br i1 %cmp193829, label %for.body195, label %for.end253

for.body195:                                      ; preds = %for.body177, %for.body195
  %indvars.iv871 = phi i64 [ %indvars.iv.next872, %for.body195 ], [ %43, %for.body177 ]
  %fiz1.1833 = phi float [ %add231, %for.body195 ], [ 0.000000e+00, %for.body177 ]
  %fiy1.1832 = phi float [ %add230, %for.body195 ], [ 0.000000e+00, %for.body177 ]
  %fix1.1831 = phi float [ %add229, %for.body195 ], [ 0.000000e+00, %for.body177 ]
  %vctot.3830 = phi float [ %add225, %for.body195 ], [ %vctot.2840, %for.body177 ]
  %arrayidx197 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv871
  %54 = load i32* %arrayidx197, align 4, !tbaa !0
  %mul198 = mul nsw i32 %54, 3
  %idxprom199 = sext i32 %mul198 to i64
  %arrayidx200 = getelementptr inbounds float* %pos, i64 %idxprom199
  %55 = load float* %arrayidx200, align 4, !tbaa !3
  %add201 = add nsw i32 %mul198, 1
  %idxprom202 = sext i32 %add201 to i64
  %arrayidx203 = getelementptr inbounds float* %pos, i64 %idxprom202
  %56 = load float* %arrayidx203, align 4, !tbaa !3
  %add204 = add nsw i32 %mul198, 2
  %idxprom205 = sext i32 %add204 to i64
  %arrayidx206 = getelementptr inbounds float* %pos, i64 %idxprom205
  %57 = load float* %arrayidx206, align 4, !tbaa !3
  %sub207 = fsub float %add180, %55
  %sub208 = fsub float %add184, %56
  %sub209 = fsub float %add188, %57
  %mul210 = fmul float %sub207, %sub207
  %mul211 = fmul float %sub208, %sub208
  %add212 = fadd float %mul210, %mul211
  %mul213 = fmul float %sub209, %sub209
  %add214 = fadd float %add212, %mul213
  %conv215 = fpext float %add214 to double
  %call216 = tail call double @sqrt(double %conv215) #2
  %div217 = fdiv double 1.000000e+00, %call216
  %conv218 = fptrunc double %div217 to float
  %mul219 = fmul float %conv218, %conv218
  %idxprom220 = sext i32 %54 to i64
  %arrayidx221 = getelementptr inbounds float* %charge, i64 %idxprom220
  %58 = load float* %arrayidx221, align 4, !tbaa !3
  %mul222 = fmul float %mul191, %58
  %mul223 = fmul float %conv218, %mul222
  %mul224 = fmul float %mul219, %mul223
  %add225 = fadd float %vctot.3830, %mul223
  %mul226 = fmul float %sub207, %mul224
  %mul227 = fmul float %sub208, %mul224
  %mul228 = fmul float %sub209, %mul224
  %add229 = fadd float %fix1.1831, %mul226
  %add230 = fadd float %fiy1.1832, %mul227
  %add231 = fadd float %fiz1.1833, %mul228
  %arrayidx233 = getelementptr inbounds float* %faction, i64 %idxprom199
  %59 = load float* %arrayidx233, align 4, !tbaa !3
  %sub234 = fsub float %59, %mul226
  store float %sub234, float* %arrayidx233, align 4, !tbaa !3
  %arrayidx239 = getelementptr inbounds float* %faction, i64 %idxprom202
  %60 = load float* %arrayidx239, align 4, !tbaa !3
  %sub240 = fsub float %60, %mul227
  store float %sub240, float* %arrayidx239, align 4, !tbaa !3
  %arrayidx246 = getelementptr inbounds float* %faction, i64 %idxprom205
  %61 = load float* %arrayidx246, align 4, !tbaa !3
  %sub247 = fsub float %61, %mul228
  store float %sub247, float* %arrayidx246, align 4, !tbaa !3
  %indvars.iv.next872 = add i64 %indvars.iv871, 1
  %62 = trunc i64 %indvars.iv.next872 to i32
  %cmp193 = icmp slt i32 %62, %10
  br i1 %cmp193, label %for.body195, label %for.end253

for.end253:                                       ; preds = %for.body195, %for.body177
  %fiz1.1.lcssa = phi float [ 0.000000e+00, %for.body177 ], [ %add231, %for.body195 ]
  %fiy1.1.lcssa = phi float [ 0.000000e+00, %for.body177 ], [ %add230, %for.body195 ]
  %fix1.1.lcssa = phi float [ 0.000000e+00, %for.body177 ], [ %add229, %for.body195 ]
  %vctot.3.lcssa = phi float [ %vctot.2840, %for.body177 ], [ %add225, %for.body195 ]
  %arrayidx255 = getelementptr inbounds float* %faction, i64 %indvars.iv875
  %63 = load float* %arrayidx255, align 4, !tbaa !3
  %add256 = fadd float %fix1.1.lcssa, %63
  store float %add256, float* %arrayidx255, align 4, !tbaa !3
  %arrayidx261 = getelementptr inbounds float* %faction, i64 %49
  %64 = load float* %arrayidx261, align 4, !tbaa !3
  %add262 = fadd float %fiy1.1.lcssa, %64
  store float %add262, float* %arrayidx261, align 4, !tbaa !3
  %arrayidx268 = getelementptr inbounds float* %faction, i64 %51
  %65 = load float* %arrayidx268, align 4, !tbaa !3
  %add269 = fadd float %fiz1.1.lcssa, %65
  store float %add269, float* %arrayidx268, align 4, !tbaa !3
  %66 = load float* %arrayidx274, align 4, !tbaa !3
  %add275 = fadd float %fix1.1.lcssa, %66
  store float %add275, float* %arrayidx274, align 4, !tbaa !3
  %67 = load float* %arrayidx280, align 4, !tbaa !3
  %add281 = fadd float %fiy1.1.lcssa, %67
  store float %add281, float* %arrayidx280, align 4, !tbaa !3
  %68 = load float* %arrayidx287, align 4, !tbaa !3
  %add288 = fadd float %fiz1.1.lcssa, %68
  store float %add288, float* %arrayidx287, align 4, !tbaa !3
  %indvars.iv.next874 = add i64 %indvars.iv873, 1
  %indvars.iv.next876 = add i64 %indvars.iv875, 3
  %inc295 = add nsw i32 %s.1841, 1
  %exitcond879 = icmp eq i32 %inc295, %3
  br i1 %exitcond879, label %for.cond174.for.cond297.loopexit_crit_edge, label %for.body177

for.cond174.for.cond297.loopexit_crit_edge:       ; preds = %for.end253
  %69 = add i32 %ii3.0.lcssa, %46
  %70 = mul i32 %2, -3
  %71 = add i32 %69, %70
  %72 = sub i32 %47, %2
  br label %for.cond297.loopexit

for.cond297.loopexit:                             ; preds = %for.cond174.for.cond297.loopexit_crit_edge, %for.cond174.loopexit
  %ii.1.lcssa = phi i32 [ %72, %for.cond174.for.cond297.loopexit_crit_edge ], [ %ii.0.lcssa, %for.cond174.loopexit ]
  %ii3.1.lcssa = phi i32 [ %71, %for.cond174.for.cond297.loopexit_crit_edge ], [ %ii3.0.lcssa, %for.cond174.loopexit ]
  %vctot.2.lcssa = phi float [ %vctot.3.lcssa, %for.cond174.for.cond297.loopexit_crit_edge ], [ %vctot.0.lcssa, %for.cond174.loopexit ]
  %cmp298857 = icmp slt i32 %3, %1
  br i1 %cmp298857, label %for.body300.lr.ph, label %for.end443

for.body300.lr.ph:                                ; preds = %for.cond297.loopexit
  %cmp317847 = icmp slt i32 %9, %10
  %arrayidx421 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx427 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx434 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %73 = sext i32 %9 to i64
  %74 = sext i32 %ii.1.lcssa to i64
  %75 = sext i32 %ii3.1.lcssa to i64
  br label %for.body300

for.body300:                                      ; preds = %for.end400, %for.body300.lr.ph
  %indvars.iv884 = phi i64 [ %75, %for.body300.lr.ph ], [ %indvars.iv.next885, %for.end400 ]
  %indvars.iv882 = phi i64 [ %74, %for.body300.lr.ph ], [ %indvars.iv.next883, %for.end400 ]
  %s.2859 = phi i32 [ %3, %for.body300.lr.ph ], [ %inc442, %for.end400 ]
  %vnbtot.2858 = phi float [ %vnbtot.0.lcssa, %for.body300.lr.ph ], [ %vnbtot.3.lcssa, %for.end400 ]
  %arrayidx302 = getelementptr inbounds float* %pos, i64 %indvars.iv884
  %76 = load float* %arrayidx302, align 4, !tbaa !3
  %add303 = fadd float %5, %76
  %77 = add nsw i64 %indvars.iv884, 1
  %arrayidx306 = getelementptr inbounds float* %pos, i64 %77
  %78 = load float* %arrayidx306, align 4, !tbaa !3
  %add307 = fadd float %6, %78
  %79 = add nsw i64 %indvars.iv884, 2
  %arrayidx310 = getelementptr inbounds float* %pos, i64 %79
  %80 = load float* %arrayidx310, align 4, !tbaa !3
  %add311 = fadd float %7, %80
  %arrayidx314 = getelementptr inbounds i32* %type, i64 %indvars.iv882
  %81 = load i32* %arrayidx314, align 4, !tbaa !0
  %mul315 = mul i32 %81, %ntype
  br i1 %cmp317847, label %for.body319, label %for.end400

for.body319:                                      ; preds = %for.body300, %for.body319
  %indvars.iv880 = phi i64 [ %indvars.iv.next881, %for.body319 ], [ %73, %for.body300 ]
  %fiz1.2851 = phi float [ %add378, %for.body319 ], [ 0.000000e+00, %for.body300 ]
  %fiy1.2850 = phi float [ %add377, %for.body319 ], [ 0.000000e+00, %for.body300 ]
  %fix1.2849 = phi float [ %add376, %for.body319 ], [ 0.000000e+00, %for.body300 ]
  %vnbtot.3848 = phi float [ %sub368, %for.body319 ], [ %vnbtot.2858, %for.body300 ]
  %arrayidx321 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv880
  %82 = load i32* %arrayidx321, align 4, !tbaa !0
  %mul322 = mul nsw i32 %82, 3
  %idxprom323 = sext i32 %mul322 to i64
  %arrayidx324 = getelementptr inbounds float* %pos, i64 %idxprom323
  %83 = load float* %arrayidx324, align 4, !tbaa !3
  %add325 = add nsw i32 %mul322, 1
  %idxprom326 = sext i32 %add325 to i64
  %arrayidx327 = getelementptr inbounds float* %pos, i64 %idxprom326
  %84 = load float* %arrayidx327, align 4, !tbaa !3
  %add328 = add nsw i32 %mul322, 2
  %idxprom329 = sext i32 %add328 to i64
  %arrayidx330 = getelementptr inbounds float* %pos, i64 %idxprom329
  %85 = load float* %arrayidx330, align 4, !tbaa !3
  %sub331 = fsub float %add303, %83
  %sub332 = fsub float %add307, %84
  %sub333 = fsub float %add311, %85
  %mul334 = fmul float %sub331, %sub331
  %mul335 = fmul float %sub332, %sub332
  %add336 = fadd float %mul334, %mul335
  %mul337 = fmul float %sub333, %sub333
  %add338 = fadd float %add336, %mul337
  %conv339 = fpext float %add338 to double
  %call340 = tail call double @sqrt(double %conv339) #2
  %div341 = fdiv double 1.000000e+00, %call340
  %conv342 = fptrunc double %div341 to float
  %mul343 = fmul float %add338, %conv342
  %mul344 = fmul float %conv342, %conv342
  %mul345 = fmul float %mul344, %mul344
  %mul346 = fmul float %mul344, %mul345
  %idxprom347 = sext i32 %82 to i64
  %arrayidx348 = getelementptr inbounds i32* %type, i64 %idxprom347
  %86 = load i32* %arrayidx348, align 4, !tbaa !0
  %tmp806 = add i32 %86, %mul315
  %tmp807 = mul i32 %tmp806, 3
  %idxprom351 = sext i32 %tmp807 to i64
  %arrayidx352 = getelementptr inbounds float* %nbfp, i64 %idxprom351
  %87 = load float* %arrayidx352, align 4, !tbaa !3
  %mul353 = fmul float %87, %mul346
  %add354 = add nsw i32 %tmp807, 2
  %idxprom355 = sext i32 %add354 to i64
  %arrayidx356 = getelementptr inbounds float* %nbfp, i64 %idxprom355
  %88 = load float* %arrayidx356, align 4, !tbaa !3
  %mul357 = fmul float %mul343, %88
  %sub358 = fsub float -0.000000e+00, %mul357
  %conv359 = fpext float %sub358 to double
  %call360 = tail call double @exp(double %conv359) #2
  %add361 = add nsw i32 %tmp807, 1
  %idxprom362 = sext i32 %add361 to i64
  %arrayidx363 = getelementptr inbounds float* %nbfp, i64 %idxprom362
  %89 = load float* %arrayidx363, align 4, !tbaa !3
  %conv364 = fpext float %89 to double
  %mul365 = fmul double %call360, %conv364
  %conv366 = fptrunc double %mul365 to float
  %add367 = fadd float %vnbtot.3848, %conv366
  %sub368 = fsub float %add367, %mul353
  %mul369 = fmul float %mul357, %conv366
  %mul370 = fmul float %mul353, 6.000000e+00
  %sub371 = fsub float %mul369, %mul370
  %mul372 = fmul float %mul344, %sub371
  %mul373 = fmul float %sub331, %mul372
  %mul374 = fmul float %sub332, %mul372
  %mul375 = fmul float %sub333, %mul372
  %add376 = fadd float %fix1.2849, %mul373
  %add377 = fadd float %fiy1.2850, %mul374
  %add378 = fadd float %fiz1.2851, %mul375
  %arrayidx380 = getelementptr inbounds float* %faction, i64 %idxprom323
  %90 = load float* %arrayidx380, align 4, !tbaa !3
  %sub381 = fsub float %90, %mul373
  store float %sub381, float* %arrayidx380, align 4, !tbaa !3
  %arrayidx386 = getelementptr inbounds float* %faction, i64 %idxprom326
  %91 = load float* %arrayidx386, align 4, !tbaa !3
  %sub387 = fsub float %91, %mul374
  store float %sub387, float* %arrayidx386, align 4, !tbaa !3
  %arrayidx393 = getelementptr inbounds float* %faction, i64 %idxprom329
  %92 = load float* %arrayidx393, align 4, !tbaa !3
  %sub394 = fsub float %92, %mul375
  store float %sub394, float* %arrayidx393, align 4, !tbaa !3
  %indvars.iv.next881 = add i64 %indvars.iv880, 1
  %93 = trunc i64 %indvars.iv.next881 to i32
  %cmp317 = icmp slt i32 %93, %10
  br i1 %cmp317, label %for.body319, label %for.end400

for.end400:                                       ; preds = %for.body319, %for.body300
  %fiz1.2.lcssa = phi float [ 0.000000e+00, %for.body300 ], [ %add378, %for.body319 ]
  %fiy1.2.lcssa = phi float [ 0.000000e+00, %for.body300 ], [ %add377, %for.body319 ]
  %fix1.2.lcssa = phi float [ 0.000000e+00, %for.body300 ], [ %add376, %for.body319 ]
  %vnbtot.3.lcssa = phi float [ %vnbtot.2858, %for.body300 ], [ %sub368, %for.body319 ]
  %arrayidx402 = getelementptr inbounds float* %faction, i64 %indvars.iv884
  %94 = load float* %arrayidx402, align 4, !tbaa !3
  %add403 = fadd float %fix1.2.lcssa, %94
  store float %add403, float* %arrayidx402, align 4, !tbaa !3
  %arrayidx408 = getelementptr inbounds float* %faction, i64 %77
  %95 = load float* %arrayidx408, align 4, !tbaa !3
  %add409 = fadd float %fiy1.2.lcssa, %95
  store float %add409, float* %arrayidx408, align 4, !tbaa !3
  %arrayidx415 = getelementptr inbounds float* %faction, i64 %79
  %96 = load float* %arrayidx415, align 4, !tbaa !3
  %add416 = fadd float %fiz1.2.lcssa, %96
  store float %add416, float* %arrayidx415, align 4, !tbaa !3
  %97 = load float* %arrayidx421, align 4, !tbaa !3
  %add422 = fadd float %fix1.2.lcssa, %97
  store float %add422, float* %arrayidx421, align 4, !tbaa !3
  %98 = load float* %arrayidx427, align 4, !tbaa !3
  %add428 = fadd float %fiy1.2.lcssa, %98
  store float %add428, float* %arrayidx427, align 4, !tbaa !3
  %99 = load float* %arrayidx434, align 4, !tbaa !3
  %add435 = fadd float %fiz1.2.lcssa, %99
  store float %add435, float* %arrayidx434, align 4, !tbaa !3
  %indvars.iv.next883 = add i64 %indvars.iv882, 1
  %indvars.iv.next885 = add i64 %indvars.iv884, 3
  %inc442 = add nsw i32 %s.2859, 1
  %exitcond888 = icmp eq i32 %inc442, %1
  br i1 %exitcond888, label %for.end443, label %for.body300

for.end443:                                       ; preds = %for.end400, %for.cond297.loopexit
  %vnbtot.2.lcssa = phi float [ %vnbtot.0.lcssa, %for.cond297.loopexit ], [ %vnbtot.3.lcssa, %for.end400 ]
  %arrayidx445 = getelementptr inbounds i32* %gid, i64 %indvars.iv889
  %100 = load i32* %arrayidx445, align 4, !tbaa !0
  %idxprom446 = sext i32 %100 to i64
  %arrayidx447 = getelementptr inbounds float* %Vc, i64 %idxprom446
  %101 = load float* %arrayidx447, align 4, !tbaa !3
  %add448 = fadd float %vctot.2.lcssa, %101
  store float %add448, float* %arrayidx447, align 4, !tbaa !3
  %arrayidx452 = getelementptr inbounds float* %Vnb, i64 %idxprom446
  %102 = load float* %arrayidx452, align 4, !tbaa !3
  %add453 = fadd float %vnbtot.2.lcssa, %102
  store float %add453, float* %arrayidx452, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next890 to i32
  %exitcond891 = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond891, label %for.end458, label %for.body

for.end458:                                       ; preds = %for.end443, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl1220(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb) #0 {
entry:
  %0 = load i32* %iinr, align 4, !tbaa !0
  %idxprom = sext i32 %0 to i64
  %arrayidx1 = getelementptr inbounds float* %charge, i64 %idxprom
  %1 = load float* %arrayidx1, align 4, !tbaa !3
  %add = add nsw i32 %0, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds float* %charge, i64 %idxprom2
  %2 = load float* %arrayidx3, align 4, !tbaa !3
  %mul = fmul float %1, %facel
  %mul4 = fmul float %2, %facel
  %arrayidx7 = getelementptr inbounds i32* %type, i64 %idxprom
  %3 = load i32* %arrayidx7, align 4, !tbaa !0
  %mul8 = mul i32 %3, %ntype
  %cmp536 = icmp sgt i32 %nri, 0
  br i1 %cmp536, label %for.body, label %for.end302

for.body:                                         ; preds = %entry, %for.end.for.body_crit_edge
  %4 = phi i32 [ %.pre, %for.end.for.body_crit_edge ], [ %0, %entry ]
  %indvars.iv538 = phi i64 [ %indvars.iv.next539, %for.end.for.body_crit_edge ], [ 0, %entry ]
  %arrayidx10 = getelementptr inbounds i32* %shift, i64 %indvars.iv538
  %5 = load i32* %arrayidx10, align 4, !tbaa !0
  %mul11 = mul nsw i32 %5, 3
  %idxprom12 = sext i32 %mul11 to i64
  %arrayidx13 = getelementptr inbounds float* %shiftvec, i64 %idxprom12
  %6 = load float* %arrayidx13, align 4, !tbaa !3
  %add14 = add nsw i32 %mul11, 1
  %idxprom15 = sext i32 %add14 to i64
  %arrayidx16 = getelementptr inbounds float* %shiftvec, i64 %idxprom15
  %7 = load float* %arrayidx16, align 4, !tbaa !3
  %add17 = add nsw i32 %mul11, 2
  %idxprom18 = sext i32 %add17 to i64
  %arrayidx19 = getelementptr inbounds float* %shiftvec, i64 %idxprom18
  %8 = load float* %arrayidx19, align 4, !tbaa !3
  %mul22 = mul nsw i32 %4, 3
  %arrayidx24 = getelementptr inbounds i32* %jindex, i64 %indvars.iv538
  %9 = load i32* %arrayidx24, align 4, !tbaa !0
  %indvars.iv.next539 = add i64 %indvars.iv538, 1
  %arrayidx27 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next539
  %10 = load i32* %arrayidx27, align 4, !tbaa !0
  %idxprom28 = sext i32 %mul22 to i64
  %arrayidx29 = getelementptr inbounds float* %pos, i64 %idxprom28
  %11 = load float* %arrayidx29, align 4, !tbaa !3
  %add30 = fadd float %6, %11
  %add31 = add nsw i32 %mul22, 1
  %idxprom32 = sext i32 %add31 to i64
  %arrayidx33 = getelementptr inbounds float* %pos, i64 %idxprom32
  %12 = load float* %arrayidx33, align 4, !tbaa !3
  %add34 = fadd float %7, %12
  %add35 = add nsw i32 %mul22, 2
  %idxprom36 = sext i32 %add35 to i64
  %arrayidx37 = getelementptr inbounds float* %pos, i64 %idxprom36
  %13 = load float* %arrayidx37, align 4, !tbaa !3
  %add38 = fadd float %8, %13
  %add39 = add nsw i32 %mul22, 3
  %idxprom40 = sext i32 %add39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %14 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = fadd float %6, %14
  %add43 = add nsw i32 %mul22, 4
  %idxprom44 = sext i32 %add43 to i64
  %arrayidx45 = getelementptr inbounds float* %pos, i64 %idxprom44
  %15 = load float* %arrayidx45, align 4, !tbaa !3
  %add46 = fadd float %7, %15
  %add47 = add nsw i32 %mul22, 5
  %idxprom48 = sext i32 %add47 to i64
  %arrayidx49 = getelementptr inbounds float* %pos, i64 %idxprom48
  %16 = load float* %arrayidx49, align 4, !tbaa !3
  %add50 = fadd float %8, %16
  %add51 = add nsw i32 %mul22, 6
  %idxprom52 = sext i32 %add51 to i64
  %arrayidx53 = getelementptr inbounds float* %pos, i64 %idxprom52
  %17 = load float* %arrayidx53, align 4, !tbaa !3
  %add54 = fadd float %6, %17
  %add55 = add nsw i32 %mul22, 7
  %idxprom56 = sext i32 %add55 to i64
  %arrayidx57 = getelementptr inbounds float* %pos, i64 %idxprom56
  %18 = load float* %arrayidx57, align 4, !tbaa !3
  %add58 = fadd float %7, %18
  %add59 = add nsw i32 %mul22, 8
  %idxprom60 = sext i32 %add59 to i64
  %arrayidx61 = getelementptr inbounds float* %pos, i64 %idxprom60
  %19 = load float* %arrayidx61, align 4, !tbaa !3
  %add62 = fadd float %8, %19
  %cmp64513 = icmp slt i32 %9, %10
  br i1 %cmp64513, label %for.body65.lr.ph, label %for.end

for.body65.lr.ph:                                 ; preds = %for.body
  %20 = sext i32 %9 to i64
  br label %for.body65

for.body65:                                       ; preds = %for.body65.lr.ph, %for.body65
  %indvars.iv = phi i64 [ %20, %for.body65.lr.ph ], [ %indvars.iv.next, %for.body65 ]
  %vctot.0524 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add184, %for.body65 ]
  %vnbtot.0523 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %sub134, %for.body65 ]
  %fix1.0522 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add148, %for.body65 ]
  %fiy1.0521 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add149, %for.body65 ]
  %fiz1.0520 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add150, %for.body65 ]
  %fix2.0519 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add172, %for.body65 ]
  %fiy2.0518 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add173, %for.body65 ]
  %fiz2.0517 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add174, %for.body65 ]
  %fix3.0516 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add188, %for.body65 ]
  %fiy3.0515 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add189, %for.body65 ]
  %fiz3.0514 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add190, %for.body65 ]
  %arrayidx67 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %21 = load i32* %arrayidx67, align 4, !tbaa !0
  %mul68 = mul nsw i32 %21, 3
  %idxprom69 = sext i32 %mul68 to i64
  %arrayidx70 = getelementptr inbounds float* %pos, i64 %idxprom69
  %22 = load float* %arrayidx70, align 4, !tbaa !3
  %add71 = add nsw i32 %mul68, 1
  %idxprom72 = sext i32 %add71 to i64
  %arrayidx73 = getelementptr inbounds float* %pos, i64 %idxprom72
  %23 = load float* %arrayidx73, align 4, !tbaa !3
  %add74 = add nsw i32 %mul68, 2
  %idxprom75 = sext i32 %add74 to i64
  %arrayidx76 = getelementptr inbounds float* %pos, i64 %idxprom75
  %24 = load float* %arrayidx76, align 4, !tbaa !3
  %sub = fsub float %add30, %22
  %sub77 = fsub float %add34, %23
  %sub78 = fsub float %add38, %24
  %mul79 = fmul float %sub, %sub
  %mul80 = fmul float %sub77, %sub77
  %add81 = fadd float %mul79, %mul80
  %mul82 = fmul float %sub78, %sub78
  %add83 = fadd float %add81, %mul82
  %sub84 = fsub float %add42, %22
  %sub85 = fsub float %add46, %23
  %sub86 = fsub float %add50, %24
  %mul87 = fmul float %sub84, %sub84
  %mul88 = fmul float %sub85, %sub85
  %add89 = fadd float %mul87, %mul88
  %mul90 = fmul float %sub86, %sub86
  %add91 = fadd float %add89, %mul90
  %sub92 = fsub float %add54, %22
  %sub93 = fsub float %add58, %23
  %sub94 = fsub float %add62, %24
  %mul95 = fmul float %sub92, %sub92
  %mul96 = fmul float %sub93, %sub93
  %add97 = fadd float %mul95, %mul96
  %mul98 = fmul float %sub94, %sub94
  %add99 = fadd float %add97, %mul98
  %conv = fpext float %add83 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv100 = fptrunc double %div to float
  %conv101 = fpext float %add91 to double
  %call102 = tail call double @sqrt(double %conv101) #2
  %div103 = fdiv double 1.000000e+00, %call102
  %conv104 = fptrunc double %div103 to float
  %conv105 = fpext float %add99 to double
  %call106 = tail call double @sqrt(double %conv105) #2
  %div107 = fdiv double 1.000000e+00, %call106
  %conv108 = fptrunc double %div107 to float
  %mul109 = fmul float %add83, %conv100
  %mul110 = fmul float %conv100, %conv100
  %mul111 = fmul float %mul110, %mul110
  %mul112 = fmul float %mul110, %mul111
  %idxprom113 = sext i32 %21 to i64
  %arrayidx114 = getelementptr inbounds i32* %type, i64 %idxprom113
  %25 = load i32* %arrayidx114, align 4, !tbaa !0
  %tmp = add i32 %25, %mul8
  %tmp512 = mul i32 %tmp, 3
  %idxprom117 = sext i32 %tmp512 to i64
  %arrayidx118 = getelementptr inbounds float* %nbfp, i64 %idxprom117
  %26 = load float* %arrayidx118, align 4, !tbaa !3
  %mul119 = fmul float %mul112, %26
  %add120 = add nsw i32 %tmp512, 2
  %idxprom121 = sext i32 %add120 to i64
  %arrayidx122 = getelementptr inbounds float* %nbfp, i64 %idxprom121
  %27 = load float* %arrayidx122, align 4, !tbaa !3
  %mul123 = fmul float %mul109, %27
  %sub124 = fsub float -0.000000e+00, %mul123
  %conv125 = fpext float %sub124 to double
  %call126 = tail call double @exp(double %conv125) #2
  %add127 = add nsw i32 %tmp512, 1
  %idxprom128 = sext i32 %add127 to i64
  %arrayidx129 = getelementptr inbounds float* %nbfp, i64 %idxprom128
  %28 = load float* %arrayidx129, align 4, !tbaa !3
  %conv130 = fpext float %28 to double
  %mul131 = fmul double %call126, %conv130
  %conv132 = fptrunc double %mul131 to float
  %add133 = fadd float %vnbtot.0523, %conv132
  %sub134 = fsub float %add133, %mul119
  %arrayidx136 = getelementptr inbounds float* %charge, i64 %idxprom113
  %29 = load float* %arrayidx136, align 4, !tbaa !3
  %mul137 = fmul float %mul, %29
  %mul138 = fmul float %conv100, %mul137
  %mul139 = fmul float %mul123, %conv132
  %mul140 = fmul float %mul119, 6.000000e+00
  %sub141 = fsub float %mul139, %mul140
  %add142 = fadd float %mul138, %sub141
  %mul143 = fmul float %mul110, %add142
  %add144 = fadd float %vctot.0524, %mul138
  %mul145 = fmul float %sub, %mul143
  %mul146 = fmul float %sub77, %mul143
  %mul147 = fmul float %sub78, %mul143
  %add148 = fadd float %fix1.0522, %mul145
  %add149 = fadd float %fiy1.0521, %mul146
  %add150 = fadd float %fiz1.0520, %mul147
  %arrayidx152 = getelementptr inbounds float* %faction, i64 %idxprom69
  %30 = load float* %arrayidx152, align 4, !tbaa !3
  %sub153 = fsub float %30, %mul145
  %arrayidx156 = getelementptr inbounds float* %faction, i64 %idxprom72
  %31 = load float* %arrayidx156, align 4, !tbaa !3
  %sub157 = fsub float %31, %mul146
  %arrayidx160 = getelementptr inbounds float* %faction, i64 %idxprom75
  %32 = load float* %arrayidx160, align 4, !tbaa !3
  %sub161 = fsub float %32, %mul147
  %mul162 = fmul float %conv104, %conv104
  %mul165 = fmul float %mul4, %29
  %mul166 = fmul float %conv104, %mul165
  %mul167 = fmul float %mul162, %mul166
  %add168 = fadd float %mul166, %add144
  %mul169 = fmul float %sub84, %mul167
  %mul170 = fmul float %sub85, %mul167
  %mul171 = fmul float %sub86, %mul167
  %add172 = fadd float %fix2.0519, %mul169
  %add173 = fadd float %fiy2.0518, %mul170
  %add174 = fadd float %fiz2.0517, %mul171
  %sub175 = fsub float %sub153, %mul169
  %sub176 = fsub float %sub157, %mul170
  %sub177 = fsub float %sub161, %mul171
  %mul178 = fmul float %conv108, %conv108
  %mul182 = fmul float %conv108, %mul165
  %mul183 = fmul float %mul178, %mul182
  %add184 = fadd float %mul182, %add168
  %mul185 = fmul float %sub92, %mul183
  %mul186 = fmul float %sub93, %mul183
  %mul187 = fmul float %sub94, %mul183
  %add188 = fadd float %fix3.0516, %mul185
  %add189 = fadd float %fiy3.0515, %mul186
  %add190 = fadd float %fiz3.0514, %mul187
  %sub191 = fsub float %sub175, %mul185
  store float %sub191, float* %arrayidx152, align 4, !tbaa !3
  %sub194 = fsub float %sub176, %mul186
  store float %sub194, float* %arrayidx156, align 4, !tbaa !3
  %sub198 = fsub float %sub177, %mul187
  store float %sub198, float* %arrayidx160, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %33 = trunc i64 %indvars.iv.next to i32
  %cmp64 = icmp slt i32 %33, %10
  br i1 %cmp64, label %for.body65, label %for.end

for.end:                                          ; preds = %for.body65, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add184, %for.body65 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %sub134, %for.body65 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add148, %for.body65 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add149, %for.body65 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add150, %for.body65 ]
  %fix2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add172, %for.body65 ]
  %fiy2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add173, %for.body65 ]
  %fiz2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add174, %for.body65 ]
  %fix3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add188, %for.body65 ]
  %fiy3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add189, %for.body65 ]
  %fiz3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add190, %for.body65 ]
  %arrayidx203 = getelementptr inbounds float* %faction, i64 %idxprom28
  %34 = load float* %arrayidx203, align 4, !tbaa !3
  %add204 = fadd float %fix1.0.lcssa, %34
  store float %add204, float* %arrayidx203, align 4, !tbaa !3
  %arrayidx209 = getelementptr inbounds float* %faction, i64 %idxprom32
  %35 = load float* %arrayidx209, align 4, !tbaa !3
  %add210 = fadd float %fiy1.0.lcssa, %35
  store float %add210, float* %arrayidx209, align 4, !tbaa !3
  %arrayidx216 = getelementptr inbounds float* %faction, i64 %idxprom36
  %36 = load float* %arrayidx216, align 4, !tbaa !3
  %add217 = fadd float %fiz1.0.lcssa, %36
  store float %add217, float* %arrayidx216, align 4, !tbaa !3
  %arrayidx223 = getelementptr inbounds float* %faction, i64 %idxprom40
  %37 = load float* %arrayidx223, align 4, !tbaa !3
  %add224 = fadd float %fix2.0.lcssa, %37
  store float %add224, float* %arrayidx223, align 4, !tbaa !3
  %arrayidx230 = getelementptr inbounds float* %faction, i64 %idxprom44
  %38 = load float* %arrayidx230, align 4, !tbaa !3
  %add231 = fadd float %fiy2.0.lcssa, %38
  store float %add231, float* %arrayidx230, align 4, !tbaa !3
  %arrayidx237 = getelementptr inbounds float* %faction, i64 %idxprom48
  %39 = load float* %arrayidx237, align 4, !tbaa !3
  %add238 = fadd float %fiz2.0.lcssa, %39
  store float %add238, float* %arrayidx237, align 4, !tbaa !3
  %arrayidx244 = getelementptr inbounds float* %faction, i64 %idxprom52
  %40 = load float* %arrayidx244, align 4, !tbaa !3
  %add245 = fadd float %fix3.0.lcssa, %40
  store float %add245, float* %arrayidx244, align 4, !tbaa !3
  %arrayidx251 = getelementptr inbounds float* %faction, i64 %idxprom56
  %41 = load float* %arrayidx251, align 4, !tbaa !3
  %add252 = fadd float %fiy3.0.lcssa, %41
  store float %add252, float* %arrayidx251, align 4, !tbaa !3
  %arrayidx258 = getelementptr inbounds float* %faction, i64 %idxprom60
  %42 = load float* %arrayidx258, align 4, !tbaa !3
  %add259 = fadd float %fiz3.0.lcssa, %42
  store float %add259, float* %arrayidx258, align 4, !tbaa !3
  %arrayidx264 = getelementptr inbounds float* %fshift, i64 %idxprom12
  %43 = load float* %arrayidx264, align 4, !tbaa !3
  %add265 = fadd float %fix1.0.lcssa, %43
  %add266 = fadd float %fix2.0.lcssa, %add265
  %add267 = fadd float %fix3.0.lcssa, %add266
  store float %add267, float* %arrayidx264, align 4, !tbaa !3
  %arrayidx272 = getelementptr inbounds float* %fshift, i64 %idxprom15
  %44 = load float* %arrayidx272, align 4, !tbaa !3
  %add273 = fadd float %fiy1.0.lcssa, %44
  %add274 = fadd float %fiy2.0.lcssa, %add273
  %add275 = fadd float %fiy3.0.lcssa, %add274
  store float %add275, float* %arrayidx272, align 4, !tbaa !3
  %arrayidx281 = getelementptr inbounds float* %fshift, i64 %idxprom18
  %45 = load float* %arrayidx281, align 4, !tbaa !3
  %add282 = fadd float %fiz1.0.lcssa, %45
  %add283 = fadd float %fiz2.0.lcssa, %add282
  %add284 = fadd float %fiz3.0.lcssa, %add283
  store float %add284, float* %arrayidx281, align 4, !tbaa !3
  %arrayidx289 = getelementptr inbounds i32* %gid, i64 %indvars.iv538
  %46 = load i32* %arrayidx289, align 4, !tbaa !0
  %idxprom290 = sext i32 %46 to i64
  %arrayidx291 = getelementptr inbounds float* %Vc, i64 %idxprom290
  %47 = load float* %arrayidx291, align 4, !tbaa !3
  %add292 = fadd float %vctot.0.lcssa, %47
  store float %add292, float* %arrayidx291, align 4, !tbaa !3
  %arrayidx296 = getelementptr inbounds float* %Vnb, i64 %idxprom290
  %48 = load float* %arrayidx296, align 4, !tbaa !3
  %add297 = fadd float %vnbtot.0.lcssa, %48
  store float %add297, float* %arrayidx296, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next539 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end302, label %for.end.for.body_crit_edge

for.end.for.body_crit_edge:                       ; preds = %for.end
  %arrayidx21.phi.trans.insert = getelementptr inbounds i32* %iinr, i64 %indvars.iv.next539
  %.pre = load i32* %arrayidx21.phi.trans.insert, align 4, !tbaa !0
  br label %for.body

for.end302:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl1230(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb) #0 {
entry:
  %0 = load i32* %iinr, align 4, !tbaa !0
  %idxprom = sext i32 %0 to i64
  %arrayidx1 = getelementptr inbounds float* %charge, i64 %idxprom
  %1 = load float* %arrayidx1, align 4, !tbaa !3
  %add = add nsw i32 %0, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds float* %charge, i64 %idxprom2
  %2 = load float* %arrayidx3, align 4, !tbaa !3
  %mul = fmul float %1, %facel
  %mul4 = fmul float %1, %mul
  %mul6 = fmul float %mul, %2
  %mul7 = fmul float %2, %facel
  %mul8 = fmul float %2, %mul7
  %mul9 = mul nsw i32 %ntype, 3
  %arrayidx11 = getelementptr inbounds i32* %type, i64 %idxprom
  %3 = load i32* %arrayidx11, align 4, !tbaa !0
  %mul12897 = add i32 %mul9, 3
  %add16 = mul i32 %3, %mul12897
  %idxprom17 = sext i32 %add16 to i64
  %arrayidx18 = getelementptr inbounds float* %nbfp, i64 %idxprom17
  %4 = load float* %arrayidx18, align 4, !tbaa !3
  %add22 = add nsw i32 %add16, 2
  %idxprom23 = sext i32 %add22 to i64
  %arrayidx24 = getelementptr inbounds float* %nbfp, i64 %idxprom23
  %5 = load float* %arrayidx24, align 4, !tbaa !3
  %cmp921 = icmp sgt i32 %nri, 0
  br i1 %cmp921, label %for.body.lr.ph, label %for.end501

for.body.lr.ph:                                   ; preds = %entry
  %add19 = add nsw i32 %add16, 1
  %idxprom20 = sext i32 %add19 to i64
  %arrayidx21 = getelementptr inbounds float* %nbfp, i64 %idxprom20
  %6 = load float* %arrayidx21, align 4, !tbaa !3
  %conv221 = fpext float %6 to double
  br label %for.body

for.body:                                         ; preds = %for.end.for.body_crit_edge, %for.body.lr.ph
  %7 = phi i32 [ %0, %for.body.lr.ph ], [ %.pre, %for.end.for.body_crit_edge ]
  %indvars.iv923 = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next924, %for.end.for.body_crit_edge ]
  %arrayidx26 = getelementptr inbounds i32* %shift, i64 %indvars.iv923
  %8 = load i32* %arrayidx26, align 4, !tbaa !0
  %mul27 = mul nsw i32 %8, 3
  %idxprom28 = sext i32 %mul27 to i64
  %arrayidx29 = getelementptr inbounds float* %shiftvec, i64 %idxprom28
  %9 = load float* %arrayidx29, align 4, !tbaa !3
  %add30 = add nsw i32 %mul27, 1
  %idxprom31 = sext i32 %add30 to i64
  %arrayidx32 = getelementptr inbounds float* %shiftvec, i64 %idxprom31
  %10 = load float* %arrayidx32, align 4, !tbaa !3
  %add33 = add nsw i32 %mul27, 2
  %idxprom34 = sext i32 %add33 to i64
  %arrayidx35 = getelementptr inbounds float* %shiftvec, i64 %idxprom34
  %11 = load float* %arrayidx35, align 4, !tbaa !3
  %mul38 = mul nsw i32 %7, 3
  %arrayidx40 = getelementptr inbounds i32* %jindex, i64 %indvars.iv923
  %12 = load i32* %arrayidx40, align 4, !tbaa !0
  %indvars.iv.next924 = add i64 %indvars.iv923, 1
  %arrayidx43 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next924
  %13 = load i32* %arrayidx43, align 4, !tbaa !0
  %idxprom44 = sext i32 %mul38 to i64
  %arrayidx45 = getelementptr inbounds float* %pos, i64 %idxprom44
  %14 = load float* %arrayidx45, align 4, !tbaa !3
  %add46 = fadd float %9, %14
  %add47 = add nsw i32 %mul38, 1
  %idxprom48 = sext i32 %add47 to i64
  %arrayidx49 = getelementptr inbounds float* %pos, i64 %idxprom48
  %15 = load float* %arrayidx49, align 4, !tbaa !3
  %add50 = fadd float %10, %15
  %add51 = add nsw i32 %mul38, 2
  %idxprom52 = sext i32 %add51 to i64
  %arrayidx53 = getelementptr inbounds float* %pos, i64 %idxprom52
  %16 = load float* %arrayidx53, align 4, !tbaa !3
  %add54 = fadd float %11, %16
  %add55 = add nsw i32 %mul38, 3
  %idxprom56 = sext i32 %add55 to i64
  %arrayidx57 = getelementptr inbounds float* %pos, i64 %idxprom56
  %17 = load float* %arrayidx57, align 4, !tbaa !3
  %add58 = fadd float %9, %17
  %add59 = add nsw i32 %mul38, 4
  %idxprom60 = sext i32 %add59 to i64
  %arrayidx61 = getelementptr inbounds float* %pos, i64 %idxprom60
  %18 = load float* %arrayidx61, align 4, !tbaa !3
  %add62 = fadd float %10, %18
  %add63 = add nsw i32 %mul38, 5
  %idxprom64 = sext i32 %add63 to i64
  %arrayidx65 = getelementptr inbounds float* %pos, i64 %idxprom64
  %19 = load float* %arrayidx65, align 4, !tbaa !3
  %add66 = fadd float %11, %19
  %add67 = add nsw i32 %mul38, 6
  %idxprom68 = sext i32 %add67 to i64
  %arrayidx69 = getelementptr inbounds float* %pos, i64 %idxprom68
  %20 = load float* %arrayidx69, align 4, !tbaa !3
  %add70 = fadd float %9, %20
  %add71 = add nsw i32 %mul38, 7
  %idxprom72 = sext i32 %add71 to i64
  %arrayidx73 = getelementptr inbounds float* %pos, i64 %idxprom72
  %21 = load float* %arrayidx73, align 4, !tbaa !3
  %add74 = fadd float %10, %21
  %add75 = add nsw i32 %mul38, 8
  %idxprom76 = sext i32 %add75 to i64
  %arrayidx77 = getelementptr inbounds float* %pos, i64 %idxprom76
  %22 = load float* %arrayidx77, align 4, !tbaa !3
  %add78 = fadd float %11, %22
  %cmp80898 = icmp slt i32 %12, %13
  br i1 %cmp80898, label %for.body81.lr.ph, label %for.end

for.body81.lr.ph:                                 ; preds = %for.body
  %23 = sext i32 %12 to i64
  br label %for.body81

for.body81:                                       ; preds = %for.body81.lr.ph, %for.body81
  %indvars.iv = phi i64 [ %23, %for.body81.lr.ph ], [ %indvars.iv.next, %for.body81 ]
  %vctot.0909 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add382, %for.body81 ]
  %vnbtot.0908 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %sub228, %for.body81 ]
  %fix1.0907 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add282, %for.body81 ]
  %fiy1.0906 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add283, %for.body81 ]
  %fiz1.0905 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add284, %for.body81 ]
  %fix2.0904 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add330, %for.body81 ]
  %fiy2.0903 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add331, %for.body81 ]
  %fiz2.0902 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add332, %for.body81 ]
  %fix3.0901 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add386, %for.body81 ]
  %fiy3.0900 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add387, %for.body81 ]
  %fiz3.0899 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add388, %for.body81 ]
  %arrayidx83 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %24 = load i32* %arrayidx83, align 4, !tbaa !0
  %mul84 = mul nsw i32 %24, 3
  %idxprom85 = sext i32 %mul84 to i64
  %arrayidx86 = getelementptr inbounds float* %pos, i64 %idxprom85
  %25 = load float* %arrayidx86, align 4, !tbaa !3
  %add87 = add nsw i32 %mul84, 1
  %idxprom88 = sext i32 %add87 to i64
  %arrayidx89 = getelementptr inbounds float* %pos, i64 %idxprom88
  %26 = load float* %arrayidx89, align 4, !tbaa !3
  %add90 = add nsw i32 %mul84, 2
  %idxprom91 = sext i32 %add90 to i64
  %arrayidx92 = getelementptr inbounds float* %pos, i64 %idxprom91
  %27 = load float* %arrayidx92, align 4, !tbaa !3
  %add93 = add nsw i32 %mul84, 3
  %idxprom94 = sext i32 %add93 to i64
  %arrayidx95 = getelementptr inbounds float* %pos, i64 %idxprom94
  %28 = load float* %arrayidx95, align 4, !tbaa !3
  %add96 = add nsw i32 %mul84, 4
  %idxprom97 = sext i32 %add96 to i64
  %arrayidx98 = getelementptr inbounds float* %pos, i64 %idxprom97
  %29 = load float* %arrayidx98, align 4, !tbaa !3
  %add99 = add nsw i32 %mul84, 5
  %idxprom100 = sext i32 %add99 to i64
  %arrayidx101 = getelementptr inbounds float* %pos, i64 %idxprom100
  %30 = load float* %arrayidx101, align 4, !tbaa !3
  %add102 = add nsw i32 %mul84, 6
  %idxprom103 = sext i32 %add102 to i64
  %arrayidx104 = getelementptr inbounds float* %pos, i64 %idxprom103
  %31 = load float* %arrayidx104, align 4, !tbaa !3
  %add105 = add nsw i32 %mul84, 7
  %idxprom106 = sext i32 %add105 to i64
  %arrayidx107 = getelementptr inbounds float* %pos, i64 %idxprom106
  %32 = load float* %arrayidx107, align 4, !tbaa !3
  %add108 = add nsw i32 %mul84, 8
  %idxprom109 = sext i32 %add108 to i64
  %arrayidx110 = getelementptr inbounds float* %pos, i64 %idxprom109
  %33 = load float* %arrayidx110, align 4, !tbaa !3
  %sub = fsub float %add46, %25
  %sub111 = fsub float %add50, %26
  %sub112 = fsub float %add54, %27
  %mul113 = fmul float %sub, %sub
  %mul114 = fmul float %sub111, %sub111
  %add115 = fadd float %mul113, %mul114
  %mul116 = fmul float %sub112, %sub112
  %add117 = fadd float %add115, %mul116
  %sub118 = fsub float %add46, %28
  %sub119 = fsub float %add50, %29
  %sub120 = fsub float %add54, %30
  %mul121 = fmul float %sub118, %sub118
  %mul122 = fmul float %sub119, %sub119
  %add123 = fadd float %mul121, %mul122
  %mul124 = fmul float %sub120, %sub120
  %add125 = fadd float %add123, %mul124
  %sub126 = fsub float %add46, %31
  %sub127 = fsub float %add50, %32
  %sub128 = fsub float %add54, %33
  %mul129 = fmul float %sub126, %sub126
  %mul130 = fmul float %sub127, %sub127
  %add131 = fadd float %mul129, %mul130
  %mul132 = fmul float %sub128, %sub128
  %add133 = fadd float %add131, %mul132
  %sub134 = fsub float %add58, %25
  %sub135 = fsub float %add62, %26
  %sub136 = fsub float %add66, %27
  %mul137 = fmul float %sub134, %sub134
  %mul138 = fmul float %sub135, %sub135
  %add139 = fadd float %mul137, %mul138
  %mul140 = fmul float %sub136, %sub136
  %add141 = fadd float %add139, %mul140
  %sub142 = fsub float %add58, %28
  %sub143 = fsub float %add62, %29
  %sub144 = fsub float %add66, %30
  %mul145 = fmul float %sub142, %sub142
  %mul146 = fmul float %sub143, %sub143
  %add147 = fadd float %mul145, %mul146
  %mul148 = fmul float %sub144, %sub144
  %add149 = fadd float %add147, %mul148
  %sub150 = fsub float %add58, %31
  %sub151 = fsub float %add62, %32
  %sub152 = fsub float %add66, %33
  %mul153 = fmul float %sub150, %sub150
  %mul154 = fmul float %sub151, %sub151
  %add155 = fadd float %mul153, %mul154
  %mul156 = fmul float %sub152, %sub152
  %add157 = fadd float %add155, %mul156
  %sub158 = fsub float %add70, %25
  %sub159 = fsub float %add74, %26
  %sub160 = fsub float %add78, %27
  %mul161 = fmul float %sub158, %sub158
  %mul162 = fmul float %sub159, %sub159
  %add163 = fadd float %mul161, %mul162
  %mul164 = fmul float %sub160, %sub160
  %add165 = fadd float %add163, %mul164
  %sub166 = fsub float %add70, %28
  %sub167 = fsub float %add74, %29
  %sub168 = fsub float %add78, %30
  %mul169 = fmul float %sub166, %sub166
  %mul170 = fmul float %sub167, %sub167
  %add171 = fadd float %mul169, %mul170
  %mul172 = fmul float %sub168, %sub168
  %add173 = fadd float %add171, %mul172
  %sub174 = fsub float %add70, %31
  %sub175 = fsub float %add74, %32
  %sub176 = fsub float %add78, %33
  %mul177 = fmul float %sub174, %sub174
  %mul178 = fmul float %sub175, %sub175
  %add179 = fadd float %mul177, %mul178
  %mul180 = fmul float %sub176, %sub176
  %add181 = fadd float %add179, %mul180
  %conv = fpext float %add117 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv182 = fptrunc double %div to float
  %conv183 = fpext float %add141 to double
  %call184 = tail call double @sqrt(double %conv183) #2
  %div185 = fdiv double 1.000000e+00, %call184
  %conv186 = fptrunc double %div185 to float
  %conv187 = fpext float %add165 to double
  %call188 = tail call double @sqrt(double %conv187) #2
  %div189 = fdiv double 1.000000e+00, %call188
  %conv190 = fptrunc double %div189 to float
  %conv191 = fpext float %add125 to double
  %call192 = tail call double @sqrt(double %conv191) #2
  %div193 = fdiv double 1.000000e+00, %call192
  %conv194 = fptrunc double %div193 to float
  %conv195 = fpext float %add149 to double
  %call196 = tail call double @sqrt(double %conv195) #2
  %div197 = fdiv double 1.000000e+00, %call196
  %conv198 = fptrunc double %div197 to float
  %conv199 = fpext float %add173 to double
  %call200 = tail call double @sqrt(double %conv199) #2
  %div201 = fdiv double 1.000000e+00, %call200
  %conv202 = fptrunc double %div201 to float
  %conv203 = fpext float %add133 to double
  %call204 = tail call double @sqrt(double %conv203) #2
  %div205 = fdiv double 1.000000e+00, %call204
  %conv206 = fptrunc double %div205 to float
  %conv207 = fpext float %add157 to double
  %call208 = tail call double @sqrt(double %conv207) #2
  %div209 = fdiv double 1.000000e+00, %call208
  %conv210 = fptrunc double %div209 to float
  %conv211 = fpext float %add181 to double
  %call212 = tail call double @sqrt(double %conv211) #2
  %div213 = fdiv double 1.000000e+00, %call212
  %conv214 = fptrunc double %div213 to float
  %mul215 = fmul float %add117, %conv182
  %mul216 = fmul float %conv182, %conv182
  %mul217 = fmul float %mul216, %mul216
  %mul218 = fmul float %mul216, %mul217
  %mul219 = fmul float %4, %mul218
  %mul220 = fmul float %5, %mul215
  %sub222 = fsub float -0.000000e+00, %mul220
  %conv223 = fpext float %sub222 to double
  %call224 = tail call double @exp(double %conv223) #2
  %mul225 = fmul double %conv221, %call224
  %conv226 = fptrunc double %mul225 to float
  %add227 = fadd float %vnbtot.0908, %conv226
  %sub228 = fsub float %add227, %mul219
  %mul229 = fmul float %mul4, %conv182
  %mul230 = fmul float %mul220, %conv226
  %mul231 = fmul float %mul219, 6.000000e+00
  %sub232 = fsub float %mul230, %mul231
  %add233 = fadd float %mul229, %sub232
  %mul234 = fmul float %mul216, %add233
  %add235 = fadd float %vctot.0909, %mul229
  %mul236 = fmul float %sub, %mul234
  %mul237 = fmul float %sub111, %mul234
  %mul238 = fmul float %sub112, %mul234
  %add239 = fadd float %fix1.0907, %mul236
  %add240 = fadd float %fiy1.0906, %mul237
  %add241 = fadd float %fiz1.0905, %mul238
  %arrayidx243 = getelementptr inbounds float* %faction, i64 %idxprom85
  %34 = load float* %arrayidx243, align 4, !tbaa !3
  %sub244 = fsub float %34, %mul236
  %arrayidx247 = getelementptr inbounds float* %faction, i64 %idxprom88
  %35 = load float* %arrayidx247, align 4, !tbaa !3
  %sub248 = fsub float %35, %mul237
  %arrayidx251 = getelementptr inbounds float* %faction, i64 %idxprom91
  %36 = load float* %arrayidx251, align 4, !tbaa !3
  %sub252 = fsub float %36, %mul238
  %mul253 = fmul float %conv194, %conv194
  %mul254 = fmul float %mul6, %conv194
  %mul255 = fmul float %mul254, %mul253
  %add256 = fadd float %add235, %mul254
  %mul257 = fmul float %sub118, %mul255
  %mul258 = fmul float %sub119, %mul255
  %mul259 = fmul float %sub120, %mul255
  %add260 = fadd float %mul257, %add239
  %add261 = fadd float %mul258, %add240
  %add262 = fadd float %mul259, %add241
  %arrayidx265 = getelementptr inbounds float* %faction, i64 %idxprom94
  %37 = load float* %arrayidx265, align 4, !tbaa !3
  %sub266 = fsub float %37, %mul257
  %arrayidx269 = getelementptr inbounds float* %faction, i64 %idxprom97
  %38 = load float* %arrayidx269, align 4, !tbaa !3
  %sub270 = fsub float %38, %mul258
  %arrayidx273 = getelementptr inbounds float* %faction, i64 %idxprom100
  %39 = load float* %arrayidx273, align 4, !tbaa !3
  %sub274 = fsub float %39, %mul259
  %mul275 = fmul float %conv206, %conv206
  %mul276 = fmul float %mul6, %conv206
  %mul277 = fmul float %mul276, %mul275
  %add278 = fadd float %add256, %mul276
  %mul279 = fmul float %sub126, %mul277
  %mul280 = fmul float %sub127, %mul277
  %mul281 = fmul float %sub128, %mul277
  %add282 = fadd float %mul279, %add260
  %add283 = fadd float %mul280, %add261
  %add284 = fadd float %mul281, %add262
  %arrayidx287 = getelementptr inbounds float* %faction, i64 %idxprom103
  %40 = load float* %arrayidx287, align 4, !tbaa !3
  %sub288 = fsub float %40, %mul279
  %arrayidx291 = getelementptr inbounds float* %faction, i64 %idxprom106
  %41 = load float* %arrayidx291, align 4, !tbaa !3
  %sub292 = fsub float %41, %mul280
  %arrayidx295 = getelementptr inbounds float* %faction, i64 %idxprom109
  %42 = load float* %arrayidx295, align 4, !tbaa !3
  %sub296 = fsub float %42, %mul281
  %mul297 = fmul float %conv186, %conv186
  %mul298 = fmul float %mul6, %conv186
  %mul299 = fmul float %mul298, %mul297
  %add300 = fadd float %mul298, %add278
  %mul301 = fmul float %sub134, %mul299
  %mul302 = fmul float %sub135, %mul299
  %mul303 = fmul float %sub136, %mul299
  %add304 = fadd float %fix2.0904, %mul301
  %add305 = fadd float %fiy2.0903, %mul302
  %add306 = fadd float %fiz2.0902, %mul303
  %sub307 = fsub float %sub244, %mul301
  %sub308 = fsub float %sub248, %mul302
  %sub309 = fsub float %sub252, %mul303
  %mul310 = fmul float %conv198, %conv198
  %mul311 = fmul float %mul8, %conv198
  %mul312 = fmul float %mul311, %mul310
  %add313 = fadd float %mul311, %add300
  %mul314 = fmul float %sub142, %mul312
  %mul315 = fmul float %sub143, %mul312
  %mul316 = fmul float %sub144, %mul312
  %add317 = fadd float %add304, %mul314
  %add318 = fadd float %add305, %mul315
  %add319 = fadd float %add306, %mul316
  %sub320 = fsub float %sub266, %mul314
  %sub321 = fsub float %sub270, %mul315
  %sub322 = fsub float %sub274, %mul316
  %mul323 = fmul float %conv210, %conv210
  %mul324 = fmul float %mul8, %conv210
  %mul325 = fmul float %mul324, %mul323
  %add326 = fadd float %mul324, %add313
  %mul327 = fmul float %sub150, %mul325
  %mul328 = fmul float %sub151, %mul325
  %mul329 = fmul float %sub152, %mul325
  %add330 = fadd float %add317, %mul327
  %add331 = fadd float %add318, %mul328
  %add332 = fadd float %add319, %mul329
  %sub333 = fsub float %sub288, %mul327
  %sub334 = fsub float %sub292, %mul328
  %sub335 = fsub float %sub296, %mul329
  %mul336 = fmul float %conv190, %conv190
  %mul337 = fmul float %mul6, %conv190
  %mul338 = fmul float %mul337, %mul336
  %add339 = fadd float %mul337, %add326
  %mul340 = fmul float %sub158, %mul338
  %mul341 = fmul float %sub159, %mul338
  %mul342 = fmul float %sub160, %mul338
  %add343 = fadd float %fix3.0901, %mul340
  %add344 = fadd float %fiy3.0900, %mul341
  %add345 = fadd float %fiz3.0899, %mul342
  %sub346 = fsub float %sub307, %mul340
  store float %sub346, float* %arrayidx243, align 4, !tbaa !3
  %sub349 = fsub float %sub308, %mul341
  store float %sub349, float* %arrayidx247, align 4, !tbaa !3
  %sub353 = fsub float %sub309, %mul342
  store float %sub353, float* %arrayidx251, align 4, !tbaa !3
  %mul357 = fmul float %conv202, %conv202
  %mul358 = fmul float %mul8, %conv202
  %mul359 = fmul float %mul358, %mul357
  %add360 = fadd float %mul358, %add339
  %mul361 = fmul float %sub166, %mul359
  %mul362 = fmul float %sub167, %mul359
  %mul363 = fmul float %sub168, %mul359
  %add364 = fadd float %add343, %mul361
  %add365 = fadd float %add344, %mul362
  %add366 = fadd float %add345, %mul363
  %sub367 = fsub float %sub320, %mul361
  store float %sub367, float* %arrayidx265, align 4, !tbaa !3
  %sub371 = fsub float %sub321, %mul362
  store float %sub371, float* %arrayidx269, align 4, !tbaa !3
  %sub375 = fsub float %sub322, %mul363
  store float %sub375, float* %arrayidx273, align 4, !tbaa !3
  %mul379 = fmul float %conv214, %conv214
  %mul380 = fmul float %mul8, %conv214
  %mul381 = fmul float %mul380, %mul379
  %add382 = fadd float %mul380, %add360
  %mul383 = fmul float %sub174, %mul381
  %mul384 = fmul float %sub175, %mul381
  %mul385 = fmul float %sub176, %mul381
  %add386 = fadd float %add364, %mul383
  %add387 = fadd float %add365, %mul384
  %add388 = fadd float %add366, %mul385
  %sub389 = fsub float %sub333, %mul383
  store float %sub389, float* %arrayidx287, align 4, !tbaa !3
  %sub393 = fsub float %sub334, %mul384
  store float %sub393, float* %arrayidx291, align 4, !tbaa !3
  %sub397 = fsub float %sub335, %mul385
  store float %sub397, float* %arrayidx295, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %43 = trunc i64 %indvars.iv.next to i32
  %cmp80 = icmp slt i32 %43, %13
  br i1 %cmp80, label %for.body81, label %for.end

for.end:                                          ; preds = %for.body81, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add382, %for.body81 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %sub228, %for.body81 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add282, %for.body81 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add283, %for.body81 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add284, %for.body81 ]
  %fix2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add330, %for.body81 ]
  %fiy2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add331, %for.body81 ]
  %fiz2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add332, %for.body81 ]
  %fix3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add386, %for.body81 ]
  %fiy3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add387, %for.body81 ]
  %fiz3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add388, %for.body81 ]
  %arrayidx402 = getelementptr inbounds float* %faction, i64 %idxprom44
  %44 = load float* %arrayidx402, align 4, !tbaa !3
  %add403 = fadd float %fix1.0.lcssa, %44
  store float %add403, float* %arrayidx402, align 4, !tbaa !3
  %arrayidx408 = getelementptr inbounds float* %faction, i64 %idxprom48
  %45 = load float* %arrayidx408, align 4, !tbaa !3
  %add409 = fadd float %fiy1.0.lcssa, %45
  store float %add409, float* %arrayidx408, align 4, !tbaa !3
  %arrayidx415 = getelementptr inbounds float* %faction, i64 %idxprom52
  %46 = load float* %arrayidx415, align 4, !tbaa !3
  %add416 = fadd float %fiz1.0.lcssa, %46
  store float %add416, float* %arrayidx415, align 4, !tbaa !3
  %arrayidx422 = getelementptr inbounds float* %faction, i64 %idxprom56
  %47 = load float* %arrayidx422, align 4, !tbaa !3
  %add423 = fadd float %fix2.0.lcssa, %47
  store float %add423, float* %arrayidx422, align 4, !tbaa !3
  %arrayidx429 = getelementptr inbounds float* %faction, i64 %idxprom60
  %48 = load float* %arrayidx429, align 4, !tbaa !3
  %add430 = fadd float %fiy2.0.lcssa, %48
  store float %add430, float* %arrayidx429, align 4, !tbaa !3
  %arrayidx436 = getelementptr inbounds float* %faction, i64 %idxprom64
  %49 = load float* %arrayidx436, align 4, !tbaa !3
  %add437 = fadd float %fiz2.0.lcssa, %49
  store float %add437, float* %arrayidx436, align 4, !tbaa !3
  %arrayidx443 = getelementptr inbounds float* %faction, i64 %idxprom68
  %50 = load float* %arrayidx443, align 4, !tbaa !3
  %add444 = fadd float %fix3.0.lcssa, %50
  store float %add444, float* %arrayidx443, align 4, !tbaa !3
  %arrayidx450 = getelementptr inbounds float* %faction, i64 %idxprom72
  %51 = load float* %arrayidx450, align 4, !tbaa !3
  %add451 = fadd float %fiy3.0.lcssa, %51
  store float %add451, float* %arrayidx450, align 4, !tbaa !3
  %arrayidx457 = getelementptr inbounds float* %faction, i64 %idxprom76
  %52 = load float* %arrayidx457, align 4, !tbaa !3
  %add458 = fadd float %fiz3.0.lcssa, %52
  store float %add458, float* %arrayidx457, align 4, !tbaa !3
  %arrayidx463 = getelementptr inbounds float* %fshift, i64 %idxprom28
  %53 = load float* %arrayidx463, align 4, !tbaa !3
  %add464 = fadd float %fix1.0.lcssa, %53
  %add465 = fadd float %fix2.0.lcssa, %add464
  %add466 = fadd float %fix3.0.lcssa, %add465
  store float %add466, float* %arrayidx463, align 4, !tbaa !3
  %arrayidx471 = getelementptr inbounds float* %fshift, i64 %idxprom31
  %54 = load float* %arrayidx471, align 4, !tbaa !3
  %add472 = fadd float %fiy1.0.lcssa, %54
  %add473 = fadd float %fiy2.0.lcssa, %add472
  %add474 = fadd float %fiy3.0.lcssa, %add473
  store float %add474, float* %arrayidx471, align 4, !tbaa !3
  %arrayidx480 = getelementptr inbounds float* %fshift, i64 %idxprom34
  %55 = load float* %arrayidx480, align 4, !tbaa !3
  %add481 = fadd float %fiz1.0.lcssa, %55
  %add482 = fadd float %fiz2.0.lcssa, %add481
  %add483 = fadd float %fiz3.0.lcssa, %add482
  store float %add483, float* %arrayidx480, align 4, !tbaa !3
  %arrayidx488 = getelementptr inbounds i32* %gid, i64 %indvars.iv923
  %56 = load i32* %arrayidx488, align 4, !tbaa !0
  %idxprom489 = sext i32 %56 to i64
  %arrayidx490 = getelementptr inbounds float* %Vc, i64 %idxprom489
  %57 = load float* %arrayidx490, align 4, !tbaa !3
  %add491 = fadd float %vctot.0.lcssa, %57
  store float %add491, float* %arrayidx490, align 4, !tbaa !3
  %arrayidx495 = getelementptr inbounds float* %Vnb, i64 %idxprom489
  %58 = load float* %arrayidx495, align 4, !tbaa !3
  %add496 = fadd float %vnbtot.0.lcssa, %58
  store float %add496, float* %arrayidx495, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next924 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end501, label %for.end.for.body_crit_edge

for.end.for.body_crit_edge:                       ; preds = %for.end
  %arrayidx37.phi.trans.insert = getelementptr inbounds i32* %iinr, i64 %indvars.iv.next924
  %.pre = load i32* %arrayidx37.phi.trans.insert, align 4, !tbaa !0
  br label %for.body

for.end501:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl1300(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab) #0 {
entry:
  %cmp361 = icmp sgt i32 %nri, 0
  br i1 %cmp361, label %for.body.lr.ph, label %for.end207

for.body.lr.ph:                                   ; preds = %entry
  %mul30 = shl i32 %ntype, 1
  br label %for.body

for.body:                                         ; preds = %for.end, %for.body.lr.ph
  %indvars.iv363 = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next364, %for.end ]
  %arrayidx = getelementptr inbounds i32* %shift, i64 %indvars.iv363
  %0 = load i32* %arrayidx, align 4, !tbaa !0
  %mul = mul nsw i32 %0, 3
  %idxprom1 = sext i32 %mul to i64
  %arrayidx2 = getelementptr inbounds float* %shiftvec, i64 %idxprom1
  %1 = load float* %arrayidx2, align 4, !tbaa !3
  %add = add nsw i32 %mul, 1
  %idxprom3 = sext i32 %add to i64
  %arrayidx4 = getelementptr inbounds float* %shiftvec, i64 %idxprom3
  %2 = load float* %arrayidx4, align 4, !tbaa !3
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds float* %shiftvec, i64 %idxprom6
  %3 = load float* %arrayidx7, align 4, !tbaa !3
  %arrayidx9 = getelementptr inbounds i32* %iinr, i64 %indvars.iv363
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %arrayidx12 = getelementptr inbounds i32* %jindex, i64 %indvars.iv363
  %5 = load i32* %arrayidx12, align 4, !tbaa !0
  %indvars.iv.next364 = add i64 %indvars.iv363, 1
  %arrayidx15 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next364
  %6 = load i32* %arrayidx15, align 4, !tbaa !0
  %idxprom16 = sext i32 %mul10 to i64
  %arrayidx17 = getelementptr inbounds float* %pos, i64 %idxprom16
  %7 = load float* %arrayidx17, align 4, !tbaa !3
  %add18 = fadd float %1, %7
  %add19 = add nsw i32 %mul10, 1
  %idxprom20 = sext i32 %add19 to i64
  %arrayidx21 = getelementptr inbounds float* %pos, i64 %idxprom20
  %8 = load float* %arrayidx21, align 4, !tbaa !3
  %add22 = fadd float %2, %8
  %add23 = add nsw i32 %mul10, 2
  %idxprom24 = sext i32 %add23 to i64
  %arrayidx25 = getelementptr inbounds float* %pos, i64 %idxprom24
  %9 = load float* %arrayidx25, align 4, !tbaa !3
  %add26 = fadd float %3, %9
  %idxprom27 = sext i32 %4 to i64
  %arrayidx28 = getelementptr inbounds float* %charge, i64 %idxprom27
  %10 = load float* %arrayidx28, align 4, !tbaa !3
  %mul29 = fmul float %10, %facel
  %arrayidx32 = getelementptr inbounds i32* %type, i64 %idxprom27
  %11 = load i32* %arrayidx32, align 4, !tbaa !0
  %mul33 = mul nsw i32 %mul30, %11
  %cmp35350 = icmp slt i32 %5, %6
  br i1 %cmp35350, label %for.body36.lr.ph, label %for.end

for.body36.lr.ph:                                 ; preds = %for.body
  %12 = sext i32 %5 to i64
  br label %for.body36

for.body36:                                       ; preds = %for.body36.lr.ph, %for.body36
  %indvars.iv = phi i64 [ %12, %for.body36.lr.ph ], [ %indvars.iv.next, %for.body36 ]
  %vctot.0355 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add129, %for.body36 ]
  %vnbtot.0354 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add119, %for.body36 ]
  %fix1.0353 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add133, %for.body36 ]
  %fiy1.0352 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add134, %for.body36 ]
  %fiz1.0351 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add135, %for.body36 ]
  %arrayidx38 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %13 = load i32* %arrayidx38, align 4, !tbaa !0
  %mul39 = mul nsw i32 %13, 3
  %idxprom40 = sext i32 %mul39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %14 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = add nsw i32 %mul39, 1
  %idxprom43 = sext i32 %add42 to i64
  %arrayidx44 = getelementptr inbounds float* %pos, i64 %idxprom43
  %15 = load float* %arrayidx44, align 4, !tbaa !3
  %add45 = add nsw i32 %mul39, 2
  %idxprom46 = sext i32 %add45 to i64
  %arrayidx47 = getelementptr inbounds float* %pos, i64 %idxprom46
  %16 = load float* %arrayidx47, align 4, !tbaa !3
  %sub = fsub float %add18, %14
  %sub48 = fsub float %add22, %15
  %sub49 = fsub float %add26, %16
  %mul50 = fmul float %sub, %sub
  %mul51 = fmul float %sub48, %sub48
  %add52 = fadd float %mul50, %mul51
  %mul53 = fmul float %sub49, %sub49
  %add54 = fadd float %add52, %mul53
  %conv = fpext float %add54 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv55 = fptrunc double %div to float
  %mul56 = fmul float %add54, %conv55
  %mul58 = fmul float %mul56, %tabscale
  %conv59 = fptosi float %mul58 to i32
  %conv60 = sitofp i32 %conv59 to float
  %sub61 = fsub float %mul58, %conv60
  %mul62 = fmul float %sub61, %sub61
  %mul63 = shl nsw i32 %conv59, 3
  %idxprom64 = sext i32 %13 to i64
  %arrayidx65 = getelementptr inbounds i32* %type, i64 %idxprom64
  %17 = load i32* %arrayidx65, align 4, !tbaa !0
  %mul66 = shl nsw i32 %17, 1
  %add67 = add nsw i32 %mul66, %mul33
  %idxprom68 = sext i32 %add67 to i64
  %arrayidx69 = getelementptr inbounds float* %nbfp, i64 %idxprom68
  %18 = load float* %arrayidx69, align 4, !tbaa !3
  %add70342 = or i32 %add67, 1
  %idxprom71 = sext i32 %add70342 to i64
  %arrayidx72 = getelementptr inbounds float* %nbfp, i64 %idxprom71
  %19 = load float* %arrayidx72, align 4, !tbaa !3
  %idxprom73 = sext i32 %mul63 to i64
  %arrayidx74 = getelementptr inbounds float* %VFtab, i64 %idxprom73
  %20 = load float* %arrayidx74, align 4, !tbaa !3
  %add75343 = or i32 %mul63, 1
  %idxprom76 = sext i32 %add75343 to i64
  %arrayidx77 = getelementptr inbounds float* %VFtab, i64 %idxprom76
  %21 = load float* %arrayidx77, align 4, !tbaa !3
  %add78344 = or i32 %mul63, 2
  %idxprom79 = sext i32 %add78344 to i64
  %arrayidx80 = getelementptr inbounds float* %VFtab, i64 %idxprom79
  %22 = load float* %arrayidx80, align 4, !tbaa !3
  %mul81 = fmul float %sub61, %22
  %add82345 = or i32 %mul63, 3
  %idxprom83 = sext i32 %add82345 to i64
  %arrayidx84 = getelementptr inbounds float* %VFtab, i64 %idxprom83
  %23 = load float* %arrayidx84, align 4, !tbaa !3
  %mul85 = fmul float %mul62, %23
  %add86 = fadd float %21, %mul81
  %add87 = fadd float %add86, %mul85
  %mul88 = fmul float %sub61, %add87
  %add89 = fadd float %20, %mul88
  %add90 = fadd float %mul81, %add87
  %mul91 = fmul float %mul85, 2.000000e+00
  %add92 = fadd float %mul91, %add90
  %mul93 = fmul float %18, %add89
  %mul94 = fmul float %18, %add92
  %add95346 = or i32 %mul63, 4
  %idxprom96 = sext i32 %add95346 to i64
  %arrayidx97 = getelementptr inbounds float* %VFtab, i64 %idxprom96
  %24 = load float* %arrayidx97, align 4, !tbaa !3
  %add98347 = or i32 %mul63, 5
  %idxprom99 = sext i32 %add98347 to i64
  %arrayidx100 = getelementptr inbounds float* %VFtab, i64 %idxprom99
  %25 = load float* %arrayidx100, align 4, !tbaa !3
  %add101348 = or i32 %mul63, 6
  %idxprom102 = sext i32 %add101348 to i64
  %arrayidx103 = getelementptr inbounds float* %VFtab, i64 %idxprom102
  %26 = load float* %arrayidx103, align 4, !tbaa !3
  %mul104 = fmul float %sub61, %26
  %add105349 = or i32 %mul63, 7
  %idxprom106 = sext i32 %add105349 to i64
  %arrayidx107 = getelementptr inbounds float* %VFtab, i64 %idxprom106
  %27 = load float* %arrayidx107, align 4, !tbaa !3
  %mul108 = fmul float %mul62, %27
  %add109 = fadd float %25, %mul104
  %add110 = fadd float %add109, %mul108
  %mul111 = fmul float %sub61, %add110
  %add112 = fadd float %24, %mul111
  %add113 = fadd float %mul104, %add110
  %mul114 = fmul float %mul108, 2.000000e+00
  %add115 = fadd float %mul114, %add113
  %mul116 = fmul float %19, %add112
  %mul117 = fmul float %19, %add115
  %add118 = fadd float %vnbtot.0354, %mul93
  %add119 = fadd float %add118, %mul116
  %arrayidx121 = getelementptr inbounds float* %charge, i64 %idxprom64
  %28 = load float* %arrayidx121, align 4, !tbaa !3
  %mul122 = fmul float %mul29, %28
  %mul123 = fmul float %conv55, %mul122
  %mul124 = fmul float %conv55, %mul123
  %add125 = fadd float %mul94, %mul117
  %mul126 = fmul float %add125, %tabscale
  %sub127 = fsub float %mul124, %mul126
  %mul128 = fmul float %conv55, %sub127
  %add129 = fadd float %vctot.0355, %mul123
  %mul130 = fmul float %sub, %mul128
  %mul131 = fmul float %sub48, %mul128
  %mul132 = fmul float %sub49, %mul128
  %add133 = fadd float %fix1.0353, %mul130
  %add134 = fadd float %fiy1.0352, %mul131
  %add135 = fadd float %fiz1.0351, %mul132
  %arrayidx137 = getelementptr inbounds float* %faction, i64 %idxprom40
  %29 = load float* %arrayidx137, align 4, !tbaa !3
  %sub138 = fsub float %29, %mul130
  store float %sub138, float* %arrayidx137, align 4, !tbaa !3
  %arrayidx143 = getelementptr inbounds float* %faction, i64 %idxprom43
  %30 = load float* %arrayidx143, align 4, !tbaa !3
  %sub144 = fsub float %30, %mul131
  store float %sub144, float* %arrayidx143, align 4, !tbaa !3
  %arrayidx150 = getelementptr inbounds float* %faction, i64 %idxprom46
  %31 = load float* %arrayidx150, align 4, !tbaa !3
  %sub151 = fsub float %31, %mul132
  store float %sub151, float* %arrayidx150, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %32 = trunc i64 %indvars.iv.next to i32
  %cmp35 = icmp slt i32 %32, %6
  br i1 %cmp35, label %for.body36, label %for.end

for.end:                                          ; preds = %for.body36, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add129, %for.body36 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add119, %for.body36 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add133, %for.body36 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add134, %for.body36 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add135, %for.body36 ]
  %arrayidx156 = getelementptr inbounds float* %faction, i64 %idxprom16
  %33 = load float* %arrayidx156, align 4, !tbaa !3
  %add157 = fadd float %fix1.0.lcssa, %33
  store float %add157, float* %arrayidx156, align 4, !tbaa !3
  %arrayidx162 = getelementptr inbounds float* %faction, i64 %idxprom20
  %34 = load float* %arrayidx162, align 4, !tbaa !3
  %add163 = fadd float %fiy1.0.lcssa, %34
  store float %add163, float* %arrayidx162, align 4, !tbaa !3
  %arrayidx169 = getelementptr inbounds float* %faction, i64 %idxprom24
  %35 = load float* %arrayidx169, align 4, !tbaa !3
  %add170 = fadd float %fiz1.0.lcssa, %35
  store float %add170, float* %arrayidx169, align 4, !tbaa !3
  %arrayidx175 = getelementptr inbounds float* %fshift, i64 %idxprom1
  %36 = load float* %arrayidx175, align 4, !tbaa !3
  %add176 = fadd float %fix1.0.lcssa, %36
  store float %add176, float* %arrayidx175, align 4, !tbaa !3
  %arrayidx181 = getelementptr inbounds float* %fshift, i64 %idxprom3
  %37 = load float* %arrayidx181, align 4, !tbaa !3
  %add182 = fadd float %fiy1.0.lcssa, %37
  store float %add182, float* %arrayidx181, align 4, !tbaa !3
  %arrayidx188 = getelementptr inbounds float* %fshift, i64 %idxprom6
  %38 = load float* %arrayidx188, align 4, !tbaa !3
  %add189 = fadd float %fiz1.0.lcssa, %38
  store float %add189, float* %arrayidx188, align 4, !tbaa !3
  %arrayidx194 = getelementptr inbounds i32* %gid, i64 %indvars.iv363
  %39 = load i32* %arrayidx194, align 4, !tbaa !0
  %idxprom195 = sext i32 %39 to i64
  %arrayidx196 = getelementptr inbounds float* %Vc, i64 %idxprom195
  %40 = load float* %arrayidx196, align 4, !tbaa !3
  %add197 = fadd float %vctot.0.lcssa, %40
  store float %add197, float* %arrayidx196, align 4, !tbaa !3
  %arrayidx201 = getelementptr inbounds float* %Vnb, i64 %idxprom195
  %41 = load float* %arrayidx201, align 4, !tbaa !3
  %add202 = fadd float %vnbtot.0.lcssa, %41
  store float %add202, float* %arrayidx201, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next364 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end207, label %for.body

for.end207:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl1310(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab, i32* nocapture %nsatoms) #0 {
entry:
  %cmp1032 = icmp sgt i32 %nri, 0
  br i1 %cmp1032, label %for.body.lr.ph, label %for.end534

for.body.lr.ph:                                   ; preds = %entry
  %mul350 = shl i32 %ntype, 1
  br label %for.body

for.body:                                         ; preds = %for.end519, %for.body.lr.ph
  %indvars.iv1058 = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next1059, %for.end519 ]
  %0 = trunc i64 %indvars.iv1058 to i32
  %mul = mul nsw i32 %0, 3
  %idxprom = sext i32 %mul to i64
  %arrayidx = getelementptr inbounds i32* %nsatoms, i64 %idxprom
  %1 = load i32* %arrayidx, align 4, !tbaa !0
  %add = add nsw i32 %mul, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds i32* %nsatoms, i64 %idxprom2
  %2 = load i32* %arrayidx3, align 4, !tbaa !0
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds i32* %nsatoms, i64 %idxprom6
  %3 = load i32* %arrayidx7, align 4, !tbaa !0
  %arrayidx9 = getelementptr inbounds i32* %shift, i64 %indvars.iv1058
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %idxprom11 = sext i32 %mul10 to i64
  %arrayidx12 = getelementptr inbounds float* %shiftvec, i64 %idxprom11
  %5 = load float* %arrayidx12, align 4, !tbaa !3
  %add13 = add nsw i32 %mul10, 1
  %idxprom14 = sext i32 %add13 to i64
  %arrayidx15 = getelementptr inbounds float* %shiftvec, i64 %idxprom14
  %6 = load float* %arrayidx15, align 4, !tbaa !3
  %add16 = add nsw i32 %mul10, 2
  %idxprom17 = sext i32 %add16 to i64
  %arrayidx18 = getelementptr inbounds float* %shiftvec, i64 %idxprom17
  %7 = load float* %arrayidx18, align 4, !tbaa !3
  %arrayidx20 = getelementptr inbounds i32* %iinr, i64 %indvars.iv1058
  %8 = load i32* %arrayidx20, align 4, !tbaa !0
  %mul21 = mul i32 %8, 3
  %arrayidx23 = getelementptr inbounds i32* %jindex, i64 %indvars.iv1058
  %9 = load i32* %arrayidx23, align 4, !tbaa !0
  %indvars.iv.next1059 = add i64 %indvars.iv1058, 1
  %arrayidx26 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next1059
  %10 = load i32* %arrayidx26, align 4, !tbaa !0
  %cmp28988 = icmp sgt i32 %2, 0
  br i1 %cmp28988, label %for.body29.lr.ph, label %for.cond212.loopexit

for.body29.lr.ph:                                 ; preds = %for.body
  %cmp49977 = icmp slt i32 %9, %10
  %arrayidx189 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx195 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx202 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %11 = sext i32 %9 to i64
  %12 = sext i32 %8 to i64
  %13 = sext i32 %mul21 to i64
  %14 = add i32 %2, %8
  %15 = mul i32 %14, 3
  br label %for.body29

for.body29:                                       ; preds = %for.end, %for.body29.lr.ph
  %indvars.iv1036 = phi i64 [ %13, %for.body29.lr.ph ], [ %indvars.iv.next1037, %for.end ]
  %indvars.iv1034 = phi i64 [ %12, %for.body29.lr.ph ], [ %indvars.iv.next1035, %for.end ]
  %s.0991 = phi i32 [ 0, %for.body29.lr.ph ], [ %inc210, %for.end ]
  %vnbtot.0990 = phi float [ 0.000000e+00, %for.body29.lr.ph ], [ %vnbtot.1.lcssa, %for.end ]
  %vctot.0989 = phi float [ 0.000000e+00, %for.body29.lr.ph ], [ %vctot.1.lcssa, %for.end ]
  %arrayidx31 = getelementptr inbounds float* %pos, i64 %indvars.iv1036
  %16 = load float* %arrayidx31, align 4, !tbaa !3
  %add32 = fadd float %5, %16
  %17 = add nsw i64 %indvars.iv1036, 1
  %arrayidx35 = getelementptr inbounds float* %pos, i64 %17
  %18 = load float* %arrayidx35, align 4, !tbaa !3
  %add36 = fadd float %6, %18
  %19 = add nsw i64 %indvars.iv1036, 2
  %arrayidx39 = getelementptr inbounds float* %pos, i64 %19
  %20 = load float* %arrayidx39, align 4, !tbaa !3
  %add40 = fadd float %7, %20
  %arrayidx42 = getelementptr inbounds float* %charge, i64 %indvars.iv1034
  %21 = load float* %arrayidx42, align 4, !tbaa !3
  %mul43 = fmul float %21, %facel
  %arrayidx46 = getelementptr inbounds i32* %type, i64 %indvars.iv1034
  %22 = load i32* %arrayidx46, align 4, !tbaa !0
  %mul47 = mul nsw i32 %mul350, %22
  br i1 %cmp49977, label %for.body50, label %for.end

for.body50:                                       ; preds = %for.body29, %for.body50
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body50 ], [ %11, %for.body29 ]
  %fiz1.0982 = phi float [ %add149, %for.body50 ], [ 0.000000e+00, %for.body29 ]
  %fiy1.0981 = phi float [ %add148, %for.body50 ], [ 0.000000e+00, %for.body29 ]
  %fix1.0980 = phi float [ %add147, %for.body50 ], [ 0.000000e+00, %for.body29 ]
  %vnbtot.1979 = phi float [ %add133, %for.body50 ], [ %vnbtot.0990, %for.body29 ]
  %vctot.1978 = phi float [ %add143, %for.body50 ], [ %vctot.0989, %for.body29 ]
  %arrayidx52 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %23 = load i32* %arrayidx52, align 4, !tbaa !0
  %mul53 = mul nsw i32 %23, 3
  %idxprom54 = sext i32 %mul53 to i64
  %arrayidx55 = getelementptr inbounds float* %pos, i64 %idxprom54
  %24 = load float* %arrayidx55, align 4, !tbaa !3
  %add56 = add nsw i32 %mul53, 1
  %idxprom57 = sext i32 %add56 to i64
  %arrayidx58 = getelementptr inbounds float* %pos, i64 %idxprom57
  %25 = load float* %arrayidx58, align 4, !tbaa !3
  %add59 = add nsw i32 %mul53, 2
  %idxprom60 = sext i32 %add59 to i64
  %arrayidx61 = getelementptr inbounds float* %pos, i64 %idxprom60
  %26 = load float* %arrayidx61, align 4, !tbaa !3
  %sub = fsub float %add32, %24
  %sub62 = fsub float %add36, %25
  %sub63 = fsub float %add40, %26
  %mul64 = fmul float %sub, %sub
  %mul65 = fmul float %sub62, %sub62
  %add66 = fadd float %mul64, %mul65
  %mul67 = fmul float %sub63, %sub63
  %add68 = fadd float %add66, %mul67
  %conv = fpext float %add68 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv69 = fptrunc double %div to float
  %mul70 = fmul float %add68, %conv69
  %mul72 = fmul float %mul70, %tabscale
  %conv73 = fptosi float %mul72 to i32
  %conv74 = sitofp i32 %conv73 to float
  %sub75 = fsub float %mul72, %conv74
  %mul76 = fmul float %sub75, %sub75
  %mul77 = shl nsw i32 %conv73, 3
  %idxprom78 = sext i32 %23 to i64
  %arrayidx79 = getelementptr inbounds i32* %type, i64 %idxprom78
  %27 = load i32* %arrayidx79, align 4, !tbaa !0
  %mul80 = shl nsw i32 %27, 1
  %add81 = add nsw i32 %mul80, %mul47
  %idxprom82 = sext i32 %add81 to i64
  %arrayidx83 = getelementptr inbounds float* %nbfp, i64 %idxprom82
  %28 = load float* %arrayidx83, align 4, !tbaa !3
  %add84969 = or i32 %add81, 1
  %idxprom85 = sext i32 %add84969 to i64
  %arrayidx86 = getelementptr inbounds float* %nbfp, i64 %idxprom85
  %29 = load float* %arrayidx86, align 4, !tbaa !3
  %idxprom87 = sext i32 %mul77 to i64
  %arrayidx88 = getelementptr inbounds float* %VFtab, i64 %idxprom87
  %30 = load float* %arrayidx88, align 4, !tbaa !3
  %add89970 = or i32 %mul77, 1
  %idxprom90 = sext i32 %add89970 to i64
  %arrayidx91 = getelementptr inbounds float* %VFtab, i64 %idxprom90
  %31 = load float* %arrayidx91, align 4, !tbaa !3
  %add92971 = or i32 %mul77, 2
  %idxprom93 = sext i32 %add92971 to i64
  %arrayidx94 = getelementptr inbounds float* %VFtab, i64 %idxprom93
  %32 = load float* %arrayidx94, align 4, !tbaa !3
  %mul95 = fmul float %sub75, %32
  %add96972 = or i32 %mul77, 3
  %idxprom97 = sext i32 %add96972 to i64
  %arrayidx98 = getelementptr inbounds float* %VFtab, i64 %idxprom97
  %33 = load float* %arrayidx98, align 4, !tbaa !3
  %mul99 = fmul float %mul76, %33
  %add100 = fadd float %31, %mul95
  %add101 = fadd float %add100, %mul99
  %mul102 = fmul float %sub75, %add101
  %add103 = fadd float %30, %mul102
  %add104 = fadd float %mul95, %add101
  %mul105 = fmul float %mul99, 2.000000e+00
  %add106 = fadd float %mul105, %add104
  %mul107 = fmul float %28, %add103
  %mul108 = fmul float %28, %add106
  %add109973 = or i32 %mul77, 4
  %idxprom110 = sext i32 %add109973 to i64
  %arrayidx111 = getelementptr inbounds float* %VFtab, i64 %idxprom110
  %34 = load float* %arrayidx111, align 4, !tbaa !3
  %add112974 = or i32 %mul77, 5
  %idxprom113 = sext i32 %add112974 to i64
  %arrayidx114 = getelementptr inbounds float* %VFtab, i64 %idxprom113
  %35 = load float* %arrayidx114, align 4, !tbaa !3
  %add115975 = or i32 %mul77, 6
  %idxprom116 = sext i32 %add115975 to i64
  %arrayidx117 = getelementptr inbounds float* %VFtab, i64 %idxprom116
  %36 = load float* %arrayidx117, align 4, !tbaa !3
  %mul118 = fmul float %sub75, %36
  %add119976 = or i32 %mul77, 7
  %idxprom120 = sext i32 %add119976 to i64
  %arrayidx121 = getelementptr inbounds float* %VFtab, i64 %idxprom120
  %37 = load float* %arrayidx121, align 4, !tbaa !3
  %mul122 = fmul float %mul76, %37
  %add123 = fadd float %35, %mul118
  %add124 = fadd float %add123, %mul122
  %mul125 = fmul float %sub75, %add124
  %add126 = fadd float %34, %mul125
  %add127 = fadd float %mul118, %add124
  %mul128 = fmul float %mul122, 2.000000e+00
  %add129 = fadd float %mul128, %add127
  %mul130 = fmul float %29, %add126
  %mul131 = fmul float %29, %add129
  %add132 = fadd float %vnbtot.1979, %mul107
  %add133 = fadd float %add132, %mul130
  %arrayidx135 = getelementptr inbounds float* %charge, i64 %idxprom78
  %38 = load float* %arrayidx135, align 4, !tbaa !3
  %mul136 = fmul float %mul43, %38
  %mul137 = fmul float %conv69, %mul136
  %mul138 = fmul float %conv69, %mul137
  %add139 = fadd float %mul108, %mul131
  %mul140 = fmul float %add139, %tabscale
  %sub141 = fsub float %mul138, %mul140
  %mul142 = fmul float %conv69, %sub141
  %add143 = fadd float %vctot.1978, %mul137
  %mul144 = fmul float %sub, %mul142
  %mul145 = fmul float %sub62, %mul142
  %mul146 = fmul float %sub63, %mul142
  %add147 = fadd float %fix1.0980, %mul144
  %add148 = fadd float %fiy1.0981, %mul145
  %add149 = fadd float %fiz1.0982, %mul146
  %arrayidx151 = getelementptr inbounds float* %faction, i64 %idxprom54
  %39 = load float* %arrayidx151, align 4, !tbaa !3
  %sub152 = fsub float %39, %mul144
  store float %sub152, float* %arrayidx151, align 4, !tbaa !3
  %arrayidx157 = getelementptr inbounds float* %faction, i64 %idxprom57
  %40 = load float* %arrayidx157, align 4, !tbaa !3
  %sub158 = fsub float %40, %mul145
  store float %sub158, float* %arrayidx157, align 4, !tbaa !3
  %arrayidx164 = getelementptr inbounds float* %faction, i64 %idxprom60
  %41 = load float* %arrayidx164, align 4, !tbaa !3
  %sub165 = fsub float %41, %mul146
  store float %sub165, float* %arrayidx164, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %42 = trunc i64 %indvars.iv.next to i32
  %cmp49 = icmp slt i32 %42, %10
  br i1 %cmp49, label %for.body50, label %for.end

for.end:                                          ; preds = %for.body50, %for.body29
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add149, %for.body50 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add148, %for.body50 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add147, %for.body50 ]
  %vnbtot.1.lcssa = phi float [ %vnbtot.0990, %for.body29 ], [ %add133, %for.body50 ]
  %vctot.1.lcssa = phi float [ %vctot.0989, %for.body29 ], [ %add143, %for.body50 ]
  %arrayidx170 = getelementptr inbounds float* %faction, i64 %indvars.iv1036
  %43 = load float* %arrayidx170, align 4, !tbaa !3
  %add171 = fadd float %fix1.0.lcssa, %43
  store float %add171, float* %arrayidx170, align 4, !tbaa !3
  %arrayidx176 = getelementptr inbounds float* %faction, i64 %17
  %44 = load float* %arrayidx176, align 4, !tbaa !3
  %add177 = fadd float %fiy1.0.lcssa, %44
  store float %add177, float* %arrayidx176, align 4, !tbaa !3
  %arrayidx183 = getelementptr inbounds float* %faction, i64 %19
  %45 = load float* %arrayidx183, align 4, !tbaa !3
  %add184 = fadd float %fiz1.0.lcssa, %45
  store float %add184, float* %arrayidx183, align 4, !tbaa !3
  %46 = load float* %arrayidx189, align 4, !tbaa !3
  %add190 = fadd float %fix1.0.lcssa, %46
  store float %add190, float* %arrayidx189, align 4, !tbaa !3
  %47 = load float* %arrayidx195, align 4, !tbaa !3
  %add196 = fadd float %fiy1.0.lcssa, %47
  store float %add196, float* %arrayidx195, align 4, !tbaa !3
  %48 = load float* %arrayidx202, align 4, !tbaa !3
  %add203 = fadd float %fiz1.0.lcssa, %48
  store float %add203, float* %arrayidx202, align 4, !tbaa !3
  %indvars.iv.next1035 = add i64 %indvars.iv1034, 1
  %indvars.iv.next1037 = add i64 %indvars.iv1036, 3
  %inc210 = add nsw i32 %s.0991, 1
  %exitcond = icmp eq i32 %inc210, %2
  br i1 %exitcond, label %for.cond27.for.cond212.loopexit_crit_edge, label %for.body29

for.cond27.for.cond212.loopexit_crit_edge:        ; preds = %for.end
  %49 = add i32 %2, %8
  br label %for.cond212.loopexit

for.cond212.loopexit:                             ; preds = %for.cond27.for.cond212.loopexit_crit_edge, %for.body
  %ii.0.lcssa = phi i32 [ %49, %for.cond27.for.cond212.loopexit_crit_edge ], [ %8, %for.body ]
  %ii3.0.lcssa = phi i32 [ %15, %for.cond27.for.cond212.loopexit_crit_edge ], [ %mul21, %for.body ]
  %vnbtot.0.lcssa = phi float [ %vnbtot.1.lcssa, %for.cond27.for.cond212.loopexit_crit_edge ], [ 0.000000e+00, %for.body ]
  %vctot.0.lcssa = phi float [ %vctot.1.lcssa, %for.cond27.for.cond212.loopexit_crit_edge ], [ 0.000000e+00, %for.body ]
  %cmp2131008 = icmp slt i32 %2, %3
  br i1 %cmp2131008, label %for.body215.lr.ph, label %for.cond335.loopexit

for.body215.lr.ph:                                ; preds = %for.cond212.loopexit
  %cmp231998 = icmp slt i32 %9, %10
  %arrayidx312 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx318 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx325 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %50 = sext i32 %9 to i64
  %51 = sext i32 %ii.0.lcssa to i64
  %52 = sext i32 %ii3.0.lcssa to i64
  %53 = mul i32 %3, 3
  %54 = add i32 %ii.0.lcssa, %3
  br label %for.body215

for.body215:                                      ; preds = %for.end291, %for.body215.lr.ph
  %indvars.iv1044 = phi i64 [ %52, %for.body215.lr.ph ], [ %indvars.iv.next1045, %for.end291 ]
  %indvars.iv1042 = phi i64 [ %51, %for.body215.lr.ph ], [ %indvars.iv.next1043, %for.end291 ]
  %s.11010 = phi i32 [ %2, %for.body215.lr.ph ], [ %inc333, %for.end291 ]
  %vctot.21009 = phi float [ %vctot.0.lcssa, %for.body215.lr.ph ], [ %vctot.3.lcssa, %for.end291 ]
  %arrayidx217 = getelementptr inbounds float* %pos, i64 %indvars.iv1044
  %55 = load float* %arrayidx217, align 4, !tbaa !3
  %add218 = fadd float %5, %55
  %56 = add nsw i64 %indvars.iv1044, 1
  %arrayidx221 = getelementptr inbounds float* %pos, i64 %56
  %57 = load float* %arrayidx221, align 4, !tbaa !3
  %add222 = fadd float %6, %57
  %58 = add nsw i64 %indvars.iv1044, 2
  %arrayidx225 = getelementptr inbounds float* %pos, i64 %58
  %59 = load float* %arrayidx225, align 4, !tbaa !3
  %add226 = fadd float %7, %59
  %arrayidx228 = getelementptr inbounds float* %charge, i64 %indvars.iv1042
  %60 = load float* %arrayidx228, align 4, !tbaa !3
  %mul229 = fmul float %60, %facel
  br i1 %cmp231998, label %for.body233, label %for.end291

for.body233:                                      ; preds = %for.body215, %for.body233
  %indvars.iv1040 = phi i64 [ %indvars.iv.next1041, %for.body233 ], [ %50, %for.body215 ]
  %fiz1.11002 = phi float [ %add269, %for.body233 ], [ 0.000000e+00, %for.body215 ]
  %fiy1.11001 = phi float [ %add268, %for.body233 ], [ 0.000000e+00, %for.body215 ]
  %fix1.11000 = phi float [ %add267, %for.body233 ], [ 0.000000e+00, %for.body215 ]
  %vctot.3999 = phi float [ %add263, %for.body233 ], [ %vctot.21009, %for.body215 ]
  %arrayidx235 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv1040
  %61 = load i32* %arrayidx235, align 4, !tbaa !0
  %mul236 = mul nsw i32 %61, 3
  %idxprom237 = sext i32 %mul236 to i64
  %arrayidx238 = getelementptr inbounds float* %pos, i64 %idxprom237
  %62 = load float* %arrayidx238, align 4, !tbaa !3
  %add239 = add nsw i32 %mul236, 1
  %idxprom240 = sext i32 %add239 to i64
  %arrayidx241 = getelementptr inbounds float* %pos, i64 %idxprom240
  %63 = load float* %arrayidx241, align 4, !tbaa !3
  %add242 = add nsw i32 %mul236, 2
  %idxprom243 = sext i32 %add242 to i64
  %arrayidx244 = getelementptr inbounds float* %pos, i64 %idxprom243
  %64 = load float* %arrayidx244, align 4, !tbaa !3
  %sub245 = fsub float %add218, %62
  %sub246 = fsub float %add222, %63
  %sub247 = fsub float %add226, %64
  %mul248 = fmul float %sub245, %sub245
  %mul249 = fmul float %sub246, %sub246
  %add250 = fadd float %mul248, %mul249
  %mul251 = fmul float %sub247, %sub247
  %add252 = fadd float %add250, %mul251
  %conv253 = fpext float %add252 to double
  %call254 = tail call double @sqrt(double %conv253) #2
  %div255 = fdiv double 1.000000e+00, %call254
  %conv256 = fptrunc double %div255 to float
  %mul257 = fmul float %conv256, %conv256
  %idxprom258 = sext i32 %61 to i64
  %arrayidx259 = getelementptr inbounds float* %charge, i64 %idxprom258
  %65 = load float* %arrayidx259, align 4, !tbaa !3
  %mul260 = fmul float %mul229, %65
  %mul261 = fmul float %conv256, %mul260
  %mul262 = fmul float %mul257, %mul261
  %add263 = fadd float %vctot.3999, %mul261
  %mul264 = fmul float %sub245, %mul262
  %mul265 = fmul float %sub246, %mul262
  %mul266 = fmul float %sub247, %mul262
  %add267 = fadd float %fix1.11000, %mul264
  %add268 = fadd float %fiy1.11001, %mul265
  %add269 = fadd float %fiz1.11002, %mul266
  %arrayidx271 = getelementptr inbounds float* %faction, i64 %idxprom237
  %66 = load float* %arrayidx271, align 4, !tbaa !3
  %sub272 = fsub float %66, %mul264
  store float %sub272, float* %arrayidx271, align 4, !tbaa !3
  %arrayidx277 = getelementptr inbounds float* %faction, i64 %idxprom240
  %67 = load float* %arrayidx277, align 4, !tbaa !3
  %sub278 = fsub float %67, %mul265
  store float %sub278, float* %arrayidx277, align 4, !tbaa !3
  %arrayidx284 = getelementptr inbounds float* %faction, i64 %idxprom243
  %68 = load float* %arrayidx284, align 4, !tbaa !3
  %sub285 = fsub float %68, %mul266
  store float %sub285, float* %arrayidx284, align 4, !tbaa !3
  %indvars.iv.next1041 = add i64 %indvars.iv1040, 1
  %69 = trunc i64 %indvars.iv.next1041 to i32
  %cmp231 = icmp slt i32 %69, %10
  br i1 %cmp231, label %for.body233, label %for.end291

for.end291:                                       ; preds = %for.body233, %for.body215
  %fiz1.1.lcssa = phi float [ 0.000000e+00, %for.body215 ], [ %add269, %for.body233 ]
  %fiy1.1.lcssa = phi float [ 0.000000e+00, %for.body215 ], [ %add268, %for.body233 ]
  %fix1.1.lcssa = phi float [ 0.000000e+00, %for.body215 ], [ %add267, %for.body233 ]
  %vctot.3.lcssa = phi float [ %vctot.21009, %for.body215 ], [ %add263, %for.body233 ]
  %arrayidx293 = getelementptr inbounds float* %faction, i64 %indvars.iv1044
  %70 = load float* %arrayidx293, align 4, !tbaa !3
  %add294 = fadd float %fix1.1.lcssa, %70
  store float %add294, float* %arrayidx293, align 4, !tbaa !3
  %arrayidx299 = getelementptr inbounds float* %faction, i64 %56
  %71 = load float* %arrayidx299, align 4, !tbaa !3
  %add300 = fadd float %fiy1.1.lcssa, %71
  store float %add300, float* %arrayidx299, align 4, !tbaa !3
  %arrayidx306 = getelementptr inbounds float* %faction, i64 %58
  %72 = load float* %arrayidx306, align 4, !tbaa !3
  %add307 = fadd float %fiz1.1.lcssa, %72
  store float %add307, float* %arrayidx306, align 4, !tbaa !3
  %73 = load float* %arrayidx312, align 4, !tbaa !3
  %add313 = fadd float %fix1.1.lcssa, %73
  store float %add313, float* %arrayidx312, align 4, !tbaa !3
  %74 = load float* %arrayidx318, align 4, !tbaa !3
  %add319 = fadd float %fiy1.1.lcssa, %74
  store float %add319, float* %arrayidx318, align 4, !tbaa !3
  %75 = load float* %arrayidx325, align 4, !tbaa !3
  %add326 = fadd float %fiz1.1.lcssa, %75
  store float %add326, float* %arrayidx325, align 4, !tbaa !3
  %indvars.iv.next1043 = add i64 %indvars.iv1042, 1
  %indvars.iv.next1045 = add i64 %indvars.iv1044, 3
  %inc333 = add nsw i32 %s.11010, 1
  %exitcond1048 = icmp eq i32 %inc333, %3
  br i1 %exitcond1048, label %for.cond212.for.cond335.loopexit_crit_edge, label %for.body215

for.cond212.for.cond335.loopexit_crit_edge:       ; preds = %for.end291
  %76 = add i32 %ii3.0.lcssa, %53
  %77 = mul i32 %2, -3
  %78 = add i32 %76, %77
  %79 = sub i32 %54, %2
  br label %for.cond335.loopexit

for.cond335.loopexit:                             ; preds = %for.cond212.for.cond335.loopexit_crit_edge, %for.cond212.loopexit
  %ii.1.lcssa = phi i32 [ %79, %for.cond212.for.cond335.loopexit_crit_edge ], [ %ii.0.lcssa, %for.cond212.loopexit ]
  %ii3.1.lcssa = phi i32 [ %78, %for.cond212.for.cond335.loopexit_crit_edge ], [ %ii3.0.lcssa, %for.cond212.loopexit ]
  %vctot.2.lcssa = phi float [ %vctot.3.lcssa, %for.cond212.for.cond335.loopexit_crit_edge ], [ %vctot.0.lcssa, %for.cond212.loopexit ]
  %cmp3361026 = icmp slt i32 %3, %1
  br i1 %cmp3361026, label %for.body338.lr.ph, label %for.end519

for.body338.lr.ph:                                ; preds = %for.cond335.loopexit
  %cmp3551016 = icmp slt i32 %9, %10
  %arrayidx497 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx503 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx510 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %80 = sext i32 %9 to i64
  %81 = sext i32 %ii.1.lcssa to i64
  %82 = sext i32 %ii3.1.lcssa to i64
  br label %for.body338

for.body338:                                      ; preds = %for.end476, %for.body338.lr.ph
  %indvars.iv1053 = phi i64 [ %82, %for.body338.lr.ph ], [ %indvars.iv.next1054, %for.end476 ]
  %indvars.iv1051 = phi i64 [ %81, %for.body338.lr.ph ], [ %indvars.iv.next1052, %for.end476 ]
  %s.21028 = phi i32 [ %3, %for.body338.lr.ph ], [ %inc518, %for.end476 ]
  %vnbtot.21027 = phi float [ %vnbtot.0.lcssa, %for.body338.lr.ph ], [ %vnbtot.3.lcssa, %for.end476 ]
  %arrayidx340 = getelementptr inbounds float* %pos, i64 %indvars.iv1053
  %83 = load float* %arrayidx340, align 4, !tbaa !3
  %add341 = fadd float %5, %83
  %84 = add nsw i64 %indvars.iv1053, 1
  %arrayidx344 = getelementptr inbounds float* %pos, i64 %84
  %85 = load float* %arrayidx344, align 4, !tbaa !3
  %add345 = fadd float %6, %85
  %86 = add nsw i64 %indvars.iv1053, 2
  %arrayidx348 = getelementptr inbounds float* %pos, i64 %86
  %87 = load float* %arrayidx348, align 4, !tbaa !3
  %add349 = fadd float %7, %87
  %arrayidx352 = getelementptr inbounds i32* %type, i64 %indvars.iv1051
  %88 = load i32* %arrayidx352, align 4, !tbaa !0
  %mul353 = mul nsw i32 %mul350, %88
  br i1 %cmp3551016, label %for.body357, label %for.end476

for.body357:                                      ; preds = %for.body338, %for.body357
  %indvars.iv1049 = phi i64 [ %indvars.iv.next1050, %for.body357 ], [ %80, %for.body338 ]
  %fiz1.21020 = phi float [ %add454, %for.body357 ], [ 0.000000e+00, %for.body338 ]
  %fiy1.21019 = phi float [ %add453, %for.body357 ], [ 0.000000e+00, %for.body338 ]
  %fix1.21018 = phi float [ %add452, %for.body357 ], [ 0.000000e+00, %for.body338 ]
  %vnbtot.31017 = phi float [ %add444, %for.body357 ], [ %vnbtot.21027, %for.body338 ]
  %arrayidx359 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv1049
  %89 = load i32* %arrayidx359, align 4, !tbaa !0
  %mul360 = mul nsw i32 %89, 3
  %idxprom361 = sext i32 %mul360 to i64
  %arrayidx362 = getelementptr inbounds float* %pos, i64 %idxprom361
  %90 = load float* %arrayidx362, align 4, !tbaa !3
  %add363 = add nsw i32 %mul360, 1
  %idxprom364 = sext i32 %add363 to i64
  %arrayidx365 = getelementptr inbounds float* %pos, i64 %idxprom364
  %91 = load float* %arrayidx365, align 4, !tbaa !3
  %add366 = add nsw i32 %mul360, 2
  %idxprom367 = sext i32 %add366 to i64
  %arrayidx368 = getelementptr inbounds float* %pos, i64 %idxprom367
  %92 = load float* %arrayidx368, align 4, !tbaa !3
  %sub369 = fsub float %add341, %90
  %sub370 = fsub float %add345, %91
  %sub371 = fsub float %add349, %92
  %mul372 = fmul float %sub369, %sub369
  %mul373 = fmul float %sub370, %sub370
  %add374 = fadd float %mul372, %mul373
  %mul375 = fmul float %sub371, %sub371
  %add376 = fadd float %add374, %mul375
  %conv377 = fpext float %add376 to double
  %call378 = tail call double @sqrt(double %conv377) #2
  %div379 = fdiv double 1.000000e+00, %call378
  %conv380 = fptrunc double %div379 to float
  %mul381 = fmul float %add376, %conv380
  %mul383 = fmul float %mul381, %tabscale
  %conv384 = fptosi float %mul383 to i32
  %conv385 = sitofp i32 %conv384 to float
  %sub386 = fsub float %mul383, %conv385
  %mul387 = fmul float %sub386, %sub386
  %mul388 = shl nsw i32 %conv384, 3
  %idxprom389 = sext i32 %89 to i64
  %arrayidx390 = getelementptr inbounds i32* %type, i64 %idxprom389
  %93 = load i32* %arrayidx390, align 4, !tbaa !0
  %mul391 = shl nsw i32 %93, 1
  %add392 = add nsw i32 %mul391, %mul353
  %idxprom393 = sext i32 %add392 to i64
  %arrayidx394 = getelementptr inbounds float* %nbfp, i64 %idxprom393
  %94 = load float* %arrayidx394, align 4, !tbaa !3
  %add395961 = or i32 %add392, 1
  %idxprom396 = sext i32 %add395961 to i64
  %arrayidx397 = getelementptr inbounds float* %nbfp, i64 %idxprom396
  %95 = load float* %arrayidx397, align 4, !tbaa !3
  %idxprom398 = sext i32 %mul388 to i64
  %arrayidx399 = getelementptr inbounds float* %VFtab, i64 %idxprom398
  %96 = load float* %arrayidx399, align 4, !tbaa !3
  %add400962 = or i32 %mul388, 1
  %idxprom401 = sext i32 %add400962 to i64
  %arrayidx402 = getelementptr inbounds float* %VFtab, i64 %idxprom401
  %97 = load float* %arrayidx402, align 4, !tbaa !3
  %add403963 = or i32 %mul388, 2
  %idxprom404 = sext i32 %add403963 to i64
  %arrayidx405 = getelementptr inbounds float* %VFtab, i64 %idxprom404
  %98 = load float* %arrayidx405, align 4, !tbaa !3
  %mul406 = fmul float %sub386, %98
  %add407964 = or i32 %mul388, 3
  %idxprom408 = sext i32 %add407964 to i64
  %arrayidx409 = getelementptr inbounds float* %VFtab, i64 %idxprom408
  %99 = load float* %arrayidx409, align 4, !tbaa !3
  %mul410 = fmul float %mul387, %99
  %add411 = fadd float %97, %mul406
  %add412 = fadd float %add411, %mul410
  %mul413 = fmul float %sub386, %add412
  %add414 = fadd float %96, %mul413
  %add415 = fadd float %mul406, %add412
  %mul416 = fmul float %mul410, 2.000000e+00
  %add417 = fadd float %mul416, %add415
  %mul418 = fmul float %94, %add414
  %mul419 = fmul float %94, %add417
  %add420965 = or i32 %mul388, 4
  %idxprom421 = sext i32 %add420965 to i64
  %arrayidx422 = getelementptr inbounds float* %VFtab, i64 %idxprom421
  %100 = load float* %arrayidx422, align 4, !tbaa !3
  %add423966 = or i32 %mul388, 5
  %idxprom424 = sext i32 %add423966 to i64
  %arrayidx425 = getelementptr inbounds float* %VFtab, i64 %idxprom424
  %101 = load float* %arrayidx425, align 4, !tbaa !3
  %add426967 = or i32 %mul388, 6
  %idxprom427 = sext i32 %add426967 to i64
  %arrayidx428 = getelementptr inbounds float* %VFtab, i64 %idxprom427
  %102 = load float* %arrayidx428, align 4, !tbaa !3
  %mul429 = fmul float %sub386, %102
  %add430968 = or i32 %mul388, 7
  %idxprom431 = sext i32 %add430968 to i64
  %arrayidx432 = getelementptr inbounds float* %VFtab, i64 %idxprom431
  %103 = load float* %arrayidx432, align 4, !tbaa !3
  %mul433 = fmul float %mul387, %103
  %add434 = fadd float %101, %mul429
  %add435 = fadd float %add434, %mul433
  %mul436 = fmul float %sub386, %add435
  %add437 = fadd float %100, %mul436
  %add438 = fadd float %mul429, %add435
  %mul439 = fmul float %mul433, 2.000000e+00
  %add440 = fadd float %mul439, %add438
  %mul441 = fmul float %95, %add437
  %mul442 = fmul float %95, %add440
  %add443 = fadd float %vnbtot.31017, %mul418
  %add444 = fadd float %add443, %mul441
  %add445 = fadd float %mul419, %mul442
  %mul446 = fmul float %add445, %tabscale
  %104 = fmul float %conv380, %mul446
  %mul448 = fsub float -0.000000e+00, %104
  %mul449 = fmul float %sub369, %mul448
  %mul450 = fmul float %sub370, %mul448
  %mul451 = fmul float %sub371, %mul448
  %add452 = fadd float %fix1.21018, %mul449
  %add453 = fadd float %fiy1.21019, %mul450
  %add454 = fadd float %fiz1.21020, %mul451
  %arrayidx456 = getelementptr inbounds float* %faction, i64 %idxprom361
  %105 = load float* %arrayidx456, align 4, !tbaa !3
  %sub457 = fsub float %105, %mul449
  store float %sub457, float* %arrayidx456, align 4, !tbaa !3
  %arrayidx462 = getelementptr inbounds float* %faction, i64 %idxprom364
  %106 = load float* %arrayidx462, align 4, !tbaa !3
  %sub463 = fsub float %106, %mul450
  store float %sub463, float* %arrayidx462, align 4, !tbaa !3
  %arrayidx469 = getelementptr inbounds float* %faction, i64 %idxprom367
  %107 = load float* %arrayidx469, align 4, !tbaa !3
  %sub470 = fsub float %107, %mul451
  store float %sub470, float* %arrayidx469, align 4, !tbaa !3
  %indvars.iv.next1050 = add i64 %indvars.iv1049, 1
  %108 = trunc i64 %indvars.iv.next1050 to i32
  %cmp355 = icmp slt i32 %108, %10
  br i1 %cmp355, label %for.body357, label %for.end476

for.end476:                                       ; preds = %for.body357, %for.body338
  %fiz1.2.lcssa = phi float [ 0.000000e+00, %for.body338 ], [ %add454, %for.body357 ]
  %fiy1.2.lcssa = phi float [ 0.000000e+00, %for.body338 ], [ %add453, %for.body357 ]
  %fix1.2.lcssa = phi float [ 0.000000e+00, %for.body338 ], [ %add452, %for.body357 ]
  %vnbtot.3.lcssa = phi float [ %vnbtot.21027, %for.body338 ], [ %add444, %for.body357 ]
  %arrayidx478 = getelementptr inbounds float* %faction, i64 %indvars.iv1053
  %109 = load float* %arrayidx478, align 4, !tbaa !3
  %add479 = fadd float %fix1.2.lcssa, %109
  store float %add479, float* %arrayidx478, align 4, !tbaa !3
  %arrayidx484 = getelementptr inbounds float* %faction, i64 %84
  %110 = load float* %arrayidx484, align 4, !tbaa !3
  %add485 = fadd float %fiy1.2.lcssa, %110
  store float %add485, float* %arrayidx484, align 4, !tbaa !3
  %arrayidx491 = getelementptr inbounds float* %faction, i64 %86
  %111 = load float* %arrayidx491, align 4, !tbaa !3
  %add492 = fadd float %fiz1.2.lcssa, %111
  store float %add492, float* %arrayidx491, align 4, !tbaa !3
  %112 = load float* %arrayidx497, align 4, !tbaa !3
  %add498 = fadd float %fix1.2.lcssa, %112
  store float %add498, float* %arrayidx497, align 4, !tbaa !3
  %113 = load float* %arrayidx503, align 4, !tbaa !3
  %add504 = fadd float %fiy1.2.lcssa, %113
  store float %add504, float* %arrayidx503, align 4, !tbaa !3
  %114 = load float* %arrayidx510, align 4, !tbaa !3
  %add511 = fadd float %fiz1.2.lcssa, %114
  store float %add511, float* %arrayidx510, align 4, !tbaa !3
  %indvars.iv.next1052 = add i64 %indvars.iv1051, 1
  %indvars.iv.next1054 = add i64 %indvars.iv1053, 3
  %inc518 = add nsw i32 %s.21028, 1
  %exitcond1057 = icmp eq i32 %inc518, %1
  br i1 %exitcond1057, label %for.end519, label %for.body338

for.end519:                                       ; preds = %for.end476, %for.cond335.loopexit
  %vnbtot.2.lcssa = phi float [ %vnbtot.0.lcssa, %for.cond335.loopexit ], [ %vnbtot.3.lcssa, %for.end476 ]
  %arrayidx521 = getelementptr inbounds i32* %gid, i64 %indvars.iv1058
  %115 = load i32* %arrayidx521, align 4, !tbaa !0
  %idxprom522 = sext i32 %115 to i64
  %arrayidx523 = getelementptr inbounds float* %Vc, i64 %idxprom522
  %116 = load float* %arrayidx523, align 4, !tbaa !3
  %add524 = fadd float %vctot.2.lcssa, %116
  store float %add524, float* %arrayidx523, align 4, !tbaa !3
  %arrayidx528 = getelementptr inbounds float* %Vnb, i64 %idxprom522
  %117 = load float* %arrayidx528, align 4, !tbaa !3
  %add529 = fadd float %vnbtot.2.lcssa, %117
  store float %add529, float* %arrayidx528, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next1059 to i32
  %exitcond1060 = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond1060, label %for.end534, label %for.body

for.end534:                                       ; preds = %for.end519, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl1320(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab) #0 {
entry:
  %0 = load i32* %iinr, align 4, !tbaa !0
  %idxprom = sext i32 %0 to i64
  %arrayidx1 = getelementptr inbounds float* %charge, i64 %idxprom
  %1 = load float* %arrayidx1, align 4, !tbaa !3
  %add = add nsw i32 %0, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds float* %charge, i64 %idxprom2
  %2 = load float* %arrayidx3, align 4, !tbaa !3
  %mul = fmul float %1, %facel
  %mul4 = fmul float %2, %facel
  %mul5 = shl i32 %ntype, 1
  %arrayidx7 = getelementptr inbounds i32* %type, i64 %idxprom
  %3 = load i32* %arrayidx7, align 4, !tbaa !0
  %mul8 = mul nsw i32 %mul5, %3
  %cmp614 = icmp sgt i32 %nri, 0
  br i1 %cmp614, label %for.body, label %for.end340

for.body:                                         ; preds = %entry, %for.end.for.body_crit_edge
  %4 = phi i32 [ %.pre, %for.end.for.body_crit_edge ], [ %0, %entry ]
  %indvars.iv616 = phi i64 [ %indvars.iv.next617, %for.end.for.body_crit_edge ], [ 0, %entry ]
  %arrayidx10 = getelementptr inbounds i32* %shift, i64 %indvars.iv616
  %5 = load i32* %arrayidx10, align 4, !tbaa !0
  %mul11 = mul nsw i32 %5, 3
  %idxprom12 = sext i32 %mul11 to i64
  %arrayidx13 = getelementptr inbounds float* %shiftvec, i64 %idxprom12
  %6 = load float* %arrayidx13, align 4, !tbaa !3
  %add14 = add nsw i32 %mul11, 1
  %idxprom15 = sext i32 %add14 to i64
  %arrayidx16 = getelementptr inbounds float* %shiftvec, i64 %idxprom15
  %7 = load float* %arrayidx16, align 4, !tbaa !3
  %add17 = add nsw i32 %mul11, 2
  %idxprom18 = sext i32 %add17 to i64
  %arrayidx19 = getelementptr inbounds float* %shiftvec, i64 %idxprom18
  %8 = load float* %arrayidx19, align 4, !tbaa !3
  %mul22 = mul nsw i32 %4, 3
  %arrayidx24 = getelementptr inbounds i32* %jindex, i64 %indvars.iv616
  %9 = load i32* %arrayidx24, align 4, !tbaa !0
  %indvars.iv.next617 = add i64 %indvars.iv616, 1
  %arrayidx27 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next617
  %10 = load i32* %arrayidx27, align 4, !tbaa !0
  %idxprom28 = sext i32 %mul22 to i64
  %arrayidx29 = getelementptr inbounds float* %pos, i64 %idxprom28
  %11 = load float* %arrayidx29, align 4, !tbaa !3
  %add30 = fadd float %6, %11
  %add31 = add nsw i32 %mul22, 1
  %idxprom32 = sext i32 %add31 to i64
  %arrayidx33 = getelementptr inbounds float* %pos, i64 %idxprom32
  %12 = load float* %arrayidx33, align 4, !tbaa !3
  %add34 = fadd float %7, %12
  %add35 = add nsw i32 %mul22, 2
  %idxprom36 = sext i32 %add35 to i64
  %arrayidx37 = getelementptr inbounds float* %pos, i64 %idxprom36
  %13 = load float* %arrayidx37, align 4, !tbaa !3
  %add38 = fadd float %8, %13
  %add39 = add nsw i32 %mul22, 3
  %idxprom40 = sext i32 %add39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %14 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = fadd float %6, %14
  %add43 = add nsw i32 %mul22, 4
  %idxprom44 = sext i32 %add43 to i64
  %arrayidx45 = getelementptr inbounds float* %pos, i64 %idxprom44
  %15 = load float* %arrayidx45, align 4, !tbaa !3
  %add46 = fadd float %7, %15
  %add47 = add nsw i32 %mul22, 5
  %idxprom48 = sext i32 %add47 to i64
  %arrayidx49 = getelementptr inbounds float* %pos, i64 %idxprom48
  %16 = load float* %arrayidx49, align 4, !tbaa !3
  %add50 = fadd float %8, %16
  %add51 = add nsw i32 %mul22, 6
  %idxprom52 = sext i32 %add51 to i64
  %arrayidx53 = getelementptr inbounds float* %pos, i64 %idxprom52
  %17 = load float* %arrayidx53, align 4, !tbaa !3
  %add54 = fadd float %6, %17
  %add55 = add nsw i32 %mul22, 7
  %idxprom56 = sext i32 %add55 to i64
  %arrayidx57 = getelementptr inbounds float* %pos, i64 %idxprom56
  %18 = load float* %arrayidx57, align 4, !tbaa !3
  %add58 = fadd float %7, %18
  %add59 = add nsw i32 %mul22, 8
  %idxprom60 = sext i32 %add59 to i64
  %arrayidx61 = getelementptr inbounds float* %pos, i64 %idxprom60
  %19 = load float* %arrayidx61, align 4, !tbaa !3
  %add62 = fadd float %8, %19
  %cmp64591 = icmp slt i32 %9, %10
  br i1 %cmp64591, label %for.body65.lr.ph, label %for.end

for.body65.lr.ph:                                 ; preds = %for.body
  %20 = sext i32 %9 to i64
  br label %for.body65

for.body65:                                       ; preds = %for.body65.lr.ph, %for.body65
  %indvars.iv = phi i64 [ %20, %for.body65.lr.ph ], [ %indvars.iv.next, %for.body65 ]
  %vctot.0602 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add222, %for.body65 ]
  %vnbtot.0601 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add172, %for.body65 ]
  %fix1.0600 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add186, %for.body65 ]
  %fiy1.0599 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add187, %for.body65 ]
  %fiz1.0598 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add188, %for.body65 ]
  %fix2.0597 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add210, %for.body65 ]
  %fiy2.0596 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add211, %for.body65 ]
  %fiz2.0595 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add212, %for.body65 ]
  %fix3.0594 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add226, %for.body65 ]
  %fiy3.0593 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add227, %for.body65 ]
  %fiz3.0592 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add228, %for.body65 ]
  %arrayidx67 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %21 = load i32* %arrayidx67, align 4, !tbaa !0
  %mul68 = mul nsw i32 %21, 3
  %idxprom69 = sext i32 %mul68 to i64
  %arrayidx70 = getelementptr inbounds float* %pos, i64 %idxprom69
  %22 = load float* %arrayidx70, align 4, !tbaa !3
  %add71 = add nsw i32 %mul68, 1
  %idxprom72 = sext i32 %add71 to i64
  %arrayidx73 = getelementptr inbounds float* %pos, i64 %idxprom72
  %23 = load float* %arrayidx73, align 4, !tbaa !3
  %add74 = add nsw i32 %mul68, 2
  %idxprom75 = sext i32 %add74 to i64
  %arrayidx76 = getelementptr inbounds float* %pos, i64 %idxprom75
  %24 = load float* %arrayidx76, align 4, !tbaa !3
  %sub = fsub float %add30, %22
  %sub77 = fsub float %add34, %23
  %sub78 = fsub float %add38, %24
  %mul79 = fmul float %sub, %sub
  %mul80 = fmul float %sub77, %sub77
  %add81 = fadd float %mul79, %mul80
  %mul82 = fmul float %sub78, %sub78
  %add83 = fadd float %add81, %mul82
  %sub84 = fsub float %add42, %22
  %sub85 = fsub float %add46, %23
  %sub86 = fsub float %add50, %24
  %mul87 = fmul float %sub84, %sub84
  %mul88 = fmul float %sub85, %sub85
  %add89 = fadd float %mul87, %mul88
  %mul90 = fmul float %sub86, %sub86
  %add91 = fadd float %add89, %mul90
  %sub92 = fsub float %add54, %22
  %sub93 = fsub float %add58, %23
  %sub94 = fsub float %add62, %24
  %mul95 = fmul float %sub92, %sub92
  %mul96 = fmul float %sub93, %sub93
  %add97 = fadd float %mul95, %mul96
  %mul98 = fmul float %sub94, %sub94
  %add99 = fadd float %add97, %mul98
  %conv = fpext float %add83 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv100 = fptrunc double %div to float
  %conv101 = fpext float %add91 to double
  %call102 = tail call double @sqrt(double %conv101) #2
  %div103 = fdiv double 1.000000e+00, %call102
  %conv104 = fptrunc double %div103 to float
  %conv105 = fpext float %add99 to double
  %call106 = tail call double @sqrt(double %conv105) #2
  %div107 = fdiv double 1.000000e+00, %call106
  %conv108 = fptrunc double %div107 to float
  %mul109 = fmul float %add83, %conv100
  %mul111 = fmul float %mul109, %tabscale
  %conv112 = fptosi float %mul111 to i32
  %conv113 = sitofp i32 %conv112 to float
  %sub114 = fsub float %mul111, %conv113
  %mul115 = fmul float %sub114, %sub114
  %mul116 = shl nsw i32 %conv112, 3
  %idxprom117 = sext i32 %21 to i64
  %arrayidx118 = getelementptr inbounds i32* %type, i64 %idxprom117
  %25 = load i32* %arrayidx118, align 4, !tbaa !0
  %mul119 = shl nsw i32 %25, 1
  %add120 = add nsw i32 %mul119, %mul8
  %idxprom121 = sext i32 %add120 to i64
  %arrayidx122 = getelementptr inbounds float* %nbfp, i64 %idxprom121
  %26 = load float* %arrayidx122, align 4, !tbaa !3
  %add123583 = or i32 %add120, 1
  %idxprom124 = sext i32 %add123583 to i64
  %arrayidx125 = getelementptr inbounds float* %nbfp, i64 %idxprom124
  %27 = load float* %arrayidx125, align 4, !tbaa !3
  %idxprom126 = sext i32 %mul116 to i64
  %arrayidx127 = getelementptr inbounds float* %VFtab, i64 %idxprom126
  %28 = load float* %arrayidx127, align 4, !tbaa !3
  %add128584 = or i32 %mul116, 1
  %idxprom129 = sext i32 %add128584 to i64
  %arrayidx130 = getelementptr inbounds float* %VFtab, i64 %idxprom129
  %29 = load float* %arrayidx130, align 4, !tbaa !3
  %add131585 = or i32 %mul116, 2
  %idxprom132 = sext i32 %add131585 to i64
  %arrayidx133 = getelementptr inbounds float* %VFtab, i64 %idxprom132
  %30 = load float* %arrayidx133, align 4, !tbaa !3
  %mul134 = fmul float %sub114, %30
  %add135586 = or i32 %mul116, 3
  %idxprom136 = sext i32 %add135586 to i64
  %arrayidx137 = getelementptr inbounds float* %VFtab, i64 %idxprom136
  %31 = load float* %arrayidx137, align 4, !tbaa !3
  %mul138 = fmul float %mul115, %31
  %add139 = fadd float %29, %mul134
  %add140 = fadd float %add139, %mul138
  %mul141 = fmul float %sub114, %add140
  %add142 = fadd float %28, %mul141
  %add143 = fadd float %mul134, %add140
  %mul144 = fmul float %mul138, 2.000000e+00
  %add145 = fadd float %mul144, %add143
  %mul146 = fmul float %26, %add142
  %mul147 = fmul float %26, %add145
  %add148587 = or i32 %mul116, 4
  %idxprom149 = sext i32 %add148587 to i64
  %arrayidx150 = getelementptr inbounds float* %VFtab, i64 %idxprom149
  %32 = load float* %arrayidx150, align 4, !tbaa !3
  %add151588 = or i32 %mul116, 5
  %idxprom152 = sext i32 %add151588 to i64
  %arrayidx153 = getelementptr inbounds float* %VFtab, i64 %idxprom152
  %33 = load float* %arrayidx153, align 4, !tbaa !3
  %add154589 = or i32 %mul116, 6
  %idxprom155 = sext i32 %add154589 to i64
  %arrayidx156 = getelementptr inbounds float* %VFtab, i64 %idxprom155
  %34 = load float* %arrayidx156, align 4, !tbaa !3
  %mul157 = fmul float %sub114, %34
  %add158590 = or i32 %mul116, 7
  %idxprom159 = sext i32 %add158590 to i64
  %arrayidx160 = getelementptr inbounds float* %VFtab, i64 %idxprom159
  %35 = load float* %arrayidx160, align 4, !tbaa !3
  %mul161 = fmul float %mul115, %35
  %add162 = fadd float %33, %mul157
  %add163 = fadd float %add162, %mul161
  %mul164 = fmul float %sub114, %add163
  %add165 = fadd float %32, %mul164
  %add166 = fadd float %mul157, %add163
  %mul167 = fmul float %mul161, 2.000000e+00
  %add168 = fadd float %mul167, %add166
  %mul169 = fmul float %27, %add165
  %mul170 = fmul float %27, %add168
  %add171 = fadd float %vnbtot.0601, %mul146
  %add172 = fadd float %add171, %mul169
  %arrayidx174 = getelementptr inbounds float* %charge, i64 %idxprom117
  %36 = load float* %arrayidx174, align 4, !tbaa !3
  %mul175 = fmul float %mul, %36
  %mul176 = fmul float %conv100, %mul175
  %mul177 = fmul float %conv100, %mul176
  %add178 = fadd float %mul147, %mul170
  %mul179 = fmul float %add178, %tabscale
  %sub180 = fsub float %mul177, %mul179
  %mul181 = fmul float %conv100, %sub180
  %add182 = fadd float %vctot.0602, %mul176
  %mul183 = fmul float %sub, %mul181
  %mul184 = fmul float %sub77, %mul181
  %mul185 = fmul float %sub78, %mul181
  %add186 = fadd float %fix1.0600, %mul183
  %add187 = fadd float %fiy1.0599, %mul184
  %add188 = fadd float %fiz1.0598, %mul185
  %arrayidx190 = getelementptr inbounds float* %faction, i64 %idxprom69
  %37 = load float* %arrayidx190, align 4, !tbaa !3
  %sub191 = fsub float %37, %mul183
  %arrayidx194 = getelementptr inbounds float* %faction, i64 %idxprom72
  %38 = load float* %arrayidx194, align 4, !tbaa !3
  %sub195 = fsub float %38, %mul184
  %arrayidx198 = getelementptr inbounds float* %faction, i64 %idxprom75
  %39 = load float* %arrayidx198, align 4, !tbaa !3
  %sub199 = fsub float %39, %mul185
  %mul200 = fmul float %conv104, %conv104
  %mul203 = fmul float %mul4, %36
  %mul204 = fmul float %conv104, %mul203
  %mul205 = fmul float %mul200, %mul204
  %add206 = fadd float %mul204, %add182
  %mul207 = fmul float %sub84, %mul205
  %mul208 = fmul float %sub85, %mul205
  %mul209 = fmul float %sub86, %mul205
  %add210 = fadd float %fix2.0597, %mul207
  %add211 = fadd float %fiy2.0596, %mul208
  %add212 = fadd float %fiz2.0595, %mul209
  %sub213 = fsub float %sub191, %mul207
  %sub214 = fsub float %sub195, %mul208
  %sub215 = fsub float %sub199, %mul209
  %mul216 = fmul float %conv108, %conv108
  %mul220 = fmul float %conv108, %mul203
  %mul221 = fmul float %mul216, %mul220
  %add222 = fadd float %mul220, %add206
  %mul223 = fmul float %sub92, %mul221
  %mul224 = fmul float %sub93, %mul221
  %mul225 = fmul float %sub94, %mul221
  %add226 = fadd float %fix3.0594, %mul223
  %add227 = fadd float %fiy3.0593, %mul224
  %add228 = fadd float %fiz3.0592, %mul225
  %sub229 = fsub float %sub213, %mul223
  store float %sub229, float* %arrayidx190, align 4, !tbaa !3
  %sub232 = fsub float %sub214, %mul224
  store float %sub232, float* %arrayidx194, align 4, !tbaa !3
  %sub236 = fsub float %sub215, %mul225
  store float %sub236, float* %arrayidx198, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %40 = trunc i64 %indvars.iv.next to i32
  %cmp64 = icmp slt i32 %40, %10
  br i1 %cmp64, label %for.body65, label %for.end

for.end:                                          ; preds = %for.body65, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add222, %for.body65 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add172, %for.body65 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add186, %for.body65 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add187, %for.body65 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add188, %for.body65 ]
  %fix2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add210, %for.body65 ]
  %fiy2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add211, %for.body65 ]
  %fiz2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add212, %for.body65 ]
  %fix3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add226, %for.body65 ]
  %fiy3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add227, %for.body65 ]
  %fiz3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add228, %for.body65 ]
  %arrayidx241 = getelementptr inbounds float* %faction, i64 %idxprom28
  %41 = load float* %arrayidx241, align 4, !tbaa !3
  %add242 = fadd float %fix1.0.lcssa, %41
  store float %add242, float* %arrayidx241, align 4, !tbaa !3
  %arrayidx247 = getelementptr inbounds float* %faction, i64 %idxprom32
  %42 = load float* %arrayidx247, align 4, !tbaa !3
  %add248 = fadd float %fiy1.0.lcssa, %42
  store float %add248, float* %arrayidx247, align 4, !tbaa !3
  %arrayidx254 = getelementptr inbounds float* %faction, i64 %idxprom36
  %43 = load float* %arrayidx254, align 4, !tbaa !3
  %add255 = fadd float %fiz1.0.lcssa, %43
  store float %add255, float* %arrayidx254, align 4, !tbaa !3
  %arrayidx261 = getelementptr inbounds float* %faction, i64 %idxprom40
  %44 = load float* %arrayidx261, align 4, !tbaa !3
  %add262 = fadd float %fix2.0.lcssa, %44
  store float %add262, float* %arrayidx261, align 4, !tbaa !3
  %arrayidx268 = getelementptr inbounds float* %faction, i64 %idxprom44
  %45 = load float* %arrayidx268, align 4, !tbaa !3
  %add269 = fadd float %fiy2.0.lcssa, %45
  store float %add269, float* %arrayidx268, align 4, !tbaa !3
  %arrayidx275 = getelementptr inbounds float* %faction, i64 %idxprom48
  %46 = load float* %arrayidx275, align 4, !tbaa !3
  %add276 = fadd float %fiz2.0.lcssa, %46
  store float %add276, float* %arrayidx275, align 4, !tbaa !3
  %arrayidx282 = getelementptr inbounds float* %faction, i64 %idxprom52
  %47 = load float* %arrayidx282, align 4, !tbaa !3
  %add283 = fadd float %fix3.0.lcssa, %47
  store float %add283, float* %arrayidx282, align 4, !tbaa !3
  %arrayidx289 = getelementptr inbounds float* %faction, i64 %idxprom56
  %48 = load float* %arrayidx289, align 4, !tbaa !3
  %add290 = fadd float %fiy3.0.lcssa, %48
  store float %add290, float* %arrayidx289, align 4, !tbaa !3
  %arrayidx296 = getelementptr inbounds float* %faction, i64 %idxprom60
  %49 = load float* %arrayidx296, align 4, !tbaa !3
  %add297 = fadd float %fiz3.0.lcssa, %49
  store float %add297, float* %arrayidx296, align 4, !tbaa !3
  %arrayidx302 = getelementptr inbounds float* %fshift, i64 %idxprom12
  %50 = load float* %arrayidx302, align 4, !tbaa !3
  %add303 = fadd float %fix1.0.lcssa, %50
  %add304 = fadd float %fix2.0.lcssa, %add303
  %add305 = fadd float %fix3.0.lcssa, %add304
  store float %add305, float* %arrayidx302, align 4, !tbaa !3
  %arrayidx310 = getelementptr inbounds float* %fshift, i64 %idxprom15
  %51 = load float* %arrayidx310, align 4, !tbaa !3
  %add311 = fadd float %fiy1.0.lcssa, %51
  %add312 = fadd float %fiy2.0.lcssa, %add311
  %add313 = fadd float %fiy3.0.lcssa, %add312
  store float %add313, float* %arrayidx310, align 4, !tbaa !3
  %arrayidx319 = getelementptr inbounds float* %fshift, i64 %idxprom18
  %52 = load float* %arrayidx319, align 4, !tbaa !3
  %add320 = fadd float %fiz1.0.lcssa, %52
  %add321 = fadd float %fiz2.0.lcssa, %add320
  %add322 = fadd float %fiz3.0.lcssa, %add321
  store float %add322, float* %arrayidx319, align 4, !tbaa !3
  %arrayidx327 = getelementptr inbounds i32* %gid, i64 %indvars.iv616
  %53 = load i32* %arrayidx327, align 4, !tbaa !0
  %idxprom328 = sext i32 %53 to i64
  %arrayidx329 = getelementptr inbounds float* %Vc, i64 %idxprom328
  %54 = load float* %arrayidx329, align 4, !tbaa !3
  %add330 = fadd float %vctot.0.lcssa, %54
  store float %add330, float* %arrayidx329, align 4, !tbaa !3
  %arrayidx334 = getelementptr inbounds float* %Vnb, i64 %idxprom328
  %55 = load float* %arrayidx334, align 4, !tbaa !3
  %add335 = fadd float %vnbtot.0.lcssa, %55
  store float %add335, float* %arrayidx334, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next617 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end340, label %for.end.for.body_crit_edge

for.end.for.body_crit_edge:                       ; preds = %for.end
  %arrayidx21.phi.trans.insert = getelementptr inbounds i32* %iinr, i64 %indvars.iv.next617
  %.pre = load i32* %arrayidx21.phi.trans.insert, align 4, !tbaa !0
  br label %for.body

for.end340:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl1330(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab) #0 {
entry:
  %0 = load i32* %iinr, align 4, !tbaa !0
  %idxprom = sext i32 %0 to i64
  %arrayidx1 = getelementptr inbounds float* %charge, i64 %idxprom
  %1 = load float* %arrayidx1, align 4, !tbaa !3
  %add = add nsw i32 %0, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds float* %charge, i64 %idxprom2
  %2 = load float* %arrayidx3, align 4, !tbaa !3
  %mul = fmul float %1, %facel
  %mul4 = fmul float %1, %mul
  %mul6 = fmul float %mul, %2
  %mul7 = fmul float %2, %facel
  %mul8 = fmul float %2, %mul7
  %mul9 = shl i32 %ntype, 1
  %arrayidx11 = getelementptr inbounds i32* %type, i64 %idxprom
  %3 = load i32* %arrayidx11, align 4, !tbaa !0
  %mul12 = mul nsw i32 %mul9, %3
  %mul15 = shl nsw i32 %3, 1
  %add16 = add nsw i32 %mul12, %mul15
  %idxprom17 = sext i32 %add16 to i64
  %arrayidx18 = getelementptr inbounds float* %nbfp, i64 %idxprom17
  %4 = load float* %arrayidx18, align 4, !tbaa !3
  %add19968 = or i32 %add16, 1
  %idxprom20 = sext i32 %add19968 to i64
  %arrayidx21 = getelementptr inbounds float* %nbfp, i64 %idxprom20
  %5 = load float* %arrayidx21, align 4, !tbaa !3
  %cmp999 = icmp sgt i32 %nri, 0
  br i1 %cmp999, label %for.body, label %for.end539

for.body:                                         ; preds = %entry, %for.end.for.body_crit_edge
  %6 = phi i32 [ %.pre, %for.end.for.body_crit_edge ], [ %0, %entry ]
  %indvars.iv1001 = phi i64 [ %indvars.iv.next1002, %for.end.for.body_crit_edge ], [ 0, %entry ]
  %arrayidx23 = getelementptr inbounds i32* %shift, i64 %indvars.iv1001
  %7 = load i32* %arrayidx23, align 4, !tbaa !0
  %mul24 = mul nsw i32 %7, 3
  %idxprom25 = sext i32 %mul24 to i64
  %arrayidx26 = getelementptr inbounds float* %shiftvec, i64 %idxprom25
  %8 = load float* %arrayidx26, align 4, !tbaa !3
  %add27 = add nsw i32 %mul24, 1
  %idxprom28 = sext i32 %add27 to i64
  %arrayidx29 = getelementptr inbounds float* %shiftvec, i64 %idxprom28
  %9 = load float* %arrayidx29, align 4, !tbaa !3
  %add30 = add nsw i32 %mul24, 2
  %idxprom31 = sext i32 %add30 to i64
  %arrayidx32 = getelementptr inbounds float* %shiftvec, i64 %idxprom31
  %10 = load float* %arrayidx32, align 4, !tbaa !3
  %mul35 = mul nsw i32 %6, 3
  %arrayidx37 = getelementptr inbounds i32* %jindex, i64 %indvars.iv1001
  %11 = load i32* %arrayidx37, align 4, !tbaa !0
  %indvars.iv.next1002 = add i64 %indvars.iv1001, 1
  %arrayidx40 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next1002
  %12 = load i32* %arrayidx40, align 4, !tbaa !0
  %idxprom41 = sext i32 %mul35 to i64
  %arrayidx42 = getelementptr inbounds float* %pos, i64 %idxprom41
  %13 = load float* %arrayidx42, align 4, !tbaa !3
  %add43 = fadd float %8, %13
  %add44 = add nsw i32 %mul35, 1
  %idxprom45 = sext i32 %add44 to i64
  %arrayidx46 = getelementptr inbounds float* %pos, i64 %idxprom45
  %14 = load float* %arrayidx46, align 4, !tbaa !3
  %add47 = fadd float %9, %14
  %add48 = add nsw i32 %mul35, 2
  %idxprom49 = sext i32 %add48 to i64
  %arrayidx50 = getelementptr inbounds float* %pos, i64 %idxprom49
  %15 = load float* %arrayidx50, align 4, !tbaa !3
  %add51 = fadd float %10, %15
  %add52 = add nsw i32 %mul35, 3
  %idxprom53 = sext i32 %add52 to i64
  %arrayidx54 = getelementptr inbounds float* %pos, i64 %idxprom53
  %16 = load float* %arrayidx54, align 4, !tbaa !3
  %add55 = fadd float %8, %16
  %add56 = add nsw i32 %mul35, 4
  %idxprom57 = sext i32 %add56 to i64
  %arrayidx58 = getelementptr inbounds float* %pos, i64 %idxprom57
  %17 = load float* %arrayidx58, align 4, !tbaa !3
  %add59 = fadd float %9, %17
  %add60 = add nsw i32 %mul35, 5
  %idxprom61 = sext i32 %add60 to i64
  %arrayidx62 = getelementptr inbounds float* %pos, i64 %idxprom61
  %18 = load float* %arrayidx62, align 4, !tbaa !3
  %add63 = fadd float %10, %18
  %add64 = add nsw i32 %mul35, 6
  %idxprom65 = sext i32 %add64 to i64
  %arrayidx66 = getelementptr inbounds float* %pos, i64 %idxprom65
  %19 = load float* %arrayidx66, align 4, !tbaa !3
  %add67 = fadd float %8, %19
  %add68 = add nsw i32 %mul35, 7
  %idxprom69 = sext i32 %add68 to i64
  %arrayidx70 = getelementptr inbounds float* %pos, i64 %idxprom69
  %20 = load float* %arrayidx70, align 4, !tbaa !3
  %add71 = fadd float %9, %20
  %add72 = add nsw i32 %mul35, 8
  %idxprom73 = sext i32 %add72 to i64
  %arrayidx74 = getelementptr inbounds float* %pos, i64 %idxprom73
  %21 = load float* %arrayidx74, align 4, !tbaa !3
  %add75 = fadd float %10, %21
  %cmp77976 = icmp slt i32 %11, %12
  br i1 %cmp77976, label %for.body78.lr.ph, label %for.end

for.body78.lr.ph:                                 ; preds = %for.body
  %22 = sext i32 %11 to i64
  br label %for.body78

for.body78:                                       ; preds = %for.body78.lr.ph, %for.body78
  %indvars.iv = phi i64 [ %22, %for.body78.lr.ph ], [ %indvars.iv.next, %for.body78 ]
  %vctot.0987 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add420, %for.body78 ]
  %vnbtot.0986 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add266, %for.body78 ]
  %fix1.0985 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add320, %for.body78 ]
  %fiy1.0984 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add321, %for.body78 ]
  %fiz1.0983 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add322, %for.body78 ]
  %fix2.0982 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add368, %for.body78 ]
  %fiy2.0981 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add369, %for.body78 ]
  %fiz2.0980 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add370, %for.body78 ]
  %fix3.0979 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add424, %for.body78 ]
  %fiy3.0978 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add425, %for.body78 ]
  %fiz3.0977 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add426, %for.body78 ]
  %arrayidx80 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %23 = load i32* %arrayidx80, align 4, !tbaa !0
  %mul81 = mul nsw i32 %23, 3
  %idxprom82 = sext i32 %mul81 to i64
  %arrayidx83 = getelementptr inbounds float* %pos, i64 %idxprom82
  %24 = load float* %arrayidx83, align 4, !tbaa !3
  %add84 = add nsw i32 %mul81, 1
  %idxprom85 = sext i32 %add84 to i64
  %arrayidx86 = getelementptr inbounds float* %pos, i64 %idxprom85
  %25 = load float* %arrayidx86, align 4, !tbaa !3
  %add87 = add nsw i32 %mul81, 2
  %idxprom88 = sext i32 %add87 to i64
  %arrayidx89 = getelementptr inbounds float* %pos, i64 %idxprom88
  %26 = load float* %arrayidx89, align 4, !tbaa !3
  %add90 = add nsw i32 %mul81, 3
  %idxprom91 = sext i32 %add90 to i64
  %arrayidx92 = getelementptr inbounds float* %pos, i64 %idxprom91
  %27 = load float* %arrayidx92, align 4, !tbaa !3
  %add93 = add nsw i32 %mul81, 4
  %idxprom94 = sext i32 %add93 to i64
  %arrayidx95 = getelementptr inbounds float* %pos, i64 %idxprom94
  %28 = load float* %arrayidx95, align 4, !tbaa !3
  %add96 = add nsw i32 %mul81, 5
  %idxprom97 = sext i32 %add96 to i64
  %arrayidx98 = getelementptr inbounds float* %pos, i64 %idxprom97
  %29 = load float* %arrayidx98, align 4, !tbaa !3
  %add99 = add nsw i32 %mul81, 6
  %idxprom100 = sext i32 %add99 to i64
  %arrayidx101 = getelementptr inbounds float* %pos, i64 %idxprom100
  %30 = load float* %arrayidx101, align 4, !tbaa !3
  %add102 = add nsw i32 %mul81, 7
  %idxprom103 = sext i32 %add102 to i64
  %arrayidx104 = getelementptr inbounds float* %pos, i64 %idxprom103
  %31 = load float* %arrayidx104, align 4, !tbaa !3
  %add105 = add nsw i32 %mul81, 8
  %idxprom106 = sext i32 %add105 to i64
  %arrayidx107 = getelementptr inbounds float* %pos, i64 %idxprom106
  %32 = load float* %arrayidx107, align 4, !tbaa !3
  %sub = fsub float %add43, %24
  %sub108 = fsub float %add47, %25
  %sub109 = fsub float %add51, %26
  %mul110 = fmul float %sub, %sub
  %mul111 = fmul float %sub108, %sub108
  %add112 = fadd float %mul110, %mul111
  %mul113 = fmul float %sub109, %sub109
  %add114 = fadd float %add112, %mul113
  %sub115 = fsub float %add43, %27
  %sub116 = fsub float %add47, %28
  %sub117 = fsub float %add51, %29
  %mul118 = fmul float %sub115, %sub115
  %mul119 = fmul float %sub116, %sub116
  %add120 = fadd float %mul118, %mul119
  %mul121 = fmul float %sub117, %sub117
  %add122 = fadd float %add120, %mul121
  %sub123 = fsub float %add43, %30
  %sub124 = fsub float %add47, %31
  %sub125 = fsub float %add51, %32
  %mul126 = fmul float %sub123, %sub123
  %mul127 = fmul float %sub124, %sub124
  %add128 = fadd float %mul126, %mul127
  %mul129 = fmul float %sub125, %sub125
  %add130 = fadd float %add128, %mul129
  %sub131 = fsub float %add55, %24
  %sub132 = fsub float %add59, %25
  %sub133 = fsub float %add63, %26
  %mul134 = fmul float %sub131, %sub131
  %mul135 = fmul float %sub132, %sub132
  %add136 = fadd float %mul134, %mul135
  %mul137 = fmul float %sub133, %sub133
  %add138 = fadd float %add136, %mul137
  %sub139 = fsub float %add55, %27
  %sub140 = fsub float %add59, %28
  %sub141 = fsub float %add63, %29
  %mul142 = fmul float %sub139, %sub139
  %mul143 = fmul float %sub140, %sub140
  %add144 = fadd float %mul142, %mul143
  %mul145 = fmul float %sub141, %sub141
  %add146 = fadd float %add144, %mul145
  %sub147 = fsub float %add55, %30
  %sub148 = fsub float %add59, %31
  %sub149 = fsub float %add63, %32
  %mul150 = fmul float %sub147, %sub147
  %mul151 = fmul float %sub148, %sub148
  %add152 = fadd float %mul150, %mul151
  %mul153 = fmul float %sub149, %sub149
  %add154 = fadd float %add152, %mul153
  %sub155 = fsub float %add67, %24
  %sub156 = fsub float %add71, %25
  %sub157 = fsub float %add75, %26
  %mul158 = fmul float %sub155, %sub155
  %mul159 = fmul float %sub156, %sub156
  %add160 = fadd float %mul158, %mul159
  %mul161 = fmul float %sub157, %sub157
  %add162 = fadd float %add160, %mul161
  %sub163 = fsub float %add67, %27
  %sub164 = fsub float %add71, %28
  %sub165 = fsub float %add75, %29
  %mul166 = fmul float %sub163, %sub163
  %mul167 = fmul float %sub164, %sub164
  %add168 = fadd float %mul166, %mul167
  %mul169 = fmul float %sub165, %sub165
  %add170 = fadd float %add168, %mul169
  %sub171 = fsub float %add67, %30
  %sub172 = fsub float %add71, %31
  %sub173 = fsub float %add75, %32
  %mul174 = fmul float %sub171, %sub171
  %mul175 = fmul float %sub172, %sub172
  %add176 = fadd float %mul174, %mul175
  %mul177 = fmul float %sub173, %sub173
  %add178 = fadd float %add176, %mul177
  %conv = fpext float %add114 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv179 = fptrunc double %div to float
  %conv180 = fpext float %add138 to double
  %call181 = tail call double @sqrt(double %conv180) #2
  %div182 = fdiv double 1.000000e+00, %call181
  %conv183 = fptrunc double %div182 to float
  %conv184 = fpext float %add162 to double
  %call185 = tail call double @sqrt(double %conv184) #2
  %div186 = fdiv double 1.000000e+00, %call185
  %conv187 = fptrunc double %div186 to float
  %conv188 = fpext float %add122 to double
  %call189 = tail call double @sqrt(double %conv188) #2
  %div190 = fdiv double 1.000000e+00, %call189
  %conv191 = fptrunc double %div190 to float
  %conv192 = fpext float %add146 to double
  %call193 = tail call double @sqrt(double %conv192) #2
  %div194 = fdiv double 1.000000e+00, %call193
  %conv195 = fptrunc double %div194 to float
  %conv196 = fpext float %add170 to double
  %call197 = tail call double @sqrt(double %conv196) #2
  %div198 = fdiv double 1.000000e+00, %call197
  %conv199 = fptrunc double %div198 to float
  %conv200 = fpext float %add130 to double
  %call201 = tail call double @sqrt(double %conv200) #2
  %div202 = fdiv double 1.000000e+00, %call201
  %conv203 = fptrunc double %div202 to float
  %conv204 = fpext float %add154 to double
  %call205 = tail call double @sqrt(double %conv204) #2
  %div206 = fdiv double 1.000000e+00, %call205
  %conv207 = fptrunc double %div206 to float
  %conv208 = fpext float %add178 to double
  %call209 = tail call double @sqrt(double %conv208) #2
  %div210 = fdiv double 1.000000e+00, %call209
  %conv211 = fptrunc double %div210 to float
  %mul212 = fmul float %add114, %conv179
  %mul214 = fmul float %mul212, %tabscale
  %conv215 = fptosi float %mul214 to i32
  %conv216 = sitofp i32 %conv215 to float
  %sub217 = fsub float %mul214, %conv216
  %mul218 = fmul float %sub217, %sub217
  %mul219 = shl nsw i32 %conv215, 3
  %idxprom220 = sext i32 %mul219 to i64
  %arrayidx221 = getelementptr inbounds float* %VFtab, i64 %idxprom220
  %33 = load float* %arrayidx221, align 4, !tbaa !3
  %add222969 = or i32 %mul219, 1
  %idxprom223 = sext i32 %add222969 to i64
  %arrayidx224 = getelementptr inbounds float* %VFtab, i64 %idxprom223
  %34 = load float* %arrayidx224, align 4, !tbaa !3
  %add225970 = or i32 %mul219, 2
  %idxprom226 = sext i32 %add225970 to i64
  %arrayidx227 = getelementptr inbounds float* %VFtab, i64 %idxprom226
  %35 = load float* %arrayidx227, align 4, !tbaa !3
  %mul228 = fmul float %sub217, %35
  %add229971 = or i32 %mul219, 3
  %idxprom230 = sext i32 %add229971 to i64
  %arrayidx231 = getelementptr inbounds float* %VFtab, i64 %idxprom230
  %36 = load float* %arrayidx231, align 4, !tbaa !3
  %mul232 = fmul float %mul218, %36
  %add233 = fadd float %34, %mul228
  %add234 = fadd float %add233, %mul232
  %mul235 = fmul float %sub217, %add234
  %add236 = fadd float %33, %mul235
  %add237 = fadd float %mul228, %add234
  %mul238 = fmul float %mul232, 2.000000e+00
  %add239 = fadd float %mul238, %add237
  %mul240 = fmul float %4, %add236
  %mul241 = fmul float %4, %add239
  %add242972 = or i32 %mul219, 4
  %idxprom243 = sext i32 %add242972 to i64
  %arrayidx244 = getelementptr inbounds float* %VFtab, i64 %idxprom243
  %37 = load float* %arrayidx244, align 4, !tbaa !3
  %add245973 = or i32 %mul219, 5
  %idxprom246 = sext i32 %add245973 to i64
  %arrayidx247 = getelementptr inbounds float* %VFtab, i64 %idxprom246
  %38 = load float* %arrayidx247, align 4, !tbaa !3
  %add248974 = or i32 %mul219, 6
  %idxprom249 = sext i32 %add248974 to i64
  %arrayidx250 = getelementptr inbounds float* %VFtab, i64 %idxprom249
  %39 = load float* %arrayidx250, align 4, !tbaa !3
  %mul251 = fmul float %sub217, %39
  %add252975 = or i32 %mul219, 7
  %idxprom253 = sext i32 %add252975 to i64
  %arrayidx254 = getelementptr inbounds float* %VFtab, i64 %idxprom253
  %40 = load float* %arrayidx254, align 4, !tbaa !3
  %mul255 = fmul float %mul218, %40
  %add256 = fadd float %38, %mul251
  %add257 = fadd float %add256, %mul255
  %mul258 = fmul float %sub217, %add257
  %add259 = fadd float %37, %mul258
  %add260 = fadd float %mul251, %add257
  %mul261 = fmul float %mul255, 2.000000e+00
  %add262 = fadd float %mul261, %add260
  %mul263 = fmul float %5, %add259
  %mul264 = fmul float %5, %add262
  %add265 = fadd float %vnbtot.0986, %mul240
  %add266 = fadd float %add265, %mul263
  %mul267 = fmul float %mul4, %conv179
  %mul268 = fmul float %conv179, %mul267
  %add269 = fadd float %mul241, %mul264
  %mul270 = fmul float %add269, %tabscale
  %sub271 = fsub float %mul268, %mul270
  %mul272 = fmul float %conv179, %sub271
  %add273 = fadd float %vctot.0987, %mul267
  %mul274 = fmul float %sub, %mul272
  %mul275 = fmul float %sub108, %mul272
  %mul276 = fmul float %sub109, %mul272
  %add277 = fadd float %fix1.0985, %mul274
  %add278 = fadd float %fiy1.0984, %mul275
  %add279 = fadd float %fiz1.0983, %mul276
  %arrayidx281 = getelementptr inbounds float* %faction, i64 %idxprom82
  %41 = load float* %arrayidx281, align 4, !tbaa !3
  %sub282 = fsub float %41, %mul274
  %arrayidx285 = getelementptr inbounds float* %faction, i64 %idxprom85
  %42 = load float* %arrayidx285, align 4, !tbaa !3
  %sub286 = fsub float %42, %mul275
  %arrayidx289 = getelementptr inbounds float* %faction, i64 %idxprom88
  %43 = load float* %arrayidx289, align 4, !tbaa !3
  %sub290 = fsub float %43, %mul276
  %mul291 = fmul float %conv191, %conv191
  %mul292 = fmul float %mul6, %conv191
  %mul293 = fmul float %mul292, %mul291
  %add294 = fadd float %add273, %mul292
  %mul295 = fmul float %sub115, %mul293
  %mul296 = fmul float %sub116, %mul293
  %mul297 = fmul float %sub117, %mul293
  %add298 = fadd float %mul295, %add277
  %add299 = fadd float %mul296, %add278
  %add300 = fadd float %mul297, %add279
  %arrayidx303 = getelementptr inbounds float* %faction, i64 %idxprom91
  %44 = load float* %arrayidx303, align 4, !tbaa !3
  %sub304 = fsub float %44, %mul295
  %arrayidx307 = getelementptr inbounds float* %faction, i64 %idxprom94
  %45 = load float* %arrayidx307, align 4, !tbaa !3
  %sub308 = fsub float %45, %mul296
  %arrayidx311 = getelementptr inbounds float* %faction, i64 %idxprom97
  %46 = load float* %arrayidx311, align 4, !tbaa !3
  %sub312 = fsub float %46, %mul297
  %mul313 = fmul float %conv203, %conv203
  %mul314 = fmul float %mul6, %conv203
  %mul315 = fmul float %mul314, %mul313
  %add316 = fadd float %add294, %mul314
  %mul317 = fmul float %sub123, %mul315
  %mul318 = fmul float %sub124, %mul315
  %mul319 = fmul float %sub125, %mul315
  %add320 = fadd float %mul317, %add298
  %add321 = fadd float %mul318, %add299
  %add322 = fadd float %mul319, %add300
  %arrayidx325 = getelementptr inbounds float* %faction, i64 %idxprom100
  %47 = load float* %arrayidx325, align 4, !tbaa !3
  %sub326 = fsub float %47, %mul317
  %arrayidx329 = getelementptr inbounds float* %faction, i64 %idxprom103
  %48 = load float* %arrayidx329, align 4, !tbaa !3
  %sub330 = fsub float %48, %mul318
  %arrayidx333 = getelementptr inbounds float* %faction, i64 %idxprom106
  %49 = load float* %arrayidx333, align 4, !tbaa !3
  %sub334 = fsub float %49, %mul319
  %mul335 = fmul float %conv183, %conv183
  %mul336 = fmul float %mul6, %conv183
  %mul337 = fmul float %mul336, %mul335
  %add338 = fadd float %mul336, %add316
  %mul339 = fmul float %sub131, %mul337
  %mul340 = fmul float %sub132, %mul337
  %mul341 = fmul float %sub133, %mul337
  %add342 = fadd float %fix2.0982, %mul339
  %add343 = fadd float %fiy2.0981, %mul340
  %add344 = fadd float %fiz2.0980, %mul341
  %sub345 = fsub float %sub282, %mul339
  %sub346 = fsub float %sub286, %mul340
  %sub347 = fsub float %sub290, %mul341
  %mul348 = fmul float %conv195, %conv195
  %mul349 = fmul float %mul8, %conv195
  %mul350 = fmul float %mul349, %mul348
  %add351 = fadd float %mul349, %add338
  %mul352 = fmul float %sub139, %mul350
  %mul353 = fmul float %sub140, %mul350
  %mul354 = fmul float %sub141, %mul350
  %add355 = fadd float %add342, %mul352
  %add356 = fadd float %add343, %mul353
  %add357 = fadd float %add344, %mul354
  %sub358 = fsub float %sub304, %mul352
  %sub359 = fsub float %sub308, %mul353
  %sub360 = fsub float %sub312, %mul354
  %mul361 = fmul float %conv207, %conv207
  %mul362 = fmul float %mul8, %conv207
  %mul363 = fmul float %mul362, %mul361
  %add364 = fadd float %mul362, %add351
  %mul365 = fmul float %sub147, %mul363
  %mul366 = fmul float %sub148, %mul363
  %mul367 = fmul float %sub149, %mul363
  %add368 = fadd float %add355, %mul365
  %add369 = fadd float %add356, %mul366
  %add370 = fadd float %add357, %mul367
  %sub371 = fsub float %sub326, %mul365
  %sub372 = fsub float %sub330, %mul366
  %sub373 = fsub float %sub334, %mul367
  %mul374 = fmul float %conv187, %conv187
  %mul375 = fmul float %mul6, %conv187
  %mul376 = fmul float %mul375, %mul374
  %add377 = fadd float %mul375, %add364
  %mul378 = fmul float %sub155, %mul376
  %mul379 = fmul float %sub156, %mul376
  %mul380 = fmul float %sub157, %mul376
  %add381 = fadd float %fix3.0979, %mul378
  %add382 = fadd float %fiy3.0978, %mul379
  %add383 = fadd float %fiz3.0977, %mul380
  %sub384 = fsub float %sub345, %mul378
  store float %sub384, float* %arrayidx281, align 4, !tbaa !3
  %sub387 = fsub float %sub346, %mul379
  store float %sub387, float* %arrayidx285, align 4, !tbaa !3
  %sub391 = fsub float %sub347, %mul380
  store float %sub391, float* %arrayidx289, align 4, !tbaa !3
  %mul395 = fmul float %conv199, %conv199
  %mul396 = fmul float %mul8, %conv199
  %mul397 = fmul float %mul396, %mul395
  %add398 = fadd float %mul396, %add377
  %mul399 = fmul float %sub163, %mul397
  %mul400 = fmul float %sub164, %mul397
  %mul401 = fmul float %sub165, %mul397
  %add402 = fadd float %add381, %mul399
  %add403 = fadd float %add382, %mul400
  %add404 = fadd float %add383, %mul401
  %sub405 = fsub float %sub358, %mul399
  store float %sub405, float* %arrayidx303, align 4, !tbaa !3
  %sub409 = fsub float %sub359, %mul400
  store float %sub409, float* %arrayidx307, align 4, !tbaa !3
  %sub413 = fsub float %sub360, %mul401
  store float %sub413, float* %arrayidx311, align 4, !tbaa !3
  %mul417 = fmul float %conv211, %conv211
  %mul418 = fmul float %mul8, %conv211
  %mul419 = fmul float %mul418, %mul417
  %add420 = fadd float %mul418, %add398
  %mul421 = fmul float %sub171, %mul419
  %mul422 = fmul float %sub172, %mul419
  %mul423 = fmul float %sub173, %mul419
  %add424 = fadd float %add402, %mul421
  %add425 = fadd float %add403, %mul422
  %add426 = fadd float %add404, %mul423
  %sub427 = fsub float %sub371, %mul421
  store float %sub427, float* %arrayidx325, align 4, !tbaa !3
  %sub431 = fsub float %sub372, %mul422
  store float %sub431, float* %arrayidx329, align 4, !tbaa !3
  %sub435 = fsub float %sub373, %mul423
  store float %sub435, float* %arrayidx333, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %50 = trunc i64 %indvars.iv.next to i32
  %cmp77 = icmp slt i32 %50, %12
  br i1 %cmp77, label %for.body78, label %for.end

for.end:                                          ; preds = %for.body78, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add420, %for.body78 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add266, %for.body78 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add320, %for.body78 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add321, %for.body78 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add322, %for.body78 ]
  %fix2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add368, %for.body78 ]
  %fiy2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add369, %for.body78 ]
  %fiz2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add370, %for.body78 ]
  %fix3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add424, %for.body78 ]
  %fiy3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add425, %for.body78 ]
  %fiz3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add426, %for.body78 ]
  %arrayidx440 = getelementptr inbounds float* %faction, i64 %idxprom41
  %51 = load float* %arrayidx440, align 4, !tbaa !3
  %add441 = fadd float %fix1.0.lcssa, %51
  store float %add441, float* %arrayidx440, align 4, !tbaa !3
  %arrayidx446 = getelementptr inbounds float* %faction, i64 %idxprom45
  %52 = load float* %arrayidx446, align 4, !tbaa !3
  %add447 = fadd float %fiy1.0.lcssa, %52
  store float %add447, float* %arrayidx446, align 4, !tbaa !3
  %arrayidx453 = getelementptr inbounds float* %faction, i64 %idxprom49
  %53 = load float* %arrayidx453, align 4, !tbaa !3
  %add454 = fadd float %fiz1.0.lcssa, %53
  store float %add454, float* %arrayidx453, align 4, !tbaa !3
  %arrayidx460 = getelementptr inbounds float* %faction, i64 %idxprom53
  %54 = load float* %arrayidx460, align 4, !tbaa !3
  %add461 = fadd float %fix2.0.lcssa, %54
  store float %add461, float* %arrayidx460, align 4, !tbaa !3
  %arrayidx467 = getelementptr inbounds float* %faction, i64 %idxprom57
  %55 = load float* %arrayidx467, align 4, !tbaa !3
  %add468 = fadd float %fiy2.0.lcssa, %55
  store float %add468, float* %arrayidx467, align 4, !tbaa !3
  %arrayidx474 = getelementptr inbounds float* %faction, i64 %idxprom61
  %56 = load float* %arrayidx474, align 4, !tbaa !3
  %add475 = fadd float %fiz2.0.lcssa, %56
  store float %add475, float* %arrayidx474, align 4, !tbaa !3
  %arrayidx481 = getelementptr inbounds float* %faction, i64 %idxprom65
  %57 = load float* %arrayidx481, align 4, !tbaa !3
  %add482 = fadd float %fix3.0.lcssa, %57
  store float %add482, float* %arrayidx481, align 4, !tbaa !3
  %arrayidx488 = getelementptr inbounds float* %faction, i64 %idxprom69
  %58 = load float* %arrayidx488, align 4, !tbaa !3
  %add489 = fadd float %fiy3.0.lcssa, %58
  store float %add489, float* %arrayidx488, align 4, !tbaa !3
  %arrayidx495 = getelementptr inbounds float* %faction, i64 %idxprom73
  %59 = load float* %arrayidx495, align 4, !tbaa !3
  %add496 = fadd float %fiz3.0.lcssa, %59
  store float %add496, float* %arrayidx495, align 4, !tbaa !3
  %arrayidx501 = getelementptr inbounds float* %fshift, i64 %idxprom25
  %60 = load float* %arrayidx501, align 4, !tbaa !3
  %add502 = fadd float %fix1.0.lcssa, %60
  %add503 = fadd float %fix2.0.lcssa, %add502
  %add504 = fadd float %fix3.0.lcssa, %add503
  store float %add504, float* %arrayidx501, align 4, !tbaa !3
  %arrayidx509 = getelementptr inbounds float* %fshift, i64 %idxprom28
  %61 = load float* %arrayidx509, align 4, !tbaa !3
  %add510 = fadd float %fiy1.0.lcssa, %61
  %add511 = fadd float %fiy2.0.lcssa, %add510
  %add512 = fadd float %fiy3.0.lcssa, %add511
  store float %add512, float* %arrayidx509, align 4, !tbaa !3
  %arrayidx518 = getelementptr inbounds float* %fshift, i64 %idxprom31
  %62 = load float* %arrayidx518, align 4, !tbaa !3
  %add519 = fadd float %fiz1.0.lcssa, %62
  %add520 = fadd float %fiz2.0.lcssa, %add519
  %add521 = fadd float %fiz3.0.lcssa, %add520
  store float %add521, float* %arrayidx518, align 4, !tbaa !3
  %arrayidx526 = getelementptr inbounds i32* %gid, i64 %indvars.iv1001
  %63 = load i32* %arrayidx526, align 4, !tbaa !0
  %idxprom527 = sext i32 %63 to i64
  %arrayidx528 = getelementptr inbounds float* %Vc, i64 %idxprom527
  %64 = load float* %arrayidx528, align 4, !tbaa !3
  %add529 = fadd float %vctot.0.lcssa, %64
  store float %add529, float* %arrayidx528, align 4, !tbaa !3
  %arrayidx533 = getelementptr inbounds float* %Vnb, i64 %idxprom527
  %65 = load float* %arrayidx533, align 4, !tbaa !3
  %add534 = fadd float %vnbtot.0.lcssa, %65
  store float %add534, float* %arrayidx533, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next1002 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end539, label %for.end.for.body_crit_edge

for.end.for.body_crit_edge:                       ; preds = %for.end
  %arrayidx34.phi.trans.insert = getelementptr inbounds i32* %iinr, i64 %indvars.iv.next1002
  %.pre = load i32* %arrayidx34.phi.trans.insert, align 4, !tbaa !0
  br label %for.body

for.end539:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl1400(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab, float %exptabscale) #0 {
entry:
  %cmp384 = icmp sgt i32 %nri, 0
  br i1 %cmp384, label %for.body, label %for.end219

for.body:                                         ; preds = %for.end, %entry
  %indvars.iv386 = phi i64 [ 0, %entry ], [ %indvars.iv.next387, %for.end ]
  %arrayidx = getelementptr inbounds i32* %shift, i64 %indvars.iv386
  %0 = load i32* %arrayidx, align 4, !tbaa !0
  %mul = mul nsw i32 %0, 3
  %idxprom1 = sext i32 %mul to i64
  %arrayidx2 = getelementptr inbounds float* %shiftvec, i64 %idxprom1
  %1 = load float* %arrayidx2, align 4, !tbaa !3
  %add = add nsw i32 %mul, 1
  %idxprom3 = sext i32 %add to i64
  %arrayidx4 = getelementptr inbounds float* %shiftvec, i64 %idxprom3
  %2 = load float* %arrayidx4, align 4, !tbaa !3
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds float* %shiftvec, i64 %idxprom6
  %3 = load float* %arrayidx7, align 4, !tbaa !3
  %arrayidx9 = getelementptr inbounds i32* %iinr, i64 %indvars.iv386
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %arrayidx12 = getelementptr inbounds i32* %jindex, i64 %indvars.iv386
  %5 = load i32* %arrayidx12, align 4, !tbaa !0
  %indvars.iv.next387 = add i64 %indvars.iv386, 1
  %arrayidx15 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next387
  %6 = load i32* %arrayidx15, align 4, !tbaa !0
  %idxprom16 = sext i32 %mul10 to i64
  %arrayidx17 = getelementptr inbounds float* %pos, i64 %idxprom16
  %7 = load float* %arrayidx17, align 4, !tbaa !3
  %add18 = fadd float %1, %7
  %add19 = add nsw i32 %mul10, 1
  %idxprom20 = sext i32 %add19 to i64
  %arrayidx21 = getelementptr inbounds float* %pos, i64 %idxprom20
  %8 = load float* %arrayidx21, align 4, !tbaa !3
  %add22 = fadd float %2, %8
  %add23 = add nsw i32 %mul10, 2
  %idxprom24 = sext i32 %add23 to i64
  %arrayidx25 = getelementptr inbounds float* %pos, i64 %idxprom24
  %9 = load float* %arrayidx25, align 4, !tbaa !3
  %add26 = fadd float %3, %9
  %idxprom27 = sext i32 %4 to i64
  %arrayidx28 = getelementptr inbounds float* %charge, i64 %idxprom27
  %10 = load float* %arrayidx28, align 4, !tbaa !3
  %mul29 = fmul float %10, %facel
  %arrayidx32 = getelementptr inbounds i32* %type, i64 %idxprom27
  %11 = load i32* %arrayidx32, align 4, !tbaa !0
  %mul33 = mul i32 %11, %ntype
  %cmp35373 = icmp slt i32 %5, %6
  br i1 %cmp35373, label %for.body36.lr.ph, label %for.end

for.body36.lr.ph:                                 ; preds = %for.body
  %12 = sext i32 %5 to i64
  br label %for.body36

for.body36:                                       ; preds = %for.body36.lr.ph, %for.body36
  %indvars.iv = phi i64 [ %12, %for.body36.lr.ph ], [ %indvars.iv.next, %for.body36 ]
  %vctot.0378 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add141, %for.body36 ]
  %vnbtot.0377 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add130, %for.body36 ]
  %fix1.0376 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add145, %for.body36 ]
  %fiy1.0375 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add146, %for.body36 ]
  %fiz1.0374 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add147, %for.body36 ]
  %arrayidx38 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %13 = load i32* %arrayidx38, align 4, !tbaa !0
  %mul39 = mul nsw i32 %13, 3
  %idxprom40 = sext i32 %mul39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %14 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = add nsw i32 %mul39, 1
  %idxprom43 = sext i32 %add42 to i64
  %arrayidx44 = getelementptr inbounds float* %pos, i64 %idxprom43
  %15 = load float* %arrayidx44, align 4, !tbaa !3
  %add45 = add nsw i32 %mul39, 2
  %idxprom46 = sext i32 %add45 to i64
  %arrayidx47 = getelementptr inbounds float* %pos, i64 %idxprom46
  %16 = load float* %arrayidx47, align 4, !tbaa !3
  %sub = fsub float %add18, %14
  %sub48 = fsub float %add22, %15
  %sub49 = fsub float %add26, %16
  %mul50 = fmul float %sub, %sub
  %mul51 = fmul float %sub48, %sub48
  %add52 = fadd float %mul50, %mul51
  %mul53 = fmul float %sub49, %sub49
  %add54 = fadd float %add52, %mul53
  %conv = fpext float %add54 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv55 = fptrunc double %div to float
  %mul56 = fmul float %add54, %conv55
  %mul58 = fmul float %mul56, %tabscale
  %conv59 = fptosi float %mul58 to i32
  %conv60 = sitofp i32 %conv59 to float
  %sub61 = fsub float %mul58, %conv60
  %mul62 = fmul float %sub61, %sub61
  %mul63 = shl nsw i32 %conv59, 3
  %idxprom64 = sext i32 %13 to i64
  %arrayidx65 = getelementptr inbounds i32* %type, i64 %idxprom64
  %17 = load i32* %arrayidx65, align 4, !tbaa !0
  %tmp = add i32 %17, %mul33
  %tmp372 = mul i32 %tmp, 3
  %idxprom68 = sext i32 %tmp372 to i64
  %arrayidx69 = getelementptr inbounds float* %nbfp, i64 %idxprom68
  %18 = load float* %arrayidx69, align 4, !tbaa !3
  %add70 = add nsw i32 %tmp372, 1
  %idxprom71 = sext i32 %add70 to i64
  %arrayidx72 = getelementptr inbounds float* %nbfp, i64 %idxprom71
  %19 = load float* %arrayidx72, align 4, !tbaa !3
  %add73 = add nsw i32 %tmp372, 2
  %idxprom74 = sext i32 %add73 to i64
  %arrayidx75 = getelementptr inbounds float* %nbfp, i64 %idxprom74
  %20 = load float* %arrayidx75, align 4, !tbaa !3
  %idxprom76 = sext i32 %mul63 to i64
  %arrayidx77 = getelementptr inbounds float* %VFtab, i64 %idxprom76
  %21 = load float* %arrayidx77, align 4, !tbaa !3
  %add78365 = or i32 %mul63, 1
  %idxprom79 = sext i32 %add78365 to i64
  %arrayidx80 = getelementptr inbounds float* %VFtab, i64 %idxprom79
  %22 = load float* %arrayidx80, align 4, !tbaa !3
  %add81366 = or i32 %mul63, 2
  %idxprom82 = sext i32 %add81366 to i64
  %arrayidx83 = getelementptr inbounds float* %VFtab, i64 %idxprom82
  %23 = load float* %arrayidx83, align 4, !tbaa !3
  %mul84 = fmul float %sub61, %23
  %add85367 = or i32 %mul63, 3
  %idxprom86 = sext i32 %add85367 to i64
  %arrayidx87 = getelementptr inbounds float* %VFtab, i64 %idxprom86
  %24 = load float* %arrayidx87, align 4, !tbaa !3
  %mul88 = fmul float %mul62, %24
  %add89 = fadd float %22, %mul84
  %add90 = fadd float %add89, %mul88
  %mul91 = fmul float %sub61, %add90
  %add92 = fadd float %21, %mul91
  %add93 = fadd float %mul84, %add90
  %mul94 = fmul float %mul88, 2.000000e+00
  %add95 = fadd float %mul94, %add93
  %mul96 = fmul float %18, %add92
  %mul97 = fmul float %18, %add95
  %mul98 = fmul float %mul56, %20
  %mul99 = fmul float %mul98, %exptabscale
  %conv100 = fptosi float %mul99 to i32
  %conv101 = sitofp i32 %conv100 to float
  %sub102 = fsub float %mul99, %conv101
  %mul103 = fmul float %sub102, %sub102
  %mul104 = shl nsw i32 %conv100, 3
  %add105368 = or i32 %mul104, 4
  %idxprom106 = sext i32 %add105368 to i64
  %arrayidx107 = getelementptr inbounds float* %VFtab, i64 %idxprom106
  %25 = load float* %arrayidx107, align 4, !tbaa !3
  %add108369 = or i32 %mul104, 5
  %idxprom109 = sext i32 %add108369 to i64
  %arrayidx110 = getelementptr inbounds float* %VFtab, i64 %idxprom109
  %26 = load float* %arrayidx110, align 4, !tbaa !3
  %add111370 = or i32 %mul104, 6
  %idxprom112 = sext i32 %add111370 to i64
  %arrayidx113 = getelementptr inbounds float* %VFtab, i64 %idxprom112
  %27 = load float* %arrayidx113, align 4, !tbaa !3
  %mul114 = fmul float %sub102, %27
  %add115371 = or i32 %mul104, 7
  %idxprom116 = sext i32 %add115371 to i64
  %arrayidx117 = getelementptr inbounds float* %VFtab, i64 %idxprom116
  %28 = load float* %arrayidx117, align 4, !tbaa !3
  %mul118 = fmul float %mul103, %28
  %add119 = fadd float %26, %mul114
  %add120 = fadd float %add119, %mul118
  %mul121 = fmul float %sub102, %add120
  %add122 = fadd float %25, %mul121
  %add123 = fadd float %mul114, %add120
  %mul124 = fmul float %mul118, 2.000000e+00
  %add125 = fadd float %mul124, %add123
  %mul126 = fmul float %19, %add122
  %mul127 = fmul float %19, %20
  %mul128 = fmul float %mul127, %add125
  %add129 = fadd float %vnbtot.0377, %mul96
  %add130 = fadd float %add129, %mul126
  %arrayidx132 = getelementptr inbounds float* %charge, i64 %idxprom64
  %29 = load float* %arrayidx132, align 4, !tbaa !3
  %mul133 = fmul float %mul29, %29
  %mul134 = fmul float %conv55, %mul133
  %mul135 = fmul float %conv55, %mul134
  %mul136 = fmul float %mul97, %tabscale
  %mul137 = fmul float %mul128, %exptabscale
  %add138 = fadd float %mul136, %mul137
  %sub139 = fsub float %mul135, %add138
  %mul140 = fmul float %conv55, %sub139
  %add141 = fadd float %vctot.0378, %mul134
  %mul142 = fmul float %sub, %mul140
  %mul143 = fmul float %sub48, %mul140
  %mul144 = fmul float %sub49, %mul140
  %add145 = fadd float %fix1.0376, %mul142
  %add146 = fadd float %fiy1.0375, %mul143
  %add147 = fadd float %fiz1.0374, %mul144
  %arrayidx149 = getelementptr inbounds float* %faction, i64 %idxprom40
  %30 = load float* %arrayidx149, align 4, !tbaa !3
  %sub150 = fsub float %30, %mul142
  store float %sub150, float* %arrayidx149, align 4, !tbaa !3
  %arrayidx155 = getelementptr inbounds float* %faction, i64 %idxprom43
  %31 = load float* %arrayidx155, align 4, !tbaa !3
  %sub156 = fsub float %31, %mul143
  store float %sub156, float* %arrayidx155, align 4, !tbaa !3
  %arrayidx162 = getelementptr inbounds float* %faction, i64 %idxprom46
  %32 = load float* %arrayidx162, align 4, !tbaa !3
  %sub163 = fsub float %32, %mul144
  store float %sub163, float* %arrayidx162, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %33 = trunc i64 %indvars.iv.next to i32
  %cmp35 = icmp slt i32 %33, %6
  br i1 %cmp35, label %for.body36, label %for.end

for.end:                                          ; preds = %for.body36, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add141, %for.body36 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add130, %for.body36 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add145, %for.body36 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add146, %for.body36 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add147, %for.body36 ]
  %arrayidx168 = getelementptr inbounds float* %faction, i64 %idxprom16
  %34 = load float* %arrayidx168, align 4, !tbaa !3
  %add169 = fadd float %fix1.0.lcssa, %34
  store float %add169, float* %arrayidx168, align 4, !tbaa !3
  %arrayidx174 = getelementptr inbounds float* %faction, i64 %idxprom20
  %35 = load float* %arrayidx174, align 4, !tbaa !3
  %add175 = fadd float %fiy1.0.lcssa, %35
  store float %add175, float* %arrayidx174, align 4, !tbaa !3
  %arrayidx181 = getelementptr inbounds float* %faction, i64 %idxprom24
  %36 = load float* %arrayidx181, align 4, !tbaa !3
  %add182 = fadd float %fiz1.0.lcssa, %36
  store float %add182, float* %arrayidx181, align 4, !tbaa !3
  %arrayidx187 = getelementptr inbounds float* %fshift, i64 %idxprom1
  %37 = load float* %arrayidx187, align 4, !tbaa !3
  %add188 = fadd float %fix1.0.lcssa, %37
  store float %add188, float* %arrayidx187, align 4, !tbaa !3
  %arrayidx193 = getelementptr inbounds float* %fshift, i64 %idxprom3
  %38 = load float* %arrayidx193, align 4, !tbaa !3
  %add194 = fadd float %fiy1.0.lcssa, %38
  store float %add194, float* %arrayidx193, align 4, !tbaa !3
  %arrayidx200 = getelementptr inbounds float* %fshift, i64 %idxprom6
  %39 = load float* %arrayidx200, align 4, !tbaa !3
  %add201 = fadd float %fiz1.0.lcssa, %39
  store float %add201, float* %arrayidx200, align 4, !tbaa !3
  %arrayidx206 = getelementptr inbounds i32* %gid, i64 %indvars.iv386
  %40 = load i32* %arrayidx206, align 4, !tbaa !0
  %idxprom207 = sext i32 %40 to i64
  %arrayidx208 = getelementptr inbounds float* %Vc, i64 %idxprom207
  %41 = load float* %arrayidx208, align 4, !tbaa !3
  %add209 = fadd float %vctot.0.lcssa, %41
  store float %add209, float* %arrayidx208, align 4, !tbaa !3
  %arrayidx213 = getelementptr inbounds float* %Vnb, i64 %idxprom207
  %42 = load float* %arrayidx213, align 4, !tbaa !3
  %add214 = fadd float %vnbtot.0.lcssa, %42
  store float %add214, float* %arrayidx213, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next387 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end219, label %for.body

for.end219:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl1410(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab, float %exptabscale, i32* nocapture %nsatoms) #0 {
entry:
  %cmp1081 = icmp sgt i32 %nri, 0
  br i1 %cmp1081, label %for.body, label %for.end558

for.body:                                         ; preds = %for.end543, %entry
  %indvars.iv1107 = phi i64 [ 0, %entry ], [ %indvars.iv.next1108, %for.end543 ]
  %0 = trunc i64 %indvars.iv1107 to i32
  %mul = mul nsw i32 %0, 3
  %idxprom = sext i32 %mul to i64
  %arrayidx = getelementptr inbounds i32* %nsatoms, i64 %idxprom
  %1 = load i32* %arrayidx, align 4, !tbaa !0
  %add = add nsw i32 %mul, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds i32* %nsatoms, i64 %idxprom2
  %2 = load i32* %arrayidx3, align 4, !tbaa !0
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds i32* %nsatoms, i64 %idxprom6
  %3 = load i32* %arrayidx7, align 4, !tbaa !0
  %arrayidx9 = getelementptr inbounds i32* %shift, i64 %indvars.iv1107
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %idxprom11 = sext i32 %mul10 to i64
  %arrayidx12 = getelementptr inbounds float* %shiftvec, i64 %idxprom11
  %5 = load float* %arrayidx12, align 4, !tbaa !3
  %add13 = add nsw i32 %mul10, 1
  %idxprom14 = sext i32 %add13 to i64
  %arrayidx15 = getelementptr inbounds float* %shiftvec, i64 %idxprom14
  %6 = load float* %arrayidx15, align 4, !tbaa !3
  %add16 = add nsw i32 %mul10, 2
  %idxprom17 = sext i32 %add16 to i64
  %arrayidx18 = getelementptr inbounds float* %shiftvec, i64 %idxprom17
  %7 = load float* %arrayidx18, align 4, !tbaa !3
  %arrayidx20 = getelementptr inbounds i32* %iinr, i64 %indvars.iv1107
  %8 = load i32* %arrayidx20, align 4, !tbaa !0
  %mul21 = mul i32 %8, 3
  %arrayidx23 = getelementptr inbounds i32* %jindex, i64 %indvars.iv1107
  %9 = load i32* %arrayidx23, align 4, !tbaa !0
  %indvars.iv.next1108 = add i64 %indvars.iv1107, 1
  %arrayidx26 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next1108
  %10 = load i32* %arrayidx26, align 4, !tbaa !0
  %cmp281037 = icmp sgt i32 %2, 0
  br i1 %cmp281037, label %for.body29.lr.ph, label %for.cond224.loopexit

for.body29.lr.ph:                                 ; preds = %for.body
  %cmp491026 = icmp slt i32 %9, %10
  %arrayidx201 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx207 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx214 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %11 = sext i32 %9 to i64
  %12 = sext i32 %8 to i64
  %13 = sext i32 %mul21 to i64
  %14 = add i32 %2, %8
  %15 = mul i32 %14, 3
  br label %for.body29

for.body29:                                       ; preds = %for.end, %for.body29.lr.ph
  %indvars.iv1085 = phi i64 [ %13, %for.body29.lr.ph ], [ %indvars.iv.next1086, %for.end ]
  %indvars.iv1083 = phi i64 [ %12, %for.body29.lr.ph ], [ %indvars.iv.next1084, %for.end ]
  %s.01040 = phi i32 [ 0, %for.body29.lr.ph ], [ %inc222, %for.end ]
  %vnbtot.01039 = phi float [ 0.000000e+00, %for.body29.lr.ph ], [ %vnbtot.1.lcssa, %for.end ]
  %vctot.01038 = phi float [ 0.000000e+00, %for.body29.lr.ph ], [ %vctot.1.lcssa, %for.end ]
  %arrayidx31 = getelementptr inbounds float* %pos, i64 %indvars.iv1085
  %16 = load float* %arrayidx31, align 4, !tbaa !3
  %add32 = fadd float %5, %16
  %17 = add nsw i64 %indvars.iv1085, 1
  %arrayidx35 = getelementptr inbounds float* %pos, i64 %17
  %18 = load float* %arrayidx35, align 4, !tbaa !3
  %add36 = fadd float %6, %18
  %19 = add nsw i64 %indvars.iv1085, 2
  %arrayidx39 = getelementptr inbounds float* %pos, i64 %19
  %20 = load float* %arrayidx39, align 4, !tbaa !3
  %add40 = fadd float %7, %20
  %arrayidx42 = getelementptr inbounds float* %charge, i64 %indvars.iv1083
  %21 = load float* %arrayidx42, align 4, !tbaa !3
  %mul43 = fmul float %21, %facel
  %arrayidx46 = getelementptr inbounds i32* %type, i64 %indvars.iv1083
  %22 = load i32* %arrayidx46, align 4, !tbaa !0
  %mul47 = mul i32 %22, %ntype
  br i1 %cmp491026, label %for.body50, label %for.end

for.body50:                                       ; preds = %for.body29, %for.body50
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body50 ], [ %11, %for.body29 ]
  %fiz1.01031 = phi float [ %add161, %for.body50 ], [ 0.000000e+00, %for.body29 ]
  %fiy1.01030 = phi float [ %add160, %for.body50 ], [ 0.000000e+00, %for.body29 ]
  %fix1.01029 = phi float [ %add159, %for.body50 ], [ 0.000000e+00, %for.body29 ]
  %vnbtot.11028 = phi float [ %add144, %for.body50 ], [ %vnbtot.01039, %for.body29 ]
  %vctot.11027 = phi float [ %add155, %for.body50 ], [ %vctot.01038, %for.body29 ]
  %arrayidx52 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %23 = load i32* %arrayidx52, align 4, !tbaa !0
  %mul53 = mul nsw i32 %23, 3
  %idxprom54 = sext i32 %mul53 to i64
  %arrayidx55 = getelementptr inbounds float* %pos, i64 %idxprom54
  %24 = load float* %arrayidx55, align 4, !tbaa !3
  %add56 = add nsw i32 %mul53, 1
  %idxprom57 = sext i32 %add56 to i64
  %arrayidx58 = getelementptr inbounds float* %pos, i64 %idxprom57
  %25 = load float* %arrayidx58, align 4, !tbaa !3
  %add59 = add nsw i32 %mul53, 2
  %idxprom60 = sext i32 %add59 to i64
  %arrayidx61 = getelementptr inbounds float* %pos, i64 %idxprom60
  %26 = load float* %arrayidx61, align 4, !tbaa !3
  %sub = fsub float %add32, %24
  %sub62 = fsub float %add36, %25
  %sub63 = fsub float %add40, %26
  %mul64 = fmul float %sub, %sub
  %mul65 = fmul float %sub62, %sub62
  %add66 = fadd float %mul64, %mul65
  %mul67 = fmul float %sub63, %sub63
  %add68 = fadd float %add66, %mul67
  %conv = fpext float %add68 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv69 = fptrunc double %div to float
  %mul70 = fmul float %add68, %conv69
  %mul72 = fmul float %mul70, %tabscale
  %conv73 = fptosi float %mul72 to i32
  %conv74 = sitofp i32 %conv73 to float
  %sub75 = fsub float %mul72, %conv74
  %mul76 = fmul float %sub75, %sub75
  %mul77 = shl nsw i32 %conv73, 3
  %idxprom78 = sext i32 %23 to i64
  %arrayidx79 = getelementptr inbounds i32* %type, i64 %idxprom78
  %27 = load i32* %arrayidx79, align 4, !tbaa !0
  %tmp = add i32 %27, %mul47
  %tmp1023 = mul i32 %tmp, 3
  %idxprom82 = sext i32 %tmp1023 to i64
  %arrayidx83 = getelementptr inbounds float* %nbfp, i64 %idxprom82
  %28 = load float* %arrayidx83, align 4, !tbaa !3
  %add84 = add nsw i32 %tmp1023, 1
  %idxprom85 = sext i32 %add84 to i64
  %arrayidx86 = getelementptr inbounds float* %nbfp, i64 %idxprom85
  %29 = load float* %arrayidx86, align 4, !tbaa !3
  %add87 = add nsw i32 %tmp1023, 2
  %idxprom88 = sext i32 %add87 to i64
  %arrayidx89 = getelementptr inbounds float* %nbfp, i64 %idxprom88
  %30 = load float* %arrayidx89, align 4, !tbaa !3
  %idxprom90 = sext i32 %mul77 to i64
  %arrayidx91 = getelementptr inbounds float* %VFtab, i64 %idxprom90
  %31 = load float* %arrayidx91, align 4, !tbaa !3
  %add921016 = or i32 %mul77, 1
  %idxprom93 = sext i32 %add921016 to i64
  %arrayidx94 = getelementptr inbounds float* %VFtab, i64 %idxprom93
  %32 = load float* %arrayidx94, align 4, !tbaa !3
  %add951017 = or i32 %mul77, 2
  %idxprom96 = sext i32 %add951017 to i64
  %arrayidx97 = getelementptr inbounds float* %VFtab, i64 %idxprom96
  %33 = load float* %arrayidx97, align 4, !tbaa !3
  %mul98 = fmul float %sub75, %33
  %add991018 = or i32 %mul77, 3
  %idxprom100 = sext i32 %add991018 to i64
  %arrayidx101 = getelementptr inbounds float* %VFtab, i64 %idxprom100
  %34 = load float* %arrayidx101, align 4, !tbaa !3
  %mul102 = fmul float %mul76, %34
  %add103 = fadd float %32, %mul98
  %add104 = fadd float %add103, %mul102
  %mul105 = fmul float %sub75, %add104
  %add106 = fadd float %31, %mul105
  %add107 = fadd float %mul98, %add104
  %mul108 = fmul float %mul102, 2.000000e+00
  %add109 = fadd float %mul108, %add107
  %mul110 = fmul float %28, %add106
  %mul111 = fmul float %28, %add109
  %mul112 = fmul float %mul70, %30
  %mul113 = fmul float %mul112, %exptabscale
  %conv114 = fptosi float %mul113 to i32
  %conv115 = sitofp i32 %conv114 to float
  %sub116 = fsub float %mul113, %conv115
  %mul117 = fmul float %sub116, %sub116
  %mul118 = shl nsw i32 %conv114, 3
  %add1191019 = or i32 %mul118, 4
  %idxprom120 = sext i32 %add1191019 to i64
  %arrayidx121 = getelementptr inbounds float* %VFtab, i64 %idxprom120
  %35 = load float* %arrayidx121, align 4, !tbaa !3
  %add1221020 = or i32 %mul118, 5
  %idxprom123 = sext i32 %add1221020 to i64
  %arrayidx124 = getelementptr inbounds float* %VFtab, i64 %idxprom123
  %36 = load float* %arrayidx124, align 4, !tbaa !3
  %add1251021 = or i32 %mul118, 6
  %idxprom126 = sext i32 %add1251021 to i64
  %arrayidx127 = getelementptr inbounds float* %VFtab, i64 %idxprom126
  %37 = load float* %arrayidx127, align 4, !tbaa !3
  %mul128 = fmul float %sub116, %37
  %add1291022 = or i32 %mul118, 7
  %idxprom130 = sext i32 %add1291022 to i64
  %arrayidx131 = getelementptr inbounds float* %VFtab, i64 %idxprom130
  %38 = load float* %arrayidx131, align 4, !tbaa !3
  %mul132 = fmul float %mul117, %38
  %add133 = fadd float %36, %mul128
  %add134 = fadd float %add133, %mul132
  %mul135 = fmul float %sub116, %add134
  %add136 = fadd float %35, %mul135
  %add137 = fadd float %mul128, %add134
  %mul138 = fmul float %mul132, 2.000000e+00
  %add139 = fadd float %mul138, %add137
  %mul140 = fmul float %29, %add136
  %mul141 = fmul float %29, %30
  %mul142 = fmul float %mul141, %add139
  %add143 = fadd float %vnbtot.11028, %mul110
  %add144 = fadd float %add143, %mul140
  %arrayidx146 = getelementptr inbounds float* %charge, i64 %idxprom78
  %39 = load float* %arrayidx146, align 4, !tbaa !3
  %mul147 = fmul float %mul43, %39
  %mul148 = fmul float %conv69, %mul147
  %mul149 = fmul float %conv69, %mul148
  %mul150 = fmul float %mul111, %tabscale
  %mul151 = fmul float %mul142, %exptabscale
  %add152 = fadd float %mul150, %mul151
  %sub153 = fsub float %mul149, %add152
  %mul154 = fmul float %conv69, %sub153
  %add155 = fadd float %vctot.11027, %mul148
  %mul156 = fmul float %sub, %mul154
  %mul157 = fmul float %sub62, %mul154
  %mul158 = fmul float %sub63, %mul154
  %add159 = fadd float %fix1.01029, %mul156
  %add160 = fadd float %fiy1.01030, %mul157
  %add161 = fadd float %fiz1.01031, %mul158
  %arrayidx163 = getelementptr inbounds float* %faction, i64 %idxprom54
  %40 = load float* %arrayidx163, align 4, !tbaa !3
  %sub164 = fsub float %40, %mul156
  store float %sub164, float* %arrayidx163, align 4, !tbaa !3
  %arrayidx169 = getelementptr inbounds float* %faction, i64 %idxprom57
  %41 = load float* %arrayidx169, align 4, !tbaa !3
  %sub170 = fsub float %41, %mul157
  store float %sub170, float* %arrayidx169, align 4, !tbaa !3
  %arrayidx176 = getelementptr inbounds float* %faction, i64 %idxprom60
  %42 = load float* %arrayidx176, align 4, !tbaa !3
  %sub177 = fsub float %42, %mul158
  store float %sub177, float* %arrayidx176, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %43 = trunc i64 %indvars.iv.next to i32
  %cmp49 = icmp slt i32 %43, %10
  br i1 %cmp49, label %for.body50, label %for.end

for.end:                                          ; preds = %for.body50, %for.body29
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add161, %for.body50 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add160, %for.body50 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add159, %for.body50 ]
  %vnbtot.1.lcssa = phi float [ %vnbtot.01039, %for.body29 ], [ %add144, %for.body50 ]
  %vctot.1.lcssa = phi float [ %vctot.01038, %for.body29 ], [ %add155, %for.body50 ]
  %arrayidx182 = getelementptr inbounds float* %faction, i64 %indvars.iv1085
  %44 = load float* %arrayidx182, align 4, !tbaa !3
  %add183 = fadd float %fix1.0.lcssa, %44
  store float %add183, float* %arrayidx182, align 4, !tbaa !3
  %arrayidx188 = getelementptr inbounds float* %faction, i64 %17
  %45 = load float* %arrayidx188, align 4, !tbaa !3
  %add189 = fadd float %fiy1.0.lcssa, %45
  store float %add189, float* %arrayidx188, align 4, !tbaa !3
  %arrayidx195 = getelementptr inbounds float* %faction, i64 %19
  %46 = load float* %arrayidx195, align 4, !tbaa !3
  %add196 = fadd float %fiz1.0.lcssa, %46
  store float %add196, float* %arrayidx195, align 4, !tbaa !3
  %47 = load float* %arrayidx201, align 4, !tbaa !3
  %add202 = fadd float %fix1.0.lcssa, %47
  store float %add202, float* %arrayidx201, align 4, !tbaa !3
  %48 = load float* %arrayidx207, align 4, !tbaa !3
  %add208 = fadd float %fiy1.0.lcssa, %48
  store float %add208, float* %arrayidx207, align 4, !tbaa !3
  %49 = load float* %arrayidx214, align 4, !tbaa !3
  %add215 = fadd float %fiz1.0.lcssa, %49
  store float %add215, float* %arrayidx214, align 4, !tbaa !3
  %indvars.iv.next1084 = add i64 %indvars.iv1083, 1
  %indvars.iv.next1086 = add i64 %indvars.iv1085, 3
  %inc222 = add nsw i32 %s.01040, 1
  %exitcond = icmp eq i32 %inc222, %2
  br i1 %exitcond, label %for.cond27.for.cond224.loopexit_crit_edge, label %for.body29

for.cond27.for.cond224.loopexit_crit_edge:        ; preds = %for.end
  %50 = add i32 %2, %8
  br label %for.cond224.loopexit

for.cond224.loopexit:                             ; preds = %for.cond27.for.cond224.loopexit_crit_edge, %for.body
  %ii.0.lcssa = phi i32 [ %50, %for.cond27.for.cond224.loopexit_crit_edge ], [ %8, %for.body ]
  %ii3.0.lcssa = phi i32 [ %15, %for.cond27.for.cond224.loopexit_crit_edge ], [ %mul21, %for.body ]
  %vnbtot.0.lcssa = phi float [ %vnbtot.1.lcssa, %for.cond27.for.cond224.loopexit_crit_edge ], [ 0.000000e+00, %for.body ]
  %vctot.0.lcssa = phi float [ %vctot.1.lcssa, %for.cond27.for.cond224.loopexit_crit_edge ], [ 0.000000e+00, %for.body ]
  %cmp2251057 = icmp slt i32 %2, %3
  br i1 %cmp2251057, label %for.body227.lr.ph, label %for.cond347.loopexit

for.body227.lr.ph:                                ; preds = %for.cond224.loopexit
  %cmp2431047 = icmp slt i32 %9, %10
  %arrayidx324 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx330 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx337 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %51 = sext i32 %9 to i64
  %52 = sext i32 %ii.0.lcssa to i64
  %53 = sext i32 %ii3.0.lcssa to i64
  %54 = mul i32 %3, 3
  %55 = add i32 %ii.0.lcssa, %3
  br label %for.body227

for.body227:                                      ; preds = %for.end303, %for.body227.lr.ph
  %indvars.iv1093 = phi i64 [ %53, %for.body227.lr.ph ], [ %indvars.iv.next1094, %for.end303 ]
  %indvars.iv1091 = phi i64 [ %52, %for.body227.lr.ph ], [ %indvars.iv.next1092, %for.end303 ]
  %s.11059 = phi i32 [ %2, %for.body227.lr.ph ], [ %inc345, %for.end303 ]
  %vctot.21058 = phi float [ %vctot.0.lcssa, %for.body227.lr.ph ], [ %vctot.3.lcssa, %for.end303 ]
  %arrayidx229 = getelementptr inbounds float* %pos, i64 %indvars.iv1093
  %56 = load float* %arrayidx229, align 4, !tbaa !3
  %add230 = fadd float %5, %56
  %57 = add nsw i64 %indvars.iv1093, 1
  %arrayidx233 = getelementptr inbounds float* %pos, i64 %57
  %58 = load float* %arrayidx233, align 4, !tbaa !3
  %add234 = fadd float %6, %58
  %59 = add nsw i64 %indvars.iv1093, 2
  %arrayidx237 = getelementptr inbounds float* %pos, i64 %59
  %60 = load float* %arrayidx237, align 4, !tbaa !3
  %add238 = fadd float %7, %60
  %arrayidx240 = getelementptr inbounds float* %charge, i64 %indvars.iv1091
  %61 = load float* %arrayidx240, align 4, !tbaa !3
  %mul241 = fmul float %61, %facel
  br i1 %cmp2431047, label %for.body245, label %for.end303

for.body245:                                      ; preds = %for.body227, %for.body245
  %indvars.iv1089 = phi i64 [ %indvars.iv.next1090, %for.body245 ], [ %51, %for.body227 ]
  %fiz1.11051 = phi float [ %add281, %for.body245 ], [ 0.000000e+00, %for.body227 ]
  %fiy1.11050 = phi float [ %add280, %for.body245 ], [ 0.000000e+00, %for.body227 ]
  %fix1.11049 = phi float [ %add279, %for.body245 ], [ 0.000000e+00, %for.body227 ]
  %vctot.31048 = phi float [ %add275, %for.body245 ], [ %vctot.21058, %for.body227 ]
  %arrayidx247 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv1089
  %62 = load i32* %arrayidx247, align 4, !tbaa !0
  %mul248 = mul nsw i32 %62, 3
  %idxprom249 = sext i32 %mul248 to i64
  %arrayidx250 = getelementptr inbounds float* %pos, i64 %idxprom249
  %63 = load float* %arrayidx250, align 4, !tbaa !3
  %add251 = add nsw i32 %mul248, 1
  %idxprom252 = sext i32 %add251 to i64
  %arrayidx253 = getelementptr inbounds float* %pos, i64 %idxprom252
  %64 = load float* %arrayidx253, align 4, !tbaa !3
  %add254 = add nsw i32 %mul248, 2
  %idxprom255 = sext i32 %add254 to i64
  %arrayidx256 = getelementptr inbounds float* %pos, i64 %idxprom255
  %65 = load float* %arrayidx256, align 4, !tbaa !3
  %sub257 = fsub float %add230, %63
  %sub258 = fsub float %add234, %64
  %sub259 = fsub float %add238, %65
  %mul260 = fmul float %sub257, %sub257
  %mul261 = fmul float %sub258, %sub258
  %add262 = fadd float %mul260, %mul261
  %mul263 = fmul float %sub259, %sub259
  %add264 = fadd float %add262, %mul263
  %conv265 = fpext float %add264 to double
  %call266 = tail call double @sqrt(double %conv265) #2
  %div267 = fdiv double 1.000000e+00, %call266
  %conv268 = fptrunc double %div267 to float
  %mul269 = fmul float %conv268, %conv268
  %idxprom270 = sext i32 %62 to i64
  %arrayidx271 = getelementptr inbounds float* %charge, i64 %idxprom270
  %66 = load float* %arrayidx271, align 4, !tbaa !3
  %mul272 = fmul float %mul241, %66
  %mul273 = fmul float %conv268, %mul272
  %mul274 = fmul float %mul269, %mul273
  %add275 = fadd float %vctot.31048, %mul273
  %mul276 = fmul float %sub257, %mul274
  %mul277 = fmul float %sub258, %mul274
  %mul278 = fmul float %sub259, %mul274
  %add279 = fadd float %fix1.11049, %mul276
  %add280 = fadd float %fiy1.11050, %mul277
  %add281 = fadd float %fiz1.11051, %mul278
  %arrayidx283 = getelementptr inbounds float* %faction, i64 %idxprom249
  %67 = load float* %arrayidx283, align 4, !tbaa !3
  %sub284 = fsub float %67, %mul276
  store float %sub284, float* %arrayidx283, align 4, !tbaa !3
  %arrayidx289 = getelementptr inbounds float* %faction, i64 %idxprom252
  %68 = load float* %arrayidx289, align 4, !tbaa !3
  %sub290 = fsub float %68, %mul277
  store float %sub290, float* %arrayidx289, align 4, !tbaa !3
  %arrayidx296 = getelementptr inbounds float* %faction, i64 %idxprom255
  %69 = load float* %arrayidx296, align 4, !tbaa !3
  %sub297 = fsub float %69, %mul278
  store float %sub297, float* %arrayidx296, align 4, !tbaa !3
  %indvars.iv.next1090 = add i64 %indvars.iv1089, 1
  %70 = trunc i64 %indvars.iv.next1090 to i32
  %cmp243 = icmp slt i32 %70, %10
  br i1 %cmp243, label %for.body245, label %for.end303

for.end303:                                       ; preds = %for.body245, %for.body227
  %fiz1.1.lcssa = phi float [ 0.000000e+00, %for.body227 ], [ %add281, %for.body245 ]
  %fiy1.1.lcssa = phi float [ 0.000000e+00, %for.body227 ], [ %add280, %for.body245 ]
  %fix1.1.lcssa = phi float [ 0.000000e+00, %for.body227 ], [ %add279, %for.body245 ]
  %vctot.3.lcssa = phi float [ %vctot.21058, %for.body227 ], [ %add275, %for.body245 ]
  %arrayidx305 = getelementptr inbounds float* %faction, i64 %indvars.iv1093
  %71 = load float* %arrayidx305, align 4, !tbaa !3
  %add306 = fadd float %fix1.1.lcssa, %71
  store float %add306, float* %arrayidx305, align 4, !tbaa !3
  %arrayidx311 = getelementptr inbounds float* %faction, i64 %57
  %72 = load float* %arrayidx311, align 4, !tbaa !3
  %add312 = fadd float %fiy1.1.lcssa, %72
  store float %add312, float* %arrayidx311, align 4, !tbaa !3
  %arrayidx318 = getelementptr inbounds float* %faction, i64 %59
  %73 = load float* %arrayidx318, align 4, !tbaa !3
  %add319 = fadd float %fiz1.1.lcssa, %73
  store float %add319, float* %arrayidx318, align 4, !tbaa !3
  %74 = load float* %arrayidx324, align 4, !tbaa !3
  %add325 = fadd float %fix1.1.lcssa, %74
  store float %add325, float* %arrayidx324, align 4, !tbaa !3
  %75 = load float* %arrayidx330, align 4, !tbaa !3
  %add331 = fadd float %fiy1.1.lcssa, %75
  store float %add331, float* %arrayidx330, align 4, !tbaa !3
  %76 = load float* %arrayidx337, align 4, !tbaa !3
  %add338 = fadd float %fiz1.1.lcssa, %76
  store float %add338, float* %arrayidx337, align 4, !tbaa !3
  %indvars.iv.next1092 = add i64 %indvars.iv1091, 1
  %indvars.iv.next1094 = add i64 %indvars.iv1093, 3
  %inc345 = add nsw i32 %s.11059, 1
  %exitcond1097 = icmp eq i32 %inc345, %3
  br i1 %exitcond1097, label %for.cond224.for.cond347.loopexit_crit_edge, label %for.body227

for.cond224.for.cond347.loopexit_crit_edge:       ; preds = %for.end303
  %77 = add i32 %ii3.0.lcssa, %54
  %78 = mul i32 %2, -3
  %79 = add i32 %77, %78
  %80 = sub i32 %55, %2
  br label %for.cond347.loopexit

for.cond347.loopexit:                             ; preds = %for.cond224.for.cond347.loopexit_crit_edge, %for.cond224.loopexit
  %ii.1.lcssa = phi i32 [ %80, %for.cond224.for.cond347.loopexit_crit_edge ], [ %ii.0.lcssa, %for.cond224.loopexit ]
  %ii3.1.lcssa = phi i32 [ %79, %for.cond224.for.cond347.loopexit_crit_edge ], [ %ii3.0.lcssa, %for.cond224.loopexit ]
  %vctot.2.lcssa = phi float [ %vctot.3.lcssa, %for.cond224.for.cond347.loopexit_crit_edge ], [ %vctot.0.lcssa, %for.cond224.loopexit ]
  %cmp3481075 = icmp slt i32 %3, %1
  br i1 %cmp3481075, label %for.body350.lr.ph, label %for.end543

for.body350.lr.ph:                                ; preds = %for.cond347.loopexit
  %cmp3671065 = icmp slt i32 %9, %10
  %arrayidx521 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx527 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx534 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %81 = sext i32 %9 to i64
  %82 = sext i32 %ii.1.lcssa to i64
  %83 = sext i32 %ii3.1.lcssa to i64
  br label %for.body350

for.body350:                                      ; preds = %for.end500, %for.body350.lr.ph
  %indvars.iv1102 = phi i64 [ %83, %for.body350.lr.ph ], [ %indvars.iv.next1103, %for.end500 ]
  %indvars.iv1100 = phi i64 [ %82, %for.body350.lr.ph ], [ %indvars.iv.next1101, %for.end500 ]
  %s.21077 = phi i32 [ %3, %for.body350.lr.ph ], [ %inc542, %for.end500 ]
  %vnbtot.21076 = phi float [ %vnbtot.0.lcssa, %for.body350.lr.ph ], [ %vnbtot.3.lcssa, %for.end500 ]
  %arrayidx352 = getelementptr inbounds float* %pos, i64 %indvars.iv1102
  %84 = load float* %arrayidx352, align 4, !tbaa !3
  %add353 = fadd float %5, %84
  %85 = add nsw i64 %indvars.iv1102, 1
  %arrayidx356 = getelementptr inbounds float* %pos, i64 %85
  %86 = load float* %arrayidx356, align 4, !tbaa !3
  %add357 = fadd float %6, %86
  %87 = add nsw i64 %indvars.iv1102, 2
  %arrayidx360 = getelementptr inbounds float* %pos, i64 %87
  %88 = load float* %arrayidx360, align 4, !tbaa !3
  %add361 = fadd float %7, %88
  %arrayidx364 = getelementptr inbounds i32* %type, i64 %indvars.iv1100
  %89 = load i32* %arrayidx364, align 4, !tbaa !0
  %mul365 = mul i32 %89, %ntype
  br i1 %cmp3671065, label %for.body369, label %for.end500

for.body369:                                      ; preds = %for.body350, %for.body369
  %indvars.iv1098 = phi i64 [ %indvars.iv.next1099, %for.body369 ], [ %81, %for.body350 ]
  %fiz1.21069 = phi float [ %add478, %for.body369 ], [ 0.000000e+00, %for.body350 ]
  %fiy1.21068 = phi float [ %add477, %for.body369 ], [ 0.000000e+00, %for.body350 ]
  %fix1.21067 = phi float [ %add476, %for.body369 ], [ 0.000000e+00, %for.body350 ]
  %vnbtot.31066 = phi float [ %add467, %for.body369 ], [ %vnbtot.21076, %for.body350 ]
  %arrayidx371 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv1098
  %90 = load i32* %arrayidx371, align 4, !tbaa !0
  %mul372 = mul nsw i32 %90, 3
  %idxprom373 = sext i32 %mul372 to i64
  %arrayidx374 = getelementptr inbounds float* %pos, i64 %idxprom373
  %91 = load float* %arrayidx374, align 4, !tbaa !3
  %add375 = add nsw i32 %mul372, 1
  %idxprom376 = sext i32 %add375 to i64
  %arrayidx377 = getelementptr inbounds float* %pos, i64 %idxprom376
  %92 = load float* %arrayidx377, align 4, !tbaa !3
  %add378 = add nsw i32 %mul372, 2
  %idxprom379 = sext i32 %add378 to i64
  %arrayidx380 = getelementptr inbounds float* %pos, i64 %idxprom379
  %93 = load float* %arrayidx380, align 4, !tbaa !3
  %sub381 = fsub float %add353, %91
  %sub382 = fsub float %add357, %92
  %sub383 = fsub float %add361, %93
  %mul384 = fmul float %sub381, %sub381
  %mul385 = fmul float %sub382, %sub382
  %add386 = fadd float %mul384, %mul385
  %mul387 = fmul float %sub383, %sub383
  %add388 = fadd float %add386, %mul387
  %conv389 = fpext float %add388 to double
  %call390 = tail call double @sqrt(double %conv389) #2
  %div391 = fdiv double 1.000000e+00, %call390
  %conv392 = fptrunc double %div391 to float
  %mul393 = fmul float %add388, %conv392
  %mul395 = fmul float %mul393, %tabscale
  %conv396 = fptosi float %mul395 to i32
  %conv397 = sitofp i32 %conv396 to float
  %sub398 = fsub float %mul395, %conv397
  %mul399 = fmul float %sub398, %sub398
  %mul400 = shl nsw i32 %conv396, 3
  %idxprom401 = sext i32 %90 to i64
  %arrayidx402 = getelementptr inbounds i32* %type, i64 %idxprom401
  %94 = load i32* %arrayidx402, align 4, !tbaa !0
  %tmp1024 = add i32 %94, %mul365
  %tmp1025 = mul i32 %tmp1024, 3
  %idxprom405 = sext i32 %tmp1025 to i64
  %arrayidx406 = getelementptr inbounds float* %nbfp, i64 %idxprom405
  %95 = load float* %arrayidx406, align 4, !tbaa !3
  %add407 = add nsw i32 %tmp1025, 1
  %idxprom408 = sext i32 %add407 to i64
  %arrayidx409 = getelementptr inbounds float* %nbfp, i64 %idxprom408
  %96 = load float* %arrayidx409, align 4, !tbaa !3
  %add410 = add nsw i32 %tmp1025, 2
  %idxprom411 = sext i32 %add410 to i64
  %arrayidx412 = getelementptr inbounds float* %nbfp, i64 %idxprom411
  %97 = load float* %arrayidx412, align 4, !tbaa !3
  %idxprom413 = sext i32 %mul400 to i64
  %arrayidx414 = getelementptr inbounds float* %VFtab, i64 %idxprom413
  %98 = load float* %arrayidx414, align 4, !tbaa !3
  %add4151009 = or i32 %mul400, 1
  %idxprom416 = sext i32 %add4151009 to i64
  %arrayidx417 = getelementptr inbounds float* %VFtab, i64 %idxprom416
  %99 = load float* %arrayidx417, align 4, !tbaa !3
  %add4181010 = or i32 %mul400, 2
  %idxprom419 = sext i32 %add4181010 to i64
  %arrayidx420 = getelementptr inbounds float* %VFtab, i64 %idxprom419
  %100 = load float* %arrayidx420, align 4, !tbaa !3
  %mul421 = fmul float %sub398, %100
  %add4221011 = or i32 %mul400, 3
  %idxprom423 = sext i32 %add4221011 to i64
  %arrayidx424 = getelementptr inbounds float* %VFtab, i64 %idxprom423
  %101 = load float* %arrayidx424, align 4, !tbaa !3
  %mul425 = fmul float %mul399, %101
  %add426 = fadd float %99, %mul421
  %add427 = fadd float %add426, %mul425
  %mul428 = fmul float %sub398, %add427
  %add429 = fadd float %98, %mul428
  %add430 = fadd float %mul421, %add427
  %mul431 = fmul float %mul425, 2.000000e+00
  %add432 = fadd float %mul431, %add430
  %mul433 = fmul float %95, %add429
  %mul434 = fmul float %95, %add432
  %mul435 = fmul float %mul393, %97
  %mul436 = fmul float %mul435, %exptabscale
  %conv437 = fptosi float %mul436 to i32
  %conv438 = sitofp i32 %conv437 to float
  %sub439 = fsub float %mul436, %conv438
  %mul440 = fmul float %sub439, %sub439
  %mul441 = shl nsw i32 %conv437, 3
  %add4421012 = or i32 %mul441, 4
  %idxprom443 = sext i32 %add4421012 to i64
  %arrayidx444 = getelementptr inbounds float* %VFtab, i64 %idxprom443
  %102 = load float* %arrayidx444, align 4, !tbaa !3
  %add4451013 = or i32 %mul441, 5
  %idxprom446 = sext i32 %add4451013 to i64
  %arrayidx447 = getelementptr inbounds float* %VFtab, i64 %idxprom446
  %103 = load float* %arrayidx447, align 4, !tbaa !3
  %add4481014 = or i32 %mul441, 6
  %idxprom449 = sext i32 %add4481014 to i64
  %arrayidx450 = getelementptr inbounds float* %VFtab, i64 %idxprom449
  %104 = load float* %arrayidx450, align 4, !tbaa !3
  %mul451 = fmul float %sub439, %104
  %add4521015 = or i32 %mul441, 7
  %idxprom453 = sext i32 %add4521015 to i64
  %arrayidx454 = getelementptr inbounds float* %VFtab, i64 %idxprom453
  %105 = load float* %arrayidx454, align 4, !tbaa !3
  %mul455 = fmul float %mul440, %105
  %add456 = fadd float %103, %mul451
  %add457 = fadd float %add456, %mul455
  %mul458 = fmul float %sub439, %add457
  %add459 = fadd float %102, %mul458
  %add460 = fadd float %mul451, %add457
  %mul461 = fmul float %mul455, 2.000000e+00
  %add462 = fadd float %mul461, %add460
  %mul463 = fmul float %96, %add459
  %mul464 = fmul float %96, %97
  %mul465 = fmul float %mul464, %add462
  %add466 = fadd float %vnbtot.31066, %mul433
  %add467 = fadd float %add466, %mul463
  %mul468 = fmul float %mul434, %tabscale
  %mul469 = fmul float %mul465, %exptabscale
  %add470 = fadd float %mul468, %mul469
  %106 = fmul float %conv392, %add470
  %mul472 = fsub float -0.000000e+00, %106
  %mul473 = fmul float %sub381, %mul472
  %mul474 = fmul float %sub382, %mul472
  %mul475 = fmul float %sub383, %mul472
  %add476 = fadd float %fix1.21067, %mul473
  %add477 = fadd float %fiy1.21068, %mul474
  %add478 = fadd float %fiz1.21069, %mul475
  %arrayidx480 = getelementptr inbounds float* %faction, i64 %idxprom373
  %107 = load float* %arrayidx480, align 4, !tbaa !3
  %sub481 = fsub float %107, %mul473
  store float %sub481, float* %arrayidx480, align 4, !tbaa !3
  %arrayidx486 = getelementptr inbounds float* %faction, i64 %idxprom376
  %108 = load float* %arrayidx486, align 4, !tbaa !3
  %sub487 = fsub float %108, %mul474
  store float %sub487, float* %arrayidx486, align 4, !tbaa !3
  %arrayidx493 = getelementptr inbounds float* %faction, i64 %idxprom379
  %109 = load float* %arrayidx493, align 4, !tbaa !3
  %sub494 = fsub float %109, %mul475
  store float %sub494, float* %arrayidx493, align 4, !tbaa !3
  %indvars.iv.next1099 = add i64 %indvars.iv1098, 1
  %110 = trunc i64 %indvars.iv.next1099 to i32
  %cmp367 = icmp slt i32 %110, %10
  br i1 %cmp367, label %for.body369, label %for.end500

for.end500:                                       ; preds = %for.body369, %for.body350
  %fiz1.2.lcssa = phi float [ 0.000000e+00, %for.body350 ], [ %add478, %for.body369 ]
  %fiy1.2.lcssa = phi float [ 0.000000e+00, %for.body350 ], [ %add477, %for.body369 ]
  %fix1.2.lcssa = phi float [ 0.000000e+00, %for.body350 ], [ %add476, %for.body369 ]
  %vnbtot.3.lcssa = phi float [ %vnbtot.21076, %for.body350 ], [ %add467, %for.body369 ]
  %arrayidx502 = getelementptr inbounds float* %faction, i64 %indvars.iv1102
  %111 = load float* %arrayidx502, align 4, !tbaa !3
  %add503 = fadd float %fix1.2.lcssa, %111
  store float %add503, float* %arrayidx502, align 4, !tbaa !3
  %arrayidx508 = getelementptr inbounds float* %faction, i64 %85
  %112 = load float* %arrayidx508, align 4, !tbaa !3
  %add509 = fadd float %fiy1.2.lcssa, %112
  store float %add509, float* %arrayidx508, align 4, !tbaa !3
  %arrayidx515 = getelementptr inbounds float* %faction, i64 %87
  %113 = load float* %arrayidx515, align 4, !tbaa !3
  %add516 = fadd float %fiz1.2.lcssa, %113
  store float %add516, float* %arrayidx515, align 4, !tbaa !3
  %114 = load float* %arrayidx521, align 4, !tbaa !3
  %add522 = fadd float %fix1.2.lcssa, %114
  store float %add522, float* %arrayidx521, align 4, !tbaa !3
  %115 = load float* %arrayidx527, align 4, !tbaa !3
  %add528 = fadd float %fiy1.2.lcssa, %115
  store float %add528, float* %arrayidx527, align 4, !tbaa !3
  %116 = load float* %arrayidx534, align 4, !tbaa !3
  %add535 = fadd float %fiz1.2.lcssa, %116
  store float %add535, float* %arrayidx534, align 4, !tbaa !3
  %indvars.iv.next1101 = add i64 %indvars.iv1100, 1
  %indvars.iv.next1103 = add i64 %indvars.iv1102, 3
  %inc542 = add nsw i32 %s.21077, 1
  %exitcond1106 = icmp eq i32 %inc542, %1
  br i1 %exitcond1106, label %for.end543, label %for.body350

for.end543:                                       ; preds = %for.end500, %for.cond347.loopexit
  %vnbtot.2.lcssa = phi float [ %vnbtot.0.lcssa, %for.cond347.loopexit ], [ %vnbtot.3.lcssa, %for.end500 ]
  %arrayidx545 = getelementptr inbounds i32* %gid, i64 %indvars.iv1107
  %117 = load i32* %arrayidx545, align 4, !tbaa !0
  %idxprom546 = sext i32 %117 to i64
  %arrayidx547 = getelementptr inbounds float* %Vc, i64 %idxprom546
  %118 = load float* %arrayidx547, align 4, !tbaa !3
  %add548 = fadd float %vctot.2.lcssa, %118
  store float %add548, float* %arrayidx547, align 4, !tbaa !3
  %arrayidx552 = getelementptr inbounds float* %Vnb, i64 %idxprom546
  %119 = load float* %arrayidx552, align 4, !tbaa !3
  %add553 = fadd float %vnbtot.2.lcssa, %119
  store float %add553, float* %arrayidx552, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next1108 to i32
  %exitcond1109 = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond1109, label %for.end558, label %for.body

for.end558:                                       ; preds = %for.end543, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl1420(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab, float %exptabscale) #0 {
entry:
  %0 = load i32* %iinr, align 4, !tbaa !0
  %idxprom = sext i32 %0 to i64
  %arrayidx1 = getelementptr inbounds float* %charge, i64 %idxprom
  %1 = load float* %arrayidx1, align 4, !tbaa !3
  %add = add nsw i32 %0, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds float* %charge, i64 %idxprom2
  %2 = load float* %arrayidx3, align 4, !tbaa !3
  %mul = fmul float %1, %facel
  %mul4 = fmul float %2, %facel
  %arrayidx7 = getelementptr inbounds i32* %type, i64 %idxprom
  %3 = load i32* %arrayidx7, align 4, !tbaa !0
  %mul8 = mul i32 %3, %ntype
  %cmp637 = icmp sgt i32 %nri, 0
  br i1 %cmp637, label %for.body, label %for.end352

for.body:                                         ; preds = %entry, %for.end.for.body_crit_edge
  %4 = phi i32 [ %.pre, %for.end.for.body_crit_edge ], [ %0, %entry ]
  %indvars.iv639 = phi i64 [ %indvars.iv.next640, %for.end.for.body_crit_edge ], [ 0, %entry ]
  %arrayidx10 = getelementptr inbounds i32* %shift, i64 %indvars.iv639
  %5 = load i32* %arrayidx10, align 4, !tbaa !0
  %mul11 = mul nsw i32 %5, 3
  %idxprom12 = sext i32 %mul11 to i64
  %arrayidx13 = getelementptr inbounds float* %shiftvec, i64 %idxprom12
  %6 = load float* %arrayidx13, align 4, !tbaa !3
  %add14 = add nsw i32 %mul11, 1
  %idxprom15 = sext i32 %add14 to i64
  %arrayidx16 = getelementptr inbounds float* %shiftvec, i64 %idxprom15
  %7 = load float* %arrayidx16, align 4, !tbaa !3
  %add17 = add nsw i32 %mul11, 2
  %idxprom18 = sext i32 %add17 to i64
  %arrayidx19 = getelementptr inbounds float* %shiftvec, i64 %idxprom18
  %8 = load float* %arrayidx19, align 4, !tbaa !3
  %mul22 = mul nsw i32 %4, 3
  %arrayidx24 = getelementptr inbounds i32* %jindex, i64 %indvars.iv639
  %9 = load i32* %arrayidx24, align 4, !tbaa !0
  %indvars.iv.next640 = add i64 %indvars.iv639, 1
  %arrayidx27 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next640
  %10 = load i32* %arrayidx27, align 4, !tbaa !0
  %idxprom28 = sext i32 %mul22 to i64
  %arrayidx29 = getelementptr inbounds float* %pos, i64 %idxprom28
  %11 = load float* %arrayidx29, align 4, !tbaa !3
  %add30 = fadd float %6, %11
  %add31 = add nsw i32 %mul22, 1
  %idxprom32 = sext i32 %add31 to i64
  %arrayidx33 = getelementptr inbounds float* %pos, i64 %idxprom32
  %12 = load float* %arrayidx33, align 4, !tbaa !3
  %add34 = fadd float %7, %12
  %add35 = add nsw i32 %mul22, 2
  %idxprom36 = sext i32 %add35 to i64
  %arrayidx37 = getelementptr inbounds float* %pos, i64 %idxprom36
  %13 = load float* %arrayidx37, align 4, !tbaa !3
  %add38 = fadd float %8, %13
  %add39 = add nsw i32 %mul22, 3
  %idxprom40 = sext i32 %add39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %14 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = fadd float %6, %14
  %add43 = add nsw i32 %mul22, 4
  %idxprom44 = sext i32 %add43 to i64
  %arrayidx45 = getelementptr inbounds float* %pos, i64 %idxprom44
  %15 = load float* %arrayidx45, align 4, !tbaa !3
  %add46 = fadd float %7, %15
  %add47 = add nsw i32 %mul22, 5
  %idxprom48 = sext i32 %add47 to i64
  %arrayidx49 = getelementptr inbounds float* %pos, i64 %idxprom48
  %16 = load float* %arrayidx49, align 4, !tbaa !3
  %add50 = fadd float %8, %16
  %add51 = add nsw i32 %mul22, 6
  %idxprom52 = sext i32 %add51 to i64
  %arrayidx53 = getelementptr inbounds float* %pos, i64 %idxprom52
  %17 = load float* %arrayidx53, align 4, !tbaa !3
  %add54 = fadd float %6, %17
  %add55 = add nsw i32 %mul22, 7
  %idxprom56 = sext i32 %add55 to i64
  %arrayidx57 = getelementptr inbounds float* %pos, i64 %idxprom56
  %18 = load float* %arrayidx57, align 4, !tbaa !3
  %add58 = fadd float %7, %18
  %add59 = add nsw i32 %mul22, 8
  %idxprom60 = sext i32 %add59 to i64
  %arrayidx61 = getelementptr inbounds float* %pos, i64 %idxprom60
  %19 = load float* %arrayidx61, align 4, !tbaa !3
  %add62 = fadd float %8, %19
  %cmp64614 = icmp slt i32 %9, %10
  br i1 %cmp64614, label %for.body65.lr.ph, label %for.end

for.body65.lr.ph:                                 ; preds = %for.body
  %20 = sext i32 %9 to i64
  br label %for.body65

for.body65:                                       ; preds = %for.body65.lr.ph, %for.body65
  %indvars.iv = phi i64 [ %20, %for.body65.lr.ph ], [ %indvars.iv.next, %for.body65 ]
  %vctot.0625 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add234, %for.body65 ]
  %vnbtot.0624 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add183, %for.body65 ]
  %fix1.0623 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add198, %for.body65 ]
  %fiy1.0622 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add199, %for.body65 ]
  %fiz1.0621 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add200, %for.body65 ]
  %fix2.0620 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add222, %for.body65 ]
  %fiy2.0619 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add223, %for.body65 ]
  %fiz2.0618 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add224, %for.body65 ]
  %fix3.0617 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add238, %for.body65 ]
  %fiy3.0616 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add239, %for.body65 ]
  %fiz3.0615 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add240, %for.body65 ]
  %arrayidx67 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %21 = load i32* %arrayidx67, align 4, !tbaa !0
  %mul68 = mul nsw i32 %21, 3
  %idxprom69 = sext i32 %mul68 to i64
  %arrayidx70 = getelementptr inbounds float* %pos, i64 %idxprom69
  %22 = load float* %arrayidx70, align 4, !tbaa !3
  %add71 = add nsw i32 %mul68, 1
  %idxprom72 = sext i32 %add71 to i64
  %arrayidx73 = getelementptr inbounds float* %pos, i64 %idxprom72
  %23 = load float* %arrayidx73, align 4, !tbaa !3
  %add74 = add nsw i32 %mul68, 2
  %idxprom75 = sext i32 %add74 to i64
  %arrayidx76 = getelementptr inbounds float* %pos, i64 %idxprom75
  %24 = load float* %arrayidx76, align 4, !tbaa !3
  %sub = fsub float %add30, %22
  %sub77 = fsub float %add34, %23
  %sub78 = fsub float %add38, %24
  %mul79 = fmul float %sub, %sub
  %mul80 = fmul float %sub77, %sub77
  %add81 = fadd float %mul79, %mul80
  %mul82 = fmul float %sub78, %sub78
  %add83 = fadd float %add81, %mul82
  %sub84 = fsub float %add42, %22
  %sub85 = fsub float %add46, %23
  %sub86 = fsub float %add50, %24
  %mul87 = fmul float %sub84, %sub84
  %mul88 = fmul float %sub85, %sub85
  %add89 = fadd float %mul87, %mul88
  %mul90 = fmul float %sub86, %sub86
  %add91 = fadd float %add89, %mul90
  %sub92 = fsub float %add54, %22
  %sub93 = fsub float %add58, %23
  %sub94 = fsub float %add62, %24
  %mul95 = fmul float %sub92, %sub92
  %mul96 = fmul float %sub93, %sub93
  %add97 = fadd float %mul95, %mul96
  %mul98 = fmul float %sub94, %sub94
  %add99 = fadd float %add97, %mul98
  %conv = fpext float %add83 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv100 = fptrunc double %div to float
  %conv101 = fpext float %add91 to double
  %call102 = tail call double @sqrt(double %conv101) #2
  %div103 = fdiv double 1.000000e+00, %call102
  %conv104 = fptrunc double %div103 to float
  %conv105 = fpext float %add99 to double
  %call106 = tail call double @sqrt(double %conv105) #2
  %div107 = fdiv double 1.000000e+00, %call106
  %conv108 = fptrunc double %div107 to float
  %mul109 = fmul float %add83, %conv100
  %mul111 = fmul float %mul109, %tabscale
  %conv112 = fptosi float %mul111 to i32
  %conv113 = sitofp i32 %conv112 to float
  %sub114 = fsub float %mul111, %conv113
  %mul115 = fmul float %sub114, %sub114
  %mul116 = shl nsw i32 %conv112, 3
  %idxprom117 = sext i32 %21 to i64
  %arrayidx118 = getelementptr inbounds i32* %type, i64 %idxprom117
  %25 = load i32* %arrayidx118, align 4, !tbaa !0
  %tmp = add i32 %25, %mul8
  %tmp613 = mul i32 %tmp, 3
  %idxprom121 = sext i32 %tmp613 to i64
  %arrayidx122 = getelementptr inbounds float* %nbfp, i64 %idxprom121
  %26 = load float* %arrayidx122, align 4, !tbaa !3
  %add123 = add nsw i32 %tmp613, 1
  %idxprom124 = sext i32 %add123 to i64
  %arrayidx125 = getelementptr inbounds float* %nbfp, i64 %idxprom124
  %27 = load float* %arrayidx125, align 4, !tbaa !3
  %add126 = add nsw i32 %tmp613, 2
  %idxprom127 = sext i32 %add126 to i64
  %arrayidx128 = getelementptr inbounds float* %nbfp, i64 %idxprom127
  %28 = load float* %arrayidx128, align 4, !tbaa !3
  %idxprom129 = sext i32 %mul116 to i64
  %arrayidx130 = getelementptr inbounds float* %VFtab, i64 %idxprom129
  %29 = load float* %arrayidx130, align 4, !tbaa !3
  %add131606 = or i32 %mul116, 1
  %idxprom132 = sext i32 %add131606 to i64
  %arrayidx133 = getelementptr inbounds float* %VFtab, i64 %idxprom132
  %30 = load float* %arrayidx133, align 4, !tbaa !3
  %add134607 = or i32 %mul116, 2
  %idxprom135 = sext i32 %add134607 to i64
  %arrayidx136 = getelementptr inbounds float* %VFtab, i64 %idxprom135
  %31 = load float* %arrayidx136, align 4, !tbaa !3
  %mul137 = fmul float %sub114, %31
  %add138608 = or i32 %mul116, 3
  %idxprom139 = sext i32 %add138608 to i64
  %arrayidx140 = getelementptr inbounds float* %VFtab, i64 %idxprom139
  %32 = load float* %arrayidx140, align 4, !tbaa !3
  %mul141 = fmul float %mul115, %32
  %add142 = fadd float %30, %mul137
  %add143 = fadd float %add142, %mul141
  %mul144 = fmul float %sub114, %add143
  %add145 = fadd float %29, %mul144
  %add146 = fadd float %mul137, %add143
  %mul147 = fmul float %mul141, 2.000000e+00
  %add148 = fadd float %mul147, %add146
  %mul149 = fmul float %26, %add145
  %mul150 = fmul float %26, %add148
  %mul151 = fmul float %mul109, %28
  %mul152 = fmul float %mul151, %exptabscale
  %conv153 = fptosi float %mul152 to i32
  %conv154 = sitofp i32 %conv153 to float
  %sub155 = fsub float %mul152, %conv154
  %mul156 = fmul float %sub155, %sub155
  %mul157 = shl nsw i32 %conv153, 3
  %add158609 = or i32 %mul157, 4
  %idxprom159 = sext i32 %add158609 to i64
  %arrayidx160 = getelementptr inbounds float* %VFtab, i64 %idxprom159
  %33 = load float* %arrayidx160, align 4, !tbaa !3
  %add161610 = or i32 %mul157, 5
  %idxprom162 = sext i32 %add161610 to i64
  %arrayidx163 = getelementptr inbounds float* %VFtab, i64 %idxprom162
  %34 = load float* %arrayidx163, align 4, !tbaa !3
  %add164611 = or i32 %mul157, 6
  %idxprom165 = sext i32 %add164611 to i64
  %arrayidx166 = getelementptr inbounds float* %VFtab, i64 %idxprom165
  %35 = load float* %arrayidx166, align 4, !tbaa !3
  %mul167 = fmul float %sub155, %35
  %add168612 = or i32 %mul157, 7
  %idxprom169 = sext i32 %add168612 to i64
  %arrayidx170 = getelementptr inbounds float* %VFtab, i64 %idxprom169
  %36 = load float* %arrayidx170, align 4, !tbaa !3
  %mul171 = fmul float %mul156, %36
  %add172 = fadd float %34, %mul167
  %add173 = fadd float %add172, %mul171
  %mul174 = fmul float %sub155, %add173
  %add175 = fadd float %33, %mul174
  %add176 = fadd float %mul167, %add173
  %mul177 = fmul float %mul171, 2.000000e+00
  %add178 = fadd float %mul177, %add176
  %mul179 = fmul float %27, %add175
  %mul180 = fmul float %27, %28
  %mul181 = fmul float %mul180, %add178
  %add182 = fadd float %vnbtot.0624, %mul149
  %add183 = fadd float %add182, %mul179
  %arrayidx185 = getelementptr inbounds float* %charge, i64 %idxprom117
  %37 = load float* %arrayidx185, align 4, !tbaa !3
  %mul186 = fmul float %mul, %37
  %mul187 = fmul float %conv100, %mul186
  %mul188 = fmul float %conv100, %mul187
  %mul189 = fmul float %mul150, %tabscale
  %mul190 = fmul float %mul181, %exptabscale
  %add191 = fadd float %mul189, %mul190
  %sub192 = fsub float %mul188, %add191
  %mul193 = fmul float %conv100, %sub192
  %add194 = fadd float %vctot.0625, %mul187
  %mul195 = fmul float %sub, %mul193
  %mul196 = fmul float %sub77, %mul193
  %mul197 = fmul float %sub78, %mul193
  %add198 = fadd float %fix1.0623, %mul195
  %add199 = fadd float %fiy1.0622, %mul196
  %add200 = fadd float %fiz1.0621, %mul197
  %arrayidx202 = getelementptr inbounds float* %faction, i64 %idxprom69
  %38 = load float* %arrayidx202, align 4, !tbaa !3
  %sub203 = fsub float %38, %mul195
  %arrayidx206 = getelementptr inbounds float* %faction, i64 %idxprom72
  %39 = load float* %arrayidx206, align 4, !tbaa !3
  %sub207 = fsub float %39, %mul196
  %arrayidx210 = getelementptr inbounds float* %faction, i64 %idxprom75
  %40 = load float* %arrayidx210, align 4, !tbaa !3
  %sub211 = fsub float %40, %mul197
  %mul212 = fmul float %conv104, %conv104
  %mul215 = fmul float %mul4, %37
  %mul216 = fmul float %conv104, %mul215
  %mul217 = fmul float %mul212, %mul216
  %add218 = fadd float %mul216, %add194
  %mul219 = fmul float %sub84, %mul217
  %mul220 = fmul float %sub85, %mul217
  %mul221 = fmul float %sub86, %mul217
  %add222 = fadd float %fix2.0620, %mul219
  %add223 = fadd float %fiy2.0619, %mul220
  %add224 = fadd float %fiz2.0618, %mul221
  %sub225 = fsub float %sub203, %mul219
  %sub226 = fsub float %sub207, %mul220
  %sub227 = fsub float %sub211, %mul221
  %mul228 = fmul float %conv108, %conv108
  %mul232 = fmul float %conv108, %mul215
  %mul233 = fmul float %mul228, %mul232
  %add234 = fadd float %mul232, %add218
  %mul235 = fmul float %sub92, %mul233
  %mul236 = fmul float %sub93, %mul233
  %mul237 = fmul float %sub94, %mul233
  %add238 = fadd float %fix3.0617, %mul235
  %add239 = fadd float %fiy3.0616, %mul236
  %add240 = fadd float %fiz3.0615, %mul237
  %sub241 = fsub float %sub225, %mul235
  store float %sub241, float* %arrayidx202, align 4, !tbaa !3
  %sub244 = fsub float %sub226, %mul236
  store float %sub244, float* %arrayidx206, align 4, !tbaa !3
  %sub248 = fsub float %sub227, %mul237
  store float %sub248, float* %arrayidx210, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %41 = trunc i64 %indvars.iv.next to i32
  %cmp64 = icmp slt i32 %41, %10
  br i1 %cmp64, label %for.body65, label %for.end

for.end:                                          ; preds = %for.body65, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add234, %for.body65 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add183, %for.body65 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add198, %for.body65 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add199, %for.body65 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add200, %for.body65 ]
  %fix2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add222, %for.body65 ]
  %fiy2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add223, %for.body65 ]
  %fiz2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add224, %for.body65 ]
  %fix3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add238, %for.body65 ]
  %fiy3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add239, %for.body65 ]
  %fiz3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add240, %for.body65 ]
  %arrayidx253 = getelementptr inbounds float* %faction, i64 %idxprom28
  %42 = load float* %arrayidx253, align 4, !tbaa !3
  %add254 = fadd float %fix1.0.lcssa, %42
  store float %add254, float* %arrayidx253, align 4, !tbaa !3
  %arrayidx259 = getelementptr inbounds float* %faction, i64 %idxprom32
  %43 = load float* %arrayidx259, align 4, !tbaa !3
  %add260 = fadd float %fiy1.0.lcssa, %43
  store float %add260, float* %arrayidx259, align 4, !tbaa !3
  %arrayidx266 = getelementptr inbounds float* %faction, i64 %idxprom36
  %44 = load float* %arrayidx266, align 4, !tbaa !3
  %add267 = fadd float %fiz1.0.lcssa, %44
  store float %add267, float* %arrayidx266, align 4, !tbaa !3
  %arrayidx273 = getelementptr inbounds float* %faction, i64 %idxprom40
  %45 = load float* %arrayidx273, align 4, !tbaa !3
  %add274 = fadd float %fix2.0.lcssa, %45
  store float %add274, float* %arrayidx273, align 4, !tbaa !3
  %arrayidx280 = getelementptr inbounds float* %faction, i64 %idxprom44
  %46 = load float* %arrayidx280, align 4, !tbaa !3
  %add281 = fadd float %fiy2.0.lcssa, %46
  store float %add281, float* %arrayidx280, align 4, !tbaa !3
  %arrayidx287 = getelementptr inbounds float* %faction, i64 %idxprom48
  %47 = load float* %arrayidx287, align 4, !tbaa !3
  %add288 = fadd float %fiz2.0.lcssa, %47
  store float %add288, float* %arrayidx287, align 4, !tbaa !3
  %arrayidx294 = getelementptr inbounds float* %faction, i64 %idxprom52
  %48 = load float* %arrayidx294, align 4, !tbaa !3
  %add295 = fadd float %fix3.0.lcssa, %48
  store float %add295, float* %arrayidx294, align 4, !tbaa !3
  %arrayidx301 = getelementptr inbounds float* %faction, i64 %idxprom56
  %49 = load float* %arrayidx301, align 4, !tbaa !3
  %add302 = fadd float %fiy3.0.lcssa, %49
  store float %add302, float* %arrayidx301, align 4, !tbaa !3
  %arrayidx308 = getelementptr inbounds float* %faction, i64 %idxprom60
  %50 = load float* %arrayidx308, align 4, !tbaa !3
  %add309 = fadd float %fiz3.0.lcssa, %50
  store float %add309, float* %arrayidx308, align 4, !tbaa !3
  %arrayidx314 = getelementptr inbounds float* %fshift, i64 %idxprom12
  %51 = load float* %arrayidx314, align 4, !tbaa !3
  %add315 = fadd float %fix1.0.lcssa, %51
  %add316 = fadd float %fix2.0.lcssa, %add315
  %add317 = fadd float %fix3.0.lcssa, %add316
  store float %add317, float* %arrayidx314, align 4, !tbaa !3
  %arrayidx322 = getelementptr inbounds float* %fshift, i64 %idxprom15
  %52 = load float* %arrayidx322, align 4, !tbaa !3
  %add323 = fadd float %fiy1.0.lcssa, %52
  %add324 = fadd float %fiy2.0.lcssa, %add323
  %add325 = fadd float %fiy3.0.lcssa, %add324
  store float %add325, float* %arrayidx322, align 4, !tbaa !3
  %arrayidx331 = getelementptr inbounds float* %fshift, i64 %idxprom18
  %53 = load float* %arrayidx331, align 4, !tbaa !3
  %add332 = fadd float %fiz1.0.lcssa, %53
  %add333 = fadd float %fiz2.0.lcssa, %add332
  %add334 = fadd float %fiz3.0.lcssa, %add333
  store float %add334, float* %arrayidx331, align 4, !tbaa !3
  %arrayidx339 = getelementptr inbounds i32* %gid, i64 %indvars.iv639
  %54 = load i32* %arrayidx339, align 4, !tbaa !0
  %idxprom340 = sext i32 %54 to i64
  %arrayidx341 = getelementptr inbounds float* %Vc, i64 %idxprom340
  %55 = load float* %arrayidx341, align 4, !tbaa !3
  %add342 = fadd float %vctot.0.lcssa, %55
  store float %add342, float* %arrayidx341, align 4, !tbaa !3
  %arrayidx346 = getelementptr inbounds float* %Vnb, i64 %idxprom340
  %56 = load float* %arrayidx346, align 4, !tbaa !3
  %add347 = fadd float %vnbtot.0.lcssa, %56
  store float %add347, float* %arrayidx346, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next640 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end352, label %for.end.for.body_crit_edge

for.end.for.body_crit_edge:                       ; preds = %for.end
  %arrayidx21.phi.trans.insert = getelementptr inbounds i32* %iinr, i64 %indvars.iv.next640
  %.pre = load i32* %arrayidx21.phi.trans.insert, align 4, !tbaa !0
  br label %for.body

for.end352:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl1430(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab, float %exptabscale) #0 {
entry:
  %0 = load i32* %iinr, align 4, !tbaa !0
  %idxprom = sext i32 %0 to i64
  %arrayidx1 = getelementptr inbounds float* %charge, i64 %idxprom
  %1 = load float* %arrayidx1, align 4, !tbaa !3
  %add = add nsw i32 %0, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds float* %charge, i64 %idxprom2
  %2 = load float* %arrayidx3, align 4, !tbaa !3
  %mul = fmul float %1, %facel
  %mul4 = fmul float %1, %mul
  %mul6 = fmul float %mul, %2
  %mul7 = fmul float %2, %facel
  %mul8 = fmul float %2, %mul7
  %mul9 = mul nsw i32 %ntype, 3
  %arrayidx11 = getelementptr inbounds i32* %type, i64 %idxprom
  %3 = load i32* %arrayidx11, align 4, !tbaa !0
  %mul12991 = add i32 %mul9, 3
  %add16 = mul i32 %3, %mul12991
  %idxprom17 = sext i32 %add16 to i64
  %arrayidx18 = getelementptr inbounds float* %nbfp, i64 %idxprom17
  %4 = load float* %arrayidx18, align 4, !tbaa !3
  %add19 = add nsw i32 %add16, 1
  %idxprom20 = sext i32 %add19 to i64
  %arrayidx21 = getelementptr inbounds float* %nbfp, i64 %idxprom20
  %5 = load float* %arrayidx21, align 4, !tbaa !3
  %add22 = add nsw i32 %add16, 2
  %idxprom23 = sext i32 %add22 to i64
  %arrayidx24 = getelementptr inbounds float* %nbfp, i64 %idxprom23
  %6 = load float* %arrayidx24, align 4, !tbaa !3
  %cmp1022 = icmp sgt i32 %nri, 0
  br i1 %cmp1022, label %for.body.lr.ph, label %for.end551

for.body.lr.ph:                                   ; preds = %entry
  %mul274 = fmul float %5, %6
  br label %for.body

for.body:                                         ; preds = %for.end.for.body_crit_edge, %for.body.lr.ph
  %7 = phi i32 [ %0, %for.body.lr.ph ], [ %.pre, %for.end.for.body_crit_edge ]
  %indvars.iv1024 = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next1025, %for.end.for.body_crit_edge ]
  %arrayidx26 = getelementptr inbounds i32* %shift, i64 %indvars.iv1024
  %8 = load i32* %arrayidx26, align 4, !tbaa !0
  %mul27 = mul nsw i32 %8, 3
  %idxprom28 = sext i32 %mul27 to i64
  %arrayidx29 = getelementptr inbounds float* %shiftvec, i64 %idxprom28
  %9 = load float* %arrayidx29, align 4, !tbaa !3
  %add30 = add nsw i32 %mul27, 1
  %idxprom31 = sext i32 %add30 to i64
  %arrayidx32 = getelementptr inbounds float* %shiftvec, i64 %idxprom31
  %10 = load float* %arrayidx32, align 4, !tbaa !3
  %add33 = add nsw i32 %mul27, 2
  %idxprom34 = sext i32 %add33 to i64
  %arrayidx35 = getelementptr inbounds float* %shiftvec, i64 %idxprom34
  %11 = load float* %arrayidx35, align 4, !tbaa !3
  %mul38 = mul nsw i32 %7, 3
  %arrayidx40 = getelementptr inbounds i32* %jindex, i64 %indvars.iv1024
  %12 = load i32* %arrayidx40, align 4, !tbaa !0
  %indvars.iv.next1025 = add i64 %indvars.iv1024, 1
  %arrayidx43 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next1025
  %13 = load i32* %arrayidx43, align 4, !tbaa !0
  %idxprom44 = sext i32 %mul38 to i64
  %arrayidx45 = getelementptr inbounds float* %pos, i64 %idxprom44
  %14 = load float* %arrayidx45, align 4, !tbaa !3
  %add46 = fadd float %9, %14
  %add47 = add nsw i32 %mul38, 1
  %idxprom48 = sext i32 %add47 to i64
  %arrayidx49 = getelementptr inbounds float* %pos, i64 %idxprom48
  %15 = load float* %arrayidx49, align 4, !tbaa !3
  %add50 = fadd float %10, %15
  %add51 = add nsw i32 %mul38, 2
  %idxprom52 = sext i32 %add51 to i64
  %arrayidx53 = getelementptr inbounds float* %pos, i64 %idxprom52
  %16 = load float* %arrayidx53, align 4, !tbaa !3
  %add54 = fadd float %11, %16
  %add55 = add nsw i32 %mul38, 3
  %idxprom56 = sext i32 %add55 to i64
  %arrayidx57 = getelementptr inbounds float* %pos, i64 %idxprom56
  %17 = load float* %arrayidx57, align 4, !tbaa !3
  %add58 = fadd float %9, %17
  %add59 = add nsw i32 %mul38, 4
  %idxprom60 = sext i32 %add59 to i64
  %arrayidx61 = getelementptr inbounds float* %pos, i64 %idxprom60
  %18 = load float* %arrayidx61, align 4, !tbaa !3
  %add62 = fadd float %10, %18
  %add63 = add nsw i32 %mul38, 5
  %idxprom64 = sext i32 %add63 to i64
  %arrayidx65 = getelementptr inbounds float* %pos, i64 %idxprom64
  %19 = load float* %arrayidx65, align 4, !tbaa !3
  %add66 = fadd float %11, %19
  %add67 = add nsw i32 %mul38, 6
  %idxprom68 = sext i32 %add67 to i64
  %arrayidx69 = getelementptr inbounds float* %pos, i64 %idxprom68
  %20 = load float* %arrayidx69, align 4, !tbaa !3
  %add70 = fadd float %9, %20
  %add71 = add nsw i32 %mul38, 7
  %idxprom72 = sext i32 %add71 to i64
  %arrayidx73 = getelementptr inbounds float* %pos, i64 %idxprom72
  %21 = load float* %arrayidx73, align 4, !tbaa !3
  %add74 = fadd float %10, %21
  %add75 = add nsw i32 %mul38, 8
  %idxprom76 = sext i32 %add75 to i64
  %arrayidx77 = getelementptr inbounds float* %pos, i64 %idxprom76
  %22 = load float* %arrayidx77, align 4, !tbaa !3
  %add78 = fadd float %11, %22
  %cmp80999 = icmp slt i32 %12, %13
  br i1 %cmp80999, label %for.body81.lr.ph, label %for.end

for.body81.lr.ph:                                 ; preds = %for.body
  %23 = sext i32 %12 to i64
  br label %for.body81

for.body81:                                       ; preds = %for.body81.lr.ph, %for.body81
  %indvars.iv = phi i64 [ %23, %for.body81.lr.ph ], [ %indvars.iv.next, %for.body81 ]
  %vctot.01010 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add432, %for.body81 ]
  %vnbtot.01009 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add277, %for.body81 ]
  %fix1.01008 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add332, %for.body81 ]
  %fiy1.01007 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add333, %for.body81 ]
  %fiz1.01006 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add334, %for.body81 ]
  %fix2.01005 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add380, %for.body81 ]
  %fiy2.01004 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add381, %for.body81 ]
  %fiz2.01003 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add382, %for.body81 ]
  %fix3.01002 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add436, %for.body81 ]
  %fiy3.01001 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add437, %for.body81 ]
  %fiz3.01000 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add438, %for.body81 ]
  %arrayidx83 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %24 = load i32* %arrayidx83, align 4, !tbaa !0
  %mul84 = mul nsw i32 %24, 3
  %idxprom85 = sext i32 %mul84 to i64
  %arrayidx86 = getelementptr inbounds float* %pos, i64 %idxprom85
  %25 = load float* %arrayidx86, align 4, !tbaa !3
  %add87 = add nsw i32 %mul84, 1
  %idxprom88 = sext i32 %add87 to i64
  %arrayidx89 = getelementptr inbounds float* %pos, i64 %idxprom88
  %26 = load float* %arrayidx89, align 4, !tbaa !3
  %add90 = add nsw i32 %mul84, 2
  %idxprom91 = sext i32 %add90 to i64
  %arrayidx92 = getelementptr inbounds float* %pos, i64 %idxprom91
  %27 = load float* %arrayidx92, align 4, !tbaa !3
  %add93 = add nsw i32 %mul84, 3
  %idxprom94 = sext i32 %add93 to i64
  %arrayidx95 = getelementptr inbounds float* %pos, i64 %idxprom94
  %28 = load float* %arrayidx95, align 4, !tbaa !3
  %add96 = add nsw i32 %mul84, 4
  %idxprom97 = sext i32 %add96 to i64
  %arrayidx98 = getelementptr inbounds float* %pos, i64 %idxprom97
  %29 = load float* %arrayidx98, align 4, !tbaa !3
  %add99 = add nsw i32 %mul84, 5
  %idxprom100 = sext i32 %add99 to i64
  %arrayidx101 = getelementptr inbounds float* %pos, i64 %idxprom100
  %30 = load float* %arrayidx101, align 4, !tbaa !3
  %add102 = add nsw i32 %mul84, 6
  %idxprom103 = sext i32 %add102 to i64
  %arrayidx104 = getelementptr inbounds float* %pos, i64 %idxprom103
  %31 = load float* %arrayidx104, align 4, !tbaa !3
  %add105 = add nsw i32 %mul84, 7
  %idxprom106 = sext i32 %add105 to i64
  %arrayidx107 = getelementptr inbounds float* %pos, i64 %idxprom106
  %32 = load float* %arrayidx107, align 4, !tbaa !3
  %add108 = add nsw i32 %mul84, 8
  %idxprom109 = sext i32 %add108 to i64
  %arrayidx110 = getelementptr inbounds float* %pos, i64 %idxprom109
  %33 = load float* %arrayidx110, align 4, !tbaa !3
  %sub = fsub float %add46, %25
  %sub111 = fsub float %add50, %26
  %sub112 = fsub float %add54, %27
  %mul113 = fmul float %sub, %sub
  %mul114 = fmul float %sub111, %sub111
  %add115 = fadd float %mul113, %mul114
  %mul116 = fmul float %sub112, %sub112
  %add117 = fadd float %add115, %mul116
  %sub118 = fsub float %add46, %28
  %sub119 = fsub float %add50, %29
  %sub120 = fsub float %add54, %30
  %mul121 = fmul float %sub118, %sub118
  %mul122 = fmul float %sub119, %sub119
  %add123 = fadd float %mul121, %mul122
  %mul124 = fmul float %sub120, %sub120
  %add125 = fadd float %add123, %mul124
  %sub126 = fsub float %add46, %31
  %sub127 = fsub float %add50, %32
  %sub128 = fsub float %add54, %33
  %mul129 = fmul float %sub126, %sub126
  %mul130 = fmul float %sub127, %sub127
  %add131 = fadd float %mul129, %mul130
  %mul132 = fmul float %sub128, %sub128
  %add133 = fadd float %add131, %mul132
  %sub134 = fsub float %add58, %25
  %sub135 = fsub float %add62, %26
  %sub136 = fsub float %add66, %27
  %mul137 = fmul float %sub134, %sub134
  %mul138 = fmul float %sub135, %sub135
  %add139 = fadd float %mul137, %mul138
  %mul140 = fmul float %sub136, %sub136
  %add141 = fadd float %add139, %mul140
  %sub142 = fsub float %add58, %28
  %sub143 = fsub float %add62, %29
  %sub144 = fsub float %add66, %30
  %mul145 = fmul float %sub142, %sub142
  %mul146 = fmul float %sub143, %sub143
  %add147 = fadd float %mul145, %mul146
  %mul148 = fmul float %sub144, %sub144
  %add149 = fadd float %add147, %mul148
  %sub150 = fsub float %add58, %31
  %sub151 = fsub float %add62, %32
  %sub152 = fsub float %add66, %33
  %mul153 = fmul float %sub150, %sub150
  %mul154 = fmul float %sub151, %sub151
  %add155 = fadd float %mul153, %mul154
  %mul156 = fmul float %sub152, %sub152
  %add157 = fadd float %add155, %mul156
  %sub158 = fsub float %add70, %25
  %sub159 = fsub float %add74, %26
  %sub160 = fsub float %add78, %27
  %mul161 = fmul float %sub158, %sub158
  %mul162 = fmul float %sub159, %sub159
  %add163 = fadd float %mul161, %mul162
  %mul164 = fmul float %sub160, %sub160
  %add165 = fadd float %add163, %mul164
  %sub166 = fsub float %add70, %28
  %sub167 = fsub float %add74, %29
  %sub168 = fsub float %add78, %30
  %mul169 = fmul float %sub166, %sub166
  %mul170 = fmul float %sub167, %sub167
  %add171 = fadd float %mul169, %mul170
  %mul172 = fmul float %sub168, %sub168
  %add173 = fadd float %add171, %mul172
  %sub174 = fsub float %add70, %31
  %sub175 = fsub float %add74, %32
  %sub176 = fsub float %add78, %33
  %mul177 = fmul float %sub174, %sub174
  %mul178 = fmul float %sub175, %sub175
  %add179 = fadd float %mul177, %mul178
  %mul180 = fmul float %sub176, %sub176
  %add181 = fadd float %add179, %mul180
  %conv = fpext float %add117 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv182 = fptrunc double %div to float
  %conv183 = fpext float %add141 to double
  %call184 = tail call double @sqrt(double %conv183) #2
  %div185 = fdiv double 1.000000e+00, %call184
  %conv186 = fptrunc double %div185 to float
  %conv187 = fpext float %add165 to double
  %call188 = tail call double @sqrt(double %conv187) #2
  %div189 = fdiv double 1.000000e+00, %call188
  %conv190 = fptrunc double %div189 to float
  %conv191 = fpext float %add125 to double
  %call192 = tail call double @sqrt(double %conv191) #2
  %div193 = fdiv double 1.000000e+00, %call192
  %conv194 = fptrunc double %div193 to float
  %conv195 = fpext float %add149 to double
  %call196 = tail call double @sqrt(double %conv195) #2
  %div197 = fdiv double 1.000000e+00, %call196
  %conv198 = fptrunc double %div197 to float
  %conv199 = fpext float %add173 to double
  %call200 = tail call double @sqrt(double %conv199) #2
  %div201 = fdiv double 1.000000e+00, %call200
  %conv202 = fptrunc double %div201 to float
  %conv203 = fpext float %add133 to double
  %call204 = tail call double @sqrt(double %conv203) #2
  %div205 = fdiv double 1.000000e+00, %call204
  %conv206 = fptrunc double %div205 to float
  %conv207 = fpext float %add157 to double
  %call208 = tail call double @sqrt(double %conv207) #2
  %div209 = fdiv double 1.000000e+00, %call208
  %conv210 = fptrunc double %div209 to float
  %conv211 = fpext float %add181 to double
  %call212 = tail call double @sqrt(double %conv211) #2
  %div213 = fdiv double 1.000000e+00, %call212
  %conv214 = fptrunc double %div213 to float
  %mul215 = fmul float %add117, %conv182
  %mul217 = fmul float %mul215, %tabscale
  %conv218 = fptosi float %mul217 to i32
  %conv219 = sitofp i32 %conv218 to float
  %sub220 = fsub float %mul217, %conv219
  %mul221 = fmul float %sub220, %sub220
  %mul222 = shl nsw i32 %conv218, 3
  %idxprom223 = sext i32 %mul222 to i64
  %arrayidx224 = getelementptr inbounds float* %VFtab, i64 %idxprom223
  %34 = load float* %arrayidx224, align 4, !tbaa !3
  %add225992 = or i32 %mul222, 1
  %idxprom226 = sext i32 %add225992 to i64
  %arrayidx227 = getelementptr inbounds float* %VFtab, i64 %idxprom226
  %35 = load float* %arrayidx227, align 4, !tbaa !3
  %add228993 = or i32 %mul222, 2
  %idxprom229 = sext i32 %add228993 to i64
  %arrayidx230 = getelementptr inbounds float* %VFtab, i64 %idxprom229
  %36 = load float* %arrayidx230, align 4, !tbaa !3
  %mul231 = fmul float %sub220, %36
  %add232994 = or i32 %mul222, 3
  %idxprom233 = sext i32 %add232994 to i64
  %arrayidx234 = getelementptr inbounds float* %VFtab, i64 %idxprom233
  %37 = load float* %arrayidx234, align 4, !tbaa !3
  %mul235 = fmul float %mul221, %37
  %add236 = fadd float %35, %mul231
  %add237 = fadd float %add236, %mul235
  %mul238 = fmul float %sub220, %add237
  %add239 = fadd float %34, %mul238
  %add240 = fadd float %mul231, %add237
  %mul241 = fmul float %mul235, 2.000000e+00
  %add242 = fadd float %mul241, %add240
  %mul243 = fmul float %4, %add239
  %mul244 = fmul float %4, %add242
  %mul245 = fmul float %6, %mul215
  %mul246 = fmul float %mul245, %exptabscale
  %conv247 = fptosi float %mul246 to i32
  %conv248 = sitofp i32 %conv247 to float
  %sub249 = fsub float %mul246, %conv248
  %mul250 = fmul float %sub249, %sub249
  %mul251 = shl nsw i32 %conv247, 3
  %add252995 = or i32 %mul251, 4
  %idxprom253 = sext i32 %add252995 to i64
  %arrayidx254 = getelementptr inbounds float* %VFtab, i64 %idxprom253
  %38 = load float* %arrayidx254, align 4, !tbaa !3
  %add255996 = or i32 %mul251, 5
  %idxprom256 = sext i32 %add255996 to i64
  %arrayidx257 = getelementptr inbounds float* %VFtab, i64 %idxprom256
  %39 = load float* %arrayidx257, align 4, !tbaa !3
  %add258997 = or i32 %mul251, 6
  %idxprom259 = sext i32 %add258997 to i64
  %arrayidx260 = getelementptr inbounds float* %VFtab, i64 %idxprom259
  %40 = load float* %arrayidx260, align 4, !tbaa !3
  %mul261 = fmul float %sub249, %40
  %add262998 = or i32 %mul251, 7
  %idxprom263 = sext i32 %add262998 to i64
  %arrayidx264 = getelementptr inbounds float* %VFtab, i64 %idxprom263
  %41 = load float* %arrayidx264, align 4, !tbaa !3
  %mul265 = fmul float %mul250, %41
  %add266 = fadd float %39, %mul261
  %add267 = fadd float %add266, %mul265
  %mul268 = fmul float %sub249, %add267
  %add269 = fadd float %38, %mul268
  %add270 = fadd float %mul261, %add267
  %mul271 = fmul float %mul265, 2.000000e+00
  %add272 = fadd float %mul271, %add270
  %mul273 = fmul float %5, %add269
  %mul275 = fmul float %mul274, %add272
  %add276 = fadd float %vnbtot.01009, %mul243
  %add277 = fadd float %add276, %mul273
  %mul278 = fmul float %mul4, %conv182
  %mul279 = fmul float %conv182, %mul278
  %mul280 = fmul float %mul244, %tabscale
  %mul281 = fmul float %mul275, %exptabscale
  %add282 = fadd float %mul280, %mul281
  %sub283 = fsub float %mul279, %add282
  %mul284 = fmul float %conv182, %sub283
  %add285 = fadd float %vctot.01010, %mul278
  %mul286 = fmul float %sub, %mul284
  %mul287 = fmul float %sub111, %mul284
  %mul288 = fmul float %sub112, %mul284
  %add289 = fadd float %fix1.01008, %mul286
  %add290 = fadd float %fiy1.01007, %mul287
  %add291 = fadd float %fiz1.01006, %mul288
  %arrayidx293 = getelementptr inbounds float* %faction, i64 %idxprom85
  %42 = load float* %arrayidx293, align 4, !tbaa !3
  %sub294 = fsub float %42, %mul286
  %arrayidx297 = getelementptr inbounds float* %faction, i64 %idxprom88
  %43 = load float* %arrayidx297, align 4, !tbaa !3
  %sub298 = fsub float %43, %mul287
  %arrayidx301 = getelementptr inbounds float* %faction, i64 %idxprom91
  %44 = load float* %arrayidx301, align 4, !tbaa !3
  %sub302 = fsub float %44, %mul288
  %mul303 = fmul float %conv194, %conv194
  %mul304 = fmul float %mul6, %conv194
  %mul305 = fmul float %mul304, %mul303
  %add306 = fadd float %add285, %mul304
  %mul307 = fmul float %sub118, %mul305
  %mul308 = fmul float %sub119, %mul305
  %mul309 = fmul float %sub120, %mul305
  %add310 = fadd float %mul307, %add289
  %add311 = fadd float %mul308, %add290
  %add312 = fadd float %mul309, %add291
  %arrayidx315 = getelementptr inbounds float* %faction, i64 %idxprom94
  %45 = load float* %arrayidx315, align 4, !tbaa !3
  %sub316 = fsub float %45, %mul307
  %arrayidx319 = getelementptr inbounds float* %faction, i64 %idxprom97
  %46 = load float* %arrayidx319, align 4, !tbaa !3
  %sub320 = fsub float %46, %mul308
  %arrayidx323 = getelementptr inbounds float* %faction, i64 %idxprom100
  %47 = load float* %arrayidx323, align 4, !tbaa !3
  %sub324 = fsub float %47, %mul309
  %mul325 = fmul float %conv206, %conv206
  %mul326 = fmul float %mul6, %conv206
  %mul327 = fmul float %mul326, %mul325
  %add328 = fadd float %add306, %mul326
  %mul329 = fmul float %sub126, %mul327
  %mul330 = fmul float %sub127, %mul327
  %mul331 = fmul float %sub128, %mul327
  %add332 = fadd float %mul329, %add310
  %add333 = fadd float %mul330, %add311
  %add334 = fadd float %mul331, %add312
  %arrayidx337 = getelementptr inbounds float* %faction, i64 %idxprom103
  %48 = load float* %arrayidx337, align 4, !tbaa !3
  %sub338 = fsub float %48, %mul329
  %arrayidx341 = getelementptr inbounds float* %faction, i64 %idxprom106
  %49 = load float* %arrayidx341, align 4, !tbaa !3
  %sub342 = fsub float %49, %mul330
  %arrayidx345 = getelementptr inbounds float* %faction, i64 %idxprom109
  %50 = load float* %arrayidx345, align 4, !tbaa !3
  %sub346 = fsub float %50, %mul331
  %mul347 = fmul float %conv186, %conv186
  %mul348 = fmul float %mul6, %conv186
  %mul349 = fmul float %mul348, %mul347
  %add350 = fadd float %mul348, %add328
  %mul351 = fmul float %sub134, %mul349
  %mul352 = fmul float %sub135, %mul349
  %mul353 = fmul float %sub136, %mul349
  %add354 = fadd float %fix2.01005, %mul351
  %add355 = fadd float %fiy2.01004, %mul352
  %add356 = fadd float %fiz2.01003, %mul353
  %sub357 = fsub float %sub294, %mul351
  %sub358 = fsub float %sub298, %mul352
  %sub359 = fsub float %sub302, %mul353
  %mul360 = fmul float %conv198, %conv198
  %mul361 = fmul float %mul8, %conv198
  %mul362 = fmul float %mul361, %mul360
  %add363 = fadd float %mul361, %add350
  %mul364 = fmul float %sub142, %mul362
  %mul365 = fmul float %sub143, %mul362
  %mul366 = fmul float %sub144, %mul362
  %add367 = fadd float %add354, %mul364
  %add368 = fadd float %add355, %mul365
  %add369 = fadd float %add356, %mul366
  %sub370 = fsub float %sub316, %mul364
  %sub371 = fsub float %sub320, %mul365
  %sub372 = fsub float %sub324, %mul366
  %mul373 = fmul float %conv210, %conv210
  %mul374 = fmul float %mul8, %conv210
  %mul375 = fmul float %mul374, %mul373
  %add376 = fadd float %mul374, %add363
  %mul377 = fmul float %sub150, %mul375
  %mul378 = fmul float %sub151, %mul375
  %mul379 = fmul float %sub152, %mul375
  %add380 = fadd float %add367, %mul377
  %add381 = fadd float %add368, %mul378
  %add382 = fadd float %add369, %mul379
  %sub383 = fsub float %sub338, %mul377
  %sub384 = fsub float %sub342, %mul378
  %sub385 = fsub float %sub346, %mul379
  %mul386 = fmul float %conv190, %conv190
  %mul387 = fmul float %mul6, %conv190
  %mul388 = fmul float %mul387, %mul386
  %add389 = fadd float %mul387, %add376
  %mul390 = fmul float %sub158, %mul388
  %mul391 = fmul float %sub159, %mul388
  %mul392 = fmul float %sub160, %mul388
  %add393 = fadd float %fix3.01002, %mul390
  %add394 = fadd float %fiy3.01001, %mul391
  %add395 = fadd float %fiz3.01000, %mul392
  %sub396 = fsub float %sub357, %mul390
  store float %sub396, float* %arrayidx293, align 4, !tbaa !3
  %sub399 = fsub float %sub358, %mul391
  store float %sub399, float* %arrayidx297, align 4, !tbaa !3
  %sub403 = fsub float %sub359, %mul392
  store float %sub403, float* %arrayidx301, align 4, !tbaa !3
  %mul407 = fmul float %conv202, %conv202
  %mul408 = fmul float %mul8, %conv202
  %mul409 = fmul float %mul408, %mul407
  %add410 = fadd float %mul408, %add389
  %mul411 = fmul float %sub166, %mul409
  %mul412 = fmul float %sub167, %mul409
  %mul413 = fmul float %sub168, %mul409
  %add414 = fadd float %add393, %mul411
  %add415 = fadd float %add394, %mul412
  %add416 = fadd float %add395, %mul413
  %sub417 = fsub float %sub370, %mul411
  store float %sub417, float* %arrayidx315, align 4, !tbaa !3
  %sub421 = fsub float %sub371, %mul412
  store float %sub421, float* %arrayidx319, align 4, !tbaa !3
  %sub425 = fsub float %sub372, %mul413
  store float %sub425, float* %arrayidx323, align 4, !tbaa !3
  %mul429 = fmul float %conv214, %conv214
  %mul430 = fmul float %mul8, %conv214
  %mul431 = fmul float %mul430, %mul429
  %add432 = fadd float %mul430, %add410
  %mul433 = fmul float %sub174, %mul431
  %mul434 = fmul float %sub175, %mul431
  %mul435 = fmul float %sub176, %mul431
  %add436 = fadd float %add414, %mul433
  %add437 = fadd float %add415, %mul434
  %add438 = fadd float %add416, %mul435
  %sub439 = fsub float %sub383, %mul433
  store float %sub439, float* %arrayidx337, align 4, !tbaa !3
  %sub443 = fsub float %sub384, %mul434
  store float %sub443, float* %arrayidx341, align 4, !tbaa !3
  %sub447 = fsub float %sub385, %mul435
  store float %sub447, float* %arrayidx345, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %51 = trunc i64 %indvars.iv.next to i32
  %cmp80 = icmp slt i32 %51, %13
  br i1 %cmp80, label %for.body81, label %for.end

for.end:                                          ; preds = %for.body81, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add432, %for.body81 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add277, %for.body81 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add332, %for.body81 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add333, %for.body81 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add334, %for.body81 ]
  %fix2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add380, %for.body81 ]
  %fiy2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add381, %for.body81 ]
  %fiz2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add382, %for.body81 ]
  %fix3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add436, %for.body81 ]
  %fiy3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add437, %for.body81 ]
  %fiz3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add438, %for.body81 ]
  %arrayidx452 = getelementptr inbounds float* %faction, i64 %idxprom44
  %52 = load float* %arrayidx452, align 4, !tbaa !3
  %add453 = fadd float %fix1.0.lcssa, %52
  store float %add453, float* %arrayidx452, align 4, !tbaa !3
  %arrayidx458 = getelementptr inbounds float* %faction, i64 %idxprom48
  %53 = load float* %arrayidx458, align 4, !tbaa !3
  %add459 = fadd float %fiy1.0.lcssa, %53
  store float %add459, float* %arrayidx458, align 4, !tbaa !3
  %arrayidx465 = getelementptr inbounds float* %faction, i64 %idxprom52
  %54 = load float* %arrayidx465, align 4, !tbaa !3
  %add466 = fadd float %fiz1.0.lcssa, %54
  store float %add466, float* %arrayidx465, align 4, !tbaa !3
  %arrayidx472 = getelementptr inbounds float* %faction, i64 %idxprom56
  %55 = load float* %arrayidx472, align 4, !tbaa !3
  %add473 = fadd float %fix2.0.lcssa, %55
  store float %add473, float* %arrayidx472, align 4, !tbaa !3
  %arrayidx479 = getelementptr inbounds float* %faction, i64 %idxprom60
  %56 = load float* %arrayidx479, align 4, !tbaa !3
  %add480 = fadd float %fiy2.0.lcssa, %56
  store float %add480, float* %arrayidx479, align 4, !tbaa !3
  %arrayidx486 = getelementptr inbounds float* %faction, i64 %idxprom64
  %57 = load float* %arrayidx486, align 4, !tbaa !3
  %add487 = fadd float %fiz2.0.lcssa, %57
  store float %add487, float* %arrayidx486, align 4, !tbaa !3
  %arrayidx493 = getelementptr inbounds float* %faction, i64 %idxprom68
  %58 = load float* %arrayidx493, align 4, !tbaa !3
  %add494 = fadd float %fix3.0.lcssa, %58
  store float %add494, float* %arrayidx493, align 4, !tbaa !3
  %arrayidx500 = getelementptr inbounds float* %faction, i64 %idxprom72
  %59 = load float* %arrayidx500, align 4, !tbaa !3
  %add501 = fadd float %fiy3.0.lcssa, %59
  store float %add501, float* %arrayidx500, align 4, !tbaa !3
  %arrayidx507 = getelementptr inbounds float* %faction, i64 %idxprom76
  %60 = load float* %arrayidx507, align 4, !tbaa !3
  %add508 = fadd float %fiz3.0.lcssa, %60
  store float %add508, float* %arrayidx507, align 4, !tbaa !3
  %arrayidx513 = getelementptr inbounds float* %fshift, i64 %idxprom28
  %61 = load float* %arrayidx513, align 4, !tbaa !3
  %add514 = fadd float %fix1.0.lcssa, %61
  %add515 = fadd float %fix2.0.lcssa, %add514
  %add516 = fadd float %fix3.0.lcssa, %add515
  store float %add516, float* %arrayidx513, align 4, !tbaa !3
  %arrayidx521 = getelementptr inbounds float* %fshift, i64 %idxprom31
  %62 = load float* %arrayidx521, align 4, !tbaa !3
  %add522 = fadd float %fiy1.0.lcssa, %62
  %add523 = fadd float %fiy2.0.lcssa, %add522
  %add524 = fadd float %fiy3.0.lcssa, %add523
  store float %add524, float* %arrayidx521, align 4, !tbaa !3
  %arrayidx530 = getelementptr inbounds float* %fshift, i64 %idxprom34
  %63 = load float* %arrayidx530, align 4, !tbaa !3
  %add531 = fadd float %fiz1.0.lcssa, %63
  %add532 = fadd float %fiz2.0.lcssa, %add531
  %add533 = fadd float %fiz3.0.lcssa, %add532
  store float %add533, float* %arrayidx530, align 4, !tbaa !3
  %arrayidx538 = getelementptr inbounds i32* %gid, i64 %indvars.iv1024
  %64 = load i32* %arrayidx538, align 4, !tbaa !0
  %idxprom539 = sext i32 %64 to i64
  %arrayidx540 = getelementptr inbounds float* %Vc, i64 %idxprom539
  %65 = load float* %arrayidx540, align 4, !tbaa !3
  %add541 = fadd float %vctot.0.lcssa, %65
  store float %add541, float* %arrayidx540, align 4, !tbaa !3
  %arrayidx545 = getelementptr inbounds float* %Vnb, i64 %idxprom539
  %66 = load float* %arrayidx545, align 4, !tbaa !3
  %add546 = fadd float %vnbtot.0.lcssa, %66
  store float %add546, float* %arrayidx545, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next1025 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end551, label %for.end.for.body_crit_edge

for.end.for.body_crit_edge:                       ; preds = %for.end
  %arrayidx37.phi.trans.insert = getelementptr inbounds i32* %iinr, i64 %indvars.iv.next1025
  %.pre = load i32* %arrayidx37.phi.trans.insert, align 4, !tbaa !0
  br label %for.body

for.end551:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl2000(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, float %krf, float %crf) #0 {
entry:
  %cmp232 = icmp sgt i32 %nri, 0
  br i1 %cmp232, label %for.body, label %for.end137

for.body:                                         ; preds = %for.end, %entry
  %indvars.iv234 = phi i64 [ 0, %entry ], [ %indvars.iv.next235, %for.end ]
  %arrayidx = getelementptr inbounds i32* %shift, i64 %indvars.iv234
  %0 = load i32* %arrayidx, align 4, !tbaa !0
  %mul = mul nsw i32 %0, 3
  %idxprom1 = sext i32 %mul to i64
  %arrayidx2 = getelementptr inbounds float* %shiftvec, i64 %idxprom1
  %1 = load float* %arrayidx2, align 4, !tbaa !3
  %add = add nsw i32 %mul, 1
  %idxprom3 = sext i32 %add to i64
  %arrayidx4 = getelementptr inbounds float* %shiftvec, i64 %idxprom3
  %2 = load float* %arrayidx4, align 4, !tbaa !3
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds float* %shiftvec, i64 %idxprom6
  %3 = load float* %arrayidx7, align 4, !tbaa !3
  %arrayidx9 = getelementptr inbounds i32* %iinr, i64 %indvars.iv234
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %arrayidx12 = getelementptr inbounds i32* %jindex, i64 %indvars.iv234
  %5 = load i32* %arrayidx12, align 4, !tbaa !0
  %indvars.iv.next235 = add i64 %indvars.iv234, 1
  %arrayidx15 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next235
  %6 = load i32* %arrayidx15, align 4, !tbaa !0
  %idxprom16 = sext i32 %mul10 to i64
  %arrayidx17 = getelementptr inbounds float* %pos, i64 %idxprom16
  %7 = load float* %arrayidx17, align 4, !tbaa !3
  %add18 = fadd float %1, %7
  %add19 = add nsw i32 %mul10, 1
  %idxprom20 = sext i32 %add19 to i64
  %arrayidx21 = getelementptr inbounds float* %pos, i64 %idxprom20
  %8 = load float* %arrayidx21, align 4, !tbaa !3
  %add22 = fadd float %2, %8
  %add23 = add nsw i32 %mul10, 2
  %idxprom24 = sext i32 %add23 to i64
  %arrayidx25 = getelementptr inbounds float* %pos, i64 %idxprom24
  %9 = load float* %arrayidx25, align 4, !tbaa !3
  %add26 = fadd float %3, %9
  %idxprom27 = sext i32 %4 to i64
  %arrayidx28 = getelementptr inbounds float* %charge, i64 %idxprom27
  %10 = load float* %arrayidx28, align 4, !tbaa !3
  %mul29 = fmul float %10, %facel
  %cmp31223 = icmp slt i32 %5, %6
  br i1 %cmp31223, label %for.body32.lr.ph, label %for.end

for.body32.lr.ph:                                 ; preds = %for.body
  %11 = sext i32 %5 to i64
  br label %for.body32

for.body32:                                       ; preds = %for.body32.lr.ph, %for.body32
  %indvars.iv = phi i64 [ %11, %for.body32.lr.ph ], [ %indvars.iv.next, %for.body32 ]
  %vctot.0227 = phi float [ 0.000000e+00, %for.body32.lr.ph ], [ %add64, %for.body32 ]
  %fix1.0226 = phi float [ 0.000000e+00, %for.body32.lr.ph ], [ %add68, %for.body32 ]
  %fiy1.0225 = phi float [ 0.000000e+00, %for.body32.lr.ph ], [ %add69, %for.body32 ]
  %fiz1.0224 = phi float [ 0.000000e+00, %for.body32.lr.ph ], [ %add70, %for.body32 ]
  %arrayidx34 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %12 = load i32* %arrayidx34, align 4, !tbaa !0
  %mul35 = mul nsw i32 %12, 3
  %idxprom36 = sext i32 %mul35 to i64
  %arrayidx37 = getelementptr inbounds float* %pos, i64 %idxprom36
  %13 = load float* %arrayidx37, align 4, !tbaa !3
  %add38 = add nsw i32 %mul35, 1
  %idxprom39 = sext i32 %add38 to i64
  %arrayidx40 = getelementptr inbounds float* %pos, i64 %idxprom39
  %14 = load float* %arrayidx40, align 4, !tbaa !3
  %add41 = add nsw i32 %mul35, 2
  %idxprom42 = sext i32 %add41 to i64
  %arrayidx43 = getelementptr inbounds float* %pos, i64 %idxprom42
  %15 = load float* %arrayidx43, align 4, !tbaa !3
  %sub = fsub float %add18, %13
  %sub44 = fsub float %add22, %14
  %sub45 = fsub float %add26, %15
  %mul46 = fmul float %sub, %sub
  %mul47 = fmul float %sub44, %sub44
  %add48 = fadd float %mul46, %mul47
  %mul49 = fmul float %sub45, %sub45
  %add50 = fadd float %add48, %mul49
  %conv = fpext float %add50 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv51 = fptrunc double %div to float
  %mul52 = fmul float %conv51, %conv51
  %idxprom53 = sext i32 %12 to i64
  %arrayidx54 = getelementptr inbounds float* %charge, i64 %idxprom53
  %16 = load float* %arrayidx54, align 4, !tbaa !3
  %mul55 = fmul float %mul29, %16
  %mul56 = fmul float %add50, %krf
  %add57 = fadd float %conv51, %mul56
  %sub58 = fsub float %add57, %crf
  %mul59 = fmul float %mul55, %sub58
  %mul60 = fmul float %mul56, 2.000000e+00
  %sub61 = fsub float %conv51, %mul60
  %mul62 = fmul float %mul55, %sub61
  %mul63 = fmul float %mul52, %mul62
  %add64 = fadd float %vctot.0227, %mul59
  %mul65 = fmul float %sub, %mul63
  %mul66 = fmul float %sub44, %mul63
  %mul67 = fmul float %sub45, %mul63
  %add68 = fadd float %fix1.0226, %mul65
  %add69 = fadd float %fiy1.0225, %mul66
  %add70 = fadd float %fiz1.0224, %mul67
  %arrayidx72 = getelementptr inbounds float* %faction, i64 %idxprom36
  %17 = load float* %arrayidx72, align 4, !tbaa !3
  %sub73 = fsub float %17, %mul65
  store float %sub73, float* %arrayidx72, align 4, !tbaa !3
  %arrayidx78 = getelementptr inbounds float* %faction, i64 %idxprom39
  %18 = load float* %arrayidx78, align 4, !tbaa !3
  %sub79 = fsub float %18, %mul66
  store float %sub79, float* %arrayidx78, align 4, !tbaa !3
  %arrayidx85 = getelementptr inbounds float* %faction, i64 %idxprom42
  %19 = load float* %arrayidx85, align 4, !tbaa !3
  %sub86 = fsub float %19, %mul67
  store float %sub86, float* %arrayidx85, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %20 = trunc i64 %indvars.iv.next to i32
  %cmp31 = icmp slt i32 %20, %6
  br i1 %cmp31, label %for.body32, label %for.end

for.end:                                          ; preds = %for.body32, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add64, %for.body32 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add68, %for.body32 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add69, %for.body32 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add70, %for.body32 ]
  %arrayidx91 = getelementptr inbounds float* %faction, i64 %idxprom16
  %21 = load float* %arrayidx91, align 4, !tbaa !3
  %add92 = fadd float %fix1.0.lcssa, %21
  store float %add92, float* %arrayidx91, align 4, !tbaa !3
  %arrayidx97 = getelementptr inbounds float* %faction, i64 %idxprom20
  %22 = load float* %arrayidx97, align 4, !tbaa !3
  %add98 = fadd float %fiy1.0.lcssa, %22
  store float %add98, float* %arrayidx97, align 4, !tbaa !3
  %arrayidx104 = getelementptr inbounds float* %faction, i64 %idxprom24
  %23 = load float* %arrayidx104, align 4, !tbaa !3
  %add105 = fadd float %fiz1.0.lcssa, %23
  store float %add105, float* %arrayidx104, align 4, !tbaa !3
  %arrayidx110 = getelementptr inbounds float* %fshift, i64 %idxprom1
  %24 = load float* %arrayidx110, align 4, !tbaa !3
  %add111 = fadd float %fix1.0.lcssa, %24
  store float %add111, float* %arrayidx110, align 4, !tbaa !3
  %arrayidx116 = getelementptr inbounds float* %fshift, i64 %idxprom3
  %25 = load float* %arrayidx116, align 4, !tbaa !3
  %add117 = fadd float %fiy1.0.lcssa, %25
  store float %add117, float* %arrayidx116, align 4, !tbaa !3
  %arrayidx123 = getelementptr inbounds float* %fshift, i64 %idxprom6
  %26 = load float* %arrayidx123, align 4, !tbaa !3
  %add124 = fadd float %fiz1.0.lcssa, %26
  store float %add124, float* %arrayidx123, align 4, !tbaa !3
  %arrayidx129 = getelementptr inbounds i32* %gid, i64 %indvars.iv234
  %27 = load i32* %arrayidx129, align 4, !tbaa !0
  %idxprom130 = sext i32 %27 to i64
  %arrayidx131 = getelementptr inbounds float* %Vc, i64 %idxprom130
  %28 = load float* %arrayidx131, align 4, !tbaa !3
  %add132 = fadd float %vctot.0.lcssa, %28
  store float %add132, float* %arrayidx131, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next235 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end137, label %for.body

for.end137:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl2010(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, float %krf, float %crf, i32* nocapture %nsatoms) #0 {
entry:
  %cmp265 = icmp sgt i32 %nri, 0
  br i1 %cmp265, label %for.body, label %for.end156

for.body:                                         ; preds = %for.end146, %entry
  %indvars.iv273 = phi i64 [ 0, %entry ], [ %indvars.iv.next274, %for.end146 ]
  %add5 = mul i64 %indvars.iv273, 12884901888
  %sext = add i64 %add5, 8589934592
  %idxprom6 = ashr exact i64 %sext, 32
  %arrayidx7 = getelementptr inbounds i32* %nsatoms, i64 %idxprom6
  %0 = load i32* %arrayidx7, align 4, !tbaa !0
  %arrayidx9 = getelementptr inbounds i32* %shift, i64 %indvars.iv273
  %1 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %1, 3
  %idxprom11 = sext i32 %mul10 to i64
  %arrayidx12 = getelementptr inbounds float* %shiftvec, i64 %idxprom11
  %2 = load float* %arrayidx12, align 4, !tbaa !3
  %add13 = add nsw i32 %mul10, 1
  %idxprom14 = sext i32 %add13 to i64
  %arrayidx15 = getelementptr inbounds float* %shiftvec, i64 %idxprom14
  %3 = load float* %arrayidx15, align 4, !tbaa !3
  %add16 = add nsw i32 %mul10, 2
  %idxprom17 = sext i32 %add16 to i64
  %arrayidx18 = getelementptr inbounds float* %shiftvec, i64 %idxprom17
  %4 = load float* %arrayidx18, align 4, !tbaa !3
  %arrayidx20 = getelementptr inbounds i32* %iinr, i64 %indvars.iv273
  %5 = load i32* %arrayidx20, align 4, !tbaa !0
  %arrayidx23 = getelementptr inbounds i32* %jindex, i64 %indvars.iv273
  %6 = load i32* %arrayidx23, align 4, !tbaa !0
  %indvars.iv.next274 = add i64 %indvars.iv273, 1
  %arrayidx26 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next274
  %7 = load i32* %arrayidx26, align 4, !tbaa !0
  %cmp28259 = icmp sgt i32 %0, 0
  br i1 %cmp28259, label %for.body29.lr.ph, label %for.end146

for.body29.lr.ph:                                 ; preds = %for.body
  %cmp45250 = icmp slt i32 %6, %7
  %arrayidx124 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx130 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx137 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %8 = sext i32 %6 to i64
  %9 = sext i32 %5 to i64
  %10 = mul i32 %5, 3
  %11 = sext i32 %10 to i64
  br label %for.body29

for.body29:                                       ; preds = %for.end, %for.body29.lr.ph
  %indvars.iv269 = phi i64 [ %11, %for.body29.lr.ph ], [ %indvars.iv.next270, %for.end ]
  %indvars.iv267 = phi i64 [ %9, %for.body29.lr.ph ], [ %indvars.iv.next268, %for.end ]
  %s.0261 = phi i32 [ 0, %for.body29.lr.ph ], [ %inc145, %for.end ]
  %vctot.0260 = phi float [ 0.000000e+00, %for.body29.lr.ph ], [ %vctot.1.lcssa, %for.end ]
  %arrayidx31 = getelementptr inbounds float* %pos, i64 %indvars.iv269
  %12 = load float* %arrayidx31, align 4, !tbaa !3
  %add32 = fadd float %2, %12
  %13 = add nsw i64 %indvars.iv269, 1
  %arrayidx35 = getelementptr inbounds float* %pos, i64 %13
  %14 = load float* %arrayidx35, align 4, !tbaa !3
  %add36 = fadd float %3, %14
  %15 = add nsw i64 %indvars.iv269, 2
  %arrayidx39 = getelementptr inbounds float* %pos, i64 %15
  %16 = load float* %arrayidx39, align 4, !tbaa !3
  %add40 = fadd float %4, %16
  %arrayidx42 = getelementptr inbounds float* %charge, i64 %indvars.iv267
  %17 = load float* %arrayidx42, align 4, !tbaa !3
  %mul43 = fmul float %17, %facel
  br i1 %cmp45250, label %for.body46, label %for.end

for.body46:                                       ; preds = %for.body29, %for.body46
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body46 ], [ %8, %for.body29 ]
  %vctot.1254 = phi float [ %add78, %for.body46 ], [ %vctot.0260, %for.body29 ]
  %fix1.0253 = phi float [ %add82, %for.body46 ], [ 0.000000e+00, %for.body29 ]
  %fiy1.0252 = phi float [ %add83, %for.body46 ], [ 0.000000e+00, %for.body29 ]
  %fiz1.0251 = phi float [ %add84, %for.body46 ], [ 0.000000e+00, %for.body29 ]
  %arrayidx48 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %18 = load i32* %arrayidx48, align 4, !tbaa !0
  %mul49 = mul nsw i32 %18, 3
  %idxprom50 = sext i32 %mul49 to i64
  %arrayidx51 = getelementptr inbounds float* %pos, i64 %idxprom50
  %19 = load float* %arrayidx51, align 4, !tbaa !3
  %add52 = add nsw i32 %mul49, 1
  %idxprom53 = sext i32 %add52 to i64
  %arrayidx54 = getelementptr inbounds float* %pos, i64 %idxprom53
  %20 = load float* %arrayidx54, align 4, !tbaa !3
  %add55 = add nsw i32 %mul49, 2
  %idxprom56 = sext i32 %add55 to i64
  %arrayidx57 = getelementptr inbounds float* %pos, i64 %idxprom56
  %21 = load float* %arrayidx57, align 4, !tbaa !3
  %sub = fsub float %add32, %19
  %sub58 = fsub float %add36, %20
  %sub59 = fsub float %add40, %21
  %mul60 = fmul float %sub, %sub
  %mul61 = fmul float %sub58, %sub58
  %add62 = fadd float %mul60, %mul61
  %mul63 = fmul float %sub59, %sub59
  %add64 = fadd float %add62, %mul63
  %conv = fpext float %add64 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv65 = fptrunc double %div to float
  %mul66 = fmul float %conv65, %conv65
  %idxprom67 = sext i32 %18 to i64
  %arrayidx68 = getelementptr inbounds float* %charge, i64 %idxprom67
  %22 = load float* %arrayidx68, align 4, !tbaa !3
  %mul69 = fmul float %mul43, %22
  %mul70 = fmul float %add64, %krf
  %add71 = fadd float %conv65, %mul70
  %sub72 = fsub float %add71, %crf
  %mul73 = fmul float %mul69, %sub72
  %mul74 = fmul float %mul70, 2.000000e+00
  %sub75 = fsub float %conv65, %mul74
  %mul76 = fmul float %mul69, %sub75
  %mul77 = fmul float %mul66, %mul76
  %add78 = fadd float %vctot.1254, %mul73
  %mul79 = fmul float %sub, %mul77
  %mul80 = fmul float %sub58, %mul77
  %mul81 = fmul float %sub59, %mul77
  %add82 = fadd float %fix1.0253, %mul79
  %add83 = fadd float %fiy1.0252, %mul80
  %add84 = fadd float %fiz1.0251, %mul81
  %arrayidx86 = getelementptr inbounds float* %faction, i64 %idxprom50
  %23 = load float* %arrayidx86, align 4, !tbaa !3
  %sub87 = fsub float %23, %mul79
  store float %sub87, float* %arrayidx86, align 4, !tbaa !3
  %arrayidx92 = getelementptr inbounds float* %faction, i64 %idxprom53
  %24 = load float* %arrayidx92, align 4, !tbaa !3
  %sub93 = fsub float %24, %mul80
  store float %sub93, float* %arrayidx92, align 4, !tbaa !3
  %arrayidx99 = getelementptr inbounds float* %faction, i64 %idxprom56
  %25 = load float* %arrayidx99, align 4, !tbaa !3
  %sub100 = fsub float %25, %mul81
  store float %sub100, float* %arrayidx99, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %26 = trunc i64 %indvars.iv.next to i32
  %cmp45 = icmp slt i32 %26, %7
  br i1 %cmp45, label %for.body46, label %for.end

for.end:                                          ; preds = %for.body46, %for.body29
  %vctot.1.lcssa = phi float [ %vctot.0260, %for.body29 ], [ %add78, %for.body46 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add82, %for.body46 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add83, %for.body46 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add84, %for.body46 ]
  %arrayidx105 = getelementptr inbounds float* %faction, i64 %indvars.iv269
  %27 = load float* %arrayidx105, align 4, !tbaa !3
  %add106 = fadd float %fix1.0.lcssa, %27
  store float %add106, float* %arrayidx105, align 4, !tbaa !3
  %arrayidx111 = getelementptr inbounds float* %faction, i64 %13
  %28 = load float* %arrayidx111, align 4, !tbaa !3
  %add112 = fadd float %fiy1.0.lcssa, %28
  store float %add112, float* %arrayidx111, align 4, !tbaa !3
  %arrayidx118 = getelementptr inbounds float* %faction, i64 %15
  %29 = load float* %arrayidx118, align 4, !tbaa !3
  %add119 = fadd float %fiz1.0.lcssa, %29
  store float %add119, float* %arrayidx118, align 4, !tbaa !3
  %30 = load float* %arrayidx124, align 4, !tbaa !3
  %add125 = fadd float %fix1.0.lcssa, %30
  store float %add125, float* %arrayidx124, align 4, !tbaa !3
  %31 = load float* %arrayidx130, align 4, !tbaa !3
  %add131 = fadd float %fiy1.0.lcssa, %31
  store float %add131, float* %arrayidx130, align 4, !tbaa !3
  %32 = load float* %arrayidx137, align 4, !tbaa !3
  %add138 = fadd float %fiz1.0.lcssa, %32
  store float %add138, float* %arrayidx137, align 4, !tbaa !3
  %indvars.iv.next268 = add i64 %indvars.iv267, 1
  %indvars.iv.next270 = add i64 %indvars.iv269, 3
  %inc145 = add nsw i32 %s.0261, 1
  %exitcond = icmp eq i32 %inc145, %0
  br i1 %exitcond, label %for.end146, label %for.body29

for.end146:                                       ; preds = %for.end, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %vctot.1.lcssa, %for.end ]
  %arrayidx148 = getelementptr inbounds i32* %gid, i64 %indvars.iv273
  %33 = load i32* %arrayidx148, align 4, !tbaa !0
  %idxprom149 = sext i32 %33 to i64
  %arrayidx150 = getelementptr inbounds float* %Vc, i64 %idxprom149
  %34 = load float* %arrayidx150, align 4, !tbaa !3
  %add151 = fadd float %vctot.0.lcssa, %34
  store float %add151, float* %arrayidx150, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next274 to i32
  %exitcond275 = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond275, label %for.end156, label %for.body

for.end156:                                       ; preds = %for.end146, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl2020(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, float %krf, float %crf) #0 {
entry:
  %0 = load i32* %iinr, align 4, !tbaa !0
  %idxprom = sext i32 %0 to i64
  %arrayidx1 = getelementptr inbounds float* %charge, i64 %idxprom
  %1 = load float* %arrayidx1, align 4, !tbaa !3
  %add = add nsw i32 %0, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds float* %charge, i64 %idxprom2
  %2 = load float* %arrayidx3, align 4, !tbaa !3
  %mul = fmul float %1, %facel
  %mul4 = fmul float %2, %facel
  %cmp509 = icmp sgt i32 %nri, 0
  br i1 %cmp509, label %for.body, label %for.end282

for.body:                                         ; preds = %entry, %for.end.for.body_crit_edge
  %3 = phi i32 [ %.pre, %for.end.for.body_crit_edge ], [ %0, %entry ]
  %indvars.iv511 = phi i64 [ %indvars.iv.next512, %for.end.for.body_crit_edge ], [ 0, %entry ]
  %arrayidx6 = getelementptr inbounds i32* %shift, i64 %indvars.iv511
  %4 = load i32* %arrayidx6, align 4, !tbaa !0
  %mul7 = mul nsw i32 %4, 3
  %idxprom8 = sext i32 %mul7 to i64
  %arrayidx9 = getelementptr inbounds float* %shiftvec, i64 %idxprom8
  %5 = load float* %arrayidx9, align 4, !tbaa !3
  %add10 = add nsw i32 %mul7, 1
  %idxprom11 = sext i32 %add10 to i64
  %arrayidx12 = getelementptr inbounds float* %shiftvec, i64 %idxprom11
  %6 = load float* %arrayidx12, align 4, !tbaa !3
  %add13 = add nsw i32 %mul7, 2
  %idxprom14 = sext i32 %add13 to i64
  %arrayidx15 = getelementptr inbounds float* %shiftvec, i64 %idxprom14
  %7 = load float* %arrayidx15, align 4, !tbaa !3
  %mul18 = mul nsw i32 %3, 3
  %arrayidx20 = getelementptr inbounds i32* %jindex, i64 %indvars.iv511
  %8 = load i32* %arrayidx20, align 4, !tbaa !0
  %indvars.iv.next512 = add i64 %indvars.iv511, 1
  %arrayidx23 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next512
  %9 = load i32* %arrayidx23, align 4, !tbaa !0
  %idxprom24 = sext i32 %mul18 to i64
  %arrayidx25 = getelementptr inbounds float* %pos, i64 %idxprom24
  %10 = load float* %arrayidx25, align 4, !tbaa !3
  %add26 = fadd float %5, %10
  %add27 = add nsw i32 %mul18, 1
  %idxprom28 = sext i32 %add27 to i64
  %arrayidx29 = getelementptr inbounds float* %pos, i64 %idxprom28
  %11 = load float* %arrayidx29, align 4, !tbaa !3
  %add30 = fadd float %6, %11
  %add31 = add nsw i32 %mul18, 2
  %idxprom32 = sext i32 %add31 to i64
  %arrayidx33 = getelementptr inbounds float* %pos, i64 %idxprom32
  %12 = load float* %arrayidx33, align 4, !tbaa !3
  %add34 = fadd float %7, %12
  %add35 = add nsw i32 %mul18, 3
  %idxprom36 = sext i32 %add35 to i64
  %arrayidx37 = getelementptr inbounds float* %pos, i64 %idxprom36
  %13 = load float* %arrayidx37, align 4, !tbaa !3
  %add38 = fadd float %5, %13
  %add39 = add nsw i32 %mul18, 4
  %idxprom40 = sext i32 %add39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %14 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = fadd float %6, %14
  %add43 = add nsw i32 %mul18, 5
  %idxprom44 = sext i32 %add43 to i64
  %arrayidx45 = getelementptr inbounds float* %pos, i64 %idxprom44
  %15 = load float* %arrayidx45, align 4, !tbaa !3
  %add46 = fadd float %7, %15
  %add47 = add nsw i32 %mul18, 6
  %idxprom48 = sext i32 %add47 to i64
  %arrayidx49 = getelementptr inbounds float* %pos, i64 %idxprom48
  %16 = load float* %arrayidx49, align 4, !tbaa !3
  %add50 = fadd float %5, %16
  %add51 = add nsw i32 %mul18, 7
  %idxprom52 = sext i32 %add51 to i64
  %arrayidx53 = getelementptr inbounds float* %pos, i64 %idxprom52
  %17 = load float* %arrayidx53, align 4, !tbaa !3
  %add54 = fadd float %6, %17
  %add55 = add nsw i32 %mul18, 8
  %idxprom56 = sext i32 %add55 to i64
  %arrayidx57 = getelementptr inbounds float* %pos, i64 %idxprom56
  %18 = load float* %arrayidx57, align 4, !tbaa !3
  %add58 = fadd float %7, %18
  %cmp60488 = icmp slt i32 %8, %9
  br i1 %cmp60488, label %for.body61.lr.ph, label %for.end

for.body61.lr.ph:                                 ; preds = %for.body
  %19 = sext i32 %8 to i64
  br label %for.body61

for.body61:                                       ; preds = %for.body61.lr.ph, %for.body61
  %indvars.iv = phi i64 [ %19, %for.body61.lr.ph ], [ %indvars.iv.next, %for.body61 ]
  %vctot.0498 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add169, %for.body61 ]
  %fix1.0497 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add121, %for.body61 ]
  %fiy1.0496 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add122, %for.body61 ]
  %fiz1.0495 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add123, %for.body61 ]
  %fix2.0494 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add151, %for.body61 ]
  %fiy2.0493 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add152, %for.body61 ]
  %fiz2.0492 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add153, %for.body61 ]
  %fix3.0491 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add173, %for.body61 ]
  %fiy3.0490 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add174, %for.body61 ]
  %fiz3.0489 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add175, %for.body61 ]
  %arrayidx63 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %20 = load i32* %arrayidx63, align 4, !tbaa !0
  %mul64 = mul nsw i32 %20, 3
  %idxprom65 = sext i32 %mul64 to i64
  %arrayidx66 = getelementptr inbounds float* %pos, i64 %idxprom65
  %21 = load float* %arrayidx66, align 4, !tbaa !3
  %add67 = add nsw i32 %mul64, 1
  %idxprom68 = sext i32 %add67 to i64
  %arrayidx69 = getelementptr inbounds float* %pos, i64 %idxprom68
  %22 = load float* %arrayidx69, align 4, !tbaa !3
  %add70 = add nsw i32 %mul64, 2
  %idxprom71 = sext i32 %add70 to i64
  %arrayidx72 = getelementptr inbounds float* %pos, i64 %idxprom71
  %23 = load float* %arrayidx72, align 4, !tbaa !3
  %sub = fsub float %add26, %21
  %sub73 = fsub float %add30, %22
  %sub74 = fsub float %add34, %23
  %mul75 = fmul float %sub, %sub
  %mul76 = fmul float %sub73, %sub73
  %add77 = fadd float %mul75, %mul76
  %mul78 = fmul float %sub74, %sub74
  %add79 = fadd float %add77, %mul78
  %sub80 = fsub float %add38, %21
  %sub81 = fsub float %add42, %22
  %sub82 = fsub float %add46, %23
  %mul83 = fmul float %sub80, %sub80
  %mul84 = fmul float %sub81, %sub81
  %add85 = fadd float %mul83, %mul84
  %mul86 = fmul float %sub82, %sub82
  %add87 = fadd float %add85, %mul86
  %sub88 = fsub float %add50, %21
  %sub89 = fsub float %add54, %22
  %sub90 = fsub float %add58, %23
  %mul91 = fmul float %sub88, %sub88
  %mul92 = fmul float %sub89, %sub89
  %add93 = fadd float %mul91, %mul92
  %mul94 = fmul float %sub90, %sub90
  %add95 = fadd float %add93, %mul94
  %conv = fpext float %add79 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv96 = fptrunc double %div to float
  %conv97 = fpext float %add87 to double
  %call98 = tail call double @sqrt(double %conv97) #2
  %div99 = fdiv double 1.000000e+00, %call98
  %conv100 = fptrunc double %div99 to float
  %conv101 = fpext float %add95 to double
  %call102 = tail call double @sqrt(double %conv101) #2
  %div103 = fdiv double 1.000000e+00, %call102
  %conv104 = fptrunc double %div103 to float
  %mul105 = fmul float %conv96, %conv96
  %idxprom106 = sext i32 %20 to i64
  %arrayidx107 = getelementptr inbounds float* %charge, i64 %idxprom106
  %24 = load float* %arrayidx107, align 4, !tbaa !3
  %mul108 = fmul float %mul, %24
  %mul109 = fmul float %add79, %krf
  %add110 = fadd float %conv96, %mul109
  %sub111 = fsub float %add110, %crf
  %mul112 = fmul float %sub111, %mul108
  %mul113 = fmul float %mul109, 2.000000e+00
  %sub114 = fsub float %conv96, %mul113
  %mul115 = fmul float %sub114, %mul108
  %mul116 = fmul float %mul105, %mul115
  %add117 = fadd float %vctot.0498, %mul112
  %mul118 = fmul float %sub, %mul116
  %mul119 = fmul float %sub73, %mul116
  %mul120 = fmul float %sub74, %mul116
  %add121 = fadd float %fix1.0497, %mul118
  %add122 = fadd float %fiy1.0496, %mul119
  %add123 = fadd float %fiz1.0495, %mul120
  %arrayidx125 = getelementptr inbounds float* %faction, i64 %idxprom65
  %25 = load float* %arrayidx125, align 4, !tbaa !3
  %sub126 = fsub float %25, %mul118
  %arrayidx129 = getelementptr inbounds float* %faction, i64 %idxprom68
  %26 = load float* %arrayidx129, align 4, !tbaa !3
  %sub130 = fsub float %26, %mul119
  %arrayidx133 = getelementptr inbounds float* %faction, i64 %idxprom71
  %27 = load float* %arrayidx133, align 4, !tbaa !3
  %sub134 = fsub float %27, %mul120
  %mul135 = fmul float %conv100, %conv100
  %mul138 = fmul float %mul4, %24
  %mul139 = fmul float %add87, %krf
  %add140 = fadd float %mul139, %conv100
  %sub141 = fsub float %add140, %crf
  %mul142 = fmul float %sub141, %mul138
  %mul143 = fmul float %mul139, 2.000000e+00
  %sub144 = fsub float %conv100, %mul143
  %mul145 = fmul float %sub144, %mul138
  %mul146 = fmul float %mul135, %mul145
  %add147 = fadd float %mul142, %add117
  %mul148 = fmul float %sub80, %mul146
  %mul149 = fmul float %sub81, %mul146
  %mul150 = fmul float %sub82, %mul146
  %add151 = fadd float %fix2.0494, %mul148
  %add152 = fadd float %fiy2.0493, %mul149
  %add153 = fadd float %fiz2.0492, %mul150
  %sub154 = fsub float %sub126, %mul148
  %sub155 = fsub float %sub130, %mul149
  %sub156 = fsub float %sub134, %mul150
  %mul157 = fmul float %conv104, %conv104
  %mul161 = fmul float %add95, %krf
  %add162 = fadd float %mul161, %conv104
  %sub163 = fsub float %add162, %crf
  %mul164 = fmul float %mul138, %sub163
  %mul165 = fmul float %mul161, 2.000000e+00
  %sub166 = fsub float %conv104, %mul165
  %mul167 = fmul float %mul138, %sub166
  %mul168 = fmul float %mul157, %mul167
  %add169 = fadd float %mul164, %add147
  %mul170 = fmul float %sub88, %mul168
  %mul171 = fmul float %sub89, %mul168
  %mul172 = fmul float %sub90, %mul168
  %add173 = fadd float %fix3.0491, %mul170
  %add174 = fadd float %fiy3.0490, %mul171
  %add175 = fadd float %fiz3.0489, %mul172
  %sub176 = fsub float %sub154, %mul170
  store float %sub176, float* %arrayidx125, align 4, !tbaa !3
  %sub179 = fsub float %sub155, %mul171
  store float %sub179, float* %arrayidx129, align 4, !tbaa !3
  %sub183 = fsub float %sub156, %mul172
  store float %sub183, float* %arrayidx133, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %28 = trunc i64 %indvars.iv.next to i32
  %cmp60 = icmp slt i32 %28, %9
  br i1 %cmp60, label %for.body61, label %for.end

for.end:                                          ; preds = %for.body61, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add169, %for.body61 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add121, %for.body61 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add122, %for.body61 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add123, %for.body61 ]
  %fix2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add151, %for.body61 ]
  %fiy2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add152, %for.body61 ]
  %fiz2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add153, %for.body61 ]
  %fix3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add173, %for.body61 ]
  %fiy3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add174, %for.body61 ]
  %fiz3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add175, %for.body61 ]
  %arrayidx188 = getelementptr inbounds float* %faction, i64 %idxprom24
  %29 = load float* %arrayidx188, align 4, !tbaa !3
  %add189 = fadd float %fix1.0.lcssa, %29
  store float %add189, float* %arrayidx188, align 4, !tbaa !3
  %arrayidx194 = getelementptr inbounds float* %faction, i64 %idxprom28
  %30 = load float* %arrayidx194, align 4, !tbaa !3
  %add195 = fadd float %fiy1.0.lcssa, %30
  store float %add195, float* %arrayidx194, align 4, !tbaa !3
  %arrayidx201 = getelementptr inbounds float* %faction, i64 %idxprom32
  %31 = load float* %arrayidx201, align 4, !tbaa !3
  %add202 = fadd float %fiz1.0.lcssa, %31
  store float %add202, float* %arrayidx201, align 4, !tbaa !3
  %arrayidx208 = getelementptr inbounds float* %faction, i64 %idxprom36
  %32 = load float* %arrayidx208, align 4, !tbaa !3
  %add209 = fadd float %fix2.0.lcssa, %32
  store float %add209, float* %arrayidx208, align 4, !tbaa !3
  %arrayidx215 = getelementptr inbounds float* %faction, i64 %idxprom40
  %33 = load float* %arrayidx215, align 4, !tbaa !3
  %add216 = fadd float %fiy2.0.lcssa, %33
  store float %add216, float* %arrayidx215, align 4, !tbaa !3
  %arrayidx222 = getelementptr inbounds float* %faction, i64 %idxprom44
  %34 = load float* %arrayidx222, align 4, !tbaa !3
  %add223 = fadd float %fiz2.0.lcssa, %34
  store float %add223, float* %arrayidx222, align 4, !tbaa !3
  %arrayidx229 = getelementptr inbounds float* %faction, i64 %idxprom48
  %35 = load float* %arrayidx229, align 4, !tbaa !3
  %add230 = fadd float %fix3.0.lcssa, %35
  store float %add230, float* %arrayidx229, align 4, !tbaa !3
  %arrayidx236 = getelementptr inbounds float* %faction, i64 %idxprom52
  %36 = load float* %arrayidx236, align 4, !tbaa !3
  %add237 = fadd float %fiy3.0.lcssa, %36
  store float %add237, float* %arrayidx236, align 4, !tbaa !3
  %arrayidx243 = getelementptr inbounds float* %faction, i64 %idxprom56
  %37 = load float* %arrayidx243, align 4, !tbaa !3
  %add244 = fadd float %fiz3.0.lcssa, %37
  store float %add244, float* %arrayidx243, align 4, !tbaa !3
  %arrayidx249 = getelementptr inbounds float* %fshift, i64 %idxprom8
  %38 = load float* %arrayidx249, align 4, !tbaa !3
  %add250 = fadd float %fix1.0.lcssa, %38
  %add251 = fadd float %fix2.0.lcssa, %add250
  %add252 = fadd float %fix3.0.lcssa, %add251
  store float %add252, float* %arrayidx249, align 4, !tbaa !3
  %arrayidx257 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %39 = load float* %arrayidx257, align 4, !tbaa !3
  %add258 = fadd float %fiy1.0.lcssa, %39
  %add259 = fadd float %fiy2.0.lcssa, %add258
  %add260 = fadd float %fiy3.0.lcssa, %add259
  store float %add260, float* %arrayidx257, align 4, !tbaa !3
  %arrayidx266 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %40 = load float* %arrayidx266, align 4, !tbaa !3
  %add267 = fadd float %fiz1.0.lcssa, %40
  %add268 = fadd float %fiz2.0.lcssa, %add267
  %add269 = fadd float %fiz3.0.lcssa, %add268
  store float %add269, float* %arrayidx266, align 4, !tbaa !3
  %arrayidx274 = getelementptr inbounds i32* %gid, i64 %indvars.iv511
  %41 = load i32* %arrayidx274, align 4, !tbaa !0
  %idxprom275 = sext i32 %41 to i64
  %arrayidx276 = getelementptr inbounds float* %Vc, i64 %idxprom275
  %42 = load float* %arrayidx276, align 4, !tbaa !3
  %add277 = fadd float %vctot.0.lcssa, %42
  store float %add277, float* %arrayidx276, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next512 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end282, label %for.end.for.body_crit_edge

for.end.for.body_crit_edge:                       ; preds = %for.end
  %arrayidx17.phi.trans.insert = getelementptr inbounds i32* %iinr, i64 %indvars.iv.next512
  %.pre = load i32* %arrayidx17.phi.trans.insert, align 4, !tbaa !0
  br label %for.body

for.end282:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl2030(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, float %krf, float %crf) #0 {
entry:
  %0 = load i32* %iinr, align 4, !tbaa !0
  %idxprom = sext i32 %0 to i64
  %arrayidx1 = getelementptr inbounds float* %charge, i64 %idxprom
  %1 = load float* %arrayidx1, align 4, !tbaa !3
  %add = add nsw i32 %0, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds float* %charge, i64 %idxprom2
  %2 = load float* %arrayidx3, align 4, !tbaa !3
  %mul = fmul float %1, %facel
  %mul4 = fmul float %1, %mul
  %mul6 = fmul float %mul, %2
  %mul7 = fmul float %2, %facel
  %mul8 = fmul float %2, %mul7
  %cmp966 = icmp sgt i32 %nri, 0
  br i1 %cmp966, label %for.body, label %for.end517

for.body:                                         ; preds = %entry, %for.end.for.body_crit_edge
  %3 = phi i32 [ %.pre, %for.end.for.body_crit_edge ], [ %0, %entry ]
  %indvars.iv968 = phi i64 [ %indvars.iv.next969, %for.end.for.body_crit_edge ], [ 0, %entry ]
  %arrayidx10 = getelementptr inbounds i32* %shift, i64 %indvars.iv968
  %4 = load i32* %arrayidx10, align 4, !tbaa !0
  %mul11 = mul nsw i32 %4, 3
  %idxprom12 = sext i32 %mul11 to i64
  %arrayidx13 = getelementptr inbounds float* %shiftvec, i64 %idxprom12
  %5 = load float* %arrayidx13, align 4, !tbaa !3
  %add14 = add nsw i32 %mul11, 1
  %idxprom15 = sext i32 %add14 to i64
  %arrayidx16 = getelementptr inbounds float* %shiftvec, i64 %idxprom15
  %6 = load float* %arrayidx16, align 4, !tbaa !3
  %add17 = add nsw i32 %mul11, 2
  %idxprom18 = sext i32 %add17 to i64
  %arrayidx19 = getelementptr inbounds float* %shiftvec, i64 %idxprom18
  %7 = load float* %arrayidx19, align 4, !tbaa !3
  %mul22 = mul nsw i32 %3, 3
  %arrayidx24 = getelementptr inbounds i32* %jindex, i64 %indvars.iv968
  %8 = load i32* %arrayidx24, align 4, !tbaa !0
  %indvars.iv.next969 = add i64 %indvars.iv968, 1
  %arrayidx27 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next969
  %9 = load i32* %arrayidx27, align 4, !tbaa !0
  %idxprom28 = sext i32 %mul22 to i64
  %arrayidx29 = getelementptr inbounds float* %pos, i64 %idxprom28
  %10 = load float* %arrayidx29, align 4, !tbaa !3
  %add30 = fadd float %5, %10
  %add31 = add nsw i32 %mul22, 1
  %idxprom32 = sext i32 %add31 to i64
  %arrayidx33 = getelementptr inbounds float* %pos, i64 %idxprom32
  %11 = load float* %arrayidx33, align 4, !tbaa !3
  %add34 = fadd float %6, %11
  %add35 = add nsw i32 %mul22, 2
  %idxprom36 = sext i32 %add35 to i64
  %arrayidx37 = getelementptr inbounds float* %pos, i64 %idxprom36
  %12 = load float* %arrayidx37, align 4, !tbaa !3
  %add38 = fadd float %7, %12
  %add39 = add nsw i32 %mul22, 3
  %idxprom40 = sext i32 %add39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %13 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = fadd float %5, %13
  %add43 = add nsw i32 %mul22, 4
  %idxprom44 = sext i32 %add43 to i64
  %arrayidx45 = getelementptr inbounds float* %pos, i64 %idxprom44
  %14 = load float* %arrayidx45, align 4, !tbaa !3
  %add46 = fadd float %6, %14
  %add47 = add nsw i32 %mul22, 5
  %idxprom48 = sext i32 %add47 to i64
  %arrayidx49 = getelementptr inbounds float* %pos, i64 %idxprom48
  %15 = load float* %arrayidx49, align 4, !tbaa !3
  %add50 = fadd float %7, %15
  %add51 = add nsw i32 %mul22, 6
  %idxprom52 = sext i32 %add51 to i64
  %arrayidx53 = getelementptr inbounds float* %pos, i64 %idxprom52
  %16 = load float* %arrayidx53, align 4, !tbaa !3
  %add54 = fadd float %5, %16
  %add55 = add nsw i32 %mul22, 7
  %idxprom56 = sext i32 %add55 to i64
  %arrayidx57 = getelementptr inbounds float* %pos, i64 %idxprom56
  %17 = load float* %arrayidx57, align 4, !tbaa !3
  %add58 = fadd float %6, %17
  %add59 = add nsw i32 %mul22, 8
  %idxprom60 = sext i32 %add59 to i64
  %arrayidx61 = getelementptr inbounds float* %pos, i64 %idxprom60
  %18 = load float* %arrayidx61, align 4, !tbaa !3
  %add62 = fadd float %7, %18
  %cmp64945 = icmp slt i32 %8, %9
  br i1 %cmp64945, label %for.body65.lr.ph, label %for.end

for.body65.lr.ph:                                 ; preds = %for.body
  %19 = sext i32 %8 to i64
  br label %for.body65

for.body65:                                       ; preds = %for.body65.lr.ph, %for.body65
  %indvars.iv = phi i64 [ %19, %for.body65.lr.ph ], [ %indvars.iv.next, %for.body65 ]
  %vctot.0955 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add403, %for.body65 ]
  %fix1.0954 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add267, %for.body65 ]
  %fiy1.0953 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add268, %for.body65 ]
  %fiz1.0952 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add269, %for.body65 ]
  %fix2.0951 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add333, %for.body65 ]
  %fiy2.0950 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add334, %for.body65 ]
  %fiz2.0949 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add335, %for.body65 ]
  %fix3.0948 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add407, %for.body65 ]
  %fiy3.0947 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add408, %for.body65 ]
  %fiz3.0946 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add409, %for.body65 ]
  %arrayidx67 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %20 = load i32* %arrayidx67, align 4, !tbaa !0
  %mul68 = mul nsw i32 %20, 3
  %idxprom69 = sext i32 %mul68 to i64
  %arrayidx70 = getelementptr inbounds float* %pos, i64 %idxprom69
  %21 = load float* %arrayidx70, align 4, !tbaa !3
  %add71 = add nsw i32 %mul68, 1
  %idxprom72 = sext i32 %add71 to i64
  %arrayidx73 = getelementptr inbounds float* %pos, i64 %idxprom72
  %22 = load float* %arrayidx73, align 4, !tbaa !3
  %add74 = add nsw i32 %mul68, 2
  %idxprom75 = sext i32 %add74 to i64
  %arrayidx76 = getelementptr inbounds float* %pos, i64 %idxprom75
  %23 = load float* %arrayidx76, align 4, !tbaa !3
  %add77 = add nsw i32 %mul68, 3
  %idxprom78 = sext i32 %add77 to i64
  %arrayidx79 = getelementptr inbounds float* %pos, i64 %idxprom78
  %24 = load float* %arrayidx79, align 4, !tbaa !3
  %add80 = add nsw i32 %mul68, 4
  %idxprom81 = sext i32 %add80 to i64
  %arrayidx82 = getelementptr inbounds float* %pos, i64 %idxprom81
  %25 = load float* %arrayidx82, align 4, !tbaa !3
  %add83 = add nsw i32 %mul68, 5
  %idxprom84 = sext i32 %add83 to i64
  %arrayidx85 = getelementptr inbounds float* %pos, i64 %idxprom84
  %26 = load float* %arrayidx85, align 4, !tbaa !3
  %add86 = add nsw i32 %mul68, 6
  %idxprom87 = sext i32 %add86 to i64
  %arrayidx88 = getelementptr inbounds float* %pos, i64 %idxprom87
  %27 = load float* %arrayidx88, align 4, !tbaa !3
  %add89 = add nsw i32 %mul68, 7
  %idxprom90 = sext i32 %add89 to i64
  %arrayidx91 = getelementptr inbounds float* %pos, i64 %idxprom90
  %28 = load float* %arrayidx91, align 4, !tbaa !3
  %add92 = add nsw i32 %mul68, 8
  %idxprom93 = sext i32 %add92 to i64
  %arrayidx94 = getelementptr inbounds float* %pos, i64 %idxprom93
  %29 = load float* %arrayidx94, align 4, !tbaa !3
  %sub = fsub float %add30, %21
  %sub95 = fsub float %add34, %22
  %sub96 = fsub float %add38, %23
  %mul97 = fmul float %sub, %sub
  %mul98 = fmul float %sub95, %sub95
  %add99 = fadd float %mul97, %mul98
  %mul100 = fmul float %sub96, %sub96
  %add101 = fadd float %add99, %mul100
  %sub102 = fsub float %add30, %24
  %sub103 = fsub float %add34, %25
  %sub104 = fsub float %add38, %26
  %mul105 = fmul float %sub102, %sub102
  %mul106 = fmul float %sub103, %sub103
  %add107 = fadd float %mul105, %mul106
  %mul108 = fmul float %sub104, %sub104
  %add109 = fadd float %add107, %mul108
  %sub110 = fsub float %add30, %27
  %sub111 = fsub float %add34, %28
  %sub112 = fsub float %add38, %29
  %mul113 = fmul float %sub110, %sub110
  %mul114 = fmul float %sub111, %sub111
  %add115 = fadd float %mul113, %mul114
  %mul116 = fmul float %sub112, %sub112
  %add117 = fadd float %add115, %mul116
  %sub118 = fsub float %add42, %21
  %sub119 = fsub float %add46, %22
  %sub120 = fsub float %add50, %23
  %mul121 = fmul float %sub118, %sub118
  %mul122 = fmul float %sub119, %sub119
  %add123 = fadd float %mul121, %mul122
  %mul124 = fmul float %sub120, %sub120
  %add125 = fadd float %add123, %mul124
  %sub126 = fsub float %add42, %24
  %sub127 = fsub float %add46, %25
  %sub128 = fsub float %add50, %26
  %mul129 = fmul float %sub126, %sub126
  %mul130 = fmul float %sub127, %sub127
  %add131 = fadd float %mul129, %mul130
  %mul132 = fmul float %sub128, %sub128
  %add133 = fadd float %add131, %mul132
  %sub134 = fsub float %add42, %27
  %sub135 = fsub float %add46, %28
  %sub136 = fsub float %add50, %29
  %mul137 = fmul float %sub134, %sub134
  %mul138 = fmul float %sub135, %sub135
  %add139 = fadd float %mul137, %mul138
  %mul140 = fmul float %sub136, %sub136
  %add141 = fadd float %add139, %mul140
  %sub142 = fsub float %add54, %21
  %sub143 = fsub float %add58, %22
  %sub144 = fsub float %add62, %23
  %mul145 = fmul float %sub142, %sub142
  %mul146 = fmul float %sub143, %sub143
  %add147 = fadd float %mul145, %mul146
  %mul148 = fmul float %sub144, %sub144
  %add149 = fadd float %add147, %mul148
  %sub150 = fsub float %add54, %24
  %sub151 = fsub float %add58, %25
  %sub152 = fsub float %add62, %26
  %mul153 = fmul float %sub150, %sub150
  %mul154 = fmul float %sub151, %sub151
  %add155 = fadd float %mul153, %mul154
  %mul156 = fmul float %sub152, %sub152
  %add157 = fadd float %add155, %mul156
  %sub158 = fsub float %add54, %27
  %sub159 = fsub float %add58, %28
  %sub160 = fsub float %add62, %29
  %mul161 = fmul float %sub158, %sub158
  %mul162 = fmul float %sub159, %sub159
  %add163 = fadd float %mul161, %mul162
  %mul164 = fmul float %sub160, %sub160
  %add165 = fadd float %add163, %mul164
  %conv = fpext float %add101 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv166 = fptrunc double %div to float
  %conv167 = fpext float %add125 to double
  %call168 = tail call double @sqrt(double %conv167) #2
  %div169 = fdiv double 1.000000e+00, %call168
  %conv170 = fptrunc double %div169 to float
  %conv171 = fpext float %add149 to double
  %call172 = tail call double @sqrt(double %conv171) #2
  %div173 = fdiv double 1.000000e+00, %call172
  %conv174 = fptrunc double %div173 to float
  %conv175 = fpext float %add109 to double
  %call176 = tail call double @sqrt(double %conv175) #2
  %div177 = fdiv double 1.000000e+00, %call176
  %conv178 = fptrunc double %div177 to float
  %conv179 = fpext float %add133 to double
  %call180 = tail call double @sqrt(double %conv179) #2
  %div181 = fdiv double 1.000000e+00, %call180
  %conv182 = fptrunc double %div181 to float
  %conv183 = fpext float %add157 to double
  %call184 = tail call double @sqrt(double %conv183) #2
  %div185 = fdiv double 1.000000e+00, %call184
  %conv186 = fptrunc double %div185 to float
  %conv187 = fpext float %add117 to double
  %call188 = tail call double @sqrt(double %conv187) #2
  %div189 = fdiv double 1.000000e+00, %call188
  %conv190 = fptrunc double %div189 to float
  %conv191 = fpext float %add141 to double
  %call192 = tail call double @sqrt(double %conv191) #2
  %div193 = fdiv double 1.000000e+00, %call192
  %conv194 = fptrunc double %div193 to float
  %conv195 = fpext float %add165 to double
  %call196 = tail call double @sqrt(double %conv195) #2
  %div197 = fdiv double 1.000000e+00, %call196
  %conv198 = fptrunc double %div197 to float
  %mul199 = fmul float %conv166, %conv166
  %mul200 = fmul float %add101, %krf
  %add201 = fadd float %mul200, %conv166
  %sub202 = fsub float %add201, %crf
  %mul203 = fmul float %mul4, %sub202
  %mul204 = fmul float %mul200, 2.000000e+00
  %sub205 = fsub float %conv166, %mul204
  %mul206 = fmul float %mul4, %sub205
  %mul207 = fmul float %mul199, %mul206
  %add208 = fadd float %vctot.0955, %mul203
  %mul209 = fmul float %sub, %mul207
  %mul210 = fmul float %sub95, %mul207
  %mul211 = fmul float %sub96, %mul207
  %add212 = fadd float %fix1.0954, %mul209
  %add213 = fadd float %fiy1.0953, %mul210
  %add214 = fadd float %fiz1.0952, %mul211
  %arrayidx216 = getelementptr inbounds float* %faction, i64 %idxprom69
  %30 = load float* %arrayidx216, align 4, !tbaa !3
  %sub217 = fsub float %30, %mul209
  %arrayidx220 = getelementptr inbounds float* %faction, i64 %idxprom72
  %31 = load float* %arrayidx220, align 4, !tbaa !3
  %sub221 = fsub float %31, %mul210
  %arrayidx224 = getelementptr inbounds float* %faction, i64 %idxprom75
  %32 = load float* %arrayidx224, align 4, !tbaa !3
  %sub225 = fsub float %32, %mul211
  %mul226 = fmul float %conv178, %conv178
  %mul227 = fmul float %add109, %krf
  %add228 = fadd float %mul227, %conv178
  %sub229 = fsub float %add228, %crf
  %mul230 = fmul float %mul6, %sub229
  %mul231 = fmul float %mul227, 2.000000e+00
  %sub232 = fsub float %conv178, %mul231
  %mul233 = fmul float %mul6, %sub232
  %mul234 = fmul float %mul226, %mul233
  %add235 = fadd float %add208, %mul230
  %mul236 = fmul float %sub102, %mul234
  %mul237 = fmul float %sub103, %mul234
  %mul238 = fmul float %sub104, %mul234
  %add239 = fadd float %add212, %mul236
  %add240 = fadd float %add213, %mul237
  %add241 = fadd float %add214, %mul238
  %arrayidx244 = getelementptr inbounds float* %faction, i64 %idxprom78
  %33 = load float* %arrayidx244, align 4, !tbaa !3
  %sub245 = fsub float %33, %mul236
  %arrayidx248 = getelementptr inbounds float* %faction, i64 %idxprom81
  %34 = load float* %arrayidx248, align 4, !tbaa !3
  %sub249 = fsub float %34, %mul237
  %arrayidx252 = getelementptr inbounds float* %faction, i64 %idxprom84
  %35 = load float* %arrayidx252, align 4, !tbaa !3
  %sub253 = fsub float %35, %mul238
  %mul254 = fmul float %conv190, %conv190
  %mul255 = fmul float %add117, %krf
  %add256 = fadd float %mul255, %conv190
  %sub257 = fsub float %add256, %crf
  %mul258 = fmul float %mul6, %sub257
  %mul259 = fmul float %mul255, 2.000000e+00
  %sub260 = fsub float %conv190, %mul259
  %mul261 = fmul float %mul6, %sub260
  %mul262 = fmul float %mul254, %mul261
  %add263 = fadd float %add235, %mul258
  %mul264 = fmul float %sub110, %mul262
  %mul265 = fmul float %sub111, %mul262
  %mul266 = fmul float %sub112, %mul262
  %add267 = fadd float %add239, %mul264
  %add268 = fadd float %add240, %mul265
  %add269 = fadd float %add241, %mul266
  %arrayidx272 = getelementptr inbounds float* %faction, i64 %idxprom87
  %36 = load float* %arrayidx272, align 4, !tbaa !3
  %sub273 = fsub float %36, %mul264
  %arrayidx276 = getelementptr inbounds float* %faction, i64 %idxprom90
  %37 = load float* %arrayidx276, align 4, !tbaa !3
  %sub277 = fsub float %37, %mul265
  %arrayidx280 = getelementptr inbounds float* %faction, i64 %idxprom93
  %38 = load float* %arrayidx280, align 4, !tbaa !3
  %sub281 = fsub float %38, %mul266
  %mul282 = fmul float %conv170, %conv170
  %mul283 = fmul float %add125, %krf
  %add284 = fadd float %mul283, %conv170
  %sub285 = fsub float %add284, %crf
  %mul286 = fmul float %mul6, %sub285
  %mul287 = fmul float %mul283, 2.000000e+00
  %sub288 = fsub float %conv170, %mul287
  %mul289 = fmul float %mul6, %sub288
  %mul290 = fmul float %mul282, %mul289
  %add291 = fadd float %mul286, %add263
  %mul292 = fmul float %sub118, %mul290
  %mul293 = fmul float %sub119, %mul290
  %mul294 = fmul float %sub120, %mul290
  %add295 = fadd float %fix2.0951, %mul292
  %add296 = fadd float %fiy2.0950, %mul293
  %add297 = fadd float %fiz2.0949, %mul294
  %sub298 = fsub float %sub217, %mul292
  %sub299 = fsub float %sub221, %mul293
  %sub300 = fsub float %sub225, %mul294
  %mul301 = fmul float %conv182, %conv182
  %mul302 = fmul float %add133, %krf
  %add303 = fadd float %mul302, %conv182
  %sub304 = fsub float %add303, %crf
  %mul305 = fmul float %mul8, %sub304
  %mul306 = fmul float %mul302, 2.000000e+00
  %sub307 = fsub float %conv182, %mul306
  %mul308 = fmul float %mul8, %sub307
  %mul309 = fmul float %mul301, %mul308
  %add310 = fadd float %mul305, %add291
  %mul311 = fmul float %sub126, %mul309
  %mul312 = fmul float %sub127, %mul309
  %mul313 = fmul float %sub128, %mul309
  %add314 = fadd float %add295, %mul311
  %add315 = fadd float %add296, %mul312
  %add316 = fadd float %add297, %mul313
  %sub317 = fsub float %sub245, %mul311
  %sub318 = fsub float %sub249, %mul312
  %sub319 = fsub float %sub253, %mul313
  %mul320 = fmul float %conv194, %conv194
  %mul321 = fmul float %add141, %krf
  %add322 = fadd float %mul321, %conv194
  %sub323 = fsub float %add322, %crf
  %mul324 = fmul float %mul8, %sub323
  %mul325 = fmul float %mul321, 2.000000e+00
  %sub326 = fsub float %conv194, %mul325
  %mul327 = fmul float %mul8, %sub326
  %mul328 = fmul float %mul320, %mul327
  %add329 = fadd float %mul324, %add310
  %mul330 = fmul float %sub134, %mul328
  %mul331 = fmul float %sub135, %mul328
  %mul332 = fmul float %sub136, %mul328
  %add333 = fadd float %add314, %mul330
  %add334 = fadd float %add315, %mul331
  %add335 = fadd float %add316, %mul332
  %sub336 = fsub float %sub273, %mul330
  %sub337 = fsub float %sub277, %mul331
  %sub338 = fsub float %sub281, %mul332
  %mul339 = fmul float %conv174, %conv174
  %mul340 = fmul float %add149, %krf
  %add341 = fadd float %mul340, %conv174
  %sub342 = fsub float %add341, %crf
  %mul343 = fmul float %mul6, %sub342
  %mul344 = fmul float %mul340, 2.000000e+00
  %sub345 = fsub float %conv174, %mul344
  %mul346 = fmul float %mul6, %sub345
  %mul347 = fmul float %mul339, %mul346
  %add348 = fadd float %mul343, %add329
  %mul349 = fmul float %sub142, %mul347
  %mul350 = fmul float %sub143, %mul347
  %mul351 = fmul float %sub144, %mul347
  %add352 = fadd float %fix3.0948, %mul349
  %add353 = fadd float %fiy3.0947, %mul350
  %add354 = fadd float %fiz3.0946, %mul351
  %sub355 = fsub float %sub298, %mul349
  store float %sub355, float* %arrayidx216, align 4, !tbaa !3
  %sub358 = fsub float %sub299, %mul350
  store float %sub358, float* %arrayidx220, align 4, !tbaa !3
  %sub362 = fsub float %sub300, %mul351
  store float %sub362, float* %arrayidx224, align 4, !tbaa !3
  %mul366 = fmul float %conv186, %conv186
  %mul367 = fmul float %add157, %krf
  %add368 = fadd float %mul367, %conv186
  %sub369 = fsub float %add368, %crf
  %mul370 = fmul float %mul8, %sub369
  %mul371 = fmul float %mul367, 2.000000e+00
  %sub372 = fsub float %conv186, %mul371
  %mul373 = fmul float %mul8, %sub372
  %mul374 = fmul float %mul366, %mul373
  %add375 = fadd float %mul370, %add348
  %mul376 = fmul float %sub150, %mul374
  %mul377 = fmul float %sub151, %mul374
  %mul378 = fmul float %sub152, %mul374
  %add379 = fadd float %add352, %mul376
  %add380 = fadd float %add353, %mul377
  %add381 = fadd float %add354, %mul378
  %sub382 = fsub float %sub317, %mul376
  store float %sub382, float* %arrayidx244, align 4, !tbaa !3
  %sub386 = fsub float %sub318, %mul377
  store float %sub386, float* %arrayidx248, align 4, !tbaa !3
  %sub390 = fsub float %sub319, %mul378
  store float %sub390, float* %arrayidx252, align 4, !tbaa !3
  %mul394 = fmul float %conv198, %conv198
  %mul395 = fmul float %add165, %krf
  %add396 = fadd float %mul395, %conv198
  %sub397 = fsub float %add396, %crf
  %mul398 = fmul float %mul8, %sub397
  %mul399 = fmul float %mul395, 2.000000e+00
  %sub400 = fsub float %conv198, %mul399
  %mul401 = fmul float %mul8, %sub400
  %mul402 = fmul float %mul394, %mul401
  %add403 = fadd float %mul398, %add375
  %mul404 = fmul float %sub158, %mul402
  %mul405 = fmul float %sub159, %mul402
  %mul406 = fmul float %sub160, %mul402
  %add407 = fadd float %add379, %mul404
  %add408 = fadd float %add380, %mul405
  %add409 = fadd float %add381, %mul406
  %sub410 = fsub float %sub336, %mul404
  store float %sub410, float* %arrayidx272, align 4, !tbaa !3
  %sub414 = fsub float %sub337, %mul405
  store float %sub414, float* %arrayidx276, align 4, !tbaa !3
  %sub418 = fsub float %sub338, %mul406
  store float %sub418, float* %arrayidx280, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %39 = trunc i64 %indvars.iv.next to i32
  %cmp64 = icmp slt i32 %39, %9
  br i1 %cmp64, label %for.body65, label %for.end

for.end:                                          ; preds = %for.body65, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add403, %for.body65 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add267, %for.body65 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add268, %for.body65 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add269, %for.body65 ]
  %fix2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add333, %for.body65 ]
  %fiy2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add334, %for.body65 ]
  %fiz2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add335, %for.body65 ]
  %fix3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add407, %for.body65 ]
  %fiy3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add408, %for.body65 ]
  %fiz3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add409, %for.body65 ]
  %arrayidx423 = getelementptr inbounds float* %faction, i64 %idxprom28
  %40 = load float* %arrayidx423, align 4, !tbaa !3
  %add424 = fadd float %fix1.0.lcssa, %40
  store float %add424, float* %arrayidx423, align 4, !tbaa !3
  %arrayidx429 = getelementptr inbounds float* %faction, i64 %idxprom32
  %41 = load float* %arrayidx429, align 4, !tbaa !3
  %add430 = fadd float %fiy1.0.lcssa, %41
  store float %add430, float* %arrayidx429, align 4, !tbaa !3
  %arrayidx436 = getelementptr inbounds float* %faction, i64 %idxprom36
  %42 = load float* %arrayidx436, align 4, !tbaa !3
  %add437 = fadd float %fiz1.0.lcssa, %42
  store float %add437, float* %arrayidx436, align 4, !tbaa !3
  %arrayidx443 = getelementptr inbounds float* %faction, i64 %idxprom40
  %43 = load float* %arrayidx443, align 4, !tbaa !3
  %add444 = fadd float %fix2.0.lcssa, %43
  store float %add444, float* %arrayidx443, align 4, !tbaa !3
  %arrayidx450 = getelementptr inbounds float* %faction, i64 %idxprom44
  %44 = load float* %arrayidx450, align 4, !tbaa !3
  %add451 = fadd float %fiy2.0.lcssa, %44
  store float %add451, float* %arrayidx450, align 4, !tbaa !3
  %arrayidx457 = getelementptr inbounds float* %faction, i64 %idxprom48
  %45 = load float* %arrayidx457, align 4, !tbaa !3
  %add458 = fadd float %fiz2.0.lcssa, %45
  store float %add458, float* %arrayidx457, align 4, !tbaa !3
  %arrayidx464 = getelementptr inbounds float* %faction, i64 %idxprom52
  %46 = load float* %arrayidx464, align 4, !tbaa !3
  %add465 = fadd float %fix3.0.lcssa, %46
  store float %add465, float* %arrayidx464, align 4, !tbaa !3
  %arrayidx471 = getelementptr inbounds float* %faction, i64 %idxprom56
  %47 = load float* %arrayidx471, align 4, !tbaa !3
  %add472 = fadd float %fiy3.0.lcssa, %47
  store float %add472, float* %arrayidx471, align 4, !tbaa !3
  %arrayidx478 = getelementptr inbounds float* %faction, i64 %idxprom60
  %48 = load float* %arrayidx478, align 4, !tbaa !3
  %add479 = fadd float %fiz3.0.lcssa, %48
  store float %add479, float* %arrayidx478, align 4, !tbaa !3
  %arrayidx484 = getelementptr inbounds float* %fshift, i64 %idxprom12
  %49 = load float* %arrayidx484, align 4, !tbaa !3
  %add485 = fadd float %fix1.0.lcssa, %49
  %add486 = fadd float %fix2.0.lcssa, %add485
  %add487 = fadd float %fix3.0.lcssa, %add486
  store float %add487, float* %arrayidx484, align 4, !tbaa !3
  %arrayidx492 = getelementptr inbounds float* %fshift, i64 %idxprom15
  %50 = load float* %arrayidx492, align 4, !tbaa !3
  %add493 = fadd float %fiy1.0.lcssa, %50
  %add494 = fadd float %fiy2.0.lcssa, %add493
  %add495 = fadd float %fiy3.0.lcssa, %add494
  store float %add495, float* %arrayidx492, align 4, !tbaa !3
  %arrayidx501 = getelementptr inbounds float* %fshift, i64 %idxprom18
  %51 = load float* %arrayidx501, align 4, !tbaa !3
  %add502 = fadd float %fiz1.0.lcssa, %51
  %add503 = fadd float %fiz2.0.lcssa, %add502
  %add504 = fadd float %fiz3.0.lcssa, %add503
  store float %add504, float* %arrayidx501, align 4, !tbaa !3
  %arrayidx509 = getelementptr inbounds i32* %gid, i64 %indvars.iv968
  %52 = load i32* %arrayidx509, align 4, !tbaa !0
  %idxprom510 = sext i32 %52 to i64
  %arrayidx511 = getelementptr inbounds float* %Vc, i64 %idxprom510
  %53 = load float* %arrayidx511, align 4, !tbaa !3
  %add512 = fadd float %vctot.0.lcssa, %53
  store float %add512, float* %arrayidx511, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next969 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end517, label %for.end.for.body_crit_edge

for.end.for.body_crit_edge:                       ; preds = %for.end
  %arrayidx21.phi.trans.insert = getelementptr inbounds i32* %iinr, i64 %indvars.iv.next969
  %.pre = load i32* %arrayidx21.phi.trans.insert, align 4, !tbaa !0
  br label %for.body

for.end517:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl2100(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, float %krf, float %crf, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb) #0 {
entry:
  %cmp280 = icmp sgt i32 %nri, 0
  br i1 %cmp280, label %for.body.lr.ph, label %for.end166

for.body.lr.ph:                                   ; preds = %entry
  %mul30 = shl i32 %ntype, 1
  br label %for.body

for.body:                                         ; preds = %for.end, %for.body.lr.ph
  %indvars.iv282 = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next283, %for.end ]
  %arrayidx = getelementptr inbounds i32* %shift, i64 %indvars.iv282
  %0 = load i32* %arrayidx, align 4, !tbaa !0
  %mul = mul nsw i32 %0, 3
  %idxprom1 = sext i32 %mul to i64
  %arrayidx2 = getelementptr inbounds float* %shiftvec, i64 %idxprom1
  %1 = load float* %arrayidx2, align 4, !tbaa !3
  %add = add nsw i32 %mul, 1
  %idxprom3 = sext i32 %add to i64
  %arrayidx4 = getelementptr inbounds float* %shiftvec, i64 %idxprom3
  %2 = load float* %arrayidx4, align 4, !tbaa !3
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds float* %shiftvec, i64 %idxprom6
  %3 = load float* %arrayidx7, align 4, !tbaa !3
  %arrayidx9 = getelementptr inbounds i32* %iinr, i64 %indvars.iv282
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %arrayidx12 = getelementptr inbounds i32* %jindex, i64 %indvars.iv282
  %5 = load i32* %arrayidx12, align 4, !tbaa !0
  %indvars.iv.next283 = add i64 %indvars.iv282, 1
  %arrayidx15 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next283
  %6 = load i32* %arrayidx15, align 4, !tbaa !0
  %idxprom16 = sext i32 %mul10 to i64
  %arrayidx17 = getelementptr inbounds float* %pos, i64 %idxprom16
  %7 = load float* %arrayidx17, align 4, !tbaa !3
  %add18 = fadd float %1, %7
  %add19 = add nsw i32 %mul10, 1
  %idxprom20 = sext i32 %add19 to i64
  %arrayidx21 = getelementptr inbounds float* %pos, i64 %idxprom20
  %8 = load float* %arrayidx21, align 4, !tbaa !3
  %add22 = fadd float %2, %8
  %add23 = add nsw i32 %mul10, 2
  %idxprom24 = sext i32 %add23 to i64
  %arrayidx25 = getelementptr inbounds float* %pos, i64 %idxprom24
  %9 = load float* %arrayidx25, align 4, !tbaa !3
  %add26 = fadd float %3, %9
  %idxprom27 = sext i32 %4 to i64
  %arrayidx28 = getelementptr inbounds float* %charge, i64 %idxprom27
  %10 = load float* %arrayidx28, align 4, !tbaa !3
  %mul29 = fmul float %10, %facel
  %arrayidx32 = getelementptr inbounds i32* %type, i64 %idxprom27
  %11 = load i32* %arrayidx32, align 4, !tbaa !0
  %mul33 = mul nsw i32 %mul30, %11
  %cmp35269 = icmp slt i32 %5, %6
  br i1 %cmp35269, label %for.body36.lr.ph, label %for.end

for.body36.lr.ph:                                 ; preds = %for.body
  %12 = sext i32 %5 to i64
  br label %for.body36

for.body36:                                       ; preds = %for.body36.lr.ph, %for.body36
  %indvars.iv = phi i64 [ %12, %for.body36.lr.ph ], [ %indvars.iv.next, %for.body36 ]
  %vctot.0274 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add88, %for.body36 ]
  %vnbtot.0273 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %sub72, %for.body36 ]
  %fix1.0272 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add92, %for.body36 ]
  %fiy1.0271 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add93, %for.body36 ]
  %fiz1.0270 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add94, %for.body36 ]
  %arrayidx38 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %13 = load i32* %arrayidx38, align 4, !tbaa !0
  %mul39 = mul nsw i32 %13, 3
  %idxprom40 = sext i32 %mul39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %14 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = add nsw i32 %mul39, 1
  %idxprom43 = sext i32 %add42 to i64
  %arrayidx44 = getelementptr inbounds float* %pos, i64 %idxprom43
  %15 = load float* %arrayidx44, align 4, !tbaa !3
  %add45 = add nsw i32 %mul39, 2
  %idxprom46 = sext i32 %add45 to i64
  %arrayidx47 = getelementptr inbounds float* %pos, i64 %idxprom46
  %16 = load float* %arrayidx47, align 4, !tbaa !3
  %sub = fsub float %add18, %14
  %sub48 = fsub float %add22, %15
  %sub49 = fsub float %add26, %16
  %mul50 = fmul float %sub, %sub
  %mul51 = fmul float %sub48, %sub48
  %add52 = fadd float %mul50, %mul51
  %mul53 = fmul float %sub49, %sub49
  %add54 = fadd float %add52, %mul53
  %conv = fpext float %add54 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv55 = fptrunc double %div to float
  %mul56 = fmul float %conv55, %conv55
  %mul57 = fmul float %mul56, %mul56
  %mul58 = fmul float %mul56, %mul57
  %idxprom59 = sext i32 %13 to i64
  %arrayidx60 = getelementptr inbounds i32* %type, i64 %idxprom59
  %17 = load i32* %arrayidx60, align 4, !tbaa !0
  %mul61 = shl nsw i32 %17, 1
  %add62 = add nsw i32 %mul61, %mul33
  %idxprom63 = sext i32 %add62 to i64
  %arrayidx64 = getelementptr inbounds float* %nbfp, i64 %idxprom63
  %18 = load float* %arrayidx64, align 4, !tbaa !3
  %mul65 = fmul float %18, %mul58
  %mul66 = fmul float %mul58, %mul58
  %add67268 = or i32 %add62, 1
  %idxprom68 = sext i32 %add67268 to i64
  %arrayidx69 = getelementptr inbounds float* %nbfp, i64 %idxprom68
  %19 = load float* %arrayidx69, align 4, !tbaa !3
  %mul70 = fmul float %19, %mul66
  %add71 = fadd float %vnbtot.0273, %mul70
  %sub72 = fsub float %add71, %mul65
  %arrayidx74 = getelementptr inbounds float* %charge, i64 %idxprom59
  %20 = load float* %arrayidx74, align 4, !tbaa !3
  %mul75 = fmul float %mul29, %20
  %mul76 = fmul float %add54, %krf
  %add77 = fadd float %conv55, %mul76
  %sub78 = fsub float %add77, %crf
  %mul79 = fmul float %sub78, %mul75
  %mul80 = fmul float %mul70, 1.200000e+01
  %mul81 = fmul float %mul65, 6.000000e+00
  %sub82 = fsub float %mul80, %mul81
  %mul83 = fmul float %mul76, 2.000000e+00
  %sub84 = fsub float %conv55, %mul83
  %mul85 = fmul float %sub84, %mul75
  %add86 = fadd float %mul85, %sub82
  %mul87 = fmul float %mul56, %add86
  %add88 = fadd float %vctot.0274, %mul79
  %mul89 = fmul float %sub, %mul87
  %mul90 = fmul float %sub48, %mul87
  %mul91 = fmul float %sub49, %mul87
  %add92 = fadd float %fix1.0272, %mul89
  %add93 = fadd float %fiy1.0271, %mul90
  %add94 = fadd float %fiz1.0270, %mul91
  %arrayidx96 = getelementptr inbounds float* %faction, i64 %idxprom40
  %21 = load float* %arrayidx96, align 4, !tbaa !3
  %sub97 = fsub float %21, %mul89
  store float %sub97, float* %arrayidx96, align 4, !tbaa !3
  %arrayidx102 = getelementptr inbounds float* %faction, i64 %idxprom43
  %22 = load float* %arrayidx102, align 4, !tbaa !3
  %sub103 = fsub float %22, %mul90
  store float %sub103, float* %arrayidx102, align 4, !tbaa !3
  %arrayidx109 = getelementptr inbounds float* %faction, i64 %idxprom46
  %23 = load float* %arrayidx109, align 4, !tbaa !3
  %sub110 = fsub float %23, %mul91
  store float %sub110, float* %arrayidx109, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %24 = trunc i64 %indvars.iv.next to i32
  %cmp35 = icmp slt i32 %24, %6
  br i1 %cmp35, label %for.body36, label %for.end

for.end:                                          ; preds = %for.body36, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add88, %for.body36 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %sub72, %for.body36 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add92, %for.body36 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add93, %for.body36 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add94, %for.body36 ]
  %arrayidx115 = getelementptr inbounds float* %faction, i64 %idxprom16
  %25 = load float* %arrayidx115, align 4, !tbaa !3
  %add116 = fadd float %fix1.0.lcssa, %25
  store float %add116, float* %arrayidx115, align 4, !tbaa !3
  %arrayidx121 = getelementptr inbounds float* %faction, i64 %idxprom20
  %26 = load float* %arrayidx121, align 4, !tbaa !3
  %add122 = fadd float %fiy1.0.lcssa, %26
  store float %add122, float* %arrayidx121, align 4, !tbaa !3
  %arrayidx128 = getelementptr inbounds float* %faction, i64 %idxprom24
  %27 = load float* %arrayidx128, align 4, !tbaa !3
  %add129 = fadd float %fiz1.0.lcssa, %27
  store float %add129, float* %arrayidx128, align 4, !tbaa !3
  %arrayidx134 = getelementptr inbounds float* %fshift, i64 %idxprom1
  %28 = load float* %arrayidx134, align 4, !tbaa !3
  %add135 = fadd float %fix1.0.lcssa, %28
  store float %add135, float* %arrayidx134, align 4, !tbaa !3
  %arrayidx140 = getelementptr inbounds float* %fshift, i64 %idxprom3
  %29 = load float* %arrayidx140, align 4, !tbaa !3
  %add141 = fadd float %fiy1.0.lcssa, %29
  store float %add141, float* %arrayidx140, align 4, !tbaa !3
  %arrayidx147 = getelementptr inbounds float* %fshift, i64 %idxprom6
  %30 = load float* %arrayidx147, align 4, !tbaa !3
  %add148 = fadd float %fiz1.0.lcssa, %30
  store float %add148, float* %arrayidx147, align 4, !tbaa !3
  %arrayidx153 = getelementptr inbounds i32* %gid, i64 %indvars.iv282
  %31 = load i32* %arrayidx153, align 4, !tbaa !0
  %idxprom154 = sext i32 %31 to i64
  %arrayidx155 = getelementptr inbounds float* %Vc, i64 %idxprom154
  %32 = load float* %arrayidx155, align 4, !tbaa !3
  %add156 = fadd float %vctot.0.lcssa, %32
  store float %add156, float* %arrayidx155, align 4, !tbaa !3
  %arrayidx160 = getelementptr inbounds float* %Vnb, i64 %idxprom154
  %33 = load float* %arrayidx160, align 4, !tbaa !3
  %add161 = fadd float %vnbtot.0.lcssa, %33
  store float %add161, float* %arrayidx160, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next283 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end166, label %for.body

for.end166:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl2110(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, float %krf, float %crf, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, i32* nocapture %nsatoms) #0 {
entry:
  %cmp853 = icmp sgt i32 %nri, 0
  br i1 %cmp853, label %for.body.lr.ph, label %for.end450

for.body.lr.ph:                                   ; preds = %entry
  %mul315 = shl i32 %ntype, 1
  br label %for.body

for.body:                                         ; preds = %for.end435, %for.body.lr.ph
  %indvars.iv879 = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next880, %for.end435 ]
  %0 = trunc i64 %indvars.iv879 to i32
  %mul = mul nsw i32 %0, 3
  %idxprom = sext i32 %mul to i64
  %arrayidx = getelementptr inbounds i32* %nsatoms, i64 %idxprom
  %1 = load i32* %arrayidx, align 4, !tbaa !0
  %add = add nsw i32 %mul, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds i32* %nsatoms, i64 %idxprom2
  %2 = load i32* %arrayidx3, align 4, !tbaa !0
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds i32* %nsatoms, i64 %idxprom6
  %3 = load i32* %arrayidx7, align 4, !tbaa !0
  %arrayidx9 = getelementptr inbounds i32* %shift, i64 %indvars.iv879
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %idxprom11 = sext i32 %mul10 to i64
  %arrayidx12 = getelementptr inbounds float* %shiftvec, i64 %idxprom11
  %5 = load float* %arrayidx12, align 4, !tbaa !3
  %add13 = add nsw i32 %mul10, 1
  %idxprom14 = sext i32 %add13 to i64
  %arrayidx15 = getelementptr inbounds float* %shiftvec, i64 %idxprom14
  %6 = load float* %arrayidx15, align 4, !tbaa !3
  %add16 = add nsw i32 %mul10, 2
  %idxprom17 = sext i32 %add16 to i64
  %arrayidx18 = getelementptr inbounds float* %shiftvec, i64 %idxprom17
  %7 = load float* %arrayidx18, align 4, !tbaa !3
  %arrayidx20 = getelementptr inbounds i32* %iinr, i64 %indvars.iv879
  %8 = load i32* %arrayidx20, align 4, !tbaa !0
  %mul21 = mul i32 %8, 3
  %arrayidx23 = getelementptr inbounds i32* %jindex, i64 %indvars.iv879
  %9 = load i32* %arrayidx23, align 4, !tbaa !0
  %indvars.iv.next880 = add i64 %indvars.iv879, 1
  %arrayidx26 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next880
  %10 = load i32* %arrayidx26, align 4, !tbaa !0
  %cmp28809 = icmp sgt i32 %2, 0
  br i1 %cmp28809, label %for.body29.lr.ph, label %for.cond171.loopexit

for.body29.lr.ph:                                 ; preds = %for.body
  %cmp49798 = icmp slt i32 %9, %10
  %arrayidx148 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx154 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx161 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %11 = sext i32 %9 to i64
  %12 = sext i32 %8 to i64
  %13 = sext i32 %mul21 to i64
  %14 = add i32 %2, %8
  %15 = mul i32 %14, 3
  br label %for.body29

for.body29:                                       ; preds = %for.end, %for.body29.lr.ph
  %indvars.iv857 = phi i64 [ %13, %for.body29.lr.ph ], [ %indvars.iv.next858, %for.end ]
  %indvars.iv855 = phi i64 [ %12, %for.body29.lr.ph ], [ %indvars.iv.next856, %for.end ]
  %s.0812 = phi i32 [ 0, %for.body29.lr.ph ], [ %inc169, %for.end ]
  %vctot.0811 = phi float [ 0.000000e+00, %for.body29.lr.ph ], [ %vctot.1.lcssa, %for.end ]
  %vnbtot.0810 = phi float [ 0.000000e+00, %for.body29.lr.ph ], [ %vnbtot.1.lcssa, %for.end ]
  %arrayidx31 = getelementptr inbounds float* %pos, i64 %indvars.iv857
  %16 = load float* %arrayidx31, align 4, !tbaa !3
  %add32 = fadd float %5, %16
  %17 = add nsw i64 %indvars.iv857, 1
  %arrayidx35 = getelementptr inbounds float* %pos, i64 %17
  %18 = load float* %arrayidx35, align 4, !tbaa !3
  %add36 = fadd float %6, %18
  %19 = add nsw i64 %indvars.iv857, 2
  %arrayidx39 = getelementptr inbounds float* %pos, i64 %19
  %20 = load float* %arrayidx39, align 4, !tbaa !3
  %add40 = fadd float %7, %20
  %arrayidx42 = getelementptr inbounds float* %charge, i64 %indvars.iv855
  %21 = load float* %arrayidx42, align 4, !tbaa !3
  %mul43 = fmul float %21, %facel
  %arrayidx46 = getelementptr inbounds i32* %type, i64 %indvars.iv855
  %22 = load i32* %arrayidx46, align 4, !tbaa !0
  %mul47 = mul nsw i32 %mul315, %22
  br i1 %cmp49798, label %for.body50, label %for.end

for.body50:                                       ; preds = %for.body29, %for.body50
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body50 ], [ %11, %for.body29 ]
  %fiz1.0803 = phi float [ %add108, %for.body50 ], [ 0.000000e+00, %for.body29 ]
  %fiy1.0802 = phi float [ %add107, %for.body50 ], [ 0.000000e+00, %for.body29 ]
  %fix1.0801 = phi float [ %add106, %for.body50 ], [ 0.000000e+00, %for.body29 ]
  %vctot.1800 = phi float [ %add102, %for.body50 ], [ %vctot.0811, %for.body29 ]
  %vnbtot.1799 = phi float [ %sub86, %for.body50 ], [ %vnbtot.0810, %for.body29 ]
  %arrayidx52 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %23 = load i32* %arrayidx52, align 4, !tbaa !0
  %mul53 = mul nsw i32 %23, 3
  %idxprom54 = sext i32 %mul53 to i64
  %arrayidx55 = getelementptr inbounds float* %pos, i64 %idxprom54
  %24 = load float* %arrayidx55, align 4, !tbaa !3
  %add56 = add nsw i32 %mul53, 1
  %idxprom57 = sext i32 %add56 to i64
  %arrayidx58 = getelementptr inbounds float* %pos, i64 %idxprom57
  %25 = load float* %arrayidx58, align 4, !tbaa !3
  %add59 = add nsw i32 %mul53, 2
  %idxprom60 = sext i32 %add59 to i64
  %arrayidx61 = getelementptr inbounds float* %pos, i64 %idxprom60
  %26 = load float* %arrayidx61, align 4, !tbaa !3
  %sub = fsub float %add32, %24
  %sub62 = fsub float %add36, %25
  %sub63 = fsub float %add40, %26
  %mul64 = fmul float %sub, %sub
  %mul65 = fmul float %sub62, %sub62
  %add66 = fadd float %mul64, %mul65
  %mul67 = fmul float %sub63, %sub63
  %add68 = fadd float %add66, %mul67
  %conv = fpext float %add68 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv69 = fptrunc double %div to float
  %mul70 = fmul float %conv69, %conv69
  %mul71 = fmul float %mul70, %mul70
  %mul72 = fmul float %mul70, %mul71
  %idxprom73 = sext i32 %23 to i64
  %arrayidx74 = getelementptr inbounds i32* %type, i64 %idxprom73
  %27 = load i32* %arrayidx74, align 4, !tbaa !0
  %mul75 = shl nsw i32 %27, 1
  %add76 = add nsw i32 %mul75, %mul47
  %idxprom77 = sext i32 %add76 to i64
  %arrayidx78 = getelementptr inbounds float* %nbfp, i64 %idxprom77
  %28 = load float* %arrayidx78, align 4, !tbaa !3
  %mul79 = fmul float %28, %mul72
  %mul80 = fmul float %mul72, %mul72
  %add81797 = or i32 %add76, 1
  %idxprom82 = sext i32 %add81797 to i64
  %arrayidx83 = getelementptr inbounds float* %nbfp, i64 %idxprom82
  %29 = load float* %arrayidx83, align 4, !tbaa !3
  %mul84 = fmul float %29, %mul80
  %add85 = fadd float %vnbtot.1799, %mul84
  %sub86 = fsub float %add85, %mul79
  %arrayidx88 = getelementptr inbounds float* %charge, i64 %idxprom73
  %30 = load float* %arrayidx88, align 4, !tbaa !3
  %mul89 = fmul float %mul43, %30
  %mul90 = fmul float %add68, %krf
  %add91 = fadd float %conv69, %mul90
  %sub92 = fsub float %add91, %crf
  %mul93 = fmul float %sub92, %mul89
  %mul94 = fmul float %mul84, 1.200000e+01
  %mul95 = fmul float %mul79, 6.000000e+00
  %sub96 = fsub float %mul94, %mul95
  %mul97 = fmul float %mul90, 2.000000e+00
  %sub98 = fsub float %conv69, %mul97
  %mul99 = fmul float %sub98, %mul89
  %add100 = fadd float %mul99, %sub96
  %mul101 = fmul float %mul70, %add100
  %add102 = fadd float %vctot.1800, %mul93
  %mul103 = fmul float %sub, %mul101
  %mul104 = fmul float %sub62, %mul101
  %mul105 = fmul float %sub63, %mul101
  %add106 = fadd float %fix1.0801, %mul103
  %add107 = fadd float %fiy1.0802, %mul104
  %add108 = fadd float %fiz1.0803, %mul105
  %arrayidx110 = getelementptr inbounds float* %faction, i64 %idxprom54
  %31 = load float* %arrayidx110, align 4, !tbaa !3
  %sub111 = fsub float %31, %mul103
  store float %sub111, float* %arrayidx110, align 4, !tbaa !3
  %arrayidx116 = getelementptr inbounds float* %faction, i64 %idxprom57
  %32 = load float* %arrayidx116, align 4, !tbaa !3
  %sub117 = fsub float %32, %mul104
  store float %sub117, float* %arrayidx116, align 4, !tbaa !3
  %arrayidx123 = getelementptr inbounds float* %faction, i64 %idxprom60
  %33 = load float* %arrayidx123, align 4, !tbaa !3
  %sub124 = fsub float %33, %mul105
  store float %sub124, float* %arrayidx123, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %34 = trunc i64 %indvars.iv.next to i32
  %cmp49 = icmp slt i32 %34, %10
  br i1 %cmp49, label %for.body50, label %for.end

for.end:                                          ; preds = %for.body50, %for.body29
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add108, %for.body50 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add107, %for.body50 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add106, %for.body50 ]
  %vctot.1.lcssa = phi float [ %vctot.0811, %for.body29 ], [ %add102, %for.body50 ]
  %vnbtot.1.lcssa = phi float [ %vnbtot.0810, %for.body29 ], [ %sub86, %for.body50 ]
  %arrayidx129 = getelementptr inbounds float* %faction, i64 %indvars.iv857
  %35 = load float* %arrayidx129, align 4, !tbaa !3
  %add130 = fadd float %fix1.0.lcssa, %35
  store float %add130, float* %arrayidx129, align 4, !tbaa !3
  %arrayidx135 = getelementptr inbounds float* %faction, i64 %17
  %36 = load float* %arrayidx135, align 4, !tbaa !3
  %add136 = fadd float %fiy1.0.lcssa, %36
  store float %add136, float* %arrayidx135, align 4, !tbaa !3
  %arrayidx142 = getelementptr inbounds float* %faction, i64 %19
  %37 = load float* %arrayidx142, align 4, !tbaa !3
  %add143 = fadd float %fiz1.0.lcssa, %37
  store float %add143, float* %arrayidx142, align 4, !tbaa !3
  %38 = load float* %arrayidx148, align 4, !tbaa !3
  %add149 = fadd float %fix1.0.lcssa, %38
  store float %add149, float* %arrayidx148, align 4, !tbaa !3
  %39 = load float* %arrayidx154, align 4, !tbaa !3
  %add155 = fadd float %fiy1.0.lcssa, %39
  store float %add155, float* %arrayidx154, align 4, !tbaa !3
  %40 = load float* %arrayidx161, align 4, !tbaa !3
  %add162 = fadd float %fiz1.0.lcssa, %40
  store float %add162, float* %arrayidx161, align 4, !tbaa !3
  %indvars.iv.next856 = add i64 %indvars.iv855, 1
  %indvars.iv.next858 = add i64 %indvars.iv857, 3
  %inc169 = add nsw i32 %s.0812, 1
  %exitcond = icmp eq i32 %inc169, %2
  br i1 %exitcond, label %for.cond27.for.cond171.loopexit_crit_edge, label %for.body29

for.cond27.for.cond171.loopexit_crit_edge:        ; preds = %for.end
  %41 = add i32 %2, %8
  br label %for.cond171.loopexit

for.cond171.loopexit:                             ; preds = %for.cond27.for.cond171.loopexit_crit_edge, %for.body
  %ii.0.lcssa = phi i32 [ %41, %for.cond27.for.cond171.loopexit_crit_edge ], [ %8, %for.body ]
  %ii3.0.lcssa = phi i32 [ %15, %for.cond27.for.cond171.loopexit_crit_edge ], [ %mul21, %for.body ]
  %vctot.0.lcssa = phi float [ %vctot.1.lcssa, %for.cond27.for.cond171.loopexit_crit_edge ], [ 0.000000e+00, %for.body ]
  %vnbtot.0.lcssa = phi float [ %vnbtot.1.lcssa, %for.cond27.for.cond171.loopexit_crit_edge ], [ 0.000000e+00, %for.body ]
  %cmp172829 = icmp slt i32 %2, %3
  br i1 %cmp172829, label %for.body174.lr.ph, label %for.cond300.loopexit

for.body174.lr.ph:                                ; preds = %for.cond171.loopexit
  %cmp190819 = icmp slt i32 %9, %10
  %arrayidx277 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx283 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx290 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %42 = sext i32 %9 to i64
  %43 = sext i32 %ii.0.lcssa to i64
  %44 = sext i32 %ii3.0.lcssa to i64
  %45 = mul i32 %3, 3
  %46 = add i32 %ii.0.lcssa, %3
  br label %for.body174

for.body174:                                      ; preds = %for.end256, %for.body174.lr.ph
  %indvars.iv865 = phi i64 [ %44, %for.body174.lr.ph ], [ %indvars.iv.next866, %for.end256 ]
  %indvars.iv863 = phi i64 [ %43, %for.body174.lr.ph ], [ %indvars.iv.next864, %for.end256 ]
  %s.1831 = phi i32 [ %2, %for.body174.lr.ph ], [ %inc298, %for.end256 ]
  %vctot.2830 = phi float [ %vctot.0.lcssa, %for.body174.lr.ph ], [ %vctot.3.lcssa, %for.end256 ]
  %arrayidx176 = getelementptr inbounds float* %pos, i64 %indvars.iv865
  %47 = load float* %arrayidx176, align 4, !tbaa !3
  %add177 = fadd float %5, %47
  %48 = add nsw i64 %indvars.iv865, 1
  %arrayidx180 = getelementptr inbounds float* %pos, i64 %48
  %49 = load float* %arrayidx180, align 4, !tbaa !3
  %add181 = fadd float %6, %49
  %50 = add nsw i64 %indvars.iv865, 2
  %arrayidx184 = getelementptr inbounds float* %pos, i64 %50
  %51 = load float* %arrayidx184, align 4, !tbaa !3
  %add185 = fadd float %7, %51
  %arrayidx187 = getelementptr inbounds float* %charge, i64 %indvars.iv863
  %52 = load float* %arrayidx187, align 4, !tbaa !3
  %mul188 = fmul float %52, %facel
  br i1 %cmp190819, label %for.body192, label %for.end256

for.body192:                                      ; preds = %for.body174, %for.body192
  %indvars.iv861 = phi i64 [ %indvars.iv.next862, %for.body192 ], [ %42, %for.body174 ]
  %fiz1.1823 = phi float [ %add234, %for.body192 ], [ 0.000000e+00, %for.body174 ]
  %fiy1.1822 = phi float [ %add233, %for.body192 ], [ 0.000000e+00, %for.body174 ]
  %fix1.1821 = phi float [ %add232, %for.body192 ], [ 0.000000e+00, %for.body174 ]
  %vctot.3820 = phi float [ %add228, %for.body192 ], [ %vctot.2830, %for.body174 ]
  %arrayidx194 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv861
  %53 = load i32* %arrayidx194, align 4, !tbaa !0
  %mul195 = mul nsw i32 %53, 3
  %idxprom196 = sext i32 %mul195 to i64
  %arrayidx197 = getelementptr inbounds float* %pos, i64 %idxprom196
  %54 = load float* %arrayidx197, align 4, !tbaa !3
  %add198 = add nsw i32 %mul195, 1
  %idxprom199 = sext i32 %add198 to i64
  %arrayidx200 = getelementptr inbounds float* %pos, i64 %idxprom199
  %55 = load float* %arrayidx200, align 4, !tbaa !3
  %add201 = add nsw i32 %mul195, 2
  %idxprom202 = sext i32 %add201 to i64
  %arrayidx203 = getelementptr inbounds float* %pos, i64 %idxprom202
  %56 = load float* %arrayidx203, align 4, !tbaa !3
  %sub204 = fsub float %add177, %54
  %sub205 = fsub float %add181, %55
  %sub206 = fsub float %add185, %56
  %mul207 = fmul float %sub204, %sub204
  %mul208 = fmul float %sub205, %sub205
  %add209 = fadd float %mul207, %mul208
  %mul210 = fmul float %sub206, %sub206
  %add211 = fadd float %add209, %mul210
  %conv212 = fpext float %add211 to double
  %call213 = tail call double @sqrt(double %conv212) #2
  %div214 = fdiv double 1.000000e+00, %call213
  %conv215 = fptrunc double %div214 to float
  %mul216 = fmul float %conv215, %conv215
  %idxprom217 = sext i32 %53 to i64
  %arrayidx218 = getelementptr inbounds float* %charge, i64 %idxprom217
  %57 = load float* %arrayidx218, align 4, !tbaa !3
  %mul219 = fmul float %mul188, %57
  %mul220 = fmul float %add211, %krf
  %add221 = fadd float %conv215, %mul220
  %sub222 = fsub float %add221, %crf
  %mul223 = fmul float %mul219, %sub222
  %mul224 = fmul float %mul220, 2.000000e+00
  %sub225 = fsub float %conv215, %mul224
  %mul226 = fmul float %mul219, %sub225
  %mul227 = fmul float %mul216, %mul226
  %add228 = fadd float %vctot.3820, %mul223
  %mul229 = fmul float %sub204, %mul227
  %mul230 = fmul float %sub205, %mul227
  %mul231 = fmul float %sub206, %mul227
  %add232 = fadd float %fix1.1821, %mul229
  %add233 = fadd float %fiy1.1822, %mul230
  %add234 = fadd float %fiz1.1823, %mul231
  %arrayidx236 = getelementptr inbounds float* %faction, i64 %idxprom196
  %58 = load float* %arrayidx236, align 4, !tbaa !3
  %sub237 = fsub float %58, %mul229
  store float %sub237, float* %arrayidx236, align 4, !tbaa !3
  %arrayidx242 = getelementptr inbounds float* %faction, i64 %idxprom199
  %59 = load float* %arrayidx242, align 4, !tbaa !3
  %sub243 = fsub float %59, %mul230
  store float %sub243, float* %arrayidx242, align 4, !tbaa !3
  %arrayidx249 = getelementptr inbounds float* %faction, i64 %idxprom202
  %60 = load float* %arrayidx249, align 4, !tbaa !3
  %sub250 = fsub float %60, %mul231
  store float %sub250, float* %arrayidx249, align 4, !tbaa !3
  %indvars.iv.next862 = add i64 %indvars.iv861, 1
  %61 = trunc i64 %indvars.iv.next862 to i32
  %cmp190 = icmp slt i32 %61, %10
  br i1 %cmp190, label %for.body192, label %for.end256

for.end256:                                       ; preds = %for.body192, %for.body174
  %fiz1.1.lcssa = phi float [ 0.000000e+00, %for.body174 ], [ %add234, %for.body192 ]
  %fiy1.1.lcssa = phi float [ 0.000000e+00, %for.body174 ], [ %add233, %for.body192 ]
  %fix1.1.lcssa = phi float [ 0.000000e+00, %for.body174 ], [ %add232, %for.body192 ]
  %vctot.3.lcssa = phi float [ %vctot.2830, %for.body174 ], [ %add228, %for.body192 ]
  %arrayidx258 = getelementptr inbounds float* %faction, i64 %indvars.iv865
  %62 = load float* %arrayidx258, align 4, !tbaa !3
  %add259 = fadd float %fix1.1.lcssa, %62
  store float %add259, float* %arrayidx258, align 4, !tbaa !3
  %arrayidx264 = getelementptr inbounds float* %faction, i64 %48
  %63 = load float* %arrayidx264, align 4, !tbaa !3
  %add265 = fadd float %fiy1.1.lcssa, %63
  store float %add265, float* %arrayidx264, align 4, !tbaa !3
  %arrayidx271 = getelementptr inbounds float* %faction, i64 %50
  %64 = load float* %arrayidx271, align 4, !tbaa !3
  %add272 = fadd float %fiz1.1.lcssa, %64
  store float %add272, float* %arrayidx271, align 4, !tbaa !3
  %65 = load float* %arrayidx277, align 4, !tbaa !3
  %add278 = fadd float %fix1.1.lcssa, %65
  store float %add278, float* %arrayidx277, align 4, !tbaa !3
  %66 = load float* %arrayidx283, align 4, !tbaa !3
  %add284 = fadd float %fiy1.1.lcssa, %66
  store float %add284, float* %arrayidx283, align 4, !tbaa !3
  %67 = load float* %arrayidx290, align 4, !tbaa !3
  %add291 = fadd float %fiz1.1.lcssa, %67
  store float %add291, float* %arrayidx290, align 4, !tbaa !3
  %indvars.iv.next864 = add i64 %indvars.iv863, 1
  %indvars.iv.next866 = add i64 %indvars.iv865, 3
  %inc298 = add nsw i32 %s.1831, 1
  %exitcond869 = icmp eq i32 %inc298, %3
  br i1 %exitcond869, label %for.cond171.for.cond300.loopexit_crit_edge, label %for.body174

for.cond171.for.cond300.loopexit_crit_edge:       ; preds = %for.end256
  %68 = add i32 %ii3.0.lcssa, %45
  %69 = mul i32 %2, -3
  %70 = add i32 %68, %69
  %71 = sub i32 %46, %2
  br label %for.cond300.loopexit

for.cond300.loopexit:                             ; preds = %for.cond171.for.cond300.loopexit_crit_edge, %for.cond171.loopexit
  %ii.1.lcssa = phi i32 [ %71, %for.cond171.for.cond300.loopexit_crit_edge ], [ %ii.0.lcssa, %for.cond171.loopexit ]
  %ii3.1.lcssa = phi i32 [ %70, %for.cond171.for.cond300.loopexit_crit_edge ], [ %ii3.0.lcssa, %for.cond171.loopexit ]
  %vctot.2.lcssa = phi float [ %vctot.3.lcssa, %for.cond171.for.cond300.loopexit_crit_edge ], [ %vctot.0.lcssa, %for.cond171.loopexit ]
  %cmp301847 = icmp slt i32 %3, %1
  br i1 %cmp301847, label %for.body303.lr.ph, label %for.end435

for.body303.lr.ph:                                ; preds = %for.cond300.loopexit
  %cmp320837 = icmp slt i32 %9, %10
  %arrayidx413 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx419 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx426 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %72 = sext i32 %9 to i64
  %73 = sext i32 %ii.1.lcssa to i64
  %74 = sext i32 %ii3.1.lcssa to i64
  br label %for.body303

for.body303:                                      ; preds = %for.end392, %for.body303.lr.ph
  %indvars.iv874 = phi i64 [ %74, %for.body303.lr.ph ], [ %indvars.iv.next875, %for.end392 ]
  %indvars.iv872 = phi i64 [ %73, %for.body303.lr.ph ], [ %indvars.iv.next873, %for.end392 ]
  %s.2849 = phi i32 [ %3, %for.body303.lr.ph ], [ %inc434, %for.end392 ]
  %vnbtot.2848 = phi float [ %vnbtot.0.lcssa, %for.body303.lr.ph ], [ %vnbtot.3.lcssa, %for.end392 ]
  %arrayidx305 = getelementptr inbounds float* %pos, i64 %indvars.iv874
  %75 = load float* %arrayidx305, align 4, !tbaa !3
  %add306 = fadd float %5, %75
  %76 = add nsw i64 %indvars.iv874, 1
  %arrayidx309 = getelementptr inbounds float* %pos, i64 %76
  %77 = load float* %arrayidx309, align 4, !tbaa !3
  %add310 = fadd float %6, %77
  %78 = add nsw i64 %indvars.iv874, 2
  %arrayidx313 = getelementptr inbounds float* %pos, i64 %78
  %79 = load float* %arrayidx313, align 4, !tbaa !3
  %add314 = fadd float %7, %79
  %arrayidx317 = getelementptr inbounds i32* %type, i64 %indvars.iv872
  %80 = load i32* %arrayidx317, align 4, !tbaa !0
  %mul318 = mul nsw i32 %mul315, %80
  br i1 %cmp320837, label %for.body322, label %for.end392

for.body322:                                      ; preds = %for.body303, %for.body322
  %indvars.iv870 = phi i64 [ %indvars.iv.next871, %for.body322 ], [ %72, %for.body303 ]
  %fiz1.2841 = phi float [ %add370, %for.body322 ], [ 0.000000e+00, %for.body303 ]
  %fiy1.2840 = phi float [ %add369, %for.body322 ], [ 0.000000e+00, %for.body303 ]
  %fix1.2839 = phi float [ %add368, %for.body322 ], [ 0.000000e+00, %for.body303 ]
  %vnbtot.3838 = phi float [ %sub360, %for.body322 ], [ %vnbtot.2848, %for.body303 ]
  %arrayidx324 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv870
  %81 = load i32* %arrayidx324, align 4, !tbaa !0
  %mul325 = mul nsw i32 %81, 3
  %idxprom326 = sext i32 %mul325 to i64
  %arrayidx327 = getelementptr inbounds float* %pos, i64 %idxprom326
  %82 = load float* %arrayidx327, align 4, !tbaa !3
  %add328 = add nsw i32 %mul325, 1
  %idxprom329 = sext i32 %add328 to i64
  %arrayidx330 = getelementptr inbounds float* %pos, i64 %idxprom329
  %83 = load float* %arrayidx330, align 4, !tbaa !3
  %add331 = add nsw i32 %mul325, 2
  %idxprom332 = sext i32 %add331 to i64
  %arrayidx333 = getelementptr inbounds float* %pos, i64 %idxprom332
  %84 = load float* %arrayidx333, align 4, !tbaa !3
  %sub334 = fsub float %add306, %82
  %sub335 = fsub float %add310, %83
  %sub336 = fsub float %add314, %84
  %mul337 = fmul float %sub334, %sub334
  %mul338 = fmul float %sub335, %sub335
  %add339 = fadd float %mul337, %mul338
  %mul340 = fmul float %sub336, %sub336
  %add341 = fadd float %add339, %mul340
  %conv344 = fdiv float 1.000000e+00, %add341
  %mul345 = fmul float %conv344, %conv344
  %mul346 = fmul float %conv344, %mul345
  %idxprom347 = sext i32 %81 to i64
  %arrayidx348 = getelementptr inbounds i32* %type, i64 %idxprom347
  %85 = load i32* %arrayidx348, align 4, !tbaa !0
  %mul349 = shl nsw i32 %85, 1
  %add350 = add nsw i32 %mul349, %mul318
  %idxprom351 = sext i32 %add350 to i64
  %arrayidx352 = getelementptr inbounds float* %nbfp, i64 %idxprom351
  %86 = load float* %arrayidx352, align 4, !tbaa !3
  %mul353 = fmul float %mul346, %86
  %mul354 = fmul float %mul346, %mul346
  %add355796 = or i32 %add350, 1
  %idxprom356 = sext i32 %add355796 to i64
  %arrayidx357 = getelementptr inbounds float* %nbfp, i64 %idxprom356
  %87 = load float* %arrayidx357, align 4, !tbaa !3
  %mul358 = fmul float %mul354, %87
  %add359 = fadd float %vnbtot.3838, %mul358
  %sub360 = fsub float %add359, %mul353
  %mul361 = fmul float %mul358, 1.200000e+01
  %mul362 = fmul float %mul353, 6.000000e+00
  %sub363 = fsub float %mul361, %mul362
  %mul364 = fmul float %conv344, %sub363
  %mul365 = fmul float %sub334, %mul364
  %mul366 = fmul float %sub335, %mul364
  %mul367 = fmul float %sub336, %mul364
  %add368 = fadd float %fix1.2839, %mul365
  %add369 = fadd float %fiy1.2840, %mul366
  %add370 = fadd float %fiz1.2841, %mul367
  %arrayidx372 = getelementptr inbounds float* %faction, i64 %idxprom326
  %88 = load float* %arrayidx372, align 4, !tbaa !3
  %sub373 = fsub float %88, %mul365
  store float %sub373, float* %arrayidx372, align 4, !tbaa !3
  %arrayidx378 = getelementptr inbounds float* %faction, i64 %idxprom329
  %89 = load float* %arrayidx378, align 4, !tbaa !3
  %sub379 = fsub float %89, %mul366
  store float %sub379, float* %arrayidx378, align 4, !tbaa !3
  %arrayidx385 = getelementptr inbounds float* %faction, i64 %idxprom332
  %90 = load float* %arrayidx385, align 4, !tbaa !3
  %sub386 = fsub float %90, %mul367
  store float %sub386, float* %arrayidx385, align 4, !tbaa !3
  %indvars.iv.next871 = add i64 %indvars.iv870, 1
  %91 = trunc i64 %indvars.iv.next871 to i32
  %cmp320 = icmp slt i32 %91, %10
  br i1 %cmp320, label %for.body322, label %for.end392

for.end392:                                       ; preds = %for.body322, %for.body303
  %fiz1.2.lcssa = phi float [ 0.000000e+00, %for.body303 ], [ %add370, %for.body322 ]
  %fiy1.2.lcssa = phi float [ 0.000000e+00, %for.body303 ], [ %add369, %for.body322 ]
  %fix1.2.lcssa = phi float [ 0.000000e+00, %for.body303 ], [ %add368, %for.body322 ]
  %vnbtot.3.lcssa = phi float [ %vnbtot.2848, %for.body303 ], [ %sub360, %for.body322 ]
  %arrayidx394 = getelementptr inbounds float* %faction, i64 %indvars.iv874
  %92 = load float* %arrayidx394, align 4, !tbaa !3
  %add395 = fadd float %fix1.2.lcssa, %92
  store float %add395, float* %arrayidx394, align 4, !tbaa !3
  %arrayidx400 = getelementptr inbounds float* %faction, i64 %76
  %93 = load float* %arrayidx400, align 4, !tbaa !3
  %add401 = fadd float %fiy1.2.lcssa, %93
  store float %add401, float* %arrayidx400, align 4, !tbaa !3
  %arrayidx407 = getelementptr inbounds float* %faction, i64 %78
  %94 = load float* %arrayidx407, align 4, !tbaa !3
  %add408 = fadd float %fiz1.2.lcssa, %94
  store float %add408, float* %arrayidx407, align 4, !tbaa !3
  %95 = load float* %arrayidx413, align 4, !tbaa !3
  %add414 = fadd float %fix1.2.lcssa, %95
  store float %add414, float* %arrayidx413, align 4, !tbaa !3
  %96 = load float* %arrayidx419, align 4, !tbaa !3
  %add420 = fadd float %fiy1.2.lcssa, %96
  store float %add420, float* %arrayidx419, align 4, !tbaa !3
  %97 = load float* %arrayidx426, align 4, !tbaa !3
  %add427 = fadd float %fiz1.2.lcssa, %97
  store float %add427, float* %arrayidx426, align 4, !tbaa !3
  %indvars.iv.next873 = add i64 %indvars.iv872, 1
  %indvars.iv.next875 = add i64 %indvars.iv874, 3
  %inc434 = add nsw i32 %s.2849, 1
  %exitcond878 = icmp eq i32 %inc434, %1
  br i1 %exitcond878, label %for.end435, label %for.body303

for.end435:                                       ; preds = %for.end392, %for.cond300.loopexit
  %vnbtot.2.lcssa = phi float [ %vnbtot.0.lcssa, %for.cond300.loopexit ], [ %vnbtot.3.lcssa, %for.end392 ]
  %arrayidx437 = getelementptr inbounds i32* %gid, i64 %indvars.iv879
  %98 = load i32* %arrayidx437, align 4, !tbaa !0
  %idxprom438 = sext i32 %98 to i64
  %arrayidx439 = getelementptr inbounds float* %Vc, i64 %idxprom438
  %99 = load float* %arrayidx439, align 4, !tbaa !3
  %add440 = fadd float %vctot.2.lcssa, %99
  store float %add440, float* %arrayidx439, align 4, !tbaa !3
  %arrayidx444 = getelementptr inbounds float* %Vnb, i64 %idxprom438
  %100 = load float* %arrayidx444, align 4, !tbaa !3
  %add445 = fadd float %vnbtot.2.lcssa, %100
  store float %add445, float* %arrayidx444, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next880 to i32
  %exitcond881 = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond881, label %for.end450, label %for.body

for.end450:                                       ; preds = %for.end435, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl2120(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, float %krf, float %crf, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb) #0 {
entry:
  %0 = load i32* %iinr, align 4, !tbaa !0
  %idxprom = sext i32 %0 to i64
  %arrayidx1 = getelementptr inbounds float* %charge, i64 %idxprom
  %1 = load float* %arrayidx1, align 4, !tbaa !3
  %add = add nsw i32 %0, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds float* %charge, i64 %idxprom2
  %2 = load float* %arrayidx3, align 4, !tbaa !3
  %mul = fmul float %1, %facel
  %mul4 = fmul float %2, %facel
  %mul5 = shl i32 %ntype, 1
  %arrayidx7 = getelementptr inbounds i32* %type, i64 %idxprom
  %3 = load i32* %arrayidx7, align 4, !tbaa !0
  %mul8 = mul nsw i32 %mul5, %3
  %cmp557 = icmp sgt i32 %nri, 0
  br i1 %cmp557, label %for.body, label %for.end311

for.body:                                         ; preds = %entry, %for.end.for.body_crit_edge
  %4 = phi i32 [ %.pre, %for.end.for.body_crit_edge ], [ %0, %entry ]
  %indvars.iv559 = phi i64 [ %indvars.iv.next560, %for.end.for.body_crit_edge ], [ 0, %entry ]
  %arrayidx10 = getelementptr inbounds i32* %shift, i64 %indvars.iv559
  %5 = load i32* %arrayidx10, align 4, !tbaa !0
  %mul11 = mul nsw i32 %5, 3
  %idxprom12 = sext i32 %mul11 to i64
  %arrayidx13 = getelementptr inbounds float* %shiftvec, i64 %idxprom12
  %6 = load float* %arrayidx13, align 4, !tbaa !3
  %add14 = add nsw i32 %mul11, 1
  %idxprom15 = sext i32 %add14 to i64
  %arrayidx16 = getelementptr inbounds float* %shiftvec, i64 %idxprom15
  %7 = load float* %arrayidx16, align 4, !tbaa !3
  %add17 = add nsw i32 %mul11, 2
  %idxprom18 = sext i32 %add17 to i64
  %arrayidx19 = getelementptr inbounds float* %shiftvec, i64 %idxprom18
  %8 = load float* %arrayidx19, align 4, !tbaa !3
  %mul22 = mul nsw i32 %4, 3
  %arrayidx24 = getelementptr inbounds i32* %jindex, i64 %indvars.iv559
  %9 = load i32* %arrayidx24, align 4, !tbaa !0
  %indvars.iv.next560 = add i64 %indvars.iv559, 1
  %arrayidx27 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next560
  %10 = load i32* %arrayidx27, align 4, !tbaa !0
  %idxprom28 = sext i32 %mul22 to i64
  %arrayidx29 = getelementptr inbounds float* %pos, i64 %idxprom28
  %11 = load float* %arrayidx29, align 4, !tbaa !3
  %add30 = fadd float %6, %11
  %add31 = add nsw i32 %mul22, 1
  %idxprom32 = sext i32 %add31 to i64
  %arrayidx33 = getelementptr inbounds float* %pos, i64 %idxprom32
  %12 = load float* %arrayidx33, align 4, !tbaa !3
  %add34 = fadd float %7, %12
  %add35 = add nsw i32 %mul22, 2
  %idxprom36 = sext i32 %add35 to i64
  %arrayidx37 = getelementptr inbounds float* %pos, i64 %idxprom36
  %13 = load float* %arrayidx37, align 4, !tbaa !3
  %add38 = fadd float %8, %13
  %add39 = add nsw i32 %mul22, 3
  %idxprom40 = sext i32 %add39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %14 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = fadd float %6, %14
  %add43 = add nsw i32 %mul22, 4
  %idxprom44 = sext i32 %add43 to i64
  %arrayidx45 = getelementptr inbounds float* %pos, i64 %idxprom44
  %15 = load float* %arrayidx45, align 4, !tbaa !3
  %add46 = fadd float %7, %15
  %add47 = add nsw i32 %mul22, 5
  %idxprom48 = sext i32 %add47 to i64
  %arrayidx49 = getelementptr inbounds float* %pos, i64 %idxprom48
  %16 = load float* %arrayidx49, align 4, !tbaa !3
  %add50 = fadd float %8, %16
  %add51 = add nsw i32 %mul22, 6
  %idxprom52 = sext i32 %add51 to i64
  %arrayidx53 = getelementptr inbounds float* %pos, i64 %idxprom52
  %17 = load float* %arrayidx53, align 4, !tbaa !3
  %add54 = fadd float %6, %17
  %add55 = add nsw i32 %mul22, 7
  %idxprom56 = sext i32 %add55 to i64
  %arrayidx57 = getelementptr inbounds float* %pos, i64 %idxprom56
  %18 = load float* %arrayidx57, align 4, !tbaa !3
  %add58 = fadd float %7, %18
  %add59 = add nsw i32 %mul22, 8
  %idxprom60 = sext i32 %add59 to i64
  %arrayidx61 = getelementptr inbounds float* %pos, i64 %idxprom60
  %19 = load float* %arrayidx61, align 4, !tbaa !3
  %add62 = fadd float %8, %19
  %cmp64534 = icmp slt i32 %9, %10
  br i1 %cmp64534, label %for.body65.lr.ph, label %for.end

for.body65.lr.ph:                                 ; preds = %for.body
  %20 = sext i32 %9 to i64
  br label %for.body65

for.body65:                                       ; preds = %for.body65.lr.ph, %for.body65
  %indvars.iv = phi i64 [ %20, %for.body65.lr.ph ], [ %indvars.iv.next, %for.body65 ]
  %vctot.0545 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add193, %for.body65 ]
  %vnbtot.0544 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %sub125, %for.body65 ]
  %fix1.0543 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add145, %for.body65 ]
  %fiy1.0542 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add146, %for.body65 ]
  %fiz1.0541 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add147, %for.body65 ]
  %fix2.0540 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add175, %for.body65 ]
  %fiy2.0539 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add176, %for.body65 ]
  %fiz2.0538 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add177, %for.body65 ]
  %fix3.0537 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add197, %for.body65 ]
  %fiy3.0536 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add198, %for.body65 ]
  %fiz3.0535 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add199, %for.body65 ]
  %arrayidx67 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %21 = load i32* %arrayidx67, align 4, !tbaa !0
  %mul68 = mul nsw i32 %21, 3
  %idxprom69 = sext i32 %mul68 to i64
  %arrayidx70 = getelementptr inbounds float* %pos, i64 %idxprom69
  %22 = load float* %arrayidx70, align 4, !tbaa !3
  %add71 = add nsw i32 %mul68, 1
  %idxprom72 = sext i32 %add71 to i64
  %arrayidx73 = getelementptr inbounds float* %pos, i64 %idxprom72
  %23 = load float* %arrayidx73, align 4, !tbaa !3
  %add74 = add nsw i32 %mul68, 2
  %idxprom75 = sext i32 %add74 to i64
  %arrayidx76 = getelementptr inbounds float* %pos, i64 %idxprom75
  %24 = load float* %arrayidx76, align 4, !tbaa !3
  %sub = fsub float %add30, %22
  %sub77 = fsub float %add34, %23
  %sub78 = fsub float %add38, %24
  %mul79 = fmul float %sub, %sub
  %mul80 = fmul float %sub77, %sub77
  %add81 = fadd float %mul79, %mul80
  %mul82 = fmul float %sub78, %sub78
  %add83 = fadd float %add81, %mul82
  %sub84 = fsub float %add42, %22
  %sub85 = fsub float %add46, %23
  %sub86 = fsub float %add50, %24
  %mul87 = fmul float %sub84, %sub84
  %mul88 = fmul float %sub85, %sub85
  %add89 = fadd float %mul87, %mul88
  %mul90 = fmul float %sub86, %sub86
  %add91 = fadd float %add89, %mul90
  %sub92 = fsub float %add54, %22
  %sub93 = fsub float %add58, %23
  %sub94 = fsub float %add62, %24
  %mul95 = fmul float %sub92, %sub92
  %mul96 = fmul float %sub93, %sub93
  %add97 = fadd float %mul95, %mul96
  %mul98 = fmul float %sub94, %sub94
  %add99 = fadd float %add97, %mul98
  %conv = fpext float %add83 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv100 = fptrunc double %div to float
  %conv101 = fpext float %add91 to double
  %call102 = tail call double @sqrt(double %conv101) #2
  %div103 = fdiv double 1.000000e+00, %call102
  %conv104 = fptrunc double %div103 to float
  %conv105 = fpext float %add99 to double
  %call106 = tail call double @sqrt(double %conv105) #2
  %div107 = fdiv double 1.000000e+00, %call106
  %conv108 = fptrunc double %div107 to float
  %mul109 = fmul float %conv100, %conv100
  %mul110 = fmul float %mul109, %mul109
  %mul111 = fmul float %mul109, %mul110
  %idxprom112 = sext i32 %21 to i64
  %arrayidx113 = getelementptr inbounds i32* %type, i64 %idxprom112
  %25 = load i32* %arrayidx113, align 4, !tbaa !0
  %mul114 = shl nsw i32 %25, 1
  %add115 = add nsw i32 %mul114, %mul8
  %idxprom116 = sext i32 %add115 to i64
  %arrayidx117 = getelementptr inbounds float* %nbfp, i64 %idxprom116
  %26 = load float* %arrayidx117, align 4, !tbaa !3
  %mul118 = fmul float %mul111, %26
  %mul119 = fmul float %mul111, %mul111
  %add120533 = or i32 %add115, 1
  %idxprom121 = sext i32 %add120533 to i64
  %arrayidx122 = getelementptr inbounds float* %nbfp, i64 %idxprom121
  %27 = load float* %arrayidx122, align 4, !tbaa !3
  %mul123 = fmul float %mul119, %27
  %add124 = fadd float %vnbtot.0544, %mul123
  %sub125 = fsub float %add124, %mul118
  %arrayidx127 = getelementptr inbounds float* %charge, i64 %idxprom112
  %28 = load float* %arrayidx127, align 4, !tbaa !3
  %mul128 = fmul float %mul, %28
  %mul129 = fmul float %add83, %krf
  %add130 = fadd float %conv100, %mul129
  %sub131 = fsub float %add130, %crf
  %mul132 = fmul float %sub131, %mul128
  %mul133 = fmul float %mul123, 1.200000e+01
  %mul134 = fmul float %mul118, 6.000000e+00
  %sub135 = fsub float %mul133, %mul134
  %mul136 = fmul float %mul129, 2.000000e+00
  %sub137 = fsub float %conv100, %mul136
  %mul138 = fmul float %sub137, %mul128
  %add139 = fadd float %sub135, %mul138
  %mul140 = fmul float %mul109, %add139
  %add141 = fadd float %vctot.0545, %mul132
  %mul142 = fmul float %sub, %mul140
  %mul143 = fmul float %sub77, %mul140
  %mul144 = fmul float %sub78, %mul140
  %add145 = fadd float %fix1.0543, %mul142
  %add146 = fadd float %fiy1.0542, %mul143
  %add147 = fadd float %fiz1.0541, %mul144
  %arrayidx149 = getelementptr inbounds float* %faction, i64 %idxprom69
  %29 = load float* %arrayidx149, align 4, !tbaa !3
  %sub150 = fsub float %29, %mul142
  %arrayidx153 = getelementptr inbounds float* %faction, i64 %idxprom72
  %30 = load float* %arrayidx153, align 4, !tbaa !3
  %sub154 = fsub float %30, %mul143
  %arrayidx157 = getelementptr inbounds float* %faction, i64 %idxprom75
  %31 = load float* %arrayidx157, align 4, !tbaa !3
  %sub158 = fsub float %31, %mul144
  %mul159 = fmul float %conv104, %conv104
  %mul162 = fmul float %mul4, %28
  %mul163 = fmul float %add91, %krf
  %add164 = fadd float %mul163, %conv104
  %sub165 = fsub float %add164, %crf
  %mul166 = fmul float %sub165, %mul162
  %mul167 = fmul float %mul163, 2.000000e+00
  %sub168 = fsub float %conv104, %mul167
  %mul169 = fmul float %sub168, %mul162
  %mul170 = fmul float %mul159, %mul169
  %add171 = fadd float %mul166, %add141
  %mul172 = fmul float %sub84, %mul170
  %mul173 = fmul float %sub85, %mul170
  %mul174 = fmul float %sub86, %mul170
  %add175 = fadd float %fix2.0540, %mul172
  %add176 = fadd float %fiy2.0539, %mul173
  %add177 = fadd float %fiz2.0538, %mul174
  %sub178 = fsub float %sub150, %mul172
  %sub179 = fsub float %sub154, %mul173
  %sub180 = fsub float %sub158, %mul174
  %mul181 = fmul float %conv108, %conv108
  %mul185 = fmul float %add99, %krf
  %add186 = fadd float %mul185, %conv108
  %sub187 = fsub float %add186, %crf
  %mul188 = fmul float %sub187, %mul162
  %mul189 = fmul float %mul185, 2.000000e+00
  %sub190 = fsub float %conv108, %mul189
  %mul191 = fmul float %sub190, %mul162
  %mul192 = fmul float %mul181, %mul191
  %add193 = fadd float %mul188, %add171
  %mul194 = fmul float %sub92, %mul192
  %mul195 = fmul float %sub93, %mul192
  %mul196 = fmul float %sub94, %mul192
  %add197 = fadd float %fix3.0537, %mul194
  %add198 = fadd float %fiy3.0536, %mul195
  %add199 = fadd float %fiz3.0535, %mul196
  %sub200 = fsub float %sub178, %mul194
  store float %sub200, float* %arrayidx149, align 4, !tbaa !3
  %sub203 = fsub float %sub179, %mul195
  store float %sub203, float* %arrayidx153, align 4, !tbaa !3
  %sub207 = fsub float %sub180, %mul196
  store float %sub207, float* %arrayidx157, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %32 = trunc i64 %indvars.iv.next to i32
  %cmp64 = icmp slt i32 %32, %10
  br i1 %cmp64, label %for.body65, label %for.end

for.end:                                          ; preds = %for.body65, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add193, %for.body65 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %sub125, %for.body65 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add145, %for.body65 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add146, %for.body65 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add147, %for.body65 ]
  %fix2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add175, %for.body65 ]
  %fiy2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add176, %for.body65 ]
  %fiz2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add177, %for.body65 ]
  %fix3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add197, %for.body65 ]
  %fiy3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add198, %for.body65 ]
  %fiz3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add199, %for.body65 ]
  %arrayidx212 = getelementptr inbounds float* %faction, i64 %idxprom28
  %33 = load float* %arrayidx212, align 4, !tbaa !3
  %add213 = fadd float %fix1.0.lcssa, %33
  store float %add213, float* %arrayidx212, align 4, !tbaa !3
  %arrayidx218 = getelementptr inbounds float* %faction, i64 %idxprom32
  %34 = load float* %arrayidx218, align 4, !tbaa !3
  %add219 = fadd float %fiy1.0.lcssa, %34
  store float %add219, float* %arrayidx218, align 4, !tbaa !3
  %arrayidx225 = getelementptr inbounds float* %faction, i64 %idxprom36
  %35 = load float* %arrayidx225, align 4, !tbaa !3
  %add226 = fadd float %fiz1.0.lcssa, %35
  store float %add226, float* %arrayidx225, align 4, !tbaa !3
  %arrayidx232 = getelementptr inbounds float* %faction, i64 %idxprom40
  %36 = load float* %arrayidx232, align 4, !tbaa !3
  %add233 = fadd float %fix2.0.lcssa, %36
  store float %add233, float* %arrayidx232, align 4, !tbaa !3
  %arrayidx239 = getelementptr inbounds float* %faction, i64 %idxprom44
  %37 = load float* %arrayidx239, align 4, !tbaa !3
  %add240 = fadd float %fiy2.0.lcssa, %37
  store float %add240, float* %arrayidx239, align 4, !tbaa !3
  %arrayidx246 = getelementptr inbounds float* %faction, i64 %idxprom48
  %38 = load float* %arrayidx246, align 4, !tbaa !3
  %add247 = fadd float %fiz2.0.lcssa, %38
  store float %add247, float* %arrayidx246, align 4, !tbaa !3
  %arrayidx253 = getelementptr inbounds float* %faction, i64 %idxprom52
  %39 = load float* %arrayidx253, align 4, !tbaa !3
  %add254 = fadd float %fix3.0.lcssa, %39
  store float %add254, float* %arrayidx253, align 4, !tbaa !3
  %arrayidx260 = getelementptr inbounds float* %faction, i64 %idxprom56
  %40 = load float* %arrayidx260, align 4, !tbaa !3
  %add261 = fadd float %fiy3.0.lcssa, %40
  store float %add261, float* %arrayidx260, align 4, !tbaa !3
  %arrayidx267 = getelementptr inbounds float* %faction, i64 %idxprom60
  %41 = load float* %arrayidx267, align 4, !tbaa !3
  %add268 = fadd float %fiz3.0.lcssa, %41
  store float %add268, float* %arrayidx267, align 4, !tbaa !3
  %arrayidx273 = getelementptr inbounds float* %fshift, i64 %idxprom12
  %42 = load float* %arrayidx273, align 4, !tbaa !3
  %add274 = fadd float %fix1.0.lcssa, %42
  %add275 = fadd float %fix2.0.lcssa, %add274
  %add276 = fadd float %fix3.0.lcssa, %add275
  store float %add276, float* %arrayidx273, align 4, !tbaa !3
  %arrayidx281 = getelementptr inbounds float* %fshift, i64 %idxprom15
  %43 = load float* %arrayidx281, align 4, !tbaa !3
  %add282 = fadd float %fiy1.0.lcssa, %43
  %add283 = fadd float %fiy2.0.lcssa, %add282
  %add284 = fadd float %fiy3.0.lcssa, %add283
  store float %add284, float* %arrayidx281, align 4, !tbaa !3
  %arrayidx290 = getelementptr inbounds float* %fshift, i64 %idxprom18
  %44 = load float* %arrayidx290, align 4, !tbaa !3
  %add291 = fadd float %fiz1.0.lcssa, %44
  %add292 = fadd float %fiz2.0.lcssa, %add291
  %add293 = fadd float %fiz3.0.lcssa, %add292
  store float %add293, float* %arrayidx290, align 4, !tbaa !3
  %arrayidx298 = getelementptr inbounds i32* %gid, i64 %indvars.iv559
  %45 = load i32* %arrayidx298, align 4, !tbaa !0
  %idxprom299 = sext i32 %45 to i64
  %arrayidx300 = getelementptr inbounds float* %Vc, i64 %idxprom299
  %46 = load float* %arrayidx300, align 4, !tbaa !3
  %add301 = fadd float %vctot.0.lcssa, %46
  store float %add301, float* %arrayidx300, align 4, !tbaa !3
  %arrayidx305 = getelementptr inbounds float* %Vnb, i64 %idxprom299
  %47 = load float* %arrayidx305, align 4, !tbaa !3
  %add306 = fadd float %vnbtot.0.lcssa, %47
  store float %add306, float* %arrayidx305, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next560 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end311, label %for.end.for.body_crit_edge

for.end.for.body_crit_edge:                       ; preds = %for.end
  %arrayidx21.phi.trans.insert = getelementptr inbounds i32* %iinr, i64 %indvars.iv.next560
  %.pre = load i32* %arrayidx21.phi.trans.insert, align 4, !tbaa !0
  br label %for.body

for.end311:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl2130(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, float %krf, float %crf, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb) #0 {
entry:
  %0 = load i32* %iinr, align 4, !tbaa !0
  %idxprom = sext i32 %0 to i64
  %arrayidx1 = getelementptr inbounds float* %charge, i64 %idxprom
  %1 = load float* %arrayidx1, align 4, !tbaa !3
  %add = add nsw i32 %0, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds float* %charge, i64 %idxprom2
  %2 = load float* %arrayidx3, align 4, !tbaa !3
  %mul = fmul float %1, %facel
  %mul4 = fmul float %1, %mul
  %mul6 = fmul float %mul, %2
  %mul7 = fmul float %2, %facel
  %mul8 = fmul float %2, %mul7
  %mul9 = shl i32 %ntype, 1
  %arrayidx11 = getelementptr inbounds i32* %type, i64 %idxprom
  %3 = load i32* %arrayidx11, align 4, !tbaa !0
  %mul12 = mul nsw i32 %mul9, %3
  %mul15 = shl nsw i32 %3, 1
  %add16 = add nsw i32 %mul12, %mul15
  %idxprom17 = sext i32 %add16 to i64
  %arrayidx18 = getelementptr inbounds float* %nbfp, i64 %idxprom17
  %4 = load float* %arrayidx18, align 4, !tbaa !3
  %add19990 = or i32 %add16, 1
  %idxprom20 = sext i32 %add19990 to i64
  %arrayidx21 = getelementptr inbounds float* %nbfp, i64 %idxprom20
  %5 = load float* %arrayidx21, align 4, !tbaa !3
  %cmp1014 = icmp sgt i32 %nri, 0
  br i1 %cmp1014, label %for.body, label %for.end546

for.body:                                         ; preds = %entry, %for.end.for.body_crit_edge
  %6 = phi i32 [ %.pre, %for.end.for.body_crit_edge ], [ %0, %entry ]
  %indvars.iv1016 = phi i64 [ %indvars.iv.next1017, %for.end.for.body_crit_edge ], [ 0, %entry ]
  %arrayidx23 = getelementptr inbounds i32* %shift, i64 %indvars.iv1016
  %7 = load i32* %arrayidx23, align 4, !tbaa !0
  %mul24 = mul nsw i32 %7, 3
  %idxprom25 = sext i32 %mul24 to i64
  %arrayidx26 = getelementptr inbounds float* %shiftvec, i64 %idxprom25
  %8 = load float* %arrayidx26, align 4, !tbaa !3
  %add27 = add nsw i32 %mul24, 1
  %idxprom28 = sext i32 %add27 to i64
  %arrayidx29 = getelementptr inbounds float* %shiftvec, i64 %idxprom28
  %9 = load float* %arrayidx29, align 4, !tbaa !3
  %add30 = add nsw i32 %mul24, 2
  %idxprom31 = sext i32 %add30 to i64
  %arrayidx32 = getelementptr inbounds float* %shiftvec, i64 %idxprom31
  %10 = load float* %arrayidx32, align 4, !tbaa !3
  %mul35 = mul nsw i32 %6, 3
  %arrayidx37 = getelementptr inbounds i32* %jindex, i64 %indvars.iv1016
  %11 = load i32* %arrayidx37, align 4, !tbaa !0
  %indvars.iv.next1017 = add i64 %indvars.iv1016, 1
  %arrayidx40 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next1017
  %12 = load i32* %arrayidx40, align 4, !tbaa !0
  %idxprom41 = sext i32 %mul35 to i64
  %arrayidx42 = getelementptr inbounds float* %pos, i64 %idxprom41
  %13 = load float* %arrayidx42, align 4, !tbaa !3
  %add43 = fadd float %8, %13
  %add44 = add nsw i32 %mul35, 1
  %idxprom45 = sext i32 %add44 to i64
  %arrayidx46 = getelementptr inbounds float* %pos, i64 %idxprom45
  %14 = load float* %arrayidx46, align 4, !tbaa !3
  %add47 = fadd float %9, %14
  %add48 = add nsw i32 %mul35, 2
  %idxprom49 = sext i32 %add48 to i64
  %arrayidx50 = getelementptr inbounds float* %pos, i64 %idxprom49
  %15 = load float* %arrayidx50, align 4, !tbaa !3
  %add51 = fadd float %10, %15
  %add52 = add nsw i32 %mul35, 3
  %idxprom53 = sext i32 %add52 to i64
  %arrayidx54 = getelementptr inbounds float* %pos, i64 %idxprom53
  %16 = load float* %arrayidx54, align 4, !tbaa !3
  %add55 = fadd float %8, %16
  %add56 = add nsw i32 %mul35, 4
  %idxprom57 = sext i32 %add56 to i64
  %arrayidx58 = getelementptr inbounds float* %pos, i64 %idxprom57
  %17 = load float* %arrayidx58, align 4, !tbaa !3
  %add59 = fadd float %9, %17
  %add60 = add nsw i32 %mul35, 5
  %idxprom61 = sext i32 %add60 to i64
  %arrayidx62 = getelementptr inbounds float* %pos, i64 %idxprom61
  %18 = load float* %arrayidx62, align 4, !tbaa !3
  %add63 = fadd float %10, %18
  %add64 = add nsw i32 %mul35, 6
  %idxprom65 = sext i32 %add64 to i64
  %arrayidx66 = getelementptr inbounds float* %pos, i64 %idxprom65
  %19 = load float* %arrayidx66, align 4, !tbaa !3
  %add67 = fadd float %8, %19
  %add68 = add nsw i32 %mul35, 7
  %idxprom69 = sext i32 %add68 to i64
  %arrayidx70 = getelementptr inbounds float* %pos, i64 %idxprom69
  %20 = load float* %arrayidx70, align 4, !tbaa !3
  %add71 = fadd float %9, %20
  %add72 = add nsw i32 %mul35, 8
  %idxprom73 = sext i32 %add72 to i64
  %arrayidx74 = getelementptr inbounds float* %pos, i64 %idxprom73
  %21 = load float* %arrayidx74, align 4, !tbaa !3
  %add75 = fadd float %10, %21
  %cmp77991 = icmp slt i32 %11, %12
  br i1 %cmp77991, label %for.body78.lr.ph, label %for.end

for.body78.lr.ph:                                 ; preds = %for.body
  %22 = sext i32 %11 to i64
  br label %for.body78

for.body78:                                       ; preds = %for.body78.lr.ph, %for.body78
  %indvars.iv = phi i64 [ %22, %for.body78.lr.ph ], [ %indvars.iv.next, %for.body78 ]
  %vctot.01002 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add427, %for.body78 ]
  %vnbtot.01001 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %sub219, %for.body78 ]
  %fix1.01000 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add291, %for.body78 ]
  %fiy1.0999 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add292, %for.body78 ]
  %fiz1.0998 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add293, %for.body78 ]
  %fix2.0997 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add357, %for.body78 ]
  %fiy2.0996 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add358, %for.body78 ]
  %fiz2.0995 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add359, %for.body78 ]
  %fix3.0994 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add431, %for.body78 ]
  %fiy3.0993 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add432, %for.body78 ]
  %fiz3.0992 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add433, %for.body78 ]
  %arrayidx80 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %23 = load i32* %arrayidx80, align 4, !tbaa !0
  %mul81 = mul nsw i32 %23, 3
  %idxprom82 = sext i32 %mul81 to i64
  %arrayidx83 = getelementptr inbounds float* %pos, i64 %idxprom82
  %24 = load float* %arrayidx83, align 4, !tbaa !3
  %add84 = add nsw i32 %mul81, 1
  %idxprom85 = sext i32 %add84 to i64
  %arrayidx86 = getelementptr inbounds float* %pos, i64 %idxprom85
  %25 = load float* %arrayidx86, align 4, !tbaa !3
  %add87 = add nsw i32 %mul81, 2
  %idxprom88 = sext i32 %add87 to i64
  %arrayidx89 = getelementptr inbounds float* %pos, i64 %idxprom88
  %26 = load float* %arrayidx89, align 4, !tbaa !3
  %add90 = add nsw i32 %mul81, 3
  %idxprom91 = sext i32 %add90 to i64
  %arrayidx92 = getelementptr inbounds float* %pos, i64 %idxprom91
  %27 = load float* %arrayidx92, align 4, !tbaa !3
  %add93 = add nsw i32 %mul81, 4
  %idxprom94 = sext i32 %add93 to i64
  %arrayidx95 = getelementptr inbounds float* %pos, i64 %idxprom94
  %28 = load float* %arrayidx95, align 4, !tbaa !3
  %add96 = add nsw i32 %mul81, 5
  %idxprom97 = sext i32 %add96 to i64
  %arrayidx98 = getelementptr inbounds float* %pos, i64 %idxprom97
  %29 = load float* %arrayidx98, align 4, !tbaa !3
  %add99 = add nsw i32 %mul81, 6
  %idxprom100 = sext i32 %add99 to i64
  %arrayidx101 = getelementptr inbounds float* %pos, i64 %idxprom100
  %30 = load float* %arrayidx101, align 4, !tbaa !3
  %add102 = add nsw i32 %mul81, 7
  %idxprom103 = sext i32 %add102 to i64
  %arrayidx104 = getelementptr inbounds float* %pos, i64 %idxprom103
  %31 = load float* %arrayidx104, align 4, !tbaa !3
  %add105 = add nsw i32 %mul81, 8
  %idxprom106 = sext i32 %add105 to i64
  %arrayidx107 = getelementptr inbounds float* %pos, i64 %idxprom106
  %32 = load float* %arrayidx107, align 4, !tbaa !3
  %sub = fsub float %add43, %24
  %sub108 = fsub float %add47, %25
  %sub109 = fsub float %add51, %26
  %mul110 = fmul float %sub, %sub
  %mul111 = fmul float %sub108, %sub108
  %add112 = fadd float %mul110, %mul111
  %mul113 = fmul float %sub109, %sub109
  %add114 = fadd float %add112, %mul113
  %sub115 = fsub float %add43, %27
  %sub116 = fsub float %add47, %28
  %sub117 = fsub float %add51, %29
  %mul118 = fmul float %sub115, %sub115
  %mul119 = fmul float %sub116, %sub116
  %add120 = fadd float %mul118, %mul119
  %mul121 = fmul float %sub117, %sub117
  %add122 = fadd float %add120, %mul121
  %sub123 = fsub float %add43, %30
  %sub124 = fsub float %add47, %31
  %sub125 = fsub float %add51, %32
  %mul126 = fmul float %sub123, %sub123
  %mul127 = fmul float %sub124, %sub124
  %add128 = fadd float %mul126, %mul127
  %mul129 = fmul float %sub125, %sub125
  %add130 = fadd float %add128, %mul129
  %sub131 = fsub float %add55, %24
  %sub132 = fsub float %add59, %25
  %sub133 = fsub float %add63, %26
  %mul134 = fmul float %sub131, %sub131
  %mul135 = fmul float %sub132, %sub132
  %add136 = fadd float %mul134, %mul135
  %mul137 = fmul float %sub133, %sub133
  %add138 = fadd float %add136, %mul137
  %sub139 = fsub float %add55, %27
  %sub140 = fsub float %add59, %28
  %sub141 = fsub float %add63, %29
  %mul142 = fmul float %sub139, %sub139
  %mul143 = fmul float %sub140, %sub140
  %add144 = fadd float %mul142, %mul143
  %mul145 = fmul float %sub141, %sub141
  %add146 = fadd float %add144, %mul145
  %sub147 = fsub float %add55, %30
  %sub148 = fsub float %add59, %31
  %sub149 = fsub float %add63, %32
  %mul150 = fmul float %sub147, %sub147
  %mul151 = fmul float %sub148, %sub148
  %add152 = fadd float %mul150, %mul151
  %mul153 = fmul float %sub149, %sub149
  %add154 = fadd float %add152, %mul153
  %sub155 = fsub float %add67, %24
  %sub156 = fsub float %add71, %25
  %sub157 = fsub float %add75, %26
  %mul158 = fmul float %sub155, %sub155
  %mul159 = fmul float %sub156, %sub156
  %add160 = fadd float %mul158, %mul159
  %mul161 = fmul float %sub157, %sub157
  %add162 = fadd float %add160, %mul161
  %sub163 = fsub float %add67, %27
  %sub164 = fsub float %add71, %28
  %sub165 = fsub float %add75, %29
  %mul166 = fmul float %sub163, %sub163
  %mul167 = fmul float %sub164, %sub164
  %add168 = fadd float %mul166, %mul167
  %mul169 = fmul float %sub165, %sub165
  %add170 = fadd float %add168, %mul169
  %sub171 = fsub float %add67, %30
  %sub172 = fsub float %add71, %31
  %sub173 = fsub float %add75, %32
  %mul174 = fmul float %sub171, %sub171
  %mul175 = fmul float %sub172, %sub172
  %add176 = fadd float %mul174, %mul175
  %mul177 = fmul float %sub173, %sub173
  %add178 = fadd float %add176, %mul177
  %conv = fpext float %add114 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv179 = fptrunc double %div to float
  %conv180 = fpext float %add138 to double
  %call181 = tail call double @sqrt(double %conv180) #2
  %div182 = fdiv double 1.000000e+00, %call181
  %conv183 = fptrunc double %div182 to float
  %conv184 = fpext float %add162 to double
  %call185 = tail call double @sqrt(double %conv184) #2
  %div186 = fdiv double 1.000000e+00, %call185
  %conv187 = fptrunc double %div186 to float
  %conv188 = fpext float %add122 to double
  %call189 = tail call double @sqrt(double %conv188) #2
  %div190 = fdiv double 1.000000e+00, %call189
  %conv191 = fptrunc double %div190 to float
  %conv192 = fpext float %add146 to double
  %call193 = tail call double @sqrt(double %conv192) #2
  %div194 = fdiv double 1.000000e+00, %call193
  %conv195 = fptrunc double %div194 to float
  %conv196 = fpext float %add170 to double
  %call197 = tail call double @sqrt(double %conv196) #2
  %div198 = fdiv double 1.000000e+00, %call197
  %conv199 = fptrunc double %div198 to float
  %conv200 = fpext float %add130 to double
  %call201 = tail call double @sqrt(double %conv200) #2
  %div202 = fdiv double 1.000000e+00, %call201
  %conv203 = fptrunc double %div202 to float
  %conv204 = fpext float %add154 to double
  %call205 = tail call double @sqrt(double %conv204) #2
  %div206 = fdiv double 1.000000e+00, %call205
  %conv207 = fptrunc double %div206 to float
  %conv208 = fpext float %add178 to double
  %call209 = tail call double @sqrt(double %conv208) #2
  %div210 = fdiv double 1.000000e+00, %call209
  %conv211 = fptrunc double %div210 to float
  %mul212 = fmul float %conv179, %conv179
  %mul213 = fmul float %mul212, %mul212
  %mul214 = fmul float %mul212, %mul213
  %mul215 = fmul float %4, %mul214
  %mul216 = fmul float %5, %mul214
  %mul217 = fmul float %mul214, %mul216
  %add218 = fadd float %vnbtot.01001, %mul217
  %sub219 = fsub float %add218, %mul215
  %mul220 = fmul float %add114, %krf
  %add221 = fadd float %mul220, %conv179
  %sub222 = fsub float %add221, %crf
  %mul223 = fmul float %mul4, %sub222
  %mul224 = fmul float %mul217, 1.200000e+01
  %mul225 = fmul float %mul215, 6.000000e+00
  %sub226 = fsub float %mul224, %mul225
  %mul227 = fmul float %mul220, 2.000000e+00
  %sub228 = fsub float %conv179, %mul227
  %mul229 = fmul float %mul4, %sub228
  %add230 = fadd float %mul229, %sub226
  %mul231 = fmul float %mul212, %add230
  %add232 = fadd float %vctot.01002, %mul223
  %mul233 = fmul float %sub, %mul231
  %mul234 = fmul float %sub108, %mul231
  %mul235 = fmul float %sub109, %mul231
  %add236 = fadd float %fix1.01000, %mul233
  %add237 = fadd float %fiy1.0999, %mul234
  %add238 = fadd float %fiz1.0998, %mul235
  %arrayidx240 = getelementptr inbounds float* %faction, i64 %idxprom82
  %33 = load float* %arrayidx240, align 4, !tbaa !3
  %sub241 = fsub float %33, %mul233
  %arrayidx244 = getelementptr inbounds float* %faction, i64 %idxprom85
  %34 = load float* %arrayidx244, align 4, !tbaa !3
  %sub245 = fsub float %34, %mul234
  %arrayidx248 = getelementptr inbounds float* %faction, i64 %idxprom88
  %35 = load float* %arrayidx248, align 4, !tbaa !3
  %sub249 = fsub float %35, %mul235
  %mul250 = fmul float %conv191, %conv191
  %mul251 = fmul float %add122, %krf
  %add252 = fadd float %mul251, %conv191
  %sub253 = fsub float %add252, %crf
  %mul254 = fmul float %mul6, %sub253
  %mul255 = fmul float %mul251, 2.000000e+00
  %sub256 = fsub float %conv191, %mul255
  %mul257 = fmul float %mul6, %sub256
  %mul258 = fmul float %mul250, %mul257
  %add259 = fadd float %add232, %mul254
  %mul260 = fmul float %sub115, %mul258
  %mul261 = fmul float %sub116, %mul258
  %mul262 = fmul float %sub117, %mul258
  %add263 = fadd float %mul260, %add236
  %add264 = fadd float %mul261, %add237
  %add265 = fadd float %mul262, %add238
  %arrayidx268 = getelementptr inbounds float* %faction, i64 %idxprom91
  %36 = load float* %arrayidx268, align 4, !tbaa !3
  %sub269 = fsub float %36, %mul260
  %arrayidx272 = getelementptr inbounds float* %faction, i64 %idxprom94
  %37 = load float* %arrayidx272, align 4, !tbaa !3
  %sub273 = fsub float %37, %mul261
  %arrayidx276 = getelementptr inbounds float* %faction, i64 %idxprom97
  %38 = load float* %arrayidx276, align 4, !tbaa !3
  %sub277 = fsub float %38, %mul262
  %mul278 = fmul float %conv203, %conv203
  %mul279 = fmul float %add130, %krf
  %add280 = fadd float %mul279, %conv203
  %sub281 = fsub float %add280, %crf
  %mul282 = fmul float %mul6, %sub281
  %mul283 = fmul float %mul279, 2.000000e+00
  %sub284 = fsub float %conv203, %mul283
  %mul285 = fmul float %mul6, %sub284
  %mul286 = fmul float %mul278, %mul285
  %add287 = fadd float %add259, %mul282
  %mul288 = fmul float %sub123, %mul286
  %mul289 = fmul float %sub124, %mul286
  %mul290 = fmul float %sub125, %mul286
  %add291 = fadd float %add263, %mul288
  %add292 = fadd float %add264, %mul289
  %add293 = fadd float %add265, %mul290
  %arrayidx296 = getelementptr inbounds float* %faction, i64 %idxprom100
  %39 = load float* %arrayidx296, align 4, !tbaa !3
  %sub297 = fsub float %39, %mul288
  %arrayidx300 = getelementptr inbounds float* %faction, i64 %idxprom103
  %40 = load float* %arrayidx300, align 4, !tbaa !3
  %sub301 = fsub float %40, %mul289
  %arrayidx304 = getelementptr inbounds float* %faction, i64 %idxprom106
  %41 = load float* %arrayidx304, align 4, !tbaa !3
  %sub305 = fsub float %41, %mul290
  %mul306 = fmul float %conv183, %conv183
  %mul307 = fmul float %add138, %krf
  %add308 = fadd float %mul307, %conv183
  %sub309 = fsub float %add308, %crf
  %mul310 = fmul float %mul6, %sub309
  %mul311 = fmul float %mul307, 2.000000e+00
  %sub312 = fsub float %conv183, %mul311
  %mul313 = fmul float %mul6, %sub312
  %mul314 = fmul float %mul306, %mul313
  %add315 = fadd float %mul310, %add287
  %mul316 = fmul float %sub131, %mul314
  %mul317 = fmul float %sub132, %mul314
  %mul318 = fmul float %sub133, %mul314
  %add319 = fadd float %fix2.0997, %mul316
  %add320 = fadd float %fiy2.0996, %mul317
  %add321 = fadd float %fiz2.0995, %mul318
  %sub322 = fsub float %sub241, %mul316
  %sub323 = fsub float %sub245, %mul317
  %sub324 = fsub float %sub249, %mul318
  %mul325 = fmul float %conv195, %conv195
  %mul326 = fmul float %add146, %krf
  %add327 = fadd float %mul326, %conv195
  %sub328 = fsub float %add327, %crf
  %mul329 = fmul float %mul8, %sub328
  %mul330 = fmul float %mul326, 2.000000e+00
  %sub331 = fsub float %conv195, %mul330
  %mul332 = fmul float %mul8, %sub331
  %mul333 = fmul float %mul325, %mul332
  %add334 = fadd float %mul329, %add315
  %mul335 = fmul float %sub139, %mul333
  %mul336 = fmul float %sub140, %mul333
  %mul337 = fmul float %sub141, %mul333
  %add338 = fadd float %add319, %mul335
  %add339 = fadd float %add320, %mul336
  %add340 = fadd float %add321, %mul337
  %sub341 = fsub float %sub269, %mul335
  %sub342 = fsub float %sub273, %mul336
  %sub343 = fsub float %sub277, %mul337
  %mul344 = fmul float %conv207, %conv207
  %mul345 = fmul float %add154, %krf
  %add346 = fadd float %mul345, %conv207
  %sub347 = fsub float %add346, %crf
  %mul348 = fmul float %mul8, %sub347
  %mul349 = fmul float %mul345, 2.000000e+00
  %sub350 = fsub float %conv207, %mul349
  %mul351 = fmul float %mul8, %sub350
  %mul352 = fmul float %mul344, %mul351
  %add353 = fadd float %mul348, %add334
  %mul354 = fmul float %sub147, %mul352
  %mul355 = fmul float %sub148, %mul352
  %mul356 = fmul float %sub149, %mul352
  %add357 = fadd float %add338, %mul354
  %add358 = fadd float %add339, %mul355
  %add359 = fadd float %add340, %mul356
  %sub360 = fsub float %sub297, %mul354
  %sub361 = fsub float %sub301, %mul355
  %sub362 = fsub float %sub305, %mul356
  %mul363 = fmul float %conv187, %conv187
  %mul364 = fmul float %add162, %krf
  %add365 = fadd float %mul364, %conv187
  %sub366 = fsub float %add365, %crf
  %mul367 = fmul float %mul6, %sub366
  %mul368 = fmul float %mul364, 2.000000e+00
  %sub369 = fsub float %conv187, %mul368
  %mul370 = fmul float %mul6, %sub369
  %mul371 = fmul float %mul363, %mul370
  %add372 = fadd float %mul367, %add353
  %mul373 = fmul float %sub155, %mul371
  %mul374 = fmul float %sub156, %mul371
  %mul375 = fmul float %sub157, %mul371
  %add376 = fadd float %fix3.0994, %mul373
  %add377 = fadd float %fiy3.0993, %mul374
  %add378 = fadd float %fiz3.0992, %mul375
  %sub379 = fsub float %sub322, %mul373
  store float %sub379, float* %arrayidx240, align 4, !tbaa !3
  %sub382 = fsub float %sub323, %mul374
  store float %sub382, float* %arrayidx244, align 4, !tbaa !3
  %sub386 = fsub float %sub324, %mul375
  store float %sub386, float* %arrayidx248, align 4, !tbaa !3
  %mul390 = fmul float %conv199, %conv199
  %mul391 = fmul float %add170, %krf
  %add392 = fadd float %mul391, %conv199
  %sub393 = fsub float %add392, %crf
  %mul394 = fmul float %mul8, %sub393
  %mul395 = fmul float %mul391, 2.000000e+00
  %sub396 = fsub float %conv199, %mul395
  %mul397 = fmul float %mul8, %sub396
  %mul398 = fmul float %mul390, %mul397
  %add399 = fadd float %mul394, %add372
  %mul400 = fmul float %sub163, %mul398
  %mul401 = fmul float %sub164, %mul398
  %mul402 = fmul float %sub165, %mul398
  %add403 = fadd float %add376, %mul400
  %add404 = fadd float %add377, %mul401
  %add405 = fadd float %add378, %mul402
  %sub406 = fsub float %sub341, %mul400
  store float %sub406, float* %arrayidx268, align 4, !tbaa !3
  %sub410 = fsub float %sub342, %mul401
  store float %sub410, float* %arrayidx272, align 4, !tbaa !3
  %sub414 = fsub float %sub343, %mul402
  store float %sub414, float* %arrayidx276, align 4, !tbaa !3
  %mul418 = fmul float %conv211, %conv211
  %mul419 = fmul float %add178, %krf
  %add420 = fadd float %mul419, %conv211
  %sub421 = fsub float %add420, %crf
  %mul422 = fmul float %mul8, %sub421
  %mul423 = fmul float %mul419, 2.000000e+00
  %sub424 = fsub float %conv211, %mul423
  %mul425 = fmul float %mul8, %sub424
  %mul426 = fmul float %mul418, %mul425
  %add427 = fadd float %mul422, %add399
  %mul428 = fmul float %sub171, %mul426
  %mul429 = fmul float %sub172, %mul426
  %mul430 = fmul float %sub173, %mul426
  %add431 = fadd float %add403, %mul428
  %add432 = fadd float %add404, %mul429
  %add433 = fadd float %add405, %mul430
  %sub434 = fsub float %sub360, %mul428
  store float %sub434, float* %arrayidx296, align 4, !tbaa !3
  %sub438 = fsub float %sub361, %mul429
  store float %sub438, float* %arrayidx300, align 4, !tbaa !3
  %sub442 = fsub float %sub362, %mul430
  store float %sub442, float* %arrayidx304, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %42 = trunc i64 %indvars.iv.next to i32
  %cmp77 = icmp slt i32 %42, %12
  br i1 %cmp77, label %for.body78, label %for.end

for.end:                                          ; preds = %for.body78, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add427, %for.body78 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %sub219, %for.body78 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add291, %for.body78 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add292, %for.body78 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add293, %for.body78 ]
  %fix2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add357, %for.body78 ]
  %fiy2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add358, %for.body78 ]
  %fiz2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add359, %for.body78 ]
  %fix3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add431, %for.body78 ]
  %fiy3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add432, %for.body78 ]
  %fiz3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add433, %for.body78 ]
  %arrayidx447 = getelementptr inbounds float* %faction, i64 %idxprom41
  %43 = load float* %arrayidx447, align 4, !tbaa !3
  %add448 = fadd float %fix1.0.lcssa, %43
  store float %add448, float* %arrayidx447, align 4, !tbaa !3
  %arrayidx453 = getelementptr inbounds float* %faction, i64 %idxprom45
  %44 = load float* %arrayidx453, align 4, !tbaa !3
  %add454 = fadd float %fiy1.0.lcssa, %44
  store float %add454, float* %arrayidx453, align 4, !tbaa !3
  %arrayidx460 = getelementptr inbounds float* %faction, i64 %idxprom49
  %45 = load float* %arrayidx460, align 4, !tbaa !3
  %add461 = fadd float %fiz1.0.lcssa, %45
  store float %add461, float* %arrayidx460, align 4, !tbaa !3
  %arrayidx467 = getelementptr inbounds float* %faction, i64 %idxprom53
  %46 = load float* %arrayidx467, align 4, !tbaa !3
  %add468 = fadd float %fix2.0.lcssa, %46
  store float %add468, float* %arrayidx467, align 4, !tbaa !3
  %arrayidx474 = getelementptr inbounds float* %faction, i64 %idxprom57
  %47 = load float* %arrayidx474, align 4, !tbaa !3
  %add475 = fadd float %fiy2.0.lcssa, %47
  store float %add475, float* %arrayidx474, align 4, !tbaa !3
  %arrayidx481 = getelementptr inbounds float* %faction, i64 %idxprom61
  %48 = load float* %arrayidx481, align 4, !tbaa !3
  %add482 = fadd float %fiz2.0.lcssa, %48
  store float %add482, float* %arrayidx481, align 4, !tbaa !3
  %arrayidx488 = getelementptr inbounds float* %faction, i64 %idxprom65
  %49 = load float* %arrayidx488, align 4, !tbaa !3
  %add489 = fadd float %fix3.0.lcssa, %49
  store float %add489, float* %arrayidx488, align 4, !tbaa !3
  %arrayidx495 = getelementptr inbounds float* %faction, i64 %idxprom69
  %50 = load float* %arrayidx495, align 4, !tbaa !3
  %add496 = fadd float %fiy3.0.lcssa, %50
  store float %add496, float* %arrayidx495, align 4, !tbaa !3
  %arrayidx502 = getelementptr inbounds float* %faction, i64 %idxprom73
  %51 = load float* %arrayidx502, align 4, !tbaa !3
  %add503 = fadd float %fiz3.0.lcssa, %51
  store float %add503, float* %arrayidx502, align 4, !tbaa !3
  %arrayidx508 = getelementptr inbounds float* %fshift, i64 %idxprom25
  %52 = load float* %arrayidx508, align 4, !tbaa !3
  %add509 = fadd float %fix1.0.lcssa, %52
  %add510 = fadd float %fix2.0.lcssa, %add509
  %add511 = fadd float %fix3.0.lcssa, %add510
  store float %add511, float* %arrayidx508, align 4, !tbaa !3
  %arrayidx516 = getelementptr inbounds float* %fshift, i64 %idxprom28
  %53 = load float* %arrayidx516, align 4, !tbaa !3
  %add517 = fadd float %fiy1.0.lcssa, %53
  %add518 = fadd float %fiy2.0.lcssa, %add517
  %add519 = fadd float %fiy3.0.lcssa, %add518
  store float %add519, float* %arrayidx516, align 4, !tbaa !3
  %arrayidx525 = getelementptr inbounds float* %fshift, i64 %idxprom31
  %54 = load float* %arrayidx525, align 4, !tbaa !3
  %add526 = fadd float %fiz1.0.lcssa, %54
  %add527 = fadd float %fiz2.0.lcssa, %add526
  %add528 = fadd float %fiz3.0.lcssa, %add527
  store float %add528, float* %arrayidx525, align 4, !tbaa !3
  %arrayidx533 = getelementptr inbounds i32* %gid, i64 %indvars.iv1016
  %55 = load i32* %arrayidx533, align 4, !tbaa !0
  %idxprom534 = sext i32 %55 to i64
  %arrayidx535 = getelementptr inbounds float* %Vc, i64 %idxprom534
  %56 = load float* %arrayidx535, align 4, !tbaa !3
  %add536 = fadd float %vctot.0.lcssa, %56
  store float %add536, float* %arrayidx535, align 4, !tbaa !3
  %arrayidx540 = getelementptr inbounds float* %Vnb, i64 %idxprom534
  %57 = load float* %arrayidx540, align 4, !tbaa !3
  %add541 = fadd float %vnbtot.0.lcssa, %57
  store float %add541, float* %arrayidx540, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next1017 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end546, label %for.end.for.body_crit_edge

for.end.for.body_crit_edge:                       ; preds = %for.end
  %arrayidx34.phi.trans.insert = getelementptr inbounds i32* %iinr, i64 %indvars.iv.next1017
  %.pre = load i32* %arrayidx34.phi.trans.insert, align 4, !tbaa !0
  br label %for.body

for.end546:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl2200(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, float %krf, float %crf, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb) #0 {
entry:
  %cmp292 = icmp sgt i32 %nri, 0
  br i1 %cmp292, label %for.body, label %for.end175

for.body:                                         ; preds = %for.end, %entry
  %indvars.iv294 = phi i64 [ 0, %entry ], [ %indvars.iv.next295, %for.end ]
  %arrayidx = getelementptr inbounds i32* %shift, i64 %indvars.iv294
  %0 = load i32* %arrayidx, align 4, !tbaa !0
  %mul = mul nsw i32 %0, 3
  %idxprom1 = sext i32 %mul to i64
  %arrayidx2 = getelementptr inbounds float* %shiftvec, i64 %idxprom1
  %1 = load float* %arrayidx2, align 4, !tbaa !3
  %add = add nsw i32 %mul, 1
  %idxprom3 = sext i32 %add to i64
  %arrayidx4 = getelementptr inbounds float* %shiftvec, i64 %idxprom3
  %2 = load float* %arrayidx4, align 4, !tbaa !3
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds float* %shiftvec, i64 %idxprom6
  %3 = load float* %arrayidx7, align 4, !tbaa !3
  %arrayidx9 = getelementptr inbounds i32* %iinr, i64 %indvars.iv294
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %arrayidx12 = getelementptr inbounds i32* %jindex, i64 %indvars.iv294
  %5 = load i32* %arrayidx12, align 4, !tbaa !0
  %indvars.iv.next295 = add i64 %indvars.iv294, 1
  %arrayidx15 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next295
  %6 = load i32* %arrayidx15, align 4, !tbaa !0
  %idxprom16 = sext i32 %mul10 to i64
  %arrayidx17 = getelementptr inbounds float* %pos, i64 %idxprom16
  %7 = load float* %arrayidx17, align 4, !tbaa !3
  %add18 = fadd float %1, %7
  %add19 = add nsw i32 %mul10, 1
  %idxprom20 = sext i32 %add19 to i64
  %arrayidx21 = getelementptr inbounds float* %pos, i64 %idxprom20
  %8 = load float* %arrayidx21, align 4, !tbaa !3
  %add22 = fadd float %2, %8
  %add23 = add nsw i32 %mul10, 2
  %idxprom24 = sext i32 %add23 to i64
  %arrayidx25 = getelementptr inbounds float* %pos, i64 %idxprom24
  %9 = load float* %arrayidx25, align 4, !tbaa !3
  %add26 = fadd float %3, %9
  %idxprom27 = sext i32 %4 to i64
  %arrayidx28 = getelementptr inbounds float* %charge, i64 %idxprom27
  %10 = load float* %arrayidx28, align 4, !tbaa !3
  %mul29 = fmul float %10, %facel
  %arrayidx32 = getelementptr inbounds i32* %type, i64 %idxprom27
  %11 = load i32* %arrayidx32, align 4, !tbaa !0
  %mul33 = mul i32 %11, %ntype
  %cmp35281 = icmp slt i32 %5, %6
  br i1 %cmp35281, label %for.body36.lr.ph, label %for.end

for.body36.lr.ph:                                 ; preds = %for.body
  %12 = sext i32 %5 to i64
  br label %for.body36

for.body36:                                       ; preds = %for.body36.lr.ph, %for.body36
  %indvars.iv = phi i64 [ %12, %for.body36.lr.ph ], [ %indvars.iv.next, %for.body36 ]
  %vctot.0286 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add97, %for.body36 ]
  %vnbtot.0285 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %sub81, %for.body36 ]
  %fix1.0284 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add101, %for.body36 ]
  %fiy1.0283 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add102, %for.body36 ]
  %fiz1.0282 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add103, %for.body36 ]
  %arrayidx38 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %13 = load i32* %arrayidx38, align 4, !tbaa !0
  %mul39 = mul nsw i32 %13, 3
  %idxprom40 = sext i32 %mul39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %14 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = add nsw i32 %mul39, 1
  %idxprom43 = sext i32 %add42 to i64
  %arrayidx44 = getelementptr inbounds float* %pos, i64 %idxprom43
  %15 = load float* %arrayidx44, align 4, !tbaa !3
  %add45 = add nsw i32 %mul39, 2
  %idxprom46 = sext i32 %add45 to i64
  %arrayidx47 = getelementptr inbounds float* %pos, i64 %idxprom46
  %16 = load float* %arrayidx47, align 4, !tbaa !3
  %sub = fsub float %add18, %14
  %sub48 = fsub float %add22, %15
  %sub49 = fsub float %add26, %16
  %mul50 = fmul float %sub, %sub
  %mul51 = fmul float %sub48, %sub48
  %add52 = fadd float %mul50, %mul51
  %mul53 = fmul float %sub49, %sub49
  %add54 = fadd float %add52, %mul53
  %conv = fpext float %add54 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv55 = fptrunc double %div to float
  %mul56 = fmul float %add54, %conv55
  %mul57 = fmul float %conv55, %conv55
  %mul58 = fmul float %mul57, %mul57
  %mul59 = fmul float %mul57, %mul58
  %idxprom60 = sext i32 %13 to i64
  %arrayidx61 = getelementptr inbounds i32* %type, i64 %idxprom60
  %17 = load i32* %arrayidx61, align 4, !tbaa !0
  %tmp = add i32 %17, %mul33
  %tmp280 = mul i32 %tmp, 3
  %idxprom64 = sext i32 %tmp280 to i64
  %arrayidx65 = getelementptr inbounds float* %nbfp, i64 %idxprom64
  %18 = load float* %arrayidx65, align 4, !tbaa !3
  %mul66 = fmul float %18, %mul59
  %add67 = add nsw i32 %tmp280, 2
  %idxprom68 = sext i32 %add67 to i64
  %arrayidx69 = getelementptr inbounds float* %nbfp, i64 %idxprom68
  %19 = load float* %arrayidx69, align 4, !tbaa !3
  %mul70 = fmul float %mul56, %19
  %sub71 = fsub float -0.000000e+00, %mul70
  %conv72 = fpext float %sub71 to double
  %call73 = tail call double @exp(double %conv72) #2
  %add74 = add nsw i32 %tmp280, 1
  %idxprom75 = sext i32 %add74 to i64
  %arrayidx76 = getelementptr inbounds float* %nbfp, i64 %idxprom75
  %20 = load float* %arrayidx76, align 4, !tbaa !3
  %conv77 = fpext float %20 to double
  %mul78 = fmul double %call73, %conv77
  %conv79 = fptrunc double %mul78 to float
  %add80 = fadd float %vnbtot.0285, %conv79
  %sub81 = fsub float %add80, %mul66
  %arrayidx83 = getelementptr inbounds float* %charge, i64 %idxprom60
  %21 = load float* %arrayidx83, align 4, !tbaa !3
  %mul84 = fmul float %mul29, %21
  %mul85 = fmul float %add54, %krf
  %add86 = fadd float %conv55, %mul85
  %sub87 = fsub float %add86, %crf
  %mul88 = fmul float %sub87, %mul84
  %mul89 = fmul float %mul70, %conv79
  %mul90 = fmul float %mul66, 6.000000e+00
  %sub91 = fsub float %mul89, %mul90
  %mul92 = fmul float %mul85, 2.000000e+00
  %sub93 = fsub float %conv55, %mul92
  %mul94 = fmul float %sub93, %mul84
  %add95 = fadd float %mul94, %sub91
  %mul96 = fmul float %mul57, %add95
  %add97 = fadd float %vctot.0286, %mul88
  %mul98 = fmul float %sub, %mul96
  %mul99 = fmul float %sub48, %mul96
  %mul100 = fmul float %sub49, %mul96
  %add101 = fadd float %fix1.0284, %mul98
  %add102 = fadd float %fiy1.0283, %mul99
  %add103 = fadd float %fiz1.0282, %mul100
  %arrayidx105 = getelementptr inbounds float* %faction, i64 %idxprom40
  %22 = load float* %arrayidx105, align 4, !tbaa !3
  %sub106 = fsub float %22, %mul98
  store float %sub106, float* %arrayidx105, align 4, !tbaa !3
  %arrayidx111 = getelementptr inbounds float* %faction, i64 %idxprom43
  %23 = load float* %arrayidx111, align 4, !tbaa !3
  %sub112 = fsub float %23, %mul99
  store float %sub112, float* %arrayidx111, align 4, !tbaa !3
  %arrayidx118 = getelementptr inbounds float* %faction, i64 %idxprom46
  %24 = load float* %arrayidx118, align 4, !tbaa !3
  %sub119 = fsub float %24, %mul100
  store float %sub119, float* %arrayidx118, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %25 = trunc i64 %indvars.iv.next to i32
  %cmp35 = icmp slt i32 %25, %6
  br i1 %cmp35, label %for.body36, label %for.end

for.end:                                          ; preds = %for.body36, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add97, %for.body36 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %sub81, %for.body36 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add101, %for.body36 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add102, %for.body36 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add103, %for.body36 ]
  %arrayidx124 = getelementptr inbounds float* %faction, i64 %idxprom16
  %26 = load float* %arrayidx124, align 4, !tbaa !3
  %add125 = fadd float %fix1.0.lcssa, %26
  store float %add125, float* %arrayidx124, align 4, !tbaa !3
  %arrayidx130 = getelementptr inbounds float* %faction, i64 %idxprom20
  %27 = load float* %arrayidx130, align 4, !tbaa !3
  %add131 = fadd float %fiy1.0.lcssa, %27
  store float %add131, float* %arrayidx130, align 4, !tbaa !3
  %arrayidx137 = getelementptr inbounds float* %faction, i64 %idxprom24
  %28 = load float* %arrayidx137, align 4, !tbaa !3
  %add138 = fadd float %fiz1.0.lcssa, %28
  store float %add138, float* %arrayidx137, align 4, !tbaa !3
  %arrayidx143 = getelementptr inbounds float* %fshift, i64 %idxprom1
  %29 = load float* %arrayidx143, align 4, !tbaa !3
  %add144 = fadd float %fix1.0.lcssa, %29
  store float %add144, float* %arrayidx143, align 4, !tbaa !3
  %arrayidx149 = getelementptr inbounds float* %fshift, i64 %idxprom3
  %30 = load float* %arrayidx149, align 4, !tbaa !3
  %add150 = fadd float %fiy1.0.lcssa, %30
  store float %add150, float* %arrayidx149, align 4, !tbaa !3
  %arrayidx156 = getelementptr inbounds float* %fshift, i64 %idxprom6
  %31 = load float* %arrayidx156, align 4, !tbaa !3
  %add157 = fadd float %fiz1.0.lcssa, %31
  store float %add157, float* %arrayidx156, align 4, !tbaa !3
  %arrayidx162 = getelementptr inbounds i32* %gid, i64 %indvars.iv294
  %32 = load i32* %arrayidx162, align 4, !tbaa !0
  %idxprom163 = sext i32 %32 to i64
  %arrayidx164 = getelementptr inbounds float* %Vc, i64 %idxprom163
  %33 = load float* %arrayidx164, align 4, !tbaa !3
  %add165 = fadd float %vctot.0.lcssa, %33
  store float %add165, float* %arrayidx164, align 4, !tbaa !3
  %arrayidx169 = getelementptr inbounds float* %Vnb, i64 %idxprom163
  %34 = load float* %arrayidx169, align 4, !tbaa !3
  %add170 = fadd float %vnbtot.0.lcssa, %34
  store float %add170, float* %arrayidx169, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next295 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end175, label %for.body

for.end175:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl2210(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, float %krf, float %crf, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, i32* nocapture %nsatoms) #0 {
entry:
  %cmp884 = icmp sgt i32 %nri, 0
  br i1 %cmp884, label %for.body, label %for.end470

for.body:                                         ; preds = %for.end455, %entry
  %indvars.iv910 = phi i64 [ 0, %entry ], [ %indvars.iv.next911, %for.end455 ]
  %0 = trunc i64 %indvars.iv910 to i32
  %mul = mul nsw i32 %0, 3
  %idxprom = sext i32 %mul to i64
  %arrayidx = getelementptr inbounds i32* %nsatoms, i64 %idxprom
  %1 = load i32* %arrayidx, align 4, !tbaa !0
  %add = add nsw i32 %mul, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds i32* %nsatoms, i64 %idxprom2
  %2 = load i32* %arrayidx3, align 4, !tbaa !0
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds i32* %nsatoms, i64 %idxprom6
  %3 = load i32* %arrayidx7, align 4, !tbaa !0
  %arrayidx9 = getelementptr inbounds i32* %shift, i64 %indvars.iv910
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %idxprom11 = sext i32 %mul10 to i64
  %arrayidx12 = getelementptr inbounds float* %shiftvec, i64 %idxprom11
  %5 = load float* %arrayidx12, align 4, !tbaa !3
  %add13 = add nsw i32 %mul10, 1
  %idxprom14 = sext i32 %add13 to i64
  %arrayidx15 = getelementptr inbounds float* %shiftvec, i64 %idxprom14
  %6 = load float* %arrayidx15, align 4, !tbaa !3
  %add16 = add nsw i32 %mul10, 2
  %idxprom17 = sext i32 %add16 to i64
  %arrayidx18 = getelementptr inbounds float* %shiftvec, i64 %idxprom17
  %7 = load float* %arrayidx18, align 4, !tbaa !3
  %arrayidx20 = getelementptr inbounds i32* %iinr, i64 %indvars.iv910
  %8 = load i32* %arrayidx20, align 4, !tbaa !0
  %mul21 = mul i32 %8, 3
  %arrayidx23 = getelementptr inbounds i32* %jindex, i64 %indvars.iv910
  %9 = load i32* %arrayidx23, align 4, !tbaa !0
  %indvars.iv.next911 = add i64 %indvars.iv910, 1
  %arrayidx26 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next911
  %10 = load i32* %arrayidx26, align 4, !tbaa !0
  %cmp28840 = icmp sgt i32 %2, 0
  br i1 %cmp28840, label %for.body29.lr.ph, label %for.cond180.loopexit

for.body29.lr.ph:                                 ; preds = %for.body
  %cmp49829 = icmp slt i32 %9, %10
  %arrayidx157 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx163 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx170 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %11 = sext i32 %9 to i64
  %12 = sext i32 %8 to i64
  %13 = sext i32 %mul21 to i64
  %14 = add i32 %2, %8
  %15 = mul i32 %14, 3
  br label %for.body29

for.body29:                                       ; preds = %for.end, %for.body29.lr.ph
  %indvars.iv888 = phi i64 [ %13, %for.body29.lr.ph ], [ %indvars.iv.next889, %for.end ]
  %indvars.iv886 = phi i64 [ %12, %for.body29.lr.ph ], [ %indvars.iv.next887, %for.end ]
  %s.0843 = phi i32 [ 0, %for.body29.lr.ph ], [ %inc178, %for.end ]
  %vctot.0842 = phi float [ 0.000000e+00, %for.body29.lr.ph ], [ %vctot.1.lcssa, %for.end ]
  %vnbtot.0841 = phi float [ 0.000000e+00, %for.body29.lr.ph ], [ %vnbtot.1.lcssa, %for.end ]
  %arrayidx31 = getelementptr inbounds float* %pos, i64 %indvars.iv888
  %16 = load float* %arrayidx31, align 4, !tbaa !3
  %add32 = fadd float %5, %16
  %17 = add nsw i64 %indvars.iv888, 1
  %arrayidx35 = getelementptr inbounds float* %pos, i64 %17
  %18 = load float* %arrayidx35, align 4, !tbaa !3
  %add36 = fadd float %6, %18
  %19 = add nsw i64 %indvars.iv888, 2
  %arrayidx39 = getelementptr inbounds float* %pos, i64 %19
  %20 = load float* %arrayidx39, align 4, !tbaa !3
  %add40 = fadd float %7, %20
  %arrayidx42 = getelementptr inbounds float* %charge, i64 %indvars.iv886
  %21 = load float* %arrayidx42, align 4, !tbaa !3
  %mul43 = fmul float %21, %facel
  %arrayidx46 = getelementptr inbounds i32* %type, i64 %indvars.iv886
  %22 = load i32* %arrayidx46, align 4, !tbaa !0
  %mul47 = mul i32 %22, %ntype
  br i1 %cmp49829, label %for.body50, label %for.end

for.body50:                                       ; preds = %for.body29, %for.body50
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body50 ], [ %11, %for.body29 ]
  %fiz1.0834 = phi float [ %add117, %for.body50 ], [ 0.000000e+00, %for.body29 ]
  %fiy1.0833 = phi float [ %add116, %for.body50 ], [ 0.000000e+00, %for.body29 ]
  %fix1.0832 = phi float [ %add115, %for.body50 ], [ 0.000000e+00, %for.body29 ]
  %vctot.1831 = phi float [ %add111, %for.body50 ], [ %vctot.0842, %for.body29 ]
  %vnbtot.1830 = phi float [ %sub95, %for.body50 ], [ %vnbtot.0841, %for.body29 ]
  %arrayidx52 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %23 = load i32* %arrayidx52, align 4, !tbaa !0
  %mul53 = mul nsw i32 %23, 3
  %idxprom54 = sext i32 %mul53 to i64
  %arrayidx55 = getelementptr inbounds float* %pos, i64 %idxprom54
  %24 = load float* %arrayidx55, align 4, !tbaa !3
  %add56 = add nsw i32 %mul53, 1
  %idxprom57 = sext i32 %add56 to i64
  %arrayidx58 = getelementptr inbounds float* %pos, i64 %idxprom57
  %25 = load float* %arrayidx58, align 4, !tbaa !3
  %add59 = add nsw i32 %mul53, 2
  %idxprom60 = sext i32 %add59 to i64
  %arrayidx61 = getelementptr inbounds float* %pos, i64 %idxprom60
  %26 = load float* %arrayidx61, align 4, !tbaa !3
  %sub = fsub float %add32, %24
  %sub62 = fsub float %add36, %25
  %sub63 = fsub float %add40, %26
  %mul64 = fmul float %sub, %sub
  %mul65 = fmul float %sub62, %sub62
  %add66 = fadd float %mul64, %mul65
  %mul67 = fmul float %sub63, %sub63
  %add68 = fadd float %add66, %mul67
  %conv = fpext float %add68 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv69 = fptrunc double %div to float
  %mul70 = fmul float %add68, %conv69
  %mul71 = fmul float %conv69, %conv69
  %mul72 = fmul float %mul71, %mul71
  %mul73 = fmul float %mul71, %mul72
  %idxprom74 = sext i32 %23 to i64
  %arrayidx75 = getelementptr inbounds i32* %type, i64 %idxprom74
  %27 = load i32* %arrayidx75, align 4, !tbaa !0
  %tmp = add i32 %27, %mul47
  %tmp826 = mul i32 %tmp, 3
  %idxprom78 = sext i32 %tmp826 to i64
  %arrayidx79 = getelementptr inbounds float* %nbfp, i64 %idxprom78
  %28 = load float* %arrayidx79, align 4, !tbaa !3
  %mul80 = fmul float %28, %mul73
  %add81 = add nsw i32 %tmp826, 2
  %idxprom82 = sext i32 %add81 to i64
  %arrayidx83 = getelementptr inbounds float* %nbfp, i64 %idxprom82
  %29 = load float* %arrayidx83, align 4, !tbaa !3
  %mul84 = fmul float %mul70, %29
  %sub85 = fsub float -0.000000e+00, %mul84
  %conv86 = fpext float %sub85 to double
  %call87 = tail call double @exp(double %conv86) #2
  %add88 = add nsw i32 %tmp826, 1
  %idxprom89 = sext i32 %add88 to i64
  %arrayidx90 = getelementptr inbounds float* %nbfp, i64 %idxprom89
  %30 = load float* %arrayidx90, align 4, !tbaa !3
  %conv91 = fpext float %30 to double
  %mul92 = fmul double %call87, %conv91
  %conv93 = fptrunc double %mul92 to float
  %add94 = fadd float %vnbtot.1830, %conv93
  %sub95 = fsub float %add94, %mul80
  %arrayidx97 = getelementptr inbounds float* %charge, i64 %idxprom74
  %31 = load float* %arrayidx97, align 4, !tbaa !3
  %mul98 = fmul float %mul43, %31
  %mul99 = fmul float %add68, %krf
  %add100 = fadd float %conv69, %mul99
  %sub101 = fsub float %add100, %crf
  %mul102 = fmul float %sub101, %mul98
  %mul103 = fmul float %mul84, %conv93
  %mul104 = fmul float %mul80, 6.000000e+00
  %sub105 = fsub float %mul103, %mul104
  %mul106 = fmul float %mul99, 2.000000e+00
  %sub107 = fsub float %conv69, %mul106
  %mul108 = fmul float %sub107, %mul98
  %add109 = fadd float %mul108, %sub105
  %mul110 = fmul float %mul71, %add109
  %add111 = fadd float %vctot.1831, %mul102
  %mul112 = fmul float %sub, %mul110
  %mul113 = fmul float %sub62, %mul110
  %mul114 = fmul float %sub63, %mul110
  %add115 = fadd float %fix1.0832, %mul112
  %add116 = fadd float %fiy1.0833, %mul113
  %add117 = fadd float %fiz1.0834, %mul114
  %arrayidx119 = getelementptr inbounds float* %faction, i64 %idxprom54
  %32 = load float* %arrayidx119, align 4, !tbaa !3
  %sub120 = fsub float %32, %mul112
  store float %sub120, float* %arrayidx119, align 4, !tbaa !3
  %arrayidx125 = getelementptr inbounds float* %faction, i64 %idxprom57
  %33 = load float* %arrayidx125, align 4, !tbaa !3
  %sub126 = fsub float %33, %mul113
  store float %sub126, float* %arrayidx125, align 4, !tbaa !3
  %arrayidx132 = getelementptr inbounds float* %faction, i64 %idxprom60
  %34 = load float* %arrayidx132, align 4, !tbaa !3
  %sub133 = fsub float %34, %mul114
  store float %sub133, float* %arrayidx132, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %35 = trunc i64 %indvars.iv.next to i32
  %cmp49 = icmp slt i32 %35, %10
  br i1 %cmp49, label %for.body50, label %for.end

for.end:                                          ; preds = %for.body50, %for.body29
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add117, %for.body50 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add116, %for.body50 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add115, %for.body50 ]
  %vctot.1.lcssa = phi float [ %vctot.0842, %for.body29 ], [ %add111, %for.body50 ]
  %vnbtot.1.lcssa = phi float [ %vnbtot.0841, %for.body29 ], [ %sub95, %for.body50 ]
  %arrayidx138 = getelementptr inbounds float* %faction, i64 %indvars.iv888
  %36 = load float* %arrayidx138, align 4, !tbaa !3
  %add139 = fadd float %fix1.0.lcssa, %36
  store float %add139, float* %arrayidx138, align 4, !tbaa !3
  %arrayidx144 = getelementptr inbounds float* %faction, i64 %17
  %37 = load float* %arrayidx144, align 4, !tbaa !3
  %add145 = fadd float %fiy1.0.lcssa, %37
  store float %add145, float* %arrayidx144, align 4, !tbaa !3
  %arrayidx151 = getelementptr inbounds float* %faction, i64 %19
  %38 = load float* %arrayidx151, align 4, !tbaa !3
  %add152 = fadd float %fiz1.0.lcssa, %38
  store float %add152, float* %arrayidx151, align 4, !tbaa !3
  %39 = load float* %arrayidx157, align 4, !tbaa !3
  %add158 = fadd float %fix1.0.lcssa, %39
  store float %add158, float* %arrayidx157, align 4, !tbaa !3
  %40 = load float* %arrayidx163, align 4, !tbaa !3
  %add164 = fadd float %fiy1.0.lcssa, %40
  store float %add164, float* %arrayidx163, align 4, !tbaa !3
  %41 = load float* %arrayidx170, align 4, !tbaa !3
  %add171 = fadd float %fiz1.0.lcssa, %41
  store float %add171, float* %arrayidx170, align 4, !tbaa !3
  %indvars.iv.next887 = add i64 %indvars.iv886, 1
  %indvars.iv.next889 = add i64 %indvars.iv888, 3
  %inc178 = add nsw i32 %s.0843, 1
  %exitcond = icmp eq i32 %inc178, %2
  br i1 %exitcond, label %for.cond27.for.cond180.loopexit_crit_edge, label %for.body29

for.cond27.for.cond180.loopexit_crit_edge:        ; preds = %for.end
  %42 = add i32 %2, %8
  br label %for.cond180.loopexit

for.cond180.loopexit:                             ; preds = %for.cond27.for.cond180.loopexit_crit_edge, %for.body
  %ii.0.lcssa = phi i32 [ %42, %for.cond27.for.cond180.loopexit_crit_edge ], [ %8, %for.body ]
  %ii3.0.lcssa = phi i32 [ %15, %for.cond27.for.cond180.loopexit_crit_edge ], [ %mul21, %for.body ]
  %vctot.0.lcssa = phi float [ %vctot.1.lcssa, %for.cond27.for.cond180.loopexit_crit_edge ], [ 0.000000e+00, %for.body ]
  %vnbtot.0.lcssa = phi float [ %vnbtot.1.lcssa, %for.cond27.for.cond180.loopexit_crit_edge ], [ 0.000000e+00, %for.body ]
  %cmp181860 = icmp slt i32 %2, %3
  br i1 %cmp181860, label %for.body183.lr.ph, label %for.cond309.loopexit

for.body183.lr.ph:                                ; preds = %for.cond180.loopexit
  %cmp199850 = icmp slt i32 %9, %10
  %arrayidx286 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx292 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx299 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %43 = sext i32 %9 to i64
  %44 = sext i32 %ii.0.lcssa to i64
  %45 = sext i32 %ii3.0.lcssa to i64
  %46 = mul i32 %3, 3
  %47 = add i32 %ii.0.lcssa, %3
  br label %for.body183

for.body183:                                      ; preds = %for.end265, %for.body183.lr.ph
  %indvars.iv896 = phi i64 [ %45, %for.body183.lr.ph ], [ %indvars.iv.next897, %for.end265 ]
  %indvars.iv894 = phi i64 [ %44, %for.body183.lr.ph ], [ %indvars.iv.next895, %for.end265 ]
  %s.1862 = phi i32 [ %2, %for.body183.lr.ph ], [ %inc307, %for.end265 ]
  %vctot.2861 = phi float [ %vctot.0.lcssa, %for.body183.lr.ph ], [ %vctot.3.lcssa, %for.end265 ]
  %arrayidx185 = getelementptr inbounds float* %pos, i64 %indvars.iv896
  %48 = load float* %arrayidx185, align 4, !tbaa !3
  %add186 = fadd float %5, %48
  %49 = add nsw i64 %indvars.iv896, 1
  %arrayidx189 = getelementptr inbounds float* %pos, i64 %49
  %50 = load float* %arrayidx189, align 4, !tbaa !3
  %add190 = fadd float %6, %50
  %51 = add nsw i64 %indvars.iv896, 2
  %arrayidx193 = getelementptr inbounds float* %pos, i64 %51
  %52 = load float* %arrayidx193, align 4, !tbaa !3
  %add194 = fadd float %7, %52
  %arrayidx196 = getelementptr inbounds float* %charge, i64 %indvars.iv894
  %53 = load float* %arrayidx196, align 4, !tbaa !3
  %mul197 = fmul float %53, %facel
  br i1 %cmp199850, label %for.body201, label %for.end265

for.body201:                                      ; preds = %for.body183, %for.body201
  %indvars.iv892 = phi i64 [ %indvars.iv.next893, %for.body201 ], [ %43, %for.body183 ]
  %fiz1.1854 = phi float [ %add243, %for.body201 ], [ 0.000000e+00, %for.body183 ]
  %fiy1.1853 = phi float [ %add242, %for.body201 ], [ 0.000000e+00, %for.body183 ]
  %fix1.1852 = phi float [ %add241, %for.body201 ], [ 0.000000e+00, %for.body183 ]
  %vctot.3851 = phi float [ %add237, %for.body201 ], [ %vctot.2861, %for.body183 ]
  %arrayidx203 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv892
  %54 = load i32* %arrayidx203, align 4, !tbaa !0
  %mul204 = mul nsw i32 %54, 3
  %idxprom205 = sext i32 %mul204 to i64
  %arrayidx206 = getelementptr inbounds float* %pos, i64 %idxprom205
  %55 = load float* %arrayidx206, align 4, !tbaa !3
  %add207 = add nsw i32 %mul204, 1
  %idxprom208 = sext i32 %add207 to i64
  %arrayidx209 = getelementptr inbounds float* %pos, i64 %idxprom208
  %56 = load float* %arrayidx209, align 4, !tbaa !3
  %add210 = add nsw i32 %mul204, 2
  %idxprom211 = sext i32 %add210 to i64
  %arrayidx212 = getelementptr inbounds float* %pos, i64 %idxprom211
  %57 = load float* %arrayidx212, align 4, !tbaa !3
  %sub213 = fsub float %add186, %55
  %sub214 = fsub float %add190, %56
  %sub215 = fsub float %add194, %57
  %mul216 = fmul float %sub213, %sub213
  %mul217 = fmul float %sub214, %sub214
  %add218 = fadd float %mul216, %mul217
  %mul219 = fmul float %sub215, %sub215
  %add220 = fadd float %add218, %mul219
  %conv221 = fpext float %add220 to double
  %call222 = tail call double @sqrt(double %conv221) #2
  %div223 = fdiv double 1.000000e+00, %call222
  %conv224 = fptrunc double %div223 to float
  %mul225 = fmul float %conv224, %conv224
  %idxprom226 = sext i32 %54 to i64
  %arrayidx227 = getelementptr inbounds float* %charge, i64 %idxprom226
  %58 = load float* %arrayidx227, align 4, !tbaa !3
  %mul228 = fmul float %mul197, %58
  %mul229 = fmul float %add220, %krf
  %add230 = fadd float %conv224, %mul229
  %sub231 = fsub float %add230, %crf
  %mul232 = fmul float %mul228, %sub231
  %mul233 = fmul float %mul229, 2.000000e+00
  %sub234 = fsub float %conv224, %mul233
  %mul235 = fmul float %mul228, %sub234
  %mul236 = fmul float %mul225, %mul235
  %add237 = fadd float %vctot.3851, %mul232
  %mul238 = fmul float %sub213, %mul236
  %mul239 = fmul float %sub214, %mul236
  %mul240 = fmul float %sub215, %mul236
  %add241 = fadd float %fix1.1852, %mul238
  %add242 = fadd float %fiy1.1853, %mul239
  %add243 = fadd float %fiz1.1854, %mul240
  %arrayidx245 = getelementptr inbounds float* %faction, i64 %idxprom205
  %59 = load float* %arrayidx245, align 4, !tbaa !3
  %sub246 = fsub float %59, %mul238
  store float %sub246, float* %arrayidx245, align 4, !tbaa !3
  %arrayidx251 = getelementptr inbounds float* %faction, i64 %idxprom208
  %60 = load float* %arrayidx251, align 4, !tbaa !3
  %sub252 = fsub float %60, %mul239
  store float %sub252, float* %arrayidx251, align 4, !tbaa !3
  %arrayidx258 = getelementptr inbounds float* %faction, i64 %idxprom211
  %61 = load float* %arrayidx258, align 4, !tbaa !3
  %sub259 = fsub float %61, %mul240
  store float %sub259, float* %arrayidx258, align 4, !tbaa !3
  %indvars.iv.next893 = add i64 %indvars.iv892, 1
  %62 = trunc i64 %indvars.iv.next893 to i32
  %cmp199 = icmp slt i32 %62, %10
  br i1 %cmp199, label %for.body201, label %for.end265

for.end265:                                       ; preds = %for.body201, %for.body183
  %fiz1.1.lcssa = phi float [ 0.000000e+00, %for.body183 ], [ %add243, %for.body201 ]
  %fiy1.1.lcssa = phi float [ 0.000000e+00, %for.body183 ], [ %add242, %for.body201 ]
  %fix1.1.lcssa = phi float [ 0.000000e+00, %for.body183 ], [ %add241, %for.body201 ]
  %vctot.3.lcssa = phi float [ %vctot.2861, %for.body183 ], [ %add237, %for.body201 ]
  %arrayidx267 = getelementptr inbounds float* %faction, i64 %indvars.iv896
  %63 = load float* %arrayidx267, align 4, !tbaa !3
  %add268 = fadd float %fix1.1.lcssa, %63
  store float %add268, float* %arrayidx267, align 4, !tbaa !3
  %arrayidx273 = getelementptr inbounds float* %faction, i64 %49
  %64 = load float* %arrayidx273, align 4, !tbaa !3
  %add274 = fadd float %fiy1.1.lcssa, %64
  store float %add274, float* %arrayidx273, align 4, !tbaa !3
  %arrayidx280 = getelementptr inbounds float* %faction, i64 %51
  %65 = load float* %arrayidx280, align 4, !tbaa !3
  %add281 = fadd float %fiz1.1.lcssa, %65
  store float %add281, float* %arrayidx280, align 4, !tbaa !3
  %66 = load float* %arrayidx286, align 4, !tbaa !3
  %add287 = fadd float %fix1.1.lcssa, %66
  store float %add287, float* %arrayidx286, align 4, !tbaa !3
  %67 = load float* %arrayidx292, align 4, !tbaa !3
  %add293 = fadd float %fiy1.1.lcssa, %67
  store float %add293, float* %arrayidx292, align 4, !tbaa !3
  %68 = load float* %arrayidx299, align 4, !tbaa !3
  %add300 = fadd float %fiz1.1.lcssa, %68
  store float %add300, float* %arrayidx299, align 4, !tbaa !3
  %indvars.iv.next895 = add i64 %indvars.iv894, 1
  %indvars.iv.next897 = add i64 %indvars.iv896, 3
  %inc307 = add nsw i32 %s.1862, 1
  %exitcond900 = icmp eq i32 %inc307, %3
  br i1 %exitcond900, label %for.cond180.for.cond309.loopexit_crit_edge, label %for.body183

for.cond180.for.cond309.loopexit_crit_edge:       ; preds = %for.end265
  %69 = add i32 %ii3.0.lcssa, %46
  %70 = mul i32 %2, -3
  %71 = add i32 %69, %70
  %72 = sub i32 %47, %2
  br label %for.cond309.loopexit

for.cond309.loopexit:                             ; preds = %for.cond180.for.cond309.loopexit_crit_edge, %for.cond180.loopexit
  %ii.1.lcssa = phi i32 [ %72, %for.cond180.for.cond309.loopexit_crit_edge ], [ %ii.0.lcssa, %for.cond180.loopexit ]
  %ii3.1.lcssa = phi i32 [ %71, %for.cond180.for.cond309.loopexit_crit_edge ], [ %ii3.0.lcssa, %for.cond180.loopexit ]
  %vctot.2.lcssa = phi float [ %vctot.3.lcssa, %for.cond180.for.cond309.loopexit_crit_edge ], [ %vctot.0.lcssa, %for.cond180.loopexit ]
  %cmp310878 = icmp slt i32 %3, %1
  br i1 %cmp310878, label %for.body312.lr.ph, label %for.end455

for.body312.lr.ph:                                ; preds = %for.cond309.loopexit
  %cmp329868 = icmp slt i32 %9, %10
  %arrayidx433 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx439 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx446 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %73 = sext i32 %9 to i64
  %74 = sext i32 %ii.1.lcssa to i64
  %75 = sext i32 %ii3.1.lcssa to i64
  br label %for.body312

for.body312:                                      ; preds = %for.end412, %for.body312.lr.ph
  %indvars.iv905 = phi i64 [ %75, %for.body312.lr.ph ], [ %indvars.iv.next906, %for.end412 ]
  %indvars.iv903 = phi i64 [ %74, %for.body312.lr.ph ], [ %indvars.iv.next904, %for.end412 ]
  %s.2880 = phi i32 [ %3, %for.body312.lr.ph ], [ %inc454, %for.end412 ]
  %vnbtot.2879 = phi float [ %vnbtot.0.lcssa, %for.body312.lr.ph ], [ %vnbtot.3.lcssa, %for.end412 ]
  %arrayidx314 = getelementptr inbounds float* %pos, i64 %indvars.iv905
  %76 = load float* %arrayidx314, align 4, !tbaa !3
  %add315 = fadd float %5, %76
  %77 = add nsw i64 %indvars.iv905, 1
  %arrayidx318 = getelementptr inbounds float* %pos, i64 %77
  %78 = load float* %arrayidx318, align 4, !tbaa !3
  %add319 = fadd float %6, %78
  %79 = add nsw i64 %indvars.iv905, 2
  %arrayidx322 = getelementptr inbounds float* %pos, i64 %79
  %80 = load float* %arrayidx322, align 4, !tbaa !3
  %add323 = fadd float %7, %80
  %arrayidx326 = getelementptr inbounds i32* %type, i64 %indvars.iv903
  %81 = load i32* %arrayidx326, align 4, !tbaa !0
  %mul327 = mul i32 %81, %ntype
  br i1 %cmp329868, label %for.body331, label %for.end412

for.body331:                                      ; preds = %for.body312, %for.body331
  %indvars.iv901 = phi i64 [ %indvars.iv.next902, %for.body331 ], [ %73, %for.body312 ]
  %fiz1.2872 = phi float [ %add390, %for.body331 ], [ 0.000000e+00, %for.body312 ]
  %fiy1.2871 = phi float [ %add389, %for.body331 ], [ 0.000000e+00, %for.body312 ]
  %fix1.2870 = phi float [ %add388, %for.body331 ], [ 0.000000e+00, %for.body312 ]
  %vnbtot.3869 = phi float [ %sub380, %for.body331 ], [ %vnbtot.2879, %for.body312 ]
  %arrayidx333 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv901
  %82 = load i32* %arrayidx333, align 4, !tbaa !0
  %mul334 = mul nsw i32 %82, 3
  %idxprom335 = sext i32 %mul334 to i64
  %arrayidx336 = getelementptr inbounds float* %pos, i64 %idxprom335
  %83 = load float* %arrayidx336, align 4, !tbaa !3
  %add337 = add nsw i32 %mul334, 1
  %idxprom338 = sext i32 %add337 to i64
  %arrayidx339 = getelementptr inbounds float* %pos, i64 %idxprom338
  %84 = load float* %arrayidx339, align 4, !tbaa !3
  %add340 = add nsw i32 %mul334, 2
  %idxprom341 = sext i32 %add340 to i64
  %arrayidx342 = getelementptr inbounds float* %pos, i64 %idxprom341
  %85 = load float* %arrayidx342, align 4, !tbaa !3
  %sub343 = fsub float %add315, %83
  %sub344 = fsub float %add319, %84
  %sub345 = fsub float %add323, %85
  %mul346 = fmul float %sub343, %sub343
  %mul347 = fmul float %sub344, %sub344
  %add348 = fadd float %mul346, %mul347
  %mul349 = fmul float %sub345, %sub345
  %add350 = fadd float %add348, %mul349
  %conv351 = fpext float %add350 to double
  %call352 = tail call double @sqrt(double %conv351) #2
  %div353 = fdiv double 1.000000e+00, %call352
  %conv354 = fptrunc double %div353 to float
  %mul355 = fmul float %add350, %conv354
  %mul356 = fmul float %conv354, %conv354
  %mul357 = fmul float %mul356, %mul356
  %mul358 = fmul float %mul356, %mul357
  %idxprom359 = sext i32 %82 to i64
  %arrayidx360 = getelementptr inbounds i32* %type, i64 %idxprom359
  %86 = load i32* %arrayidx360, align 4, !tbaa !0
  %tmp827 = add i32 %86, %mul327
  %tmp828 = mul i32 %tmp827, 3
  %idxprom363 = sext i32 %tmp828 to i64
  %arrayidx364 = getelementptr inbounds float* %nbfp, i64 %idxprom363
  %87 = load float* %arrayidx364, align 4, !tbaa !3
  %mul365 = fmul float %87, %mul358
  %add366 = add nsw i32 %tmp828, 2
  %idxprom367 = sext i32 %add366 to i64
  %arrayidx368 = getelementptr inbounds float* %nbfp, i64 %idxprom367
  %88 = load float* %arrayidx368, align 4, !tbaa !3
  %mul369 = fmul float %mul355, %88
  %sub370 = fsub float -0.000000e+00, %mul369
  %conv371 = fpext float %sub370 to double
  %call372 = tail call double @exp(double %conv371) #2
  %add373 = add nsw i32 %tmp828, 1
  %idxprom374 = sext i32 %add373 to i64
  %arrayidx375 = getelementptr inbounds float* %nbfp, i64 %idxprom374
  %89 = load float* %arrayidx375, align 4, !tbaa !3
  %conv376 = fpext float %89 to double
  %mul377 = fmul double %call372, %conv376
  %conv378 = fptrunc double %mul377 to float
  %add379 = fadd float %vnbtot.3869, %conv378
  %sub380 = fsub float %add379, %mul365
  %mul381 = fmul float %mul369, %conv378
  %mul382 = fmul float %mul365, 6.000000e+00
  %sub383 = fsub float %mul381, %mul382
  %mul384 = fmul float %mul356, %sub383
  %mul385 = fmul float %sub343, %mul384
  %mul386 = fmul float %sub344, %mul384
  %mul387 = fmul float %sub345, %mul384
  %add388 = fadd float %fix1.2870, %mul385
  %add389 = fadd float %fiy1.2871, %mul386
  %add390 = fadd float %fiz1.2872, %mul387
  %arrayidx392 = getelementptr inbounds float* %faction, i64 %idxprom335
  %90 = load float* %arrayidx392, align 4, !tbaa !3
  %sub393 = fsub float %90, %mul385
  store float %sub393, float* %arrayidx392, align 4, !tbaa !3
  %arrayidx398 = getelementptr inbounds float* %faction, i64 %idxprom338
  %91 = load float* %arrayidx398, align 4, !tbaa !3
  %sub399 = fsub float %91, %mul386
  store float %sub399, float* %arrayidx398, align 4, !tbaa !3
  %arrayidx405 = getelementptr inbounds float* %faction, i64 %idxprom341
  %92 = load float* %arrayidx405, align 4, !tbaa !3
  %sub406 = fsub float %92, %mul387
  store float %sub406, float* %arrayidx405, align 4, !tbaa !3
  %indvars.iv.next902 = add i64 %indvars.iv901, 1
  %93 = trunc i64 %indvars.iv.next902 to i32
  %cmp329 = icmp slt i32 %93, %10
  br i1 %cmp329, label %for.body331, label %for.end412

for.end412:                                       ; preds = %for.body331, %for.body312
  %fiz1.2.lcssa = phi float [ 0.000000e+00, %for.body312 ], [ %add390, %for.body331 ]
  %fiy1.2.lcssa = phi float [ 0.000000e+00, %for.body312 ], [ %add389, %for.body331 ]
  %fix1.2.lcssa = phi float [ 0.000000e+00, %for.body312 ], [ %add388, %for.body331 ]
  %vnbtot.3.lcssa = phi float [ %vnbtot.2879, %for.body312 ], [ %sub380, %for.body331 ]
  %arrayidx414 = getelementptr inbounds float* %faction, i64 %indvars.iv905
  %94 = load float* %arrayidx414, align 4, !tbaa !3
  %add415 = fadd float %fix1.2.lcssa, %94
  store float %add415, float* %arrayidx414, align 4, !tbaa !3
  %arrayidx420 = getelementptr inbounds float* %faction, i64 %77
  %95 = load float* %arrayidx420, align 4, !tbaa !3
  %add421 = fadd float %fiy1.2.lcssa, %95
  store float %add421, float* %arrayidx420, align 4, !tbaa !3
  %arrayidx427 = getelementptr inbounds float* %faction, i64 %79
  %96 = load float* %arrayidx427, align 4, !tbaa !3
  %add428 = fadd float %fiz1.2.lcssa, %96
  store float %add428, float* %arrayidx427, align 4, !tbaa !3
  %97 = load float* %arrayidx433, align 4, !tbaa !3
  %add434 = fadd float %fix1.2.lcssa, %97
  store float %add434, float* %arrayidx433, align 4, !tbaa !3
  %98 = load float* %arrayidx439, align 4, !tbaa !3
  %add440 = fadd float %fiy1.2.lcssa, %98
  store float %add440, float* %arrayidx439, align 4, !tbaa !3
  %99 = load float* %arrayidx446, align 4, !tbaa !3
  %add447 = fadd float %fiz1.2.lcssa, %99
  store float %add447, float* %arrayidx446, align 4, !tbaa !3
  %indvars.iv.next904 = add i64 %indvars.iv903, 1
  %indvars.iv.next906 = add i64 %indvars.iv905, 3
  %inc454 = add nsw i32 %s.2880, 1
  %exitcond909 = icmp eq i32 %inc454, %1
  br i1 %exitcond909, label %for.end455, label %for.body312

for.end455:                                       ; preds = %for.end412, %for.cond309.loopexit
  %vnbtot.2.lcssa = phi float [ %vnbtot.0.lcssa, %for.cond309.loopexit ], [ %vnbtot.3.lcssa, %for.end412 ]
  %arrayidx457 = getelementptr inbounds i32* %gid, i64 %indvars.iv910
  %100 = load i32* %arrayidx457, align 4, !tbaa !0
  %idxprom458 = sext i32 %100 to i64
  %arrayidx459 = getelementptr inbounds float* %Vc, i64 %idxprom458
  %101 = load float* %arrayidx459, align 4, !tbaa !3
  %add460 = fadd float %vctot.2.lcssa, %101
  store float %add460, float* %arrayidx459, align 4, !tbaa !3
  %arrayidx464 = getelementptr inbounds float* %Vnb, i64 %idxprom458
  %102 = load float* %arrayidx464, align 4, !tbaa !3
  %add465 = fadd float %vnbtot.2.lcssa, %102
  store float %add465, float* %arrayidx464, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next911 to i32
  %exitcond912 = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond912, label %for.end470, label %for.body

for.end470:                                       ; preds = %for.end455, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl2220(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, float %krf, float %crf, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb) #0 {
entry:
  %0 = load i32* %iinr, align 4, !tbaa !0
  %idxprom = sext i32 %0 to i64
  %arrayidx1 = getelementptr inbounds float* %charge, i64 %idxprom
  %1 = load float* %arrayidx1, align 4, !tbaa !3
  %add = add nsw i32 %0, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds float* %charge, i64 %idxprom2
  %2 = load float* %arrayidx3, align 4, !tbaa !3
  %mul = fmul float %1, %facel
  %mul4 = fmul float %2, %facel
  %arrayidx7 = getelementptr inbounds i32* %type, i64 %idxprom
  %3 = load i32* %arrayidx7, align 4, !tbaa !0
  %mul8 = mul i32 %3, %ntype
  %cmp569 = icmp sgt i32 %nri, 0
  br i1 %cmp569, label %for.body, label %for.end320

for.body:                                         ; preds = %entry, %for.end.for.body_crit_edge
  %4 = phi i32 [ %.pre, %for.end.for.body_crit_edge ], [ %0, %entry ]
  %indvars.iv571 = phi i64 [ %indvars.iv.next572, %for.end.for.body_crit_edge ], [ 0, %entry ]
  %arrayidx10 = getelementptr inbounds i32* %shift, i64 %indvars.iv571
  %5 = load i32* %arrayidx10, align 4, !tbaa !0
  %mul11 = mul nsw i32 %5, 3
  %idxprom12 = sext i32 %mul11 to i64
  %arrayidx13 = getelementptr inbounds float* %shiftvec, i64 %idxprom12
  %6 = load float* %arrayidx13, align 4, !tbaa !3
  %add14 = add nsw i32 %mul11, 1
  %idxprom15 = sext i32 %add14 to i64
  %arrayidx16 = getelementptr inbounds float* %shiftvec, i64 %idxprom15
  %7 = load float* %arrayidx16, align 4, !tbaa !3
  %add17 = add nsw i32 %mul11, 2
  %idxprom18 = sext i32 %add17 to i64
  %arrayidx19 = getelementptr inbounds float* %shiftvec, i64 %idxprom18
  %8 = load float* %arrayidx19, align 4, !tbaa !3
  %mul22 = mul nsw i32 %4, 3
  %arrayidx24 = getelementptr inbounds i32* %jindex, i64 %indvars.iv571
  %9 = load i32* %arrayidx24, align 4, !tbaa !0
  %indvars.iv.next572 = add i64 %indvars.iv571, 1
  %arrayidx27 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next572
  %10 = load i32* %arrayidx27, align 4, !tbaa !0
  %idxprom28 = sext i32 %mul22 to i64
  %arrayidx29 = getelementptr inbounds float* %pos, i64 %idxprom28
  %11 = load float* %arrayidx29, align 4, !tbaa !3
  %add30 = fadd float %6, %11
  %add31 = add nsw i32 %mul22, 1
  %idxprom32 = sext i32 %add31 to i64
  %arrayidx33 = getelementptr inbounds float* %pos, i64 %idxprom32
  %12 = load float* %arrayidx33, align 4, !tbaa !3
  %add34 = fadd float %7, %12
  %add35 = add nsw i32 %mul22, 2
  %idxprom36 = sext i32 %add35 to i64
  %arrayidx37 = getelementptr inbounds float* %pos, i64 %idxprom36
  %13 = load float* %arrayidx37, align 4, !tbaa !3
  %add38 = fadd float %8, %13
  %add39 = add nsw i32 %mul22, 3
  %idxprom40 = sext i32 %add39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %14 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = fadd float %6, %14
  %add43 = add nsw i32 %mul22, 4
  %idxprom44 = sext i32 %add43 to i64
  %arrayidx45 = getelementptr inbounds float* %pos, i64 %idxprom44
  %15 = load float* %arrayidx45, align 4, !tbaa !3
  %add46 = fadd float %7, %15
  %add47 = add nsw i32 %mul22, 5
  %idxprom48 = sext i32 %add47 to i64
  %arrayidx49 = getelementptr inbounds float* %pos, i64 %idxprom48
  %16 = load float* %arrayidx49, align 4, !tbaa !3
  %add50 = fadd float %8, %16
  %add51 = add nsw i32 %mul22, 6
  %idxprom52 = sext i32 %add51 to i64
  %arrayidx53 = getelementptr inbounds float* %pos, i64 %idxprom52
  %17 = load float* %arrayidx53, align 4, !tbaa !3
  %add54 = fadd float %6, %17
  %add55 = add nsw i32 %mul22, 7
  %idxprom56 = sext i32 %add55 to i64
  %arrayidx57 = getelementptr inbounds float* %pos, i64 %idxprom56
  %18 = load float* %arrayidx57, align 4, !tbaa !3
  %add58 = fadd float %7, %18
  %add59 = add nsw i32 %mul22, 8
  %idxprom60 = sext i32 %add59 to i64
  %arrayidx61 = getelementptr inbounds float* %pos, i64 %idxprom60
  %19 = load float* %arrayidx61, align 4, !tbaa !3
  %add62 = fadd float %8, %19
  %cmp64546 = icmp slt i32 %9, %10
  br i1 %cmp64546, label %for.body65.lr.ph, label %for.end

for.body65.lr.ph:                                 ; preds = %for.body
  %20 = sext i32 %9 to i64
  br label %for.body65

for.body65:                                       ; preds = %for.body65.lr.ph, %for.body65
  %indvars.iv = phi i64 [ %20, %for.body65.lr.ph ], [ %indvars.iv.next, %for.body65 ]
  %vctot.0557 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add202, %for.body65 ]
  %vnbtot.0556 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %sub134, %for.body65 ]
  %fix1.0555 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add154, %for.body65 ]
  %fiy1.0554 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add155, %for.body65 ]
  %fiz1.0553 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add156, %for.body65 ]
  %fix2.0552 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add184, %for.body65 ]
  %fiy2.0551 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add185, %for.body65 ]
  %fiz2.0550 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add186, %for.body65 ]
  %fix3.0549 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add206, %for.body65 ]
  %fiy3.0548 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add207, %for.body65 ]
  %fiz3.0547 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add208, %for.body65 ]
  %arrayidx67 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %21 = load i32* %arrayidx67, align 4, !tbaa !0
  %mul68 = mul nsw i32 %21, 3
  %idxprom69 = sext i32 %mul68 to i64
  %arrayidx70 = getelementptr inbounds float* %pos, i64 %idxprom69
  %22 = load float* %arrayidx70, align 4, !tbaa !3
  %add71 = add nsw i32 %mul68, 1
  %idxprom72 = sext i32 %add71 to i64
  %arrayidx73 = getelementptr inbounds float* %pos, i64 %idxprom72
  %23 = load float* %arrayidx73, align 4, !tbaa !3
  %add74 = add nsw i32 %mul68, 2
  %idxprom75 = sext i32 %add74 to i64
  %arrayidx76 = getelementptr inbounds float* %pos, i64 %idxprom75
  %24 = load float* %arrayidx76, align 4, !tbaa !3
  %sub = fsub float %add30, %22
  %sub77 = fsub float %add34, %23
  %sub78 = fsub float %add38, %24
  %mul79 = fmul float %sub, %sub
  %mul80 = fmul float %sub77, %sub77
  %add81 = fadd float %mul79, %mul80
  %mul82 = fmul float %sub78, %sub78
  %add83 = fadd float %add81, %mul82
  %sub84 = fsub float %add42, %22
  %sub85 = fsub float %add46, %23
  %sub86 = fsub float %add50, %24
  %mul87 = fmul float %sub84, %sub84
  %mul88 = fmul float %sub85, %sub85
  %add89 = fadd float %mul87, %mul88
  %mul90 = fmul float %sub86, %sub86
  %add91 = fadd float %add89, %mul90
  %sub92 = fsub float %add54, %22
  %sub93 = fsub float %add58, %23
  %sub94 = fsub float %add62, %24
  %mul95 = fmul float %sub92, %sub92
  %mul96 = fmul float %sub93, %sub93
  %add97 = fadd float %mul95, %mul96
  %mul98 = fmul float %sub94, %sub94
  %add99 = fadd float %add97, %mul98
  %conv = fpext float %add83 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv100 = fptrunc double %div to float
  %conv101 = fpext float %add91 to double
  %call102 = tail call double @sqrt(double %conv101) #2
  %div103 = fdiv double 1.000000e+00, %call102
  %conv104 = fptrunc double %div103 to float
  %conv105 = fpext float %add99 to double
  %call106 = tail call double @sqrt(double %conv105) #2
  %div107 = fdiv double 1.000000e+00, %call106
  %conv108 = fptrunc double %div107 to float
  %mul109 = fmul float %add83, %conv100
  %mul110 = fmul float %conv100, %conv100
  %mul111 = fmul float %mul110, %mul110
  %mul112 = fmul float %mul110, %mul111
  %idxprom113 = sext i32 %21 to i64
  %arrayidx114 = getelementptr inbounds i32* %type, i64 %idxprom113
  %25 = load i32* %arrayidx114, align 4, !tbaa !0
  %tmp = add i32 %25, %mul8
  %tmp545 = mul i32 %tmp, 3
  %idxprom117 = sext i32 %tmp545 to i64
  %arrayidx118 = getelementptr inbounds float* %nbfp, i64 %idxprom117
  %26 = load float* %arrayidx118, align 4, !tbaa !3
  %mul119 = fmul float %mul112, %26
  %add120 = add nsw i32 %tmp545, 2
  %idxprom121 = sext i32 %add120 to i64
  %arrayidx122 = getelementptr inbounds float* %nbfp, i64 %idxprom121
  %27 = load float* %arrayidx122, align 4, !tbaa !3
  %mul123 = fmul float %mul109, %27
  %sub124 = fsub float -0.000000e+00, %mul123
  %conv125 = fpext float %sub124 to double
  %call126 = tail call double @exp(double %conv125) #2
  %add127 = add nsw i32 %tmp545, 1
  %idxprom128 = sext i32 %add127 to i64
  %arrayidx129 = getelementptr inbounds float* %nbfp, i64 %idxprom128
  %28 = load float* %arrayidx129, align 4, !tbaa !3
  %conv130 = fpext float %28 to double
  %mul131 = fmul double %call126, %conv130
  %conv132 = fptrunc double %mul131 to float
  %add133 = fadd float %vnbtot.0556, %conv132
  %sub134 = fsub float %add133, %mul119
  %arrayidx136 = getelementptr inbounds float* %charge, i64 %idxprom113
  %29 = load float* %arrayidx136, align 4, !tbaa !3
  %mul137 = fmul float %mul, %29
  %mul138 = fmul float %add83, %krf
  %add139 = fadd float %conv100, %mul138
  %sub140 = fsub float %add139, %crf
  %mul141 = fmul float %sub140, %mul137
  %mul142 = fmul float %mul123, %conv132
  %mul143 = fmul float %mul119, 6.000000e+00
  %sub144 = fsub float %mul142, %mul143
  %mul145 = fmul float %mul138, 2.000000e+00
  %sub146 = fsub float %conv100, %mul145
  %mul147 = fmul float %sub146, %mul137
  %add148 = fadd float %mul147, %sub144
  %mul149 = fmul float %mul110, %add148
  %add150 = fadd float %vctot.0557, %mul141
  %mul151 = fmul float %sub, %mul149
  %mul152 = fmul float %sub77, %mul149
  %mul153 = fmul float %sub78, %mul149
  %add154 = fadd float %fix1.0555, %mul151
  %add155 = fadd float %fiy1.0554, %mul152
  %add156 = fadd float %fiz1.0553, %mul153
  %arrayidx158 = getelementptr inbounds float* %faction, i64 %idxprom69
  %30 = load float* %arrayidx158, align 4, !tbaa !3
  %sub159 = fsub float %30, %mul151
  %arrayidx162 = getelementptr inbounds float* %faction, i64 %idxprom72
  %31 = load float* %arrayidx162, align 4, !tbaa !3
  %sub163 = fsub float %31, %mul152
  %arrayidx166 = getelementptr inbounds float* %faction, i64 %idxprom75
  %32 = load float* %arrayidx166, align 4, !tbaa !3
  %sub167 = fsub float %32, %mul153
  %mul168 = fmul float %conv104, %conv104
  %mul171 = fmul float %mul4, %29
  %mul172 = fmul float %add91, %krf
  %add173 = fadd float %mul172, %conv104
  %sub174 = fsub float %add173, %crf
  %mul175 = fmul float %sub174, %mul171
  %mul176 = fmul float %mul172, 2.000000e+00
  %sub177 = fsub float %conv104, %mul176
  %mul178 = fmul float %sub177, %mul171
  %mul179 = fmul float %mul168, %mul178
  %add180 = fadd float %mul175, %add150
  %mul181 = fmul float %sub84, %mul179
  %mul182 = fmul float %sub85, %mul179
  %mul183 = fmul float %sub86, %mul179
  %add184 = fadd float %fix2.0552, %mul181
  %add185 = fadd float %fiy2.0551, %mul182
  %add186 = fadd float %fiz2.0550, %mul183
  %sub187 = fsub float %sub159, %mul181
  %sub188 = fsub float %sub163, %mul182
  %sub189 = fsub float %sub167, %mul183
  %mul190 = fmul float %conv108, %conv108
  %mul194 = fmul float %add99, %krf
  %add195 = fadd float %mul194, %conv108
  %sub196 = fsub float %add195, %crf
  %mul197 = fmul float %sub196, %mul171
  %mul198 = fmul float %mul194, 2.000000e+00
  %sub199 = fsub float %conv108, %mul198
  %mul200 = fmul float %sub199, %mul171
  %mul201 = fmul float %mul190, %mul200
  %add202 = fadd float %mul197, %add180
  %mul203 = fmul float %sub92, %mul201
  %mul204 = fmul float %sub93, %mul201
  %mul205 = fmul float %sub94, %mul201
  %add206 = fadd float %fix3.0549, %mul203
  %add207 = fadd float %fiy3.0548, %mul204
  %add208 = fadd float %fiz3.0547, %mul205
  %sub209 = fsub float %sub187, %mul203
  store float %sub209, float* %arrayidx158, align 4, !tbaa !3
  %sub212 = fsub float %sub188, %mul204
  store float %sub212, float* %arrayidx162, align 4, !tbaa !3
  %sub216 = fsub float %sub189, %mul205
  store float %sub216, float* %arrayidx166, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %33 = trunc i64 %indvars.iv.next to i32
  %cmp64 = icmp slt i32 %33, %10
  br i1 %cmp64, label %for.body65, label %for.end

for.end:                                          ; preds = %for.body65, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add202, %for.body65 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %sub134, %for.body65 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add154, %for.body65 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add155, %for.body65 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add156, %for.body65 ]
  %fix2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add184, %for.body65 ]
  %fiy2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add185, %for.body65 ]
  %fiz2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add186, %for.body65 ]
  %fix3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add206, %for.body65 ]
  %fiy3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add207, %for.body65 ]
  %fiz3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add208, %for.body65 ]
  %arrayidx221 = getelementptr inbounds float* %faction, i64 %idxprom28
  %34 = load float* %arrayidx221, align 4, !tbaa !3
  %add222 = fadd float %fix1.0.lcssa, %34
  store float %add222, float* %arrayidx221, align 4, !tbaa !3
  %arrayidx227 = getelementptr inbounds float* %faction, i64 %idxprom32
  %35 = load float* %arrayidx227, align 4, !tbaa !3
  %add228 = fadd float %fiy1.0.lcssa, %35
  store float %add228, float* %arrayidx227, align 4, !tbaa !3
  %arrayidx234 = getelementptr inbounds float* %faction, i64 %idxprom36
  %36 = load float* %arrayidx234, align 4, !tbaa !3
  %add235 = fadd float %fiz1.0.lcssa, %36
  store float %add235, float* %arrayidx234, align 4, !tbaa !3
  %arrayidx241 = getelementptr inbounds float* %faction, i64 %idxprom40
  %37 = load float* %arrayidx241, align 4, !tbaa !3
  %add242 = fadd float %fix2.0.lcssa, %37
  store float %add242, float* %arrayidx241, align 4, !tbaa !3
  %arrayidx248 = getelementptr inbounds float* %faction, i64 %idxprom44
  %38 = load float* %arrayidx248, align 4, !tbaa !3
  %add249 = fadd float %fiy2.0.lcssa, %38
  store float %add249, float* %arrayidx248, align 4, !tbaa !3
  %arrayidx255 = getelementptr inbounds float* %faction, i64 %idxprom48
  %39 = load float* %arrayidx255, align 4, !tbaa !3
  %add256 = fadd float %fiz2.0.lcssa, %39
  store float %add256, float* %arrayidx255, align 4, !tbaa !3
  %arrayidx262 = getelementptr inbounds float* %faction, i64 %idxprom52
  %40 = load float* %arrayidx262, align 4, !tbaa !3
  %add263 = fadd float %fix3.0.lcssa, %40
  store float %add263, float* %arrayidx262, align 4, !tbaa !3
  %arrayidx269 = getelementptr inbounds float* %faction, i64 %idxprom56
  %41 = load float* %arrayidx269, align 4, !tbaa !3
  %add270 = fadd float %fiy3.0.lcssa, %41
  store float %add270, float* %arrayidx269, align 4, !tbaa !3
  %arrayidx276 = getelementptr inbounds float* %faction, i64 %idxprom60
  %42 = load float* %arrayidx276, align 4, !tbaa !3
  %add277 = fadd float %fiz3.0.lcssa, %42
  store float %add277, float* %arrayidx276, align 4, !tbaa !3
  %arrayidx282 = getelementptr inbounds float* %fshift, i64 %idxprom12
  %43 = load float* %arrayidx282, align 4, !tbaa !3
  %add283 = fadd float %fix1.0.lcssa, %43
  %add284 = fadd float %fix2.0.lcssa, %add283
  %add285 = fadd float %fix3.0.lcssa, %add284
  store float %add285, float* %arrayidx282, align 4, !tbaa !3
  %arrayidx290 = getelementptr inbounds float* %fshift, i64 %idxprom15
  %44 = load float* %arrayidx290, align 4, !tbaa !3
  %add291 = fadd float %fiy1.0.lcssa, %44
  %add292 = fadd float %fiy2.0.lcssa, %add291
  %add293 = fadd float %fiy3.0.lcssa, %add292
  store float %add293, float* %arrayidx290, align 4, !tbaa !3
  %arrayidx299 = getelementptr inbounds float* %fshift, i64 %idxprom18
  %45 = load float* %arrayidx299, align 4, !tbaa !3
  %add300 = fadd float %fiz1.0.lcssa, %45
  %add301 = fadd float %fiz2.0.lcssa, %add300
  %add302 = fadd float %fiz3.0.lcssa, %add301
  store float %add302, float* %arrayidx299, align 4, !tbaa !3
  %arrayidx307 = getelementptr inbounds i32* %gid, i64 %indvars.iv571
  %46 = load i32* %arrayidx307, align 4, !tbaa !0
  %idxprom308 = sext i32 %46 to i64
  %arrayidx309 = getelementptr inbounds float* %Vc, i64 %idxprom308
  %47 = load float* %arrayidx309, align 4, !tbaa !3
  %add310 = fadd float %vctot.0.lcssa, %47
  store float %add310, float* %arrayidx309, align 4, !tbaa !3
  %arrayidx314 = getelementptr inbounds float* %Vnb, i64 %idxprom308
  %48 = load float* %arrayidx314, align 4, !tbaa !3
  %add315 = fadd float %vnbtot.0.lcssa, %48
  store float %add315, float* %arrayidx314, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next572 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end320, label %for.end.for.body_crit_edge

for.end.for.body_crit_edge:                       ; preds = %for.end
  %arrayidx21.phi.trans.insert = getelementptr inbounds i32* %iinr, i64 %indvars.iv.next572
  %.pre = load i32* %arrayidx21.phi.trans.insert, align 4, !tbaa !0
  br label %for.body

for.end320:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl2230(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, float %krf, float %crf, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb) #0 {
entry:
  %0 = load i32* %iinr, align 4, !tbaa !0
  %idxprom = sext i32 %0 to i64
  %arrayidx1 = getelementptr inbounds float* %charge, i64 %idxprom
  %1 = load float* %arrayidx1, align 4, !tbaa !3
  %add = add nsw i32 %0, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds float* %charge, i64 %idxprom2
  %2 = load float* %arrayidx3, align 4, !tbaa !3
  %mul = fmul float %1, %facel
  %mul4 = fmul float %1, %mul
  %mul6 = fmul float %mul, %2
  %mul7 = fmul float %2, %facel
  %mul8 = fmul float %2, %mul7
  %mul9 = mul nsw i32 %ntype, 3
  %arrayidx11 = getelementptr inbounds i32* %type, i64 %idxprom
  %3 = load i32* %arrayidx11, align 4, !tbaa !0
  %mul121002 = add i32 %mul9, 3
  %add16 = mul i32 %3, %mul121002
  %idxprom17 = sext i32 %add16 to i64
  %arrayidx18 = getelementptr inbounds float* %nbfp, i64 %idxprom17
  %4 = load float* %arrayidx18, align 4, !tbaa !3
  %add22 = add nsw i32 %add16, 2
  %idxprom23 = sext i32 %add22 to i64
  %arrayidx24 = getelementptr inbounds float* %nbfp, i64 %idxprom23
  %5 = load float* %arrayidx24, align 4, !tbaa !3
  %cmp1026 = icmp sgt i32 %nri, 0
  br i1 %cmp1026, label %for.body.lr.ph, label %for.end555

for.body.lr.ph:                                   ; preds = %entry
  %add19 = add nsw i32 %add16, 1
  %idxprom20 = sext i32 %add19 to i64
  %arrayidx21 = getelementptr inbounds float* %nbfp, i64 %idxprom20
  %6 = load float* %arrayidx21, align 4, !tbaa !3
  %conv221 = fpext float %6 to double
  br label %for.body

for.body:                                         ; preds = %for.end.for.body_crit_edge, %for.body.lr.ph
  %7 = phi i32 [ %0, %for.body.lr.ph ], [ %.pre, %for.end.for.body_crit_edge ]
  %indvars.iv1028 = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next1029, %for.end.for.body_crit_edge ]
  %arrayidx26 = getelementptr inbounds i32* %shift, i64 %indvars.iv1028
  %8 = load i32* %arrayidx26, align 4, !tbaa !0
  %mul27 = mul nsw i32 %8, 3
  %idxprom28 = sext i32 %mul27 to i64
  %arrayidx29 = getelementptr inbounds float* %shiftvec, i64 %idxprom28
  %9 = load float* %arrayidx29, align 4, !tbaa !3
  %add30 = add nsw i32 %mul27, 1
  %idxprom31 = sext i32 %add30 to i64
  %arrayidx32 = getelementptr inbounds float* %shiftvec, i64 %idxprom31
  %10 = load float* %arrayidx32, align 4, !tbaa !3
  %add33 = add nsw i32 %mul27, 2
  %idxprom34 = sext i32 %add33 to i64
  %arrayidx35 = getelementptr inbounds float* %shiftvec, i64 %idxprom34
  %11 = load float* %arrayidx35, align 4, !tbaa !3
  %mul38 = mul nsw i32 %7, 3
  %arrayidx40 = getelementptr inbounds i32* %jindex, i64 %indvars.iv1028
  %12 = load i32* %arrayidx40, align 4, !tbaa !0
  %indvars.iv.next1029 = add i64 %indvars.iv1028, 1
  %arrayidx43 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next1029
  %13 = load i32* %arrayidx43, align 4, !tbaa !0
  %idxprom44 = sext i32 %mul38 to i64
  %arrayidx45 = getelementptr inbounds float* %pos, i64 %idxprom44
  %14 = load float* %arrayidx45, align 4, !tbaa !3
  %add46 = fadd float %9, %14
  %add47 = add nsw i32 %mul38, 1
  %idxprom48 = sext i32 %add47 to i64
  %arrayidx49 = getelementptr inbounds float* %pos, i64 %idxprom48
  %15 = load float* %arrayidx49, align 4, !tbaa !3
  %add50 = fadd float %10, %15
  %add51 = add nsw i32 %mul38, 2
  %idxprom52 = sext i32 %add51 to i64
  %arrayidx53 = getelementptr inbounds float* %pos, i64 %idxprom52
  %16 = load float* %arrayidx53, align 4, !tbaa !3
  %add54 = fadd float %11, %16
  %add55 = add nsw i32 %mul38, 3
  %idxprom56 = sext i32 %add55 to i64
  %arrayidx57 = getelementptr inbounds float* %pos, i64 %idxprom56
  %17 = load float* %arrayidx57, align 4, !tbaa !3
  %add58 = fadd float %9, %17
  %add59 = add nsw i32 %mul38, 4
  %idxprom60 = sext i32 %add59 to i64
  %arrayidx61 = getelementptr inbounds float* %pos, i64 %idxprom60
  %18 = load float* %arrayidx61, align 4, !tbaa !3
  %add62 = fadd float %10, %18
  %add63 = add nsw i32 %mul38, 5
  %idxprom64 = sext i32 %add63 to i64
  %arrayidx65 = getelementptr inbounds float* %pos, i64 %idxprom64
  %19 = load float* %arrayidx65, align 4, !tbaa !3
  %add66 = fadd float %11, %19
  %add67 = add nsw i32 %mul38, 6
  %idxprom68 = sext i32 %add67 to i64
  %arrayidx69 = getelementptr inbounds float* %pos, i64 %idxprom68
  %20 = load float* %arrayidx69, align 4, !tbaa !3
  %add70 = fadd float %9, %20
  %add71 = add nsw i32 %mul38, 7
  %idxprom72 = sext i32 %add71 to i64
  %arrayidx73 = getelementptr inbounds float* %pos, i64 %idxprom72
  %21 = load float* %arrayidx73, align 4, !tbaa !3
  %add74 = fadd float %10, %21
  %add75 = add nsw i32 %mul38, 8
  %idxprom76 = sext i32 %add75 to i64
  %arrayidx77 = getelementptr inbounds float* %pos, i64 %idxprom76
  %22 = load float* %arrayidx77, align 4, !tbaa !3
  %add78 = fadd float %11, %22
  %cmp801003 = icmp slt i32 %12, %13
  br i1 %cmp801003, label %for.body81.lr.ph, label %for.end

for.body81.lr.ph:                                 ; preds = %for.body
  %23 = sext i32 %12 to i64
  br label %for.body81

for.body81:                                       ; preds = %for.body81.lr.ph, %for.body81
  %indvars.iv = phi i64 [ %23, %for.body81.lr.ph ], [ %indvars.iv.next, %for.body81 ]
  %vctot.01014 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add436, %for.body81 ]
  %vnbtot.01013 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %sub228, %for.body81 ]
  %fix1.01012 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add300, %for.body81 ]
  %fiy1.01011 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add301, %for.body81 ]
  %fiz1.01010 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add302, %for.body81 ]
  %fix2.01009 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add366, %for.body81 ]
  %fiy2.01008 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add367, %for.body81 ]
  %fiz2.01007 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add368, %for.body81 ]
  %fix3.01006 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add440, %for.body81 ]
  %fiy3.01005 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add441, %for.body81 ]
  %fiz3.01004 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add442, %for.body81 ]
  %arrayidx83 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %24 = load i32* %arrayidx83, align 4, !tbaa !0
  %mul84 = mul nsw i32 %24, 3
  %idxprom85 = sext i32 %mul84 to i64
  %arrayidx86 = getelementptr inbounds float* %pos, i64 %idxprom85
  %25 = load float* %arrayidx86, align 4, !tbaa !3
  %add87 = add nsw i32 %mul84, 1
  %idxprom88 = sext i32 %add87 to i64
  %arrayidx89 = getelementptr inbounds float* %pos, i64 %idxprom88
  %26 = load float* %arrayidx89, align 4, !tbaa !3
  %add90 = add nsw i32 %mul84, 2
  %idxprom91 = sext i32 %add90 to i64
  %arrayidx92 = getelementptr inbounds float* %pos, i64 %idxprom91
  %27 = load float* %arrayidx92, align 4, !tbaa !3
  %add93 = add nsw i32 %mul84, 3
  %idxprom94 = sext i32 %add93 to i64
  %arrayidx95 = getelementptr inbounds float* %pos, i64 %idxprom94
  %28 = load float* %arrayidx95, align 4, !tbaa !3
  %add96 = add nsw i32 %mul84, 4
  %idxprom97 = sext i32 %add96 to i64
  %arrayidx98 = getelementptr inbounds float* %pos, i64 %idxprom97
  %29 = load float* %arrayidx98, align 4, !tbaa !3
  %add99 = add nsw i32 %mul84, 5
  %idxprom100 = sext i32 %add99 to i64
  %arrayidx101 = getelementptr inbounds float* %pos, i64 %idxprom100
  %30 = load float* %arrayidx101, align 4, !tbaa !3
  %add102 = add nsw i32 %mul84, 6
  %idxprom103 = sext i32 %add102 to i64
  %arrayidx104 = getelementptr inbounds float* %pos, i64 %idxprom103
  %31 = load float* %arrayidx104, align 4, !tbaa !3
  %add105 = add nsw i32 %mul84, 7
  %idxprom106 = sext i32 %add105 to i64
  %arrayidx107 = getelementptr inbounds float* %pos, i64 %idxprom106
  %32 = load float* %arrayidx107, align 4, !tbaa !3
  %add108 = add nsw i32 %mul84, 8
  %idxprom109 = sext i32 %add108 to i64
  %arrayidx110 = getelementptr inbounds float* %pos, i64 %idxprom109
  %33 = load float* %arrayidx110, align 4, !tbaa !3
  %sub = fsub float %add46, %25
  %sub111 = fsub float %add50, %26
  %sub112 = fsub float %add54, %27
  %mul113 = fmul float %sub, %sub
  %mul114 = fmul float %sub111, %sub111
  %add115 = fadd float %mul113, %mul114
  %mul116 = fmul float %sub112, %sub112
  %add117 = fadd float %add115, %mul116
  %sub118 = fsub float %add46, %28
  %sub119 = fsub float %add50, %29
  %sub120 = fsub float %add54, %30
  %mul121 = fmul float %sub118, %sub118
  %mul122 = fmul float %sub119, %sub119
  %add123 = fadd float %mul121, %mul122
  %mul124 = fmul float %sub120, %sub120
  %add125 = fadd float %add123, %mul124
  %sub126 = fsub float %add46, %31
  %sub127 = fsub float %add50, %32
  %sub128 = fsub float %add54, %33
  %mul129 = fmul float %sub126, %sub126
  %mul130 = fmul float %sub127, %sub127
  %add131 = fadd float %mul129, %mul130
  %mul132 = fmul float %sub128, %sub128
  %add133 = fadd float %add131, %mul132
  %sub134 = fsub float %add58, %25
  %sub135 = fsub float %add62, %26
  %sub136 = fsub float %add66, %27
  %mul137 = fmul float %sub134, %sub134
  %mul138 = fmul float %sub135, %sub135
  %add139 = fadd float %mul137, %mul138
  %mul140 = fmul float %sub136, %sub136
  %add141 = fadd float %add139, %mul140
  %sub142 = fsub float %add58, %28
  %sub143 = fsub float %add62, %29
  %sub144 = fsub float %add66, %30
  %mul145 = fmul float %sub142, %sub142
  %mul146 = fmul float %sub143, %sub143
  %add147 = fadd float %mul145, %mul146
  %mul148 = fmul float %sub144, %sub144
  %add149 = fadd float %add147, %mul148
  %sub150 = fsub float %add58, %31
  %sub151 = fsub float %add62, %32
  %sub152 = fsub float %add66, %33
  %mul153 = fmul float %sub150, %sub150
  %mul154 = fmul float %sub151, %sub151
  %add155 = fadd float %mul153, %mul154
  %mul156 = fmul float %sub152, %sub152
  %add157 = fadd float %add155, %mul156
  %sub158 = fsub float %add70, %25
  %sub159 = fsub float %add74, %26
  %sub160 = fsub float %add78, %27
  %mul161 = fmul float %sub158, %sub158
  %mul162 = fmul float %sub159, %sub159
  %add163 = fadd float %mul161, %mul162
  %mul164 = fmul float %sub160, %sub160
  %add165 = fadd float %add163, %mul164
  %sub166 = fsub float %add70, %28
  %sub167 = fsub float %add74, %29
  %sub168 = fsub float %add78, %30
  %mul169 = fmul float %sub166, %sub166
  %mul170 = fmul float %sub167, %sub167
  %add171 = fadd float %mul169, %mul170
  %mul172 = fmul float %sub168, %sub168
  %add173 = fadd float %add171, %mul172
  %sub174 = fsub float %add70, %31
  %sub175 = fsub float %add74, %32
  %sub176 = fsub float %add78, %33
  %mul177 = fmul float %sub174, %sub174
  %mul178 = fmul float %sub175, %sub175
  %add179 = fadd float %mul177, %mul178
  %mul180 = fmul float %sub176, %sub176
  %add181 = fadd float %add179, %mul180
  %conv = fpext float %add117 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv182 = fptrunc double %div to float
  %conv183 = fpext float %add141 to double
  %call184 = tail call double @sqrt(double %conv183) #2
  %div185 = fdiv double 1.000000e+00, %call184
  %conv186 = fptrunc double %div185 to float
  %conv187 = fpext float %add165 to double
  %call188 = tail call double @sqrt(double %conv187) #2
  %div189 = fdiv double 1.000000e+00, %call188
  %conv190 = fptrunc double %div189 to float
  %conv191 = fpext float %add125 to double
  %call192 = tail call double @sqrt(double %conv191) #2
  %div193 = fdiv double 1.000000e+00, %call192
  %conv194 = fptrunc double %div193 to float
  %conv195 = fpext float %add149 to double
  %call196 = tail call double @sqrt(double %conv195) #2
  %div197 = fdiv double 1.000000e+00, %call196
  %conv198 = fptrunc double %div197 to float
  %conv199 = fpext float %add173 to double
  %call200 = tail call double @sqrt(double %conv199) #2
  %div201 = fdiv double 1.000000e+00, %call200
  %conv202 = fptrunc double %div201 to float
  %conv203 = fpext float %add133 to double
  %call204 = tail call double @sqrt(double %conv203) #2
  %div205 = fdiv double 1.000000e+00, %call204
  %conv206 = fptrunc double %div205 to float
  %conv207 = fpext float %add157 to double
  %call208 = tail call double @sqrt(double %conv207) #2
  %div209 = fdiv double 1.000000e+00, %call208
  %conv210 = fptrunc double %div209 to float
  %conv211 = fpext float %add181 to double
  %call212 = tail call double @sqrt(double %conv211) #2
  %div213 = fdiv double 1.000000e+00, %call212
  %conv214 = fptrunc double %div213 to float
  %mul215 = fmul float %add117, %conv182
  %mul216 = fmul float %conv182, %conv182
  %mul217 = fmul float %mul216, %mul216
  %mul218 = fmul float %mul216, %mul217
  %mul219 = fmul float %4, %mul218
  %mul220 = fmul float %5, %mul215
  %sub222 = fsub float -0.000000e+00, %mul220
  %conv223 = fpext float %sub222 to double
  %call224 = tail call double @exp(double %conv223) #2
  %mul225 = fmul double %conv221, %call224
  %conv226 = fptrunc double %mul225 to float
  %add227 = fadd float %vnbtot.01013, %conv226
  %sub228 = fsub float %add227, %mul219
  %mul229 = fmul float %add117, %krf
  %add230 = fadd float %mul229, %conv182
  %sub231 = fsub float %add230, %crf
  %mul232 = fmul float %mul4, %sub231
  %mul233 = fmul float %mul220, %conv226
  %mul234 = fmul float %mul219, 6.000000e+00
  %sub235 = fsub float %mul233, %mul234
  %mul236 = fmul float %mul229, 2.000000e+00
  %sub237 = fsub float %conv182, %mul236
  %mul238 = fmul float %mul4, %sub237
  %add239 = fadd float %mul238, %sub235
  %mul240 = fmul float %mul216, %add239
  %add241 = fadd float %vctot.01014, %mul232
  %mul242 = fmul float %sub, %mul240
  %mul243 = fmul float %sub111, %mul240
  %mul244 = fmul float %sub112, %mul240
  %add245 = fadd float %fix1.01012, %mul242
  %add246 = fadd float %fiy1.01011, %mul243
  %add247 = fadd float %fiz1.01010, %mul244
  %arrayidx249 = getelementptr inbounds float* %faction, i64 %idxprom85
  %34 = load float* %arrayidx249, align 4, !tbaa !3
  %sub250 = fsub float %34, %mul242
  %arrayidx253 = getelementptr inbounds float* %faction, i64 %idxprom88
  %35 = load float* %arrayidx253, align 4, !tbaa !3
  %sub254 = fsub float %35, %mul243
  %arrayidx257 = getelementptr inbounds float* %faction, i64 %idxprom91
  %36 = load float* %arrayidx257, align 4, !tbaa !3
  %sub258 = fsub float %36, %mul244
  %mul259 = fmul float %conv194, %conv194
  %mul260 = fmul float %add125, %krf
  %add261 = fadd float %mul260, %conv194
  %sub262 = fsub float %add261, %crf
  %mul263 = fmul float %mul6, %sub262
  %mul264 = fmul float %mul260, 2.000000e+00
  %sub265 = fsub float %conv194, %mul264
  %mul266 = fmul float %mul6, %sub265
  %mul267 = fmul float %mul259, %mul266
  %add268 = fadd float %add241, %mul263
  %mul269 = fmul float %sub118, %mul267
  %mul270 = fmul float %sub119, %mul267
  %mul271 = fmul float %sub120, %mul267
  %add272 = fadd float %mul269, %add245
  %add273 = fadd float %mul270, %add246
  %add274 = fadd float %mul271, %add247
  %arrayidx277 = getelementptr inbounds float* %faction, i64 %idxprom94
  %37 = load float* %arrayidx277, align 4, !tbaa !3
  %sub278 = fsub float %37, %mul269
  %arrayidx281 = getelementptr inbounds float* %faction, i64 %idxprom97
  %38 = load float* %arrayidx281, align 4, !tbaa !3
  %sub282 = fsub float %38, %mul270
  %arrayidx285 = getelementptr inbounds float* %faction, i64 %idxprom100
  %39 = load float* %arrayidx285, align 4, !tbaa !3
  %sub286 = fsub float %39, %mul271
  %mul287 = fmul float %conv206, %conv206
  %mul288 = fmul float %add133, %krf
  %add289 = fadd float %mul288, %conv206
  %sub290 = fsub float %add289, %crf
  %mul291 = fmul float %mul6, %sub290
  %mul292 = fmul float %mul288, 2.000000e+00
  %sub293 = fsub float %conv206, %mul292
  %mul294 = fmul float %mul6, %sub293
  %mul295 = fmul float %mul287, %mul294
  %add296 = fadd float %add268, %mul291
  %mul297 = fmul float %sub126, %mul295
  %mul298 = fmul float %sub127, %mul295
  %mul299 = fmul float %sub128, %mul295
  %add300 = fadd float %mul297, %add272
  %add301 = fadd float %mul298, %add273
  %add302 = fadd float %mul299, %add274
  %arrayidx305 = getelementptr inbounds float* %faction, i64 %idxprom103
  %40 = load float* %arrayidx305, align 4, !tbaa !3
  %sub306 = fsub float %40, %mul297
  %arrayidx309 = getelementptr inbounds float* %faction, i64 %idxprom106
  %41 = load float* %arrayidx309, align 4, !tbaa !3
  %sub310 = fsub float %41, %mul298
  %arrayidx313 = getelementptr inbounds float* %faction, i64 %idxprom109
  %42 = load float* %arrayidx313, align 4, !tbaa !3
  %sub314 = fsub float %42, %mul299
  %mul315 = fmul float %conv186, %conv186
  %mul316 = fmul float %add141, %krf
  %add317 = fadd float %mul316, %conv186
  %sub318 = fsub float %add317, %crf
  %mul319 = fmul float %mul6, %sub318
  %mul320 = fmul float %mul316, 2.000000e+00
  %sub321 = fsub float %conv186, %mul320
  %mul322 = fmul float %mul6, %sub321
  %mul323 = fmul float %mul315, %mul322
  %add324 = fadd float %mul319, %add296
  %mul325 = fmul float %sub134, %mul323
  %mul326 = fmul float %sub135, %mul323
  %mul327 = fmul float %sub136, %mul323
  %add328 = fadd float %fix2.01009, %mul325
  %add329 = fadd float %fiy2.01008, %mul326
  %add330 = fadd float %fiz2.01007, %mul327
  %sub331 = fsub float %sub250, %mul325
  %sub332 = fsub float %sub254, %mul326
  %sub333 = fsub float %sub258, %mul327
  %mul334 = fmul float %conv198, %conv198
  %mul335 = fmul float %add149, %krf
  %add336 = fadd float %mul335, %conv198
  %sub337 = fsub float %add336, %crf
  %mul338 = fmul float %mul8, %sub337
  %mul339 = fmul float %mul335, 2.000000e+00
  %sub340 = fsub float %conv198, %mul339
  %mul341 = fmul float %mul8, %sub340
  %mul342 = fmul float %mul334, %mul341
  %add343 = fadd float %mul338, %add324
  %mul344 = fmul float %sub142, %mul342
  %mul345 = fmul float %sub143, %mul342
  %mul346 = fmul float %sub144, %mul342
  %add347 = fadd float %add328, %mul344
  %add348 = fadd float %add329, %mul345
  %add349 = fadd float %add330, %mul346
  %sub350 = fsub float %sub278, %mul344
  %sub351 = fsub float %sub282, %mul345
  %sub352 = fsub float %sub286, %mul346
  %mul353 = fmul float %conv210, %conv210
  %mul354 = fmul float %add157, %krf
  %add355 = fadd float %mul354, %conv210
  %sub356 = fsub float %add355, %crf
  %mul357 = fmul float %mul8, %sub356
  %mul358 = fmul float %mul354, 2.000000e+00
  %sub359 = fsub float %conv210, %mul358
  %mul360 = fmul float %mul8, %sub359
  %mul361 = fmul float %mul353, %mul360
  %add362 = fadd float %mul357, %add343
  %mul363 = fmul float %sub150, %mul361
  %mul364 = fmul float %sub151, %mul361
  %mul365 = fmul float %sub152, %mul361
  %add366 = fadd float %add347, %mul363
  %add367 = fadd float %add348, %mul364
  %add368 = fadd float %add349, %mul365
  %sub369 = fsub float %sub306, %mul363
  %sub370 = fsub float %sub310, %mul364
  %sub371 = fsub float %sub314, %mul365
  %mul372 = fmul float %conv190, %conv190
  %mul373 = fmul float %add165, %krf
  %add374 = fadd float %mul373, %conv190
  %sub375 = fsub float %add374, %crf
  %mul376 = fmul float %mul6, %sub375
  %mul377 = fmul float %mul373, 2.000000e+00
  %sub378 = fsub float %conv190, %mul377
  %mul379 = fmul float %mul6, %sub378
  %mul380 = fmul float %mul372, %mul379
  %add381 = fadd float %mul376, %add362
  %mul382 = fmul float %sub158, %mul380
  %mul383 = fmul float %sub159, %mul380
  %mul384 = fmul float %sub160, %mul380
  %add385 = fadd float %fix3.01006, %mul382
  %add386 = fadd float %fiy3.01005, %mul383
  %add387 = fadd float %fiz3.01004, %mul384
  %sub388 = fsub float %sub331, %mul382
  store float %sub388, float* %arrayidx249, align 4, !tbaa !3
  %sub391 = fsub float %sub332, %mul383
  store float %sub391, float* %arrayidx253, align 4, !tbaa !3
  %sub395 = fsub float %sub333, %mul384
  store float %sub395, float* %arrayidx257, align 4, !tbaa !3
  %mul399 = fmul float %conv202, %conv202
  %mul400 = fmul float %add173, %krf
  %add401 = fadd float %mul400, %conv202
  %sub402 = fsub float %add401, %crf
  %mul403 = fmul float %mul8, %sub402
  %mul404 = fmul float %mul400, 2.000000e+00
  %sub405 = fsub float %conv202, %mul404
  %mul406 = fmul float %mul8, %sub405
  %mul407 = fmul float %mul399, %mul406
  %add408 = fadd float %mul403, %add381
  %mul409 = fmul float %sub166, %mul407
  %mul410 = fmul float %sub167, %mul407
  %mul411 = fmul float %sub168, %mul407
  %add412 = fadd float %add385, %mul409
  %add413 = fadd float %add386, %mul410
  %add414 = fadd float %add387, %mul411
  %sub415 = fsub float %sub350, %mul409
  store float %sub415, float* %arrayidx277, align 4, !tbaa !3
  %sub419 = fsub float %sub351, %mul410
  store float %sub419, float* %arrayidx281, align 4, !tbaa !3
  %sub423 = fsub float %sub352, %mul411
  store float %sub423, float* %arrayidx285, align 4, !tbaa !3
  %mul427 = fmul float %conv214, %conv214
  %mul428 = fmul float %add181, %krf
  %add429 = fadd float %mul428, %conv214
  %sub430 = fsub float %add429, %crf
  %mul431 = fmul float %mul8, %sub430
  %mul432 = fmul float %mul428, 2.000000e+00
  %sub433 = fsub float %conv214, %mul432
  %mul434 = fmul float %mul8, %sub433
  %mul435 = fmul float %mul427, %mul434
  %add436 = fadd float %mul431, %add408
  %mul437 = fmul float %sub174, %mul435
  %mul438 = fmul float %sub175, %mul435
  %mul439 = fmul float %sub176, %mul435
  %add440 = fadd float %add412, %mul437
  %add441 = fadd float %add413, %mul438
  %add442 = fadd float %add414, %mul439
  %sub443 = fsub float %sub369, %mul437
  store float %sub443, float* %arrayidx305, align 4, !tbaa !3
  %sub447 = fsub float %sub370, %mul438
  store float %sub447, float* %arrayidx309, align 4, !tbaa !3
  %sub451 = fsub float %sub371, %mul439
  store float %sub451, float* %arrayidx313, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %43 = trunc i64 %indvars.iv.next to i32
  %cmp80 = icmp slt i32 %43, %13
  br i1 %cmp80, label %for.body81, label %for.end

for.end:                                          ; preds = %for.body81, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add436, %for.body81 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %sub228, %for.body81 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add300, %for.body81 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add301, %for.body81 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add302, %for.body81 ]
  %fix2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add366, %for.body81 ]
  %fiy2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add367, %for.body81 ]
  %fiz2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add368, %for.body81 ]
  %fix3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add440, %for.body81 ]
  %fiy3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add441, %for.body81 ]
  %fiz3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add442, %for.body81 ]
  %arrayidx456 = getelementptr inbounds float* %faction, i64 %idxprom44
  %44 = load float* %arrayidx456, align 4, !tbaa !3
  %add457 = fadd float %fix1.0.lcssa, %44
  store float %add457, float* %arrayidx456, align 4, !tbaa !3
  %arrayidx462 = getelementptr inbounds float* %faction, i64 %idxprom48
  %45 = load float* %arrayidx462, align 4, !tbaa !3
  %add463 = fadd float %fiy1.0.lcssa, %45
  store float %add463, float* %arrayidx462, align 4, !tbaa !3
  %arrayidx469 = getelementptr inbounds float* %faction, i64 %idxprom52
  %46 = load float* %arrayidx469, align 4, !tbaa !3
  %add470 = fadd float %fiz1.0.lcssa, %46
  store float %add470, float* %arrayidx469, align 4, !tbaa !3
  %arrayidx476 = getelementptr inbounds float* %faction, i64 %idxprom56
  %47 = load float* %arrayidx476, align 4, !tbaa !3
  %add477 = fadd float %fix2.0.lcssa, %47
  store float %add477, float* %arrayidx476, align 4, !tbaa !3
  %arrayidx483 = getelementptr inbounds float* %faction, i64 %idxprom60
  %48 = load float* %arrayidx483, align 4, !tbaa !3
  %add484 = fadd float %fiy2.0.lcssa, %48
  store float %add484, float* %arrayidx483, align 4, !tbaa !3
  %arrayidx490 = getelementptr inbounds float* %faction, i64 %idxprom64
  %49 = load float* %arrayidx490, align 4, !tbaa !3
  %add491 = fadd float %fiz2.0.lcssa, %49
  store float %add491, float* %arrayidx490, align 4, !tbaa !3
  %arrayidx497 = getelementptr inbounds float* %faction, i64 %idxprom68
  %50 = load float* %arrayidx497, align 4, !tbaa !3
  %add498 = fadd float %fix3.0.lcssa, %50
  store float %add498, float* %arrayidx497, align 4, !tbaa !3
  %arrayidx504 = getelementptr inbounds float* %faction, i64 %idxprom72
  %51 = load float* %arrayidx504, align 4, !tbaa !3
  %add505 = fadd float %fiy3.0.lcssa, %51
  store float %add505, float* %arrayidx504, align 4, !tbaa !3
  %arrayidx511 = getelementptr inbounds float* %faction, i64 %idxprom76
  %52 = load float* %arrayidx511, align 4, !tbaa !3
  %add512 = fadd float %fiz3.0.lcssa, %52
  store float %add512, float* %arrayidx511, align 4, !tbaa !3
  %arrayidx517 = getelementptr inbounds float* %fshift, i64 %idxprom28
  %53 = load float* %arrayidx517, align 4, !tbaa !3
  %add518 = fadd float %fix1.0.lcssa, %53
  %add519 = fadd float %fix2.0.lcssa, %add518
  %add520 = fadd float %fix3.0.lcssa, %add519
  store float %add520, float* %arrayidx517, align 4, !tbaa !3
  %arrayidx525 = getelementptr inbounds float* %fshift, i64 %idxprom31
  %54 = load float* %arrayidx525, align 4, !tbaa !3
  %add526 = fadd float %fiy1.0.lcssa, %54
  %add527 = fadd float %fiy2.0.lcssa, %add526
  %add528 = fadd float %fiy3.0.lcssa, %add527
  store float %add528, float* %arrayidx525, align 4, !tbaa !3
  %arrayidx534 = getelementptr inbounds float* %fshift, i64 %idxprom34
  %55 = load float* %arrayidx534, align 4, !tbaa !3
  %add535 = fadd float %fiz1.0.lcssa, %55
  %add536 = fadd float %fiz2.0.lcssa, %add535
  %add537 = fadd float %fiz3.0.lcssa, %add536
  store float %add537, float* %arrayidx534, align 4, !tbaa !3
  %arrayidx542 = getelementptr inbounds i32* %gid, i64 %indvars.iv1028
  %56 = load i32* %arrayidx542, align 4, !tbaa !0
  %idxprom543 = sext i32 %56 to i64
  %arrayidx544 = getelementptr inbounds float* %Vc, i64 %idxprom543
  %57 = load float* %arrayidx544, align 4, !tbaa !3
  %add545 = fadd float %vctot.0.lcssa, %57
  store float %add545, float* %arrayidx544, align 4, !tbaa !3
  %arrayidx549 = getelementptr inbounds float* %Vnb, i64 %idxprom543
  %58 = load float* %arrayidx549, align 4, !tbaa !3
  %add550 = fadd float %vnbtot.0.lcssa, %58
  store float %add550, float* %arrayidx549, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next1029 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end555, label %for.end.for.body_crit_edge

for.end.for.body_crit_edge:                       ; preds = %for.end
  %arrayidx37.phi.trans.insert = getelementptr inbounds i32* %iinr, i64 %indvars.iv.next1029
  %.pre = load i32* %arrayidx37.phi.trans.insert, align 4, !tbaa !0
  br label %for.body

for.end555:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl2300(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, float %krf, float %crf, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab) #0 {
entry:
  %cmp370 = icmp sgt i32 %nri, 0
  br i1 %cmp370, label %for.body.lr.ph, label %for.end213

for.body.lr.ph:                                   ; preds = %entry
  %mul30 = shl i32 %ntype, 1
  br label %for.body

for.body:                                         ; preds = %for.end, %for.body.lr.ph
  %indvars.iv372 = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next373, %for.end ]
  %arrayidx = getelementptr inbounds i32* %shift, i64 %indvars.iv372
  %0 = load i32* %arrayidx, align 4, !tbaa !0
  %mul = mul nsw i32 %0, 3
  %idxprom1 = sext i32 %mul to i64
  %arrayidx2 = getelementptr inbounds float* %shiftvec, i64 %idxprom1
  %1 = load float* %arrayidx2, align 4, !tbaa !3
  %add = add nsw i32 %mul, 1
  %idxprom3 = sext i32 %add to i64
  %arrayidx4 = getelementptr inbounds float* %shiftvec, i64 %idxprom3
  %2 = load float* %arrayidx4, align 4, !tbaa !3
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds float* %shiftvec, i64 %idxprom6
  %3 = load float* %arrayidx7, align 4, !tbaa !3
  %arrayidx9 = getelementptr inbounds i32* %iinr, i64 %indvars.iv372
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %arrayidx12 = getelementptr inbounds i32* %jindex, i64 %indvars.iv372
  %5 = load i32* %arrayidx12, align 4, !tbaa !0
  %indvars.iv.next373 = add i64 %indvars.iv372, 1
  %arrayidx15 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next373
  %6 = load i32* %arrayidx15, align 4, !tbaa !0
  %idxprom16 = sext i32 %mul10 to i64
  %arrayidx17 = getelementptr inbounds float* %pos, i64 %idxprom16
  %7 = load float* %arrayidx17, align 4, !tbaa !3
  %add18 = fadd float %1, %7
  %add19 = add nsw i32 %mul10, 1
  %idxprom20 = sext i32 %add19 to i64
  %arrayidx21 = getelementptr inbounds float* %pos, i64 %idxprom20
  %8 = load float* %arrayidx21, align 4, !tbaa !3
  %add22 = fadd float %2, %8
  %add23 = add nsw i32 %mul10, 2
  %idxprom24 = sext i32 %add23 to i64
  %arrayidx25 = getelementptr inbounds float* %pos, i64 %idxprom24
  %9 = load float* %arrayidx25, align 4, !tbaa !3
  %add26 = fadd float %3, %9
  %idxprom27 = sext i32 %4 to i64
  %arrayidx28 = getelementptr inbounds float* %charge, i64 %idxprom27
  %10 = load float* %arrayidx28, align 4, !tbaa !3
  %mul29 = fmul float %10, %facel
  %arrayidx32 = getelementptr inbounds i32* %type, i64 %idxprom27
  %11 = load i32* %arrayidx32, align 4, !tbaa !0
  %mul33 = mul nsw i32 %mul30, %11
  %cmp35359 = icmp slt i32 %5, %6
  br i1 %cmp35359, label %for.body36.lr.ph, label %for.end

for.body36.lr.ph:                                 ; preds = %for.body
  %12 = sext i32 %5 to i64
  br label %for.body36

for.body36:                                       ; preds = %for.body36.lr.ph, %for.body36
  %indvars.iv = phi i64 [ %12, %for.body36.lr.ph ], [ %indvars.iv.next, %for.body36 ]
  %vctot.0364 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add135, %for.body36 ]
  %vnbtot.0363 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add119, %for.body36 ]
  %fix1.0362 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add139, %for.body36 ]
  %fiy1.0361 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add140, %for.body36 ]
  %fiz1.0360 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add141, %for.body36 ]
  %arrayidx38 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %13 = load i32* %arrayidx38, align 4, !tbaa !0
  %mul39 = mul nsw i32 %13, 3
  %idxprom40 = sext i32 %mul39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %14 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = add nsw i32 %mul39, 1
  %idxprom43 = sext i32 %add42 to i64
  %arrayidx44 = getelementptr inbounds float* %pos, i64 %idxprom43
  %15 = load float* %arrayidx44, align 4, !tbaa !3
  %add45 = add nsw i32 %mul39, 2
  %idxprom46 = sext i32 %add45 to i64
  %arrayidx47 = getelementptr inbounds float* %pos, i64 %idxprom46
  %16 = load float* %arrayidx47, align 4, !tbaa !3
  %sub = fsub float %add18, %14
  %sub48 = fsub float %add22, %15
  %sub49 = fsub float %add26, %16
  %mul50 = fmul float %sub, %sub
  %mul51 = fmul float %sub48, %sub48
  %add52 = fadd float %mul50, %mul51
  %mul53 = fmul float %sub49, %sub49
  %add54 = fadd float %add52, %mul53
  %conv = fpext float %add54 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv55 = fptrunc double %div to float
  %mul56 = fmul float %add54, %conv55
  %mul58 = fmul float %mul56, %tabscale
  %conv59 = fptosi float %mul58 to i32
  %conv60 = sitofp i32 %conv59 to float
  %sub61 = fsub float %mul58, %conv60
  %mul62 = fmul float %sub61, %sub61
  %mul63 = shl nsw i32 %conv59, 3
  %idxprom64 = sext i32 %13 to i64
  %arrayidx65 = getelementptr inbounds i32* %type, i64 %idxprom64
  %17 = load i32* %arrayidx65, align 4, !tbaa !0
  %mul66 = shl nsw i32 %17, 1
  %add67 = add nsw i32 %mul66, %mul33
  %idxprom68 = sext i32 %add67 to i64
  %arrayidx69 = getelementptr inbounds float* %nbfp, i64 %idxprom68
  %18 = load float* %arrayidx69, align 4, !tbaa !3
  %add70351 = or i32 %add67, 1
  %idxprom71 = sext i32 %add70351 to i64
  %arrayidx72 = getelementptr inbounds float* %nbfp, i64 %idxprom71
  %19 = load float* %arrayidx72, align 4, !tbaa !3
  %idxprom73 = sext i32 %mul63 to i64
  %arrayidx74 = getelementptr inbounds float* %VFtab, i64 %idxprom73
  %20 = load float* %arrayidx74, align 4, !tbaa !3
  %add75352 = or i32 %mul63, 1
  %idxprom76 = sext i32 %add75352 to i64
  %arrayidx77 = getelementptr inbounds float* %VFtab, i64 %idxprom76
  %21 = load float* %arrayidx77, align 4, !tbaa !3
  %add78353 = or i32 %mul63, 2
  %idxprom79 = sext i32 %add78353 to i64
  %arrayidx80 = getelementptr inbounds float* %VFtab, i64 %idxprom79
  %22 = load float* %arrayidx80, align 4, !tbaa !3
  %mul81 = fmul float %sub61, %22
  %add82354 = or i32 %mul63, 3
  %idxprom83 = sext i32 %add82354 to i64
  %arrayidx84 = getelementptr inbounds float* %VFtab, i64 %idxprom83
  %23 = load float* %arrayidx84, align 4, !tbaa !3
  %mul85 = fmul float %mul62, %23
  %add86 = fadd float %21, %mul81
  %add87 = fadd float %add86, %mul85
  %mul88 = fmul float %sub61, %add87
  %add89 = fadd float %20, %mul88
  %add90 = fadd float %mul81, %add87
  %mul91 = fmul float %mul85, 2.000000e+00
  %add92 = fadd float %mul91, %add90
  %mul93 = fmul float %18, %add89
  %mul94 = fmul float %18, %add92
  %add95355 = or i32 %mul63, 4
  %idxprom96 = sext i32 %add95355 to i64
  %arrayidx97 = getelementptr inbounds float* %VFtab, i64 %idxprom96
  %24 = load float* %arrayidx97, align 4, !tbaa !3
  %add98356 = or i32 %mul63, 5
  %idxprom99 = sext i32 %add98356 to i64
  %arrayidx100 = getelementptr inbounds float* %VFtab, i64 %idxprom99
  %25 = load float* %arrayidx100, align 4, !tbaa !3
  %add101357 = or i32 %mul63, 6
  %idxprom102 = sext i32 %add101357 to i64
  %arrayidx103 = getelementptr inbounds float* %VFtab, i64 %idxprom102
  %26 = load float* %arrayidx103, align 4, !tbaa !3
  %mul104 = fmul float %sub61, %26
  %add105358 = or i32 %mul63, 7
  %idxprom106 = sext i32 %add105358 to i64
  %arrayidx107 = getelementptr inbounds float* %VFtab, i64 %idxprom106
  %27 = load float* %arrayidx107, align 4, !tbaa !3
  %mul108 = fmul float %mul62, %27
  %add109 = fadd float %25, %mul104
  %add110 = fadd float %add109, %mul108
  %mul111 = fmul float %sub61, %add110
  %add112 = fadd float %24, %mul111
  %add113 = fadd float %mul104, %add110
  %mul114 = fmul float %mul108, 2.000000e+00
  %add115 = fadd float %mul114, %add113
  %mul116 = fmul float %19, %add112
  %mul117 = fmul float %19, %add115
  %add118 = fadd float %vnbtot.0363, %mul93
  %add119 = fadd float %add118, %mul116
  %arrayidx121 = getelementptr inbounds float* %charge, i64 %idxprom64
  %28 = load float* %arrayidx121, align 4, !tbaa !3
  %mul122 = fmul float %mul29, %28
  %mul123 = fmul float %add54, %krf
  %add124 = fadd float %conv55, %mul123
  %sub125 = fsub float %add124, %crf
  %mul126 = fmul float %sub125, %mul122
  %mul127 = fmul float %mul123, 2.000000e+00
  %sub128 = fsub float %conv55, %mul127
  %mul129 = fmul float %sub128, %mul122
  %mul130 = fmul float %conv55, %mul129
  %add131 = fadd float %mul94, %mul117
  %mul132 = fmul float %add131, %tabscale
  %sub133 = fsub float %mul130, %mul132
  %mul134 = fmul float %conv55, %sub133
  %add135 = fadd float %vctot.0364, %mul126
  %mul136 = fmul float %sub, %mul134
  %mul137 = fmul float %sub48, %mul134
  %mul138 = fmul float %sub49, %mul134
  %add139 = fadd float %fix1.0362, %mul136
  %add140 = fadd float %fiy1.0361, %mul137
  %add141 = fadd float %fiz1.0360, %mul138
  %arrayidx143 = getelementptr inbounds float* %faction, i64 %idxprom40
  %29 = load float* %arrayidx143, align 4, !tbaa !3
  %sub144 = fsub float %29, %mul136
  store float %sub144, float* %arrayidx143, align 4, !tbaa !3
  %arrayidx149 = getelementptr inbounds float* %faction, i64 %idxprom43
  %30 = load float* %arrayidx149, align 4, !tbaa !3
  %sub150 = fsub float %30, %mul137
  store float %sub150, float* %arrayidx149, align 4, !tbaa !3
  %arrayidx156 = getelementptr inbounds float* %faction, i64 %idxprom46
  %31 = load float* %arrayidx156, align 4, !tbaa !3
  %sub157 = fsub float %31, %mul138
  store float %sub157, float* %arrayidx156, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %32 = trunc i64 %indvars.iv.next to i32
  %cmp35 = icmp slt i32 %32, %6
  br i1 %cmp35, label %for.body36, label %for.end

for.end:                                          ; preds = %for.body36, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add135, %for.body36 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add119, %for.body36 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add139, %for.body36 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add140, %for.body36 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add141, %for.body36 ]
  %arrayidx162 = getelementptr inbounds float* %faction, i64 %idxprom16
  %33 = load float* %arrayidx162, align 4, !tbaa !3
  %add163 = fadd float %fix1.0.lcssa, %33
  store float %add163, float* %arrayidx162, align 4, !tbaa !3
  %arrayidx168 = getelementptr inbounds float* %faction, i64 %idxprom20
  %34 = load float* %arrayidx168, align 4, !tbaa !3
  %add169 = fadd float %fiy1.0.lcssa, %34
  store float %add169, float* %arrayidx168, align 4, !tbaa !3
  %arrayidx175 = getelementptr inbounds float* %faction, i64 %idxprom24
  %35 = load float* %arrayidx175, align 4, !tbaa !3
  %add176 = fadd float %fiz1.0.lcssa, %35
  store float %add176, float* %arrayidx175, align 4, !tbaa !3
  %arrayidx181 = getelementptr inbounds float* %fshift, i64 %idxprom1
  %36 = load float* %arrayidx181, align 4, !tbaa !3
  %add182 = fadd float %fix1.0.lcssa, %36
  store float %add182, float* %arrayidx181, align 4, !tbaa !3
  %arrayidx187 = getelementptr inbounds float* %fshift, i64 %idxprom3
  %37 = load float* %arrayidx187, align 4, !tbaa !3
  %add188 = fadd float %fiy1.0.lcssa, %37
  store float %add188, float* %arrayidx187, align 4, !tbaa !3
  %arrayidx194 = getelementptr inbounds float* %fshift, i64 %idxprom6
  %38 = load float* %arrayidx194, align 4, !tbaa !3
  %add195 = fadd float %fiz1.0.lcssa, %38
  store float %add195, float* %arrayidx194, align 4, !tbaa !3
  %arrayidx200 = getelementptr inbounds i32* %gid, i64 %indvars.iv372
  %39 = load i32* %arrayidx200, align 4, !tbaa !0
  %idxprom201 = sext i32 %39 to i64
  %arrayidx202 = getelementptr inbounds float* %Vc, i64 %idxprom201
  %40 = load float* %arrayidx202, align 4, !tbaa !3
  %add203 = fadd float %vctot.0.lcssa, %40
  store float %add203, float* %arrayidx202, align 4, !tbaa !3
  %arrayidx207 = getelementptr inbounds float* %Vnb, i64 %idxprom201
  %41 = load float* %arrayidx207, align 4, !tbaa !3
  %add208 = fadd float %vnbtot.0.lcssa, %41
  store float %add208, float* %arrayidx207, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next373 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end213, label %for.body

for.end213:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl2310(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, float %krf, float %crf, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab, i32* nocapture %nsatoms) #0 {
entry:
  %cmp1053 = icmp sgt i32 %nri, 0
  br i1 %cmp1053, label %for.body.lr.ph, label %for.end546

for.body.lr.ph:                                   ; preds = %entry
  %mul362 = shl i32 %ntype, 1
  br label %for.body

for.body:                                         ; preds = %for.end531, %for.body.lr.ph
  %indvars.iv1079 = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next1080, %for.end531 ]
  %0 = trunc i64 %indvars.iv1079 to i32
  %mul = mul nsw i32 %0, 3
  %idxprom = sext i32 %mul to i64
  %arrayidx = getelementptr inbounds i32* %nsatoms, i64 %idxprom
  %1 = load i32* %arrayidx, align 4, !tbaa !0
  %add = add nsw i32 %mul, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds i32* %nsatoms, i64 %idxprom2
  %2 = load i32* %arrayidx3, align 4, !tbaa !0
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds i32* %nsatoms, i64 %idxprom6
  %3 = load i32* %arrayidx7, align 4, !tbaa !0
  %arrayidx9 = getelementptr inbounds i32* %shift, i64 %indvars.iv1079
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %idxprom11 = sext i32 %mul10 to i64
  %arrayidx12 = getelementptr inbounds float* %shiftvec, i64 %idxprom11
  %5 = load float* %arrayidx12, align 4, !tbaa !3
  %add13 = add nsw i32 %mul10, 1
  %idxprom14 = sext i32 %add13 to i64
  %arrayidx15 = getelementptr inbounds float* %shiftvec, i64 %idxprom14
  %6 = load float* %arrayidx15, align 4, !tbaa !3
  %add16 = add nsw i32 %mul10, 2
  %idxprom17 = sext i32 %add16 to i64
  %arrayidx18 = getelementptr inbounds float* %shiftvec, i64 %idxprom17
  %7 = load float* %arrayidx18, align 4, !tbaa !3
  %arrayidx20 = getelementptr inbounds i32* %iinr, i64 %indvars.iv1079
  %8 = load i32* %arrayidx20, align 4, !tbaa !0
  %mul21 = mul i32 %8, 3
  %arrayidx23 = getelementptr inbounds i32* %jindex, i64 %indvars.iv1079
  %9 = load i32* %arrayidx23, align 4, !tbaa !0
  %indvars.iv.next1080 = add i64 %indvars.iv1079, 1
  %arrayidx26 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next1080
  %10 = load i32* %arrayidx26, align 4, !tbaa !0
  %cmp281009 = icmp sgt i32 %2, 0
  br i1 %cmp281009, label %for.body29.lr.ph, label %for.cond218.loopexit

for.body29.lr.ph:                                 ; preds = %for.body
  %cmp49998 = icmp slt i32 %9, %10
  %arrayidx195 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx201 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx208 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %11 = sext i32 %9 to i64
  %12 = sext i32 %8 to i64
  %13 = sext i32 %mul21 to i64
  %14 = add i32 %2, %8
  %15 = mul i32 %14, 3
  br label %for.body29

for.body29:                                       ; preds = %for.end, %for.body29.lr.ph
  %indvars.iv1057 = phi i64 [ %13, %for.body29.lr.ph ], [ %indvars.iv.next1058, %for.end ]
  %indvars.iv1055 = phi i64 [ %12, %for.body29.lr.ph ], [ %indvars.iv.next1056, %for.end ]
  %s.01012 = phi i32 [ 0, %for.body29.lr.ph ], [ %inc216, %for.end ]
  %vnbtot.01011 = phi float [ 0.000000e+00, %for.body29.lr.ph ], [ %vnbtot.1.lcssa, %for.end ]
  %vctot.01010 = phi float [ 0.000000e+00, %for.body29.lr.ph ], [ %vctot.1.lcssa, %for.end ]
  %arrayidx31 = getelementptr inbounds float* %pos, i64 %indvars.iv1057
  %16 = load float* %arrayidx31, align 4, !tbaa !3
  %add32 = fadd float %5, %16
  %17 = add nsw i64 %indvars.iv1057, 1
  %arrayidx35 = getelementptr inbounds float* %pos, i64 %17
  %18 = load float* %arrayidx35, align 4, !tbaa !3
  %add36 = fadd float %6, %18
  %19 = add nsw i64 %indvars.iv1057, 2
  %arrayidx39 = getelementptr inbounds float* %pos, i64 %19
  %20 = load float* %arrayidx39, align 4, !tbaa !3
  %add40 = fadd float %7, %20
  %arrayidx42 = getelementptr inbounds float* %charge, i64 %indvars.iv1055
  %21 = load float* %arrayidx42, align 4, !tbaa !3
  %mul43 = fmul float %21, %facel
  %arrayidx46 = getelementptr inbounds i32* %type, i64 %indvars.iv1055
  %22 = load i32* %arrayidx46, align 4, !tbaa !0
  %mul47 = mul nsw i32 %mul362, %22
  br i1 %cmp49998, label %for.body50, label %for.end

for.body50:                                       ; preds = %for.body29, %for.body50
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body50 ], [ %11, %for.body29 ]
  %fiz1.01003 = phi float [ %add155, %for.body50 ], [ 0.000000e+00, %for.body29 ]
  %fiy1.01002 = phi float [ %add154, %for.body50 ], [ 0.000000e+00, %for.body29 ]
  %fix1.01001 = phi float [ %add153, %for.body50 ], [ 0.000000e+00, %for.body29 ]
  %vnbtot.11000 = phi float [ %add133, %for.body50 ], [ %vnbtot.01011, %for.body29 ]
  %vctot.1999 = phi float [ %add149, %for.body50 ], [ %vctot.01010, %for.body29 ]
  %arrayidx52 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %23 = load i32* %arrayidx52, align 4, !tbaa !0
  %mul53 = mul nsw i32 %23, 3
  %idxprom54 = sext i32 %mul53 to i64
  %arrayidx55 = getelementptr inbounds float* %pos, i64 %idxprom54
  %24 = load float* %arrayidx55, align 4, !tbaa !3
  %add56 = add nsw i32 %mul53, 1
  %idxprom57 = sext i32 %add56 to i64
  %arrayidx58 = getelementptr inbounds float* %pos, i64 %idxprom57
  %25 = load float* %arrayidx58, align 4, !tbaa !3
  %add59 = add nsw i32 %mul53, 2
  %idxprom60 = sext i32 %add59 to i64
  %arrayidx61 = getelementptr inbounds float* %pos, i64 %idxprom60
  %26 = load float* %arrayidx61, align 4, !tbaa !3
  %sub = fsub float %add32, %24
  %sub62 = fsub float %add36, %25
  %sub63 = fsub float %add40, %26
  %mul64 = fmul float %sub, %sub
  %mul65 = fmul float %sub62, %sub62
  %add66 = fadd float %mul64, %mul65
  %mul67 = fmul float %sub63, %sub63
  %add68 = fadd float %add66, %mul67
  %conv = fpext float %add68 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv69 = fptrunc double %div to float
  %mul70 = fmul float %add68, %conv69
  %mul72 = fmul float %mul70, %tabscale
  %conv73 = fptosi float %mul72 to i32
  %conv74 = sitofp i32 %conv73 to float
  %sub75 = fsub float %mul72, %conv74
  %mul76 = fmul float %sub75, %sub75
  %mul77 = shl nsw i32 %conv73, 3
  %idxprom78 = sext i32 %23 to i64
  %arrayidx79 = getelementptr inbounds i32* %type, i64 %idxprom78
  %27 = load i32* %arrayidx79, align 4, !tbaa !0
  %mul80 = shl nsw i32 %27, 1
  %add81 = add nsw i32 %mul80, %mul47
  %idxprom82 = sext i32 %add81 to i64
  %arrayidx83 = getelementptr inbounds float* %nbfp, i64 %idxprom82
  %28 = load float* %arrayidx83, align 4, !tbaa !3
  %add84990 = or i32 %add81, 1
  %idxprom85 = sext i32 %add84990 to i64
  %arrayidx86 = getelementptr inbounds float* %nbfp, i64 %idxprom85
  %29 = load float* %arrayidx86, align 4, !tbaa !3
  %idxprom87 = sext i32 %mul77 to i64
  %arrayidx88 = getelementptr inbounds float* %VFtab, i64 %idxprom87
  %30 = load float* %arrayidx88, align 4, !tbaa !3
  %add89991 = or i32 %mul77, 1
  %idxprom90 = sext i32 %add89991 to i64
  %arrayidx91 = getelementptr inbounds float* %VFtab, i64 %idxprom90
  %31 = load float* %arrayidx91, align 4, !tbaa !3
  %add92992 = or i32 %mul77, 2
  %idxprom93 = sext i32 %add92992 to i64
  %arrayidx94 = getelementptr inbounds float* %VFtab, i64 %idxprom93
  %32 = load float* %arrayidx94, align 4, !tbaa !3
  %mul95 = fmul float %sub75, %32
  %add96993 = or i32 %mul77, 3
  %idxprom97 = sext i32 %add96993 to i64
  %arrayidx98 = getelementptr inbounds float* %VFtab, i64 %idxprom97
  %33 = load float* %arrayidx98, align 4, !tbaa !3
  %mul99 = fmul float %mul76, %33
  %add100 = fadd float %31, %mul95
  %add101 = fadd float %add100, %mul99
  %mul102 = fmul float %sub75, %add101
  %add103 = fadd float %30, %mul102
  %add104 = fadd float %mul95, %add101
  %mul105 = fmul float %mul99, 2.000000e+00
  %add106 = fadd float %mul105, %add104
  %mul107 = fmul float %28, %add103
  %mul108 = fmul float %28, %add106
  %add109994 = or i32 %mul77, 4
  %idxprom110 = sext i32 %add109994 to i64
  %arrayidx111 = getelementptr inbounds float* %VFtab, i64 %idxprom110
  %34 = load float* %arrayidx111, align 4, !tbaa !3
  %add112995 = or i32 %mul77, 5
  %idxprom113 = sext i32 %add112995 to i64
  %arrayidx114 = getelementptr inbounds float* %VFtab, i64 %idxprom113
  %35 = load float* %arrayidx114, align 4, !tbaa !3
  %add115996 = or i32 %mul77, 6
  %idxprom116 = sext i32 %add115996 to i64
  %arrayidx117 = getelementptr inbounds float* %VFtab, i64 %idxprom116
  %36 = load float* %arrayidx117, align 4, !tbaa !3
  %mul118 = fmul float %sub75, %36
  %add119997 = or i32 %mul77, 7
  %idxprom120 = sext i32 %add119997 to i64
  %arrayidx121 = getelementptr inbounds float* %VFtab, i64 %idxprom120
  %37 = load float* %arrayidx121, align 4, !tbaa !3
  %mul122 = fmul float %mul76, %37
  %add123 = fadd float %35, %mul118
  %add124 = fadd float %add123, %mul122
  %mul125 = fmul float %sub75, %add124
  %add126 = fadd float %34, %mul125
  %add127 = fadd float %mul118, %add124
  %mul128 = fmul float %mul122, 2.000000e+00
  %add129 = fadd float %mul128, %add127
  %mul130 = fmul float %29, %add126
  %mul131 = fmul float %29, %add129
  %add132 = fadd float %vnbtot.11000, %mul107
  %add133 = fadd float %add132, %mul130
  %arrayidx135 = getelementptr inbounds float* %charge, i64 %idxprom78
  %38 = load float* %arrayidx135, align 4, !tbaa !3
  %mul136 = fmul float %mul43, %38
  %mul137 = fmul float %add68, %krf
  %add138 = fadd float %conv69, %mul137
  %sub139 = fsub float %add138, %crf
  %mul140 = fmul float %sub139, %mul136
  %mul141 = fmul float %mul137, 2.000000e+00
  %sub142 = fsub float %conv69, %mul141
  %mul143 = fmul float %sub142, %mul136
  %mul144 = fmul float %conv69, %mul143
  %add145 = fadd float %mul108, %mul131
  %mul146 = fmul float %add145, %tabscale
  %sub147 = fsub float %mul144, %mul146
  %mul148 = fmul float %conv69, %sub147
  %add149 = fadd float %vctot.1999, %mul140
  %mul150 = fmul float %sub, %mul148
  %mul151 = fmul float %sub62, %mul148
  %mul152 = fmul float %sub63, %mul148
  %add153 = fadd float %fix1.01001, %mul150
  %add154 = fadd float %fiy1.01002, %mul151
  %add155 = fadd float %fiz1.01003, %mul152
  %arrayidx157 = getelementptr inbounds float* %faction, i64 %idxprom54
  %39 = load float* %arrayidx157, align 4, !tbaa !3
  %sub158 = fsub float %39, %mul150
  store float %sub158, float* %arrayidx157, align 4, !tbaa !3
  %arrayidx163 = getelementptr inbounds float* %faction, i64 %idxprom57
  %40 = load float* %arrayidx163, align 4, !tbaa !3
  %sub164 = fsub float %40, %mul151
  store float %sub164, float* %arrayidx163, align 4, !tbaa !3
  %arrayidx170 = getelementptr inbounds float* %faction, i64 %idxprom60
  %41 = load float* %arrayidx170, align 4, !tbaa !3
  %sub171 = fsub float %41, %mul152
  store float %sub171, float* %arrayidx170, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %42 = trunc i64 %indvars.iv.next to i32
  %cmp49 = icmp slt i32 %42, %10
  br i1 %cmp49, label %for.body50, label %for.end

for.end:                                          ; preds = %for.body50, %for.body29
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add155, %for.body50 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add154, %for.body50 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add153, %for.body50 ]
  %vnbtot.1.lcssa = phi float [ %vnbtot.01011, %for.body29 ], [ %add133, %for.body50 ]
  %vctot.1.lcssa = phi float [ %vctot.01010, %for.body29 ], [ %add149, %for.body50 ]
  %arrayidx176 = getelementptr inbounds float* %faction, i64 %indvars.iv1057
  %43 = load float* %arrayidx176, align 4, !tbaa !3
  %add177 = fadd float %fix1.0.lcssa, %43
  store float %add177, float* %arrayidx176, align 4, !tbaa !3
  %arrayidx182 = getelementptr inbounds float* %faction, i64 %17
  %44 = load float* %arrayidx182, align 4, !tbaa !3
  %add183 = fadd float %fiy1.0.lcssa, %44
  store float %add183, float* %arrayidx182, align 4, !tbaa !3
  %arrayidx189 = getelementptr inbounds float* %faction, i64 %19
  %45 = load float* %arrayidx189, align 4, !tbaa !3
  %add190 = fadd float %fiz1.0.lcssa, %45
  store float %add190, float* %arrayidx189, align 4, !tbaa !3
  %46 = load float* %arrayidx195, align 4, !tbaa !3
  %add196 = fadd float %fix1.0.lcssa, %46
  store float %add196, float* %arrayidx195, align 4, !tbaa !3
  %47 = load float* %arrayidx201, align 4, !tbaa !3
  %add202 = fadd float %fiy1.0.lcssa, %47
  store float %add202, float* %arrayidx201, align 4, !tbaa !3
  %48 = load float* %arrayidx208, align 4, !tbaa !3
  %add209 = fadd float %fiz1.0.lcssa, %48
  store float %add209, float* %arrayidx208, align 4, !tbaa !3
  %indvars.iv.next1056 = add i64 %indvars.iv1055, 1
  %indvars.iv.next1058 = add i64 %indvars.iv1057, 3
  %inc216 = add nsw i32 %s.01012, 1
  %exitcond = icmp eq i32 %inc216, %2
  br i1 %exitcond, label %for.cond27.for.cond218.loopexit_crit_edge, label %for.body29

for.cond27.for.cond218.loopexit_crit_edge:        ; preds = %for.end
  %49 = add i32 %2, %8
  br label %for.cond218.loopexit

for.cond218.loopexit:                             ; preds = %for.cond27.for.cond218.loopexit_crit_edge, %for.body
  %ii.0.lcssa = phi i32 [ %49, %for.cond27.for.cond218.loopexit_crit_edge ], [ %8, %for.body ]
  %ii3.0.lcssa = phi i32 [ %15, %for.cond27.for.cond218.loopexit_crit_edge ], [ %mul21, %for.body ]
  %vnbtot.0.lcssa = phi float [ %vnbtot.1.lcssa, %for.cond27.for.cond218.loopexit_crit_edge ], [ 0.000000e+00, %for.body ]
  %vctot.0.lcssa = phi float [ %vctot.1.lcssa, %for.cond27.for.cond218.loopexit_crit_edge ], [ 0.000000e+00, %for.body ]
  %cmp2191029 = icmp slt i32 %2, %3
  br i1 %cmp2191029, label %for.body221.lr.ph, label %for.cond347.loopexit

for.body221.lr.ph:                                ; preds = %for.cond218.loopexit
  %cmp2371019 = icmp slt i32 %9, %10
  %arrayidx324 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx330 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx337 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %50 = sext i32 %9 to i64
  %51 = sext i32 %ii.0.lcssa to i64
  %52 = sext i32 %ii3.0.lcssa to i64
  %53 = mul i32 %3, 3
  %54 = add i32 %ii.0.lcssa, %3
  br label %for.body221

for.body221:                                      ; preds = %for.end303, %for.body221.lr.ph
  %indvars.iv1065 = phi i64 [ %52, %for.body221.lr.ph ], [ %indvars.iv.next1066, %for.end303 ]
  %indvars.iv1063 = phi i64 [ %51, %for.body221.lr.ph ], [ %indvars.iv.next1064, %for.end303 ]
  %s.11031 = phi i32 [ %2, %for.body221.lr.ph ], [ %inc345, %for.end303 ]
  %vctot.21030 = phi float [ %vctot.0.lcssa, %for.body221.lr.ph ], [ %vctot.3.lcssa, %for.end303 ]
  %arrayidx223 = getelementptr inbounds float* %pos, i64 %indvars.iv1065
  %55 = load float* %arrayidx223, align 4, !tbaa !3
  %add224 = fadd float %5, %55
  %56 = add nsw i64 %indvars.iv1065, 1
  %arrayidx227 = getelementptr inbounds float* %pos, i64 %56
  %57 = load float* %arrayidx227, align 4, !tbaa !3
  %add228 = fadd float %6, %57
  %58 = add nsw i64 %indvars.iv1065, 2
  %arrayidx231 = getelementptr inbounds float* %pos, i64 %58
  %59 = load float* %arrayidx231, align 4, !tbaa !3
  %add232 = fadd float %7, %59
  %arrayidx234 = getelementptr inbounds float* %charge, i64 %indvars.iv1063
  %60 = load float* %arrayidx234, align 4, !tbaa !3
  %mul235 = fmul float %60, %facel
  br i1 %cmp2371019, label %for.body239, label %for.end303

for.body239:                                      ; preds = %for.body221, %for.body239
  %indvars.iv1061 = phi i64 [ %indvars.iv.next1062, %for.body239 ], [ %50, %for.body221 ]
  %fiz1.11023 = phi float [ %add281, %for.body239 ], [ 0.000000e+00, %for.body221 ]
  %fiy1.11022 = phi float [ %add280, %for.body239 ], [ 0.000000e+00, %for.body221 ]
  %fix1.11021 = phi float [ %add279, %for.body239 ], [ 0.000000e+00, %for.body221 ]
  %vctot.31020 = phi float [ %add275, %for.body239 ], [ %vctot.21030, %for.body221 ]
  %arrayidx241 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv1061
  %61 = load i32* %arrayidx241, align 4, !tbaa !0
  %mul242 = mul nsw i32 %61, 3
  %idxprom243 = sext i32 %mul242 to i64
  %arrayidx244 = getelementptr inbounds float* %pos, i64 %idxprom243
  %62 = load float* %arrayidx244, align 4, !tbaa !3
  %add245 = add nsw i32 %mul242, 1
  %idxprom246 = sext i32 %add245 to i64
  %arrayidx247 = getelementptr inbounds float* %pos, i64 %idxprom246
  %63 = load float* %arrayidx247, align 4, !tbaa !3
  %add248 = add nsw i32 %mul242, 2
  %idxprom249 = sext i32 %add248 to i64
  %arrayidx250 = getelementptr inbounds float* %pos, i64 %idxprom249
  %64 = load float* %arrayidx250, align 4, !tbaa !3
  %sub251 = fsub float %add224, %62
  %sub252 = fsub float %add228, %63
  %sub253 = fsub float %add232, %64
  %mul254 = fmul float %sub251, %sub251
  %mul255 = fmul float %sub252, %sub252
  %add256 = fadd float %mul254, %mul255
  %mul257 = fmul float %sub253, %sub253
  %add258 = fadd float %add256, %mul257
  %conv259 = fpext float %add258 to double
  %call260 = tail call double @sqrt(double %conv259) #2
  %div261 = fdiv double 1.000000e+00, %call260
  %conv262 = fptrunc double %div261 to float
  %mul263 = fmul float %conv262, %conv262
  %idxprom264 = sext i32 %61 to i64
  %arrayidx265 = getelementptr inbounds float* %charge, i64 %idxprom264
  %65 = load float* %arrayidx265, align 4, !tbaa !3
  %mul266 = fmul float %mul235, %65
  %mul267 = fmul float %add258, %krf
  %add268 = fadd float %conv262, %mul267
  %sub269 = fsub float %add268, %crf
  %mul270 = fmul float %mul266, %sub269
  %mul271 = fmul float %mul267, 2.000000e+00
  %sub272 = fsub float %conv262, %mul271
  %mul273 = fmul float %mul266, %sub272
  %mul274 = fmul float %mul263, %mul273
  %add275 = fadd float %vctot.31020, %mul270
  %mul276 = fmul float %sub251, %mul274
  %mul277 = fmul float %sub252, %mul274
  %mul278 = fmul float %sub253, %mul274
  %add279 = fadd float %fix1.11021, %mul276
  %add280 = fadd float %fiy1.11022, %mul277
  %add281 = fadd float %fiz1.11023, %mul278
  %arrayidx283 = getelementptr inbounds float* %faction, i64 %idxprom243
  %66 = load float* %arrayidx283, align 4, !tbaa !3
  %sub284 = fsub float %66, %mul276
  store float %sub284, float* %arrayidx283, align 4, !tbaa !3
  %arrayidx289 = getelementptr inbounds float* %faction, i64 %idxprom246
  %67 = load float* %arrayidx289, align 4, !tbaa !3
  %sub290 = fsub float %67, %mul277
  store float %sub290, float* %arrayidx289, align 4, !tbaa !3
  %arrayidx296 = getelementptr inbounds float* %faction, i64 %idxprom249
  %68 = load float* %arrayidx296, align 4, !tbaa !3
  %sub297 = fsub float %68, %mul278
  store float %sub297, float* %arrayidx296, align 4, !tbaa !3
  %indvars.iv.next1062 = add i64 %indvars.iv1061, 1
  %69 = trunc i64 %indvars.iv.next1062 to i32
  %cmp237 = icmp slt i32 %69, %10
  br i1 %cmp237, label %for.body239, label %for.end303

for.end303:                                       ; preds = %for.body239, %for.body221
  %fiz1.1.lcssa = phi float [ 0.000000e+00, %for.body221 ], [ %add281, %for.body239 ]
  %fiy1.1.lcssa = phi float [ 0.000000e+00, %for.body221 ], [ %add280, %for.body239 ]
  %fix1.1.lcssa = phi float [ 0.000000e+00, %for.body221 ], [ %add279, %for.body239 ]
  %vctot.3.lcssa = phi float [ %vctot.21030, %for.body221 ], [ %add275, %for.body239 ]
  %arrayidx305 = getelementptr inbounds float* %faction, i64 %indvars.iv1065
  %70 = load float* %arrayidx305, align 4, !tbaa !3
  %add306 = fadd float %fix1.1.lcssa, %70
  store float %add306, float* %arrayidx305, align 4, !tbaa !3
  %arrayidx311 = getelementptr inbounds float* %faction, i64 %56
  %71 = load float* %arrayidx311, align 4, !tbaa !3
  %add312 = fadd float %fiy1.1.lcssa, %71
  store float %add312, float* %arrayidx311, align 4, !tbaa !3
  %arrayidx318 = getelementptr inbounds float* %faction, i64 %58
  %72 = load float* %arrayidx318, align 4, !tbaa !3
  %add319 = fadd float %fiz1.1.lcssa, %72
  store float %add319, float* %arrayidx318, align 4, !tbaa !3
  %73 = load float* %arrayidx324, align 4, !tbaa !3
  %add325 = fadd float %fix1.1.lcssa, %73
  store float %add325, float* %arrayidx324, align 4, !tbaa !3
  %74 = load float* %arrayidx330, align 4, !tbaa !3
  %add331 = fadd float %fiy1.1.lcssa, %74
  store float %add331, float* %arrayidx330, align 4, !tbaa !3
  %75 = load float* %arrayidx337, align 4, !tbaa !3
  %add338 = fadd float %fiz1.1.lcssa, %75
  store float %add338, float* %arrayidx337, align 4, !tbaa !3
  %indvars.iv.next1064 = add i64 %indvars.iv1063, 1
  %indvars.iv.next1066 = add i64 %indvars.iv1065, 3
  %inc345 = add nsw i32 %s.11031, 1
  %exitcond1069 = icmp eq i32 %inc345, %3
  br i1 %exitcond1069, label %for.cond218.for.cond347.loopexit_crit_edge, label %for.body221

for.cond218.for.cond347.loopexit_crit_edge:       ; preds = %for.end303
  %76 = add i32 %ii3.0.lcssa, %53
  %77 = mul i32 %2, -3
  %78 = add i32 %76, %77
  %79 = sub i32 %54, %2
  br label %for.cond347.loopexit

for.cond347.loopexit:                             ; preds = %for.cond218.for.cond347.loopexit_crit_edge, %for.cond218.loopexit
  %ii.1.lcssa = phi i32 [ %79, %for.cond218.for.cond347.loopexit_crit_edge ], [ %ii.0.lcssa, %for.cond218.loopexit ]
  %ii3.1.lcssa = phi i32 [ %78, %for.cond218.for.cond347.loopexit_crit_edge ], [ %ii3.0.lcssa, %for.cond218.loopexit ]
  %vctot.2.lcssa = phi float [ %vctot.3.lcssa, %for.cond218.for.cond347.loopexit_crit_edge ], [ %vctot.0.lcssa, %for.cond218.loopexit ]
  %cmp3481047 = icmp slt i32 %3, %1
  br i1 %cmp3481047, label %for.body350.lr.ph, label %for.end531

for.body350.lr.ph:                                ; preds = %for.cond347.loopexit
  %cmp3671037 = icmp slt i32 %9, %10
  %arrayidx509 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx515 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx522 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %80 = sext i32 %9 to i64
  %81 = sext i32 %ii.1.lcssa to i64
  %82 = sext i32 %ii3.1.lcssa to i64
  br label %for.body350

for.body350:                                      ; preds = %for.end488, %for.body350.lr.ph
  %indvars.iv1074 = phi i64 [ %82, %for.body350.lr.ph ], [ %indvars.iv.next1075, %for.end488 ]
  %indvars.iv1072 = phi i64 [ %81, %for.body350.lr.ph ], [ %indvars.iv.next1073, %for.end488 ]
  %s.21049 = phi i32 [ %3, %for.body350.lr.ph ], [ %inc530, %for.end488 ]
  %vnbtot.21048 = phi float [ %vnbtot.0.lcssa, %for.body350.lr.ph ], [ %vnbtot.3.lcssa, %for.end488 ]
  %arrayidx352 = getelementptr inbounds float* %pos, i64 %indvars.iv1074
  %83 = load float* %arrayidx352, align 4, !tbaa !3
  %add353 = fadd float %5, %83
  %84 = add nsw i64 %indvars.iv1074, 1
  %arrayidx356 = getelementptr inbounds float* %pos, i64 %84
  %85 = load float* %arrayidx356, align 4, !tbaa !3
  %add357 = fadd float %6, %85
  %86 = add nsw i64 %indvars.iv1074, 2
  %arrayidx360 = getelementptr inbounds float* %pos, i64 %86
  %87 = load float* %arrayidx360, align 4, !tbaa !3
  %add361 = fadd float %7, %87
  %arrayidx364 = getelementptr inbounds i32* %type, i64 %indvars.iv1072
  %88 = load i32* %arrayidx364, align 4, !tbaa !0
  %mul365 = mul nsw i32 %mul362, %88
  br i1 %cmp3671037, label %for.body369, label %for.end488

for.body369:                                      ; preds = %for.body350, %for.body369
  %indvars.iv1070 = phi i64 [ %indvars.iv.next1071, %for.body369 ], [ %80, %for.body350 ]
  %fiz1.21041 = phi float [ %add466, %for.body369 ], [ 0.000000e+00, %for.body350 ]
  %fiy1.21040 = phi float [ %add465, %for.body369 ], [ 0.000000e+00, %for.body350 ]
  %fix1.21039 = phi float [ %add464, %for.body369 ], [ 0.000000e+00, %for.body350 ]
  %vnbtot.31038 = phi float [ %add456, %for.body369 ], [ %vnbtot.21048, %for.body350 ]
  %arrayidx371 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv1070
  %89 = load i32* %arrayidx371, align 4, !tbaa !0
  %mul372 = mul nsw i32 %89, 3
  %idxprom373 = sext i32 %mul372 to i64
  %arrayidx374 = getelementptr inbounds float* %pos, i64 %idxprom373
  %90 = load float* %arrayidx374, align 4, !tbaa !3
  %add375 = add nsw i32 %mul372, 1
  %idxprom376 = sext i32 %add375 to i64
  %arrayidx377 = getelementptr inbounds float* %pos, i64 %idxprom376
  %91 = load float* %arrayidx377, align 4, !tbaa !3
  %add378 = add nsw i32 %mul372, 2
  %idxprom379 = sext i32 %add378 to i64
  %arrayidx380 = getelementptr inbounds float* %pos, i64 %idxprom379
  %92 = load float* %arrayidx380, align 4, !tbaa !3
  %sub381 = fsub float %add353, %90
  %sub382 = fsub float %add357, %91
  %sub383 = fsub float %add361, %92
  %mul384 = fmul float %sub381, %sub381
  %mul385 = fmul float %sub382, %sub382
  %add386 = fadd float %mul384, %mul385
  %mul387 = fmul float %sub383, %sub383
  %add388 = fadd float %add386, %mul387
  %conv389 = fpext float %add388 to double
  %call390 = tail call double @sqrt(double %conv389) #2
  %div391 = fdiv double 1.000000e+00, %call390
  %conv392 = fptrunc double %div391 to float
  %mul393 = fmul float %add388, %conv392
  %mul395 = fmul float %mul393, %tabscale
  %conv396 = fptosi float %mul395 to i32
  %conv397 = sitofp i32 %conv396 to float
  %sub398 = fsub float %mul395, %conv397
  %mul399 = fmul float %sub398, %sub398
  %mul400 = shl nsw i32 %conv396, 3
  %idxprom401 = sext i32 %89 to i64
  %arrayidx402 = getelementptr inbounds i32* %type, i64 %idxprom401
  %93 = load i32* %arrayidx402, align 4, !tbaa !0
  %mul403 = shl nsw i32 %93, 1
  %add404 = add nsw i32 %mul403, %mul365
  %idxprom405 = sext i32 %add404 to i64
  %arrayidx406 = getelementptr inbounds float* %nbfp, i64 %idxprom405
  %94 = load float* %arrayidx406, align 4, !tbaa !3
  %add407982 = or i32 %add404, 1
  %idxprom408 = sext i32 %add407982 to i64
  %arrayidx409 = getelementptr inbounds float* %nbfp, i64 %idxprom408
  %95 = load float* %arrayidx409, align 4, !tbaa !3
  %idxprom410 = sext i32 %mul400 to i64
  %arrayidx411 = getelementptr inbounds float* %VFtab, i64 %idxprom410
  %96 = load float* %arrayidx411, align 4, !tbaa !3
  %add412983 = or i32 %mul400, 1
  %idxprom413 = sext i32 %add412983 to i64
  %arrayidx414 = getelementptr inbounds float* %VFtab, i64 %idxprom413
  %97 = load float* %arrayidx414, align 4, !tbaa !3
  %add415984 = or i32 %mul400, 2
  %idxprom416 = sext i32 %add415984 to i64
  %arrayidx417 = getelementptr inbounds float* %VFtab, i64 %idxprom416
  %98 = load float* %arrayidx417, align 4, !tbaa !3
  %mul418 = fmul float %sub398, %98
  %add419985 = or i32 %mul400, 3
  %idxprom420 = sext i32 %add419985 to i64
  %arrayidx421 = getelementptr inbounds float* %VFtab, i64 %idxprom420
  %99 = load float* %arrayidx421, align 4, !tbaa !3
  %mul422 = fmul float %mul399, %99
  %add423 = fadd float %97, %mul418
  %add424 = fadd float %add423, %mul422
  %mul425 = fmul float %sub398, %add424
  %add426 = fadd float %96, %mul425
  %add427 = fadd float %mul418, %add424
  %mul428 = fmul float %mul422, 2.000000e+00
  %add429 = fadd float %mul428, %add427
  %mul430 = fmul float %94, %add426
  %mul431 = fmul float %94, %add429
  %add432986 = or i32 %mul400, 4
  %idxprom433 = sext i32 %add432986 to i64
  %arrayidx434 = getelementptr inbounds float* %VFtab, i64 %idxprom433
  %100 = load float* %arrayidx434, align 4, !tbaa !3
  %add435987 = or i32 %mul400, 5
  %idxprom436 = sext i32 %add435987 to i64
  %arrayidx437 = getelementptr inbounds float* %VFtab, i64 %idxprom436
  %101 = load float* %arrayidx437, align 4, !tbaa !3
  %add438988 = or i32 %mul400, 6
  %idxprom439 = sext i32 %add438988 to i64
  %arrayidx440 = getelementptr inbounds float* %VFtab, i64 %idxprom439
  %102 = load float* %arrayidx440, align 4, !tbaa !3
  %mul441 = fmul float %sub398, %102
  %add442989 = or i32 %mul400, 7
  %idxprom443 = sext i32 %add442989 to i64
  %arrayidx444 = getelementptr inbounds float* %VFtab, i64 %idxprom443
  %103 = load float* %arrayidx444, align 4, !tbaa !3
  %mul445 = fmul float %mul399, %103
  %add446 = fadd float %101, %mul441
  %add447 = fadd float %add446, %mul445
  %mul448 = fmul float %sub398, %add447
  %add449 = fadd float %100, %mul448
  %add450 = fadd float %mul441, %add447
  %mul451 = fmul float %mul445, 2.000000e+00
  %add452 = fadd float %mul451, %add450
  %mul453 = fmul float %95, %add449
  %mul454 = fmul float %95, %add452
  %add455 = fadd float %vnbtot.31038, %mul430
  %add456 = fadd float %add455, %mul453
  %add457 = fadd float %mul431, %mul454
  %mul458 = fmul float %add457, %tabscale
  %104 = fmul float %conv392, %mul458
  %mul460 = fsub float -0.000000e+00, %104
  %mul461 = fmul float %sub381, %mul460
  %mul462 = fmul float %sub382, %mul460
  %mul463 = fmul float %sub383, %mul460
  %add464 = fadd float %fix1.21039, %mul461
  %add465 = fadd float %fiy1.21040, %mul462
  %add466 = fadd float %fiz1.21041, %mul463
  %arrayidx468 = getelementptr inbounds float* %faction, i64 %idxprom373
  %105 = load float* %arrayidx468, align 4, !tbaa !3
  %sub469 = fsub float %105, %mul461
  store float %sub469, float* %arrayidx468, align 4, !tbaa !3
  %arrayidx474 = getelementptr inbounds float* %faction, i64 %idxprom376
  %106 = load float* %arrayidx474, align 4, !tbaa !3
  %sub475 = fsub float %106, %mul462
  store float %sub475, float* %arrayidx474, align 4, !tbaa !3
  %arrayidx481 = getelementptr inbounds float* %faction, i64 %idxprom379
  %107 = load float* %arrayidx481, align 4, !tbaa !3
  %sub482 = fsub float %107, %mul463
  store float %sub482, float* %arrayidx481, align 4, !tbaa !3
  %indvars.iv.next1071 = add i64 %indvars.iv1070, 1
  %108 = trunc i64 %indvars.iv.next1071 to i32
  %cmp367 = icmp slt i32 %108, %10
  br i1 %cmp367, label %for.body369, label %for.end488

for.end488:                                       ; preds = %for.body369, %for.body350
  %fiz1.2.lcssa = phi float [ 0.000000e+00, %for.body350 ], [ %add466, %for.body369 ]
  %fiy1.2.lcssa = phi float [ 0.000000e+00, %for.body350 ], [ %add465, %for.body369 ]
  %fix1.2.lcssa = phi float [ 0.000000e+00, %for.body350 ], [ %add464, %for.body369 ]
  %vnbtot.3.lcssa = phi float [ %vnbtot.21048, %for.body350 ], [ %add456, %for.body369 ]
  %arrayidx490 = getelementptr inbounds float* %faction, i64 %indvars.iv1074
  %109 = load float* %arrayidx490, align 4, !tbaa !3
  %add491 = fadd float %fix1.2.lcssa, %109
  store float %add491, float* %arrayidx490, align 4, !tbaa !3
  %arrayidx496 = getelementptr inbounds float* %faction, i64 %84
  %110 = load float* %arrayidx496, align 4, !tbaa !3
  %add497 = fadd float %fiy1.2.lcssa, %110
  store float %add497, float* %arrayidx496, align 4, !tbaa !3
  %arrayidx503 = getelementptr inbounds float* %faction, i64 %86
  %111 = load float* %arrayidx503, align 4, !tbaa !3
  %add504 = fadd float %fiz1.2.lcssa, %111
  store float %add504, float* %arrayidx503, align 4, !tbaa !3
  %112 = load float* %arrayidx509, align 4, !tbaa !3
  %add510 = fadd float %fix1.2.lcssa, %112
  store float %add510, float* %arrayidx509, align 4, !tbaa !3
  %113 = load float* %arrayidx515, align 4, !tbaa !3
  %add516 = fadd float %fiy1.2.lcssa, %113
  store float %add516, float* %arrayidx515, align 4, !tbaa !3
  %114 = load float* %arrayidx522, align 4, !tbaa !3
  %add523 = fadd float %fiz1.2.lcssa, %114
  store float %add523, float* %arrayidx522, align 4, !tbaa !3
  %indvars.iv.next1073 = add i64 %indvars.iv1072, 1
  %indvars.iv.next1075 = add i64 %indvars.iv1074, 3
  %inc530 = add nsw i32 %s.21049, 1
  %exitcond1078 = icmp eq i32 %inc530, %1
  br i1 %exitcond1078, label %for.end531, label %for.body350

for.end531:                                       ; preds = %for.end488, %for.cond347.loopexit
  %vnbtot.2.lcssa = phi float [ %vnbtot.0.lcssa, %for.cond347.loopexit ], [ %vnbtot.3.lcssa, %for.end488 ]
  %arrayidx533 = getelementptr inbounds i32* %gid, i64 %indvars.iv1079
  %115 = load i32* %arrayidx533, align 4, !tbaa !0
  %idxprom534 = sext i32 %115 to i64
  %arrayidx535 = getelementptr inbounds float* %Vc, i64 %idxprom534
  %116 = load float* %arrayidx535, align 4, !tbaa !3
  %add536 = fadd float %vctot.2.lcssa, %116
  store float %add536, float* %arrayidx535, align 4, !tbaa !3
  %arrayidx540 = getelementptr inbounds float* %Vnb, i64 %idxprom534
  %117 = load float* %arrayidx540, align 4, !tbaa !3
  %add541 = fadd float %vnbtot.2.lcssa, %117
  store float %add541, float* %arrayidx540, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next1080 to i32
  %exitcond1081 = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond1081, label %for.end546, label %for.body

for.end546:                                       ; preds = %for.end531, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl2320(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, float %krf, float %crf, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab) #0 {
entry:
  %0 = load i32* %iinr, align 4, !tbaa !0
  %idxprom = sext i32 %0 to i64
  %arrayidx1 = getelementptr inbounds float* %charge, i64 %idxprom
  %1 = load float* %arrayidx1, align 4, !tbaa !3
  %add = add nsw i32 %0, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds float* %charge, i64 %idxprom2
  %2 = load float* %arrayidx3, align 4, !tbaa !3
  %mul = fmul float %1, %facel
  %mul4 = fmul float %2, %facel
  %mul5 = shl i32 %ntype, 1
  %arrayidx7 = getelementptr inbounds i32* %type, i64 %idxprom
  %3 = load i32* %arrayidx7, align 4, !tbaa !0
  %mul8 = mul nsw i32 %mul5, %3
  %cmp647 = icmp sgt i32 %nri, 0
  br i1 %cmp647, label %for.body, label %for.end358

for.body:                                         ; preds = %entry, %for.end.for.body_crit_edge
  %4 = phi i32 [ %.pre, %for.end.for.body_crit_edge ], [ %0, %entry ]
  %indvars.iv649 = phi i64 [ %indvars.iv.next650, %for.end.for.body_crit_edge ], [ 0, %entry ]
  %arrayidx10 = getelementptr inbounds i32* %shift, i64 %indvars.iv649
  %5 = load i32* %arrayidx10, align 4, !tbaa !0
  %mul11 = mul nsw i32 %5, 3
  %idxprom12 = sext i32 %mul11 to i64
  %arrayidx13 = getelementptr inbounds float* %shiftvec, i64 %idxprom12
  %6 = load float* %arrayidx13, align 4, !tbaa !3
  %add14 = add nsw i32 %mul11, 1
  %idxprom15 = sext i32 %add14 to i64
  %arrayidx16 = getelementptr inbounds float* %shiftvec, i64 %idxprom15
  %7 = load float* %arrayidx16, align 4, !tbaa !3
  %add17 = add nsw i32 %mul11, 2
  %idxprom18 = sext i32 %add17 to i64
  %arrayidx19 = getelementptr inbounds float* %shiftvec, i64 %idxprom18
  %8 = load float* %arrayidx19, align 4, !tbaa !3
  %mul22 = mul nsw i32 %4, 3
  %arrayidx24 = getelementptr inbounds i32* %jindex, i64 %indvars.iv649
  %9 = load i32* %arrayidx24, align 4, !tbaa !0
  %indvars.iv.next650 = add i64 %indvars.iv649, 1
  %arrayidx27 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next650
  %10 = load i32* %arrayidx27, align 4, !tbaa !0
  %idxprom28 = sext i32 %mul22 to i64
  %arrayidx29 = getelementptr inbounds float* %pos, i64 %idxprom28
  %11 = load float* %arrayidx29, align 4, !tbaa !3
  %add30 = fadd float %6, %11
  %add31 = add nsw i32 %mul22, 1
  %idxprom32 = sext i32 %add31 to i64
  %arrayidx33 = getelementptr inbounds float* %pos, i64 %idxprom32
  %12 = load float* %arrayidx33, align 4, !tbaa !3
  %add34 = fadd float %7, %12
  %add35 = add nsw i32 %mul22, 2
  %idxprom36 = sext i32 %add35 to i64
  %arrayidx37 = getelementptr inbounds float* %pos, i64 %idxprom36
  %13 = load float* %arrayidx37, align 4, !tbaa !3
  %add38 = fadd float %8, %13
  %add39 = add nsw i32 %mul22, 3
  %idxprom40 = sext i32 %add39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %14 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = fadd float %6, %14
  %add43 = add nsw i32 %mul22, 4
  %idxprom44 = sext i32 %add43 to i64
  %arrayidx45 = getelementptr inbounds float* %pos, i64 %idxprom44
  %15 = load float* %arrayidx45, align 4, !tbaa !3
  %add46 = fadd float %7, %15
  %add47 = add nsw i32 %mul22, 5
  %idxprom48 = sext i32 %add47 to i64
  %arrayidx49 = getelementptr inbounds float* %pos, i64 %idxprom48
  %16 = load float* %arrayidx49, align 4, !tbaa !3
  %add50 = fadd float %8, %16
  %add51 = add nsw i32 %mul22, 6
  %idxprom52 = sext i32 %add51 to i64
  %arrayidx53 = getelementptr inbounds float* %pos, i64 %idxprom52
  %17 = load float* %arrayidx53, align 4, !tbaa !3
  %add54 = fadd float %6, %17
  %add55 = add nsw i32 %mul22, 7
  %idxprom56 = sext i32 %add55 to i64
  %arrayidx57 = getelementptr inbounds float* %pos, i64 %idxprom56
  %18 = load float* %arrayidx57, align 4, !tbaa !3
  %add58 = fadd float %7, %18
  %add59 = add nsw i32 %mul22, 8
  %idxprom60 = sext i32 %add59 to i64
  %arrayidx61 = getelementptr inbounds float* %pos, i64 %idxprom60
  %19 = load float* %arrayidx61, align 4, !tbaa !3
  %add62 = fadd float %8, %19
  %cmp64624 = icmp slt i32 %9, %10
  br i1 %cmp64624, label %for.body65.lr.ph, label %for.end

for.body65.lr.ph:                                 ; preds = %for.body
  %20 = sext i32 %9 to i64
  br label %for.body65

for.body65:                                       ; preds = %for.body65.lr.ph, %for.body65
  %indvars.iv = phi i64 [ %20, %for.body65.lr.ph ], [ %indvars.iv.next, %for.body65 ]
  %vctot.0635 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add240, %for.body65 ]
  %vnbtot.0634 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add172, %for.body65 ]
  %fix1.0633 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add192, %for.body65 ]
  %fiy1.0632 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add193, %for.body65 ]
  %fiz1.0631 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add194, %for.body65 ]
  %fix2.0630 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add222, %for.body65 ]
  %fiy2.0629 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add223, %for.body65 ]
  %fiz2.0628 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add224, %for.body65 ]
  %fix3.0627 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add244, %for.body65 ]
  %fiy3.0626 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add245, %for.body65 ]
  %fiz3.0625 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add246, %for.body65 ]
  %arrayidx67 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %21 = load i32* %arrayidx67, align 4, !tbaa !0
  %mul68 = mul nsw i32 %21, 3
  %idxprom69 = sext i32 %mul68 to i64
  %arrayidx70 = getelementptr inbounds float* %pos, i64 %idxprom69
  %22 = load float* %arrayidx70, align 4, !tbaa !3
  %add71 = add nsw i32 %mul68, 1
  %idxprom72 = sext i32 %add71 to i64
  %arrayidx73 = getelementptr inbounds float* %pos, i64 %idxprom72
  %23 = load float* %arrayidx73, align 4, !tbaa !3
  %add74 = add nsw i32 %mul68, 2
  %idxprom75 = sext i32 %add74 to i64
  %arrayidx76 = getelementptr inbounds float* %pos, i64 %idxprom75
  %24 = load float* %arrayidx76, align 4, !tbaa !3
  %sub = fsub float %add30, %22
  %sub77 = fsub float %add34, %23
  %sub78 = fsub float %add38, %24
  %mul79 = fmul float %sub, %sub
  %mul80 = fmul float %sub77, %sub77
  %add81 = fadd float %mul79, %mul80
  %mul82 = fmul float %sub78, %sub78
  %add83 = fadd float %add81, %mul82
  %sub84 = fsub float %add42, %22
  %sub85 = fsub float %add46, %23
  %sub86 = fsub float %add50, %24
  %mul87 = fmul float %sub84, %sub84
  %mul88 = fmul float %sub85, %sub85
  %add89 = fadd float %mul87, %mul88
  %mul90 = fmul float %sub86, %sub86
  %add91 = fadd float %add89, %mul90
  %sub92 = fsub float %add54, %22
  %sub93 = fsub float %add58, %23
  %sub94 = fsub float %add62, %24
  %mul95 = fmul float %sub92, %sub92
  %mul96 = fmul float %sub93, %sub93
  %add97 = fadd float %mul95, %mul96
  %mul98 = fmul float %sub94, %sub94
  %add99 = fadd float %add97, %mul98
  %conv = fpext float %add83 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv100 = fptrunc double %div to float
  %conv101 = fpext float %add91 to double
  %call102 = tail call double @sqrt(double %conv101) #2
  %div103 = fdiv double 1.000000e+00, %call102
  %conv104 = fptrunc double %div103 to float
  %conv105 = fpext float %add99 to double
  %call106 = tail call double @sqrt(double %conv105) #2
  %div107 = fdiv double 1.000000e+00, %call106
  %conv108 = fptrunc double %div107 to float
  %mul109 = fmul float %add83, %conv100
  %mul111 = fmul float %mul109, %tabscale
  %conv112 = fptosi float %mul111 to i32
  %conv113 = sitofp i32 %conv112 to float
  %sub114 = fsub float %mul111, %conv113
  %mul115 = fmul float %sub114, %sub114
  %mul116 = shl nsw i32 %conv112, 3
  %idxprom117 = sext i32 %21 to i64
  %arrayidx118 = getelementptr inbounds i32* %type, i64 %idxprom117
  %25 = load i32* %arrayidx118, align 4, !tbaa !0
  %mul119 = shl nsw i32 %25, 1
  %add120 = add nsw i32 %mul119, %mul8
  %idxprom121 = sext i32 %add120 to i64
  %arrayidx122 = getelementptr inbounds float* %nbfp, i64 %idxprom121
  %26 = load float* %arrayidx122, align 4, !tbaa !3
  %add123616 = or i32 %add120, 1
  %idxprom124 = sext i32 %add123616 to i64
  %arrayidx125 = getelementptr inbounds float* %nbfp, i64 %idxprom124
  %27 = load float* %arrayidx125, align 4, !tbaa !3
  %idxprom126 = sext i32 %mul116 to i64
  %arrayidx127 = getelementptr inbounds float* %VFtab, i64 %idxprom126
  %28 = load float* %arrayidx127, align 4, !tbaa !3
  %add128617 = or i32 %mul116, 1
  %idxprom129 = sext i32 %add128617 to i64
  %arrayidx130 = getelementptr inbounds float* %VFtab, i64 %idxprom129
  %29 = load float* %arrayidx130, align 4, !tbaa !3
  %add131618 = or i32 %mul116, 2
  %idxprom132 = sext i32 %add131618 to i64
  %arrayidx133 = getelementptr inbounds float* %VFtab, i64 %idxprom132
  %30 = load float* %arrayidx133, align 4, !tbaa !3
  %mul134 = fmul float %sub114, %30
  %add135619 = or i32 %mul116, 3
  %idxprom136 = sext i32 %add135619 to i64
  %arrayidx137 = getelementptr inbounds float* %VFtab, i64 %idxprom136
  %31 = load float* %arrayidx137, align 4, !tbaa !3
  %mul138 = fmul float %mul115, %31
  %add139 = fadd float %29, %mul134
  %add140 = fadd float %add139, %mul138
  %mul141 = fmul float %sub114, %add140
  %add142 = fadd float %28, %mul141
  %add143 = fadd float %mul134, %add140
  %mul144 = fmul float %mul138, 2.000000e+00
  %add145 = fadd float %mul144, %add143
  %mul146 = fmul float %26, %add142
  %mul147 = fmul float %26, %add145
  %add148620 = or i32 %mul116, 4
  %idxprom149 = sext i32 %add148620 to i64
  %arrayidx150 = getelementptr inbounds float* %VFtab, i64 %idxprom149
  %32 = load float* %arrayidx150, align 4, !tbaa !3
  %add151621 = or i32 %mul116, 5
  %idxprom152 = sext i32 %add151621 to i64
  %arrayidx153 = getelementptr inbounds float* %VFtab, i64 %idxprom152
  %33 = load float* %arrayidx153, align 4, !tbaa !3
  %add154622 = or i32 %mul116, 6
  %idxprom155 = sext i32 %add154622 to i64
  %arrayidx156 = getelementptr inbounds float* %VFtab, i64 %idxprom155
  %34 = load float* %arrayidx156, align 4, !tbaa !3
  %mul157 = fmul float %sub114, %34
  %add158623 = or i32 %mul116, 7
  %idxprom159 = sext i32 %add158623 to i64
  %arrayidx160 = getelementptr inbounds float* %VFtab, i64 %idxprom159
  %35 = load float* %arrayidx160, align 4, !tbaa !3
  %mul161 = fmul float %mul115, %35
  %add162 = fadd float %33, %mul157
  %add163 = fadd float %add162, %mul161
  %mul164 = fmul float %sub114, %add163
  %add165 = fadd float %32, %mul164
  %add166 = fadd float %mul157, %add163
  %mul167 = fmul float %mul161, 2.000000e+00
  %add168 = fadd float %mul167, %add166
  %mul169 = fmul float %27, %add165
  %mul170 = fmul float %27, %add168
  %add171 = fadd float %vnbtot.0634, %mul146
  %add172 = fadd float %add171, %mul169
  %arrayidx174 = getelementptr inbounds float* %charge, i64 %idxprom117
  %36 = load float* %arrayidx174, align 4, !tbaa !3
  %mul175 = fmul float %mul, %36
  %mul176 = fmul float %add83, %krf
  %add177 = fadd float %conv100, %mul176
  %sub178 = fsub float %add177, %crf
  %mul179 = fmul float %sub178, %mul175
  %mul180 = fmul float %mul176, 2.000000e+00
  %sub181 = fsub float %conv100, %mul180
  %mul182 = fmul float %sub181, %mul175
  %mul183 = fmul float %conv100, %mul182
  %add184 = fadd float %mul147, %mul170
  %mul185 = fmul float %add184, %tabscale
  %sub186 = fsub float %mul183, %mul185
  %mul187 = fmul float %conv100, %sub186
  %add188 = fadd float %vctot.0635, %mul179
  %mul189 = fmul float %sub, %mul187
  %mul190 = fmul float %sub77, %mul187
  %mul191 = fmul float %sub78, %mul187
  %add192 = fadd float %fix1.0633, %mul189
  %add193 = fadd float %fiy1.0632, %mul190
  %add194 = fadd float %fiz1.0631, %mul191
  %arrayidx196 = getelementptr inbounds float* %faction, i64 %idxprom69
  %37 = load float* %arrayidx196, align 4, !tbaa !3
  %sub197 = fsub float %37, %mul189
  %arrayidx200 = getelementptr inbounds float* %faction, i64 %idxprom72
  %38 = load float* %arrayidx200, align 4, !tbaa !3
  %sub201 = fsub float %38, %mul190
  %arrayidx204 = getelementptr inbounds float* %faction, i64 %idxprom75
  %39 = load float* %arrayidx204, align 4, !tbaa !3
  %sub205 = fsub float %39, %mul191
  %mul206 = fmul float %conv104, %conv104
  %mul209 = fmul float %mul4, %36
  %mul210 = fmul float %add91, %krf
  %add211 = fadd float %mul210, %conv104
  %sub212 = fsub float %add211, %crf
  %mul213 = fmul float %sub212, %mul209
  %mul214 = fmul float %mul210, 2.000000e+00
  %sub215 = fsub float %conv104, %mul214
  %mul216 = fmul float %sub215, %mul209
  %mul217 = fmul float %mul206, %mul216
  %add218 = fadd float %mul213, %add188
  %mul219 = fmul float %sub84, %mul217
  %mul220 = fmul float %sub85, %mul217
  %mul221 = fmul float %sub86, %mul217
  %add222 = fadd float %fix2.0630, %mul219
  %add223 = fadd float %fiy2.0629, %mul220
  %add224 = fadd float %fiz2.0628, %mul221
  %sub225 = fsub float %sub197, %mul219
  %sub226 = fsub float %sub201, %mul220
  %sub227 = fsub float %sub205, %mul221
  %mul228 = fmul float %conv108, %conv108
  %mul232 = fmul float %add99, %krf
  %add233 = fadd float %mul232, %conv108
  %sub234 = fsub float %add233, %crf
  %mul235 = fmul float %sub234, %mul209
  %mul236 = fmul float %mul232, 2.000000e+00
  %sub237 = fsub float %conv108, %mul236
  %mul238 = fmul float %sub237, %mul209
  %mul239 = fmul float %mul228, %mul238
  %add240 = fadd float %mul235, %add218
  %mul241 = fmul float %sub92, %mul239
  %mul242 = fmul float %sub93, %mul239
  %mul243 = fmul float %sub94, %mul239
  %add244 = fadd float %fix3.0627, %mul241
  %add245 = fadd float %fiy3.0626, %mul242
  %add246 = fadd float %fiz3.0625, %mul243
  %sub247 = fsub float %sub225, %mul241
  store float %sub247, float* %arrayidx196, align 4, !tbaa !3
  %sub250 = fsub float %sub226, %mul242
  store float %sub250, float* %arrayidx200, align 4, !tbaa !3
  %sub254 = fsub float %sub227, %mul243
  store float %sub254, float* %arrayidx204, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %40 = trunc i64 %indvars.iv.next to i32
  %cmp64 = icmp slt i32 %40, %10
  br i1 %cmp64, label %for.body65, label %for.end

for.end:                                          ; preds = %for.body65, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add240, %for.body65 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add172, %for.body65 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add192, %for.body65 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add193, %for.body65 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add194, %for.body65 ]
  %fix2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add222, %for.body65 ]
  %fiy2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add223, %for.body65 ]
  %fiz2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add224, %for.body65 ]
  %fix3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add244, %for.body65 ]
  %fiy3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add245, %for.body65 ]
  %fiz3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add246, %for.body65 ]
  %arrayidx259 = getelementptr inbounds float* %faction, i64 %idxprom28
  %41 = load float* %arrayidx259, align 4, !tbaa !3
  %add260 = fadd float %fix1.0.lcssa, %41
  store float %add260, float* %arrayidx259, align 4, !tbaa !3
  %arrayidx265 = getelementptr inbounds float* %faction, i64 %idxprom32
  %42 = load float* %arrayidx265, align 4, !tbaa !3
  %add266 = fadd float %fiy1.0.lcssa, %42
  store float %add266, float* %arrayidx265, align 4, !tbaa !3
  %arrayidx272 = getelementptr inbounds float* %faction, i64 %idxprom36
  %43 = load float* %arrayidx272, align 4, !tbaa !3
  %add273 = fadd float %fiz1.0.lcssa, %43
  store float %add273, float* %arrayidx272, align 4, !tbaa !3
  %arrayidx279 = getelementptr inbounds float* %faction, i64 %idxprom40
  %44 = load float* %arrayidx279, align 4, !tbaa !3
  %add280 = fadd float %fix2.0.lcssa, %44
  store float %add280, float* %arrayidx279, align 4, !tbaa !3
  %arrayidx286 = getelementptr inbounds float* %faction, i64 %idxprom44
  %45 = load float* %arrayidx286, align 4, !tbaa !3
  %add287 = fadd float %fiy2.0.lcssa, %45
  store float %add287, float* %arrayidx286, align 4, !tbaa !3
  %arrayidx293 = getelementptr inbounds float* %faction, i64 %idxprom48
  %46 = load float* %arrayidx293, align 4, !tbaa !3
  %add294 = fadd float %fiz2.0.lcssa, %46
  store float %add294, float* %arrayidx293, align 4, !tbaa !3
  %arrayidx300 = getelementptr inbounds float* %faction, i64 %idxprom52
  %47 = load float* %arrayidx300, align 4, !tbaa !3
  %add301 = fadd float %fix3.0.lcssa, %47
  store float %add301, float* %arrayidx300, align 4, !tbaa !3
  %arrayidx307 = getelementptr inbounds float* %faction, i64 %idxprom56
  %48 = load float* %arrayidx307, align 4, !tbaa !3
  %add308 = fadd float %fiy3.0.lcssa, %48
  store float %add308, float* %arrayidx307, align 4, !tbaa !3
  %arrayidx314 = getelementptr inbounds float* %faction, i64 %idxprom60
  %49 = load float* %arrayidx314, align 4, !tbaa !3
  %add315 = fadd float %fiz3.0.lcssa, %49
  store float %add315, float* %arrayidx314, align 4, !tbaa !3
  %arrayidx320 = getelementptr inbounds float* %fshift, i64 %idxprom12
  %50 = load float* %arrayidx320, align 4, !tbaa !3
  %add321 = fadd float %fix1.0.lcssa, %50
  %add322 = fadd float %fix2.0.lcssa, %add321
  %add323 = fadd float %fix3.0.lcssa, %add322
  store float %add323, float* %arrayidx320, align 4, !tbaa !3
  %arrayidx328 = getelementptr inbounds float* %fshift, i64 %idxprom15
  %51 = load float* %arrayidx328, align 4, !tbaa !3
  %add329 = fadd float %fiy1.0.lcssa, %51
  %add330 = fadd float %fiy2.0.lcssa, %add329
  %add331 = fadd float %fiy3.0.lcssa, %add330
  store float %add331, float* %arrayidx328, align 4, !tbaa !3
  %arrayidx337 = getelementptr inbounds float* %fshift, i64 %idxprom18
  %52 = load float* %arrayidx337, align 4, !tbaa !3
  %add338 = fadd float %fiz1.0.lcssa, %52
  %add339 = fadd float %fiz2.0.lcssa, %add338
  %add340 = fadd float %fiz3.0.lcssa, %add339
  store float %add340, float* %arrayidx337, align 4, !tbaa !3
  %arrayidx345 = getelementptr inbounds i32* %gid, i64 %indvars.iv649
  %53 = load i32* %arrayidx345, align 4, !tbaa !0
  %idxprom346 = sext i32 %53 to i64
  %arrayidx347 = getelementptr inbounds float* %Vc, i64 %idxprom346
  %54 = load float* %arrayidx347, align 4, !tbaa !3
  %add348 = fadd float %vctot.0.lcssa, %54
  store float %add348, float* %arrayidx347, align 4, !tbaa !3
  %arrayidx352 = getelementptr inbounds float* %Vnb, i64 %idxprom346
  %55 = load float* %arrayidx352, align 4, !tbaa !3
  %add353 = fadd float %vnbtot.0.lcssa, %55
  store float %add353, float* %arrayidx352, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next650 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end358, label %for.end.for.body_crit_edge

for.end.for.body_crit_edge:                       ; preds = %for.end
  %arrayidx21.phi.trans.insert = getelementptr inbounds i32* %iinr, i64 %indvars.iv.next650
  %.pre = load i32* %arrayidx21.phi.trans.insert, align 4, !tbaa !0
  br label %for.body

for.end358:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl2330(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, float %krf, float %crf, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab) #0 {
entry:
  %0 = load i32* %iinr, align 4, !tbaa !0
  %idxprom = sext i32 %0 to i64
  %arrayidx1 = getelementptr inbounds float* %charge, i64 %idxprom
  %1 = load float* %arrayidx1, align 4, !tbaa !3
  %add = add nsw i32 %0, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds float* %charge, i64 %idxprom2
  %2 = load float* %arrayidx3, align 4, !tbaa !3
  %mul = fmul float %1, %facel
  %mul4 = fmul float %1, %mul
  %mul6 = fmul float %mul, %2
  %mul7 = fmul float %2, %facel
  %mul8 = fmul float %2, %mul7
  %mul9 = shl i32 %ntype, 1
  %arrayidx11 = getelementptr inbounds i32* %type, i64 %idxprom
  %3 = load i32* %arrayidx11, align 4, !tbaa !0
  %mul12 = mul nsw i32 %mul9, %3
  %mul15 = shl nsw i32 %3, 1
  %add16 = add nsw i32 %mul12, %mul15
  %idxprom17 = sext i32 %add16 to i64
  %arrayidx18 = getelementptr inbounds float* %nbfp, i64 %idxprom17
  %4 = load float* %arrayidx18, align 4, !tbaa !3
  %add191073 = or i32 %add16, 1
  %idxprom20 = sext i32 %add191073 to i64
  %arrayidx21 = getelementptr inbounds float* %nbfp, i64 %idxprom20
  %5 = load float* %arrayidx21, align 4, !tbaa !3
  %cmp1104 = icmp sgt i32 %nri, 0
  br i1 %cmp1104, label %for.body, label %for.end593

for.body:                                         ; preds = %entry, %for.end.for.body_crit_edge
  %6 = phi i32 [ %.pre, %for.end.for.body_crit_edge ], [ %0, %entry ]
  %indvars.iv1106 = phi i64 [ %indvars.iv.next1107, %for.end.for.body_crit_edge ], [ 0, %entry ]
  %arrayidx23 = getelementptr inbounds i32* %shift, i64 %indvars.iv1106
  %7 = load i32* %arrayidx23, align 4, !tbaa !0
  %mul24 = mul nsw i32 %7, 3
  %idxprom25 = sext i32 %mul24 to i64
  %arrayidx26 = getelementptr inbounds float* %shiftvec, i64 %idxprom25
  %8 = load float* %arrayidx26, align 4, !tbaa !3
  %add27 = add nsw i32 %mul24, 1
  %idxprom28 = sext i32 %add27 to i64
  %arrayidx29 = getelementptr inbounds float* %shiftvec, i64 %idxprom28
  %9 = load float* %arrayidx29, align 4, !tbaa !3
  %add30 = add nsw i32 %mul24, 2
  %idxprom31 = sext i32 %add30 to i64
  %arrayidx32 = getelementptr inbounds float* %shiftvec, i64 %idxprom31
  %10 = load float* %arrayidx32, align 4, !tbaa !3
  %mul35 = mul nsw i32 %6, 3
  %arrayidx37 = getelementptr inbounds i32* %jindex, i64 %indvars.iv1106
  %11 = load i32* %arrayidx37, align 4, !tbaa !0
  %indvars.iv.next1107 = add i64 %indvars.iv1106, 1
  %arrayidx40 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next1107
  %12 = load i32* %arrayidx40, align 4, !tbaa !0
  %idxprom41 = sext i32 %mul35 to i64
  %arrayidx42 = getelementptr inbounds float* %pos, i64 %idxprom41
  %13 = load float* %arrayidx42, align 4, !tbaa !3
  %add43 = fadd float %8, %13
  %add44 = add nsw i32 %mul35, 1
  %idxprom45 = sext i32 %add44 to i64
  %arrayidx46 = getelementptr inbounds float* %pos, i64 %idxprom45
  %14 = load float* %arrayidx46, align 4, !tbaa !3
  %add47 = fadd float %9, %14
  %add48 = add nsw i32 %mul35, 2
  %idxprom49 = sext i32 %add48 to i64
  %arrayidx50 = getelementptr inbounds float* %pos, i64 %idxprom49
  %15 = load float* %arrayidx50, align 4, !tbaa !3
  %add51 = fadd float %10, %15
  %add52 = add nsw i32 %mul35, 3
  %idxprom53 = sext i32 %add52 to i64
  %arrayidx54 = getelementptr inbounds float* %pos, i64 %idxprom53
  %16 = load float* %arrayidx54, align 4, !tbaa !3
  %add55 = fadd float %8, %16
  %add56 = add nsw i32 %mul35, 4
  %idxprom57 = sext i32 %add56 to i64
  %arrayidx58 = getelementptr inbounds float* %pos, i64 %idxprom57
  %17 = load float* %arrayidx58, align 4, !tbaa !3
  %add59 = fadd float %9, %17
  %add60 = add nsw i32 %mul35, 5
  %idxprom61 = sext i32 %add60 to i64
  %arrayidx62 = getelementptr inbounds float* %pos, i64 %idxprom61
  %18 = load float* %arrayidx62, align 4, !tbaa !3
  %add63 = fadd float %10, %18
  %add64 = add nsw i32 %mul35, 6
  %idxprom65 = sext i32 %add64 to i64
  %arrayidx66 = getelementptr inbounds float* %pos, i64 %idxprom65
  %19 = load float* %arrayidx66, align 4, !tbaa !3
  %add67 = fadd float %8, %19
  %add68 = add nsw i32 %mul35, 7
  %idxprom69 = sext i32 %add68 to i64
  %arrayidx70 = getelementptr inbounds float* %pos, i64 %idxprom69
  %20 = load float* %arrayidx70, align 4, !tbaa !3
  %add71 = fadd float %9, %20
  %add72 = add nsw i32 %mul35, 8
  %idxprom73 = sext i32 %add72 to i64
  %arrayidx74 = getelementptr inbounds float* %pos, i64 %idxprom73
  %21 = load float* %arrayidx74, align 4, !tbaa !3
  %add75 = fadd float %10, %21
  %cmp771081 = icmp slt i32 %11, %12
  br i1 %cmp771081, label %for.body78.lr.ph, label %for.end

for.body78.lr.ph:                                 ; preds = %for.body
  %22 = sext i32 %11 to i64
  br label %for.body78

for.body78:                                       ; preds = %for.body78.lr.ph, %for.body78
  %indvars.iv = phi i64 [ %22, %for.body78.lr.ph ], [ %indvars.iv.next, %for.body78 ]
  %vctot.01092 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add474, %for.body78 ]
  %vnbtot.01091 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add266, %for.body78 ]
  %fix1.01090 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add338, %for.body78 ]
  %fiy1.01089 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add339, %for.body78 ]
  %fiz1.01088 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add340, %for.body78 ]
  %fix2.01087 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add404, %for.body78 ]
  %fiy2.01086 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add405, %for.body78 ]
  %fiz2.01085 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add406, %for.body78 ]
  %fix3.01084 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add478, %for.body78 ]
  %fiy3.01083 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add479, %for.body78 ]
  %fiz3.01082 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add480, %for.body78 ]
  %arrayidx80 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %23 = load i32* %arrayidx80, align 4, !tbaa !0
  %mul81 = mul nsw i32 %23, 3
  %idxprom82 = sext i32 %mul81 to i64
  %arrayidx83 = getelementptr inbounds float* %pos, i64 %idxprom82
  %24 = load float* %arrayidx83, align 4, !tbaa !3
  %add84 = add nsw i32 %mul81, 1
  %idxprom85 = sext i32 %add84 to i64
  %arrayidx86 = getelementptr inbounds float* %pos, i64 %idxprom85
  %25 = load float* %arrayidx86, align 4, !tbaa !3
  %add87 = add nsw i32 %mul81, 2
  %idxprom88 = sext i32 %add87 to i64
  %arrayidx89 = getelementptr inbounds float* %pos, i64 %idxprom88
  %26 = load float* %arrayidx89, align 4, !tbaa !3
  %add90 = add nsw i32 %mul81, 3
  %idxprom91 = sext i32 %add90 to i64
  %arrayidx92 = getelementptr inbounds float* %pos, i64 %idxprom91
  %27 = load float* %arrayidx92, align 4, !tbaa !3
  %add93 = add nsw i32 %mul81, 4
  %idxprom94 = sext i32 %add93 to i64
  %arrayidx95 = getelementptr inbounds float* %pos, i64 %idxprom94
  %28 = load float* %arrayidx95, align 4, !tbaa !3
  %add96 = add nsw i32 %mul81, 5
  %idxprom97 = sext i32 %add96 to i64
  %arrayidx98 = getelementptr inbounds float* %pos, i64 %idxprom97
  %29 = load float* %arrayidx98, align 4, !tbaa !3
  %add99 = add nsw i32 %mul81, 6
  %idxprom100 = sext i32 %add99 to i64
  %arrayidx101 = getelementptr inbounds float* %pos, i64 %idxprom100
  %30 = load float* %arrayidx101, align 4, !tbaa !3
  %add102 = add nsw i32 %mul81, 7
  %idxprom103 = sext i32 %add102 to i64
  %arrayidx104 = getelementptr inbounds float* %pos, i64 %idxprom103
  %31 = load float* %arrayidx104, align 4, !tbaa !3
  %add105 = add nsw i32 %mul81, 8
  %idxprom106 = sext i32 %add105 to i64
  %arrayidx107 = getelementptr inbounds float* %pos, i64 %idxprom106
  %32 = load float* %arrayidx107, align 4, !tbaa !3
  %sub = fsub float %add43, %24
  %sub108 = fsub float %add47, %25
  %sub109 = fsub float %add51, %26
  %mul110 = fmul float %sub, %sub
  %mul111 = fmul float %sub108, %sub108
  %add112 = fadd float %mul110, %mul111
  %mul113 = fmul float %sub109, %sub109
  %add114 = fadd float %add112, %mul113
  %sub115 = fsub float %add43, %27
  %sub116 = fsub float %add47, %28
  %sub117 = fsub float %add51, %29
  %mul118 = fmul float %sub115, %sub115
  %mul119 = fmul float %sub116, %sub116
  %add120 = fadd float %mul118, %mul119
  %mul121 = fmul float %sub117, %sub117
  %add122 = fadd float %add120, %mul121
  %sub123 = fsub float %add43, %30
  %sub124 = fsub float %add47, %31
  %sub125 = fsub float %add51, %32
  %mul126 = fmul float %sub123, %sub123
  %mul127 = fmul float %sub124, %sub124
  %add128 = fadd float %mul126, %mul127
  %mul129 = fmul float %sub125, %sub125
  %add130 = fadd float %add128, %mul129
  %sub131 = fsub float %add55, %24
  %sub132 = fsub float %add59, %25
  %sub133 = fsub float %add63, %26
  %mul134 = fmul float %sub131, %sub131
  %mul135 = fmul float %sub132, %sub132
  %add136 = fadd float %mul134, %mul135
  %mul137 = fmul float %sub133, %sub133
  %add138 = fadd float %add136, %mul137
  %sub139 = fsub float %add55, %27
  %sub140 = fsub float %add59, %28
  %sub141 = fsub float %add63, %29
  %mul142 = fmul float %sub139, %sub139
  %mul143 = fmul float %sub140, %sub140
  %add144 = fadd float %mul142, %mul143
  %mul145 = fmul float %sub141, %sub141
  %add146 = fadd float %add144, %mul145
  %sub147 = fsub float %add55, %30
  %sub148 = fsub float %add59, %31
  %sub149 = fsub float %add63, %32
  %mul150 = fmul float %sub147, %sub147
  %mul151 = fmul float %sub148, %sub148
  %add152 = fadd float %mul150, %mul151
  %mul153 = fmul float %sub149, %sub149
  %add154 = fadd float %add152, %mul153
  %sub155 = fsub float %add67, %24
  %sub156 = fsub float %add71, %25
  %sub157 = fsub float %add75, %26
  %mul158 = fmul float %sub155, %sub155
  %mul159 = fmul float %sub156, %sub156
  %add160 = fadd float %mul158, %mul159
  %mul161 = fmul float %sub157, %sub157
  %add162 = fadd float %add160, %mul161
  %sub163 = fsub float %add67, %27
  %sub164 = fsub float %add71, %28
  %sub165 = fsub float %add75, %29
  %mul166 = fmul float %sub163, %sub163
  %mul167 = fmul float %sub164, %sub164
  %add168 = fadd float %mul166, %mul167
  %mul169 = fmul float %sub165, %sub165
  %add170 = fadd float %add168, %mul169
  %sub171 = fsub float %add67, %30
  %sub172 = fsub float %add71, %31
  %sub173 = fsub float %add75, %32
  %mul174 = fmul float %sub171, %sub171
  %mul175 = fmul float %sub172, %sub172
  %add176 = fadd float %mul174, %mul175
  %mul177 = fmul float %sub173, %sub173
  %add178 = fadd float %add176, %mul177
  %conv = fpext float %add114 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv179 = fptrunc double %div to float
  %conv180 = fpext float %add138 to double
  %call181 = tail call double @sqrt(double %conv180) #2
  %div182 = fdiv double 1.000000e+00, %call181
  %conv183 = fptrunc double %div182 to float
  %conv184 = fpext float %add162 to double
  %call185 = tail call double @sqrt(double %conv184) #2
  %div186 = fdiv double 1.000000e+00, %call185
  %conv187 = fptrunc double %div186 to float
  %conv188 = fpext float %add122 to double
  %call189 = tail call double @sqrt(double %conv188) #2
  %div190 = fdiv double 1.000000e+00, %call189
  %conv191 = fptrunc double %div190 to float
  %conv192 = fpext float %add146 to double
  %call193 = tail call double @sqrt(double %conv192) #2
  %div194 = fdiv double 1.000000e+00, %call193
  %conv195 = fptrunc double %div194 to float
  %conv196 = fpext float %add170 to double
  %call197 = tail call double @sqrt(double %conv196) #2
  %div198 = fdiv double 1.000000e+00, %call197
  %conv199 = fptrunc double %div198 to float
  %conv200 = fpext float %add130 to double
  %call201 = tail call double @sqrt(double %conv200) #2
  %div202 = fdiv double 1.000000e+00, %call201
  %conv203 = fptrunc double %div202 to float
  %conv204 = fpext float %add154 to double
  %call205 = tail call double @sqrt(double %conv204) #2
  %div206 = fdiv double 1.000000e+00, %call205
  %conv207 = fptrunc double %div206 to float
  %conv208 = fpext float %add178 to double
  %call209 = tail call double @sqrt(double %conv208) #2
  %div210 = fdiv double 1.000000e+00, %call209
  %conv211 = fptrunc double %div210 to float
  %mul212 = fmul float %add114, %conv179
  %mul214 = fmul float %mul212, %tabscale
  %conv215 = fptosi float %mul214 to i32
  %conv216 = sitofp i32 %conv215 to float
  %sub217 = fsub float %mul214, %conv216
  %mul218 = fmul float %sub217, %sub217
  %mul219 = shl nsw i32 %conv215, 3
  %idxprom220 = sext i32 %mul219 to i64
  %arrayidx221 = getelementptr inbounds float* %VFtab, i64 %idxprom220
  %33 = load float* %arrayidx221, align 4, !tbaa !3
  %add2221074 = or i32 %mul219, 1
  %idxprom223 = sext i32 %add2221074 to i64
  %arrayidx224 = getelementptr inbounds float* %VFtab, i64 %idxprom223
  %34 = load float* %arrayidx224, align 4, !tbaa !3
  %add2251075 = or i32 %mul219, 2
  %idxprom226 = sext i32 %add2251075 to i64
  %arrayidx227 = getelementptr inbounds float* %VFtab, i64 %idxprom226
  %35 = load float* %arrayidx227, align 4, !tbaa !3
  %mul228 = fmul float %sub217, %35
  %add2291076 = or i32 %mul219, 3
  %idxprom230 = sext i32 %add2291076 to i64
  %arrayidx231 = getelementptr inbounds float* %VFtab, i64 %idxprom230
  %36 = load float* %arrayidx231, align 4, !tbaa !3
  %mul232 = fmul float %mul218, %36
  %add233 = fadd float %34, %mul228
  %add234 = fadd float %add233, %mul232
  %mul235 = fmul float %sub217, %add234
  %add236 = fadd float %33, %mul235
  %add237 = fadd float %mul228, %add234
  %mul238 = fmul float %mul232, 2.000000e+00
  %add239 = fadd float %mul238, %add237
  %mul240 = fmul float %4, %add236
  %mul241 = fmul float %4, %add239
  %add2421077 = or i32 %mul219, 4
  %idxprom243 = sext i32 %add2421077 to i64
  %arrayidx244 = getelementptr inbounds float* %VFtab, i64 %idxprom243
  %37 = load float* %arrayidx244, align 4, !tbaa !3
  %add2451078 = or i32 %mul219, 5
  %idxprom246 = sext i32 %add2451078 to i64
  %arrayidx247 = getelementptr inbounds float* %VFtab, i64 %idxprom246
  %38 = load float* %arrayidx247, align 4, !tbaa !3
  %add2481079 = or i32 %mul219, 6
  %idxprom249 = sext i32 %add2481079 to i64
  %arrayidx250 = getelementptr inbounds float* %VFtab, i64 %idxprom249
  %39 = load float* %arrayidx250, align 4, !tbaa !3
  %mul251 = fmul float %sub217, %39
  %add2521080 = or i32 %mul219, 7
  %idxprom253 = sext i32 %add2521080 to i64
  %arrayidx254 = getelementptr inbounds float* %VFtab, i64 %idxprom253
  %40 = load float* %arrayidx254, align 4, !tbaa !3
  %mul255 = fmul float %mul218, %40
  %add256 = fadd float %38, %mul251
  %add257 = fadd float %add256, %mul255
  %mul258 = fmul float %sub217, %add257
  %add259 = fadd float %37, %mul258
  %add260 = fadd float %mul251, %add257
  %mul261 = fmul float %mul255, 2.000000e+00
  %add262 = fadd float %mul261, %add260
  %mul263 = fmul float %5, %add259
  %mul264 = fmul float %5, %add262
  %add265 = fadd float %vnbtot.01091, %mul240
  %add266 = fadd float %add265, %mul263
  %mul267 = fmul float %add114, %krf
  %add268 = fadd float %mul267, %conv179
  %sub269 = fsub float %add268, %crf
  %mul270 = fmul float %mul4, %sub269
  %mul271 = fmul float %mul267, 2.000000e+00
  %sub272 = fsub float %conv179, %mul271
  %mul273 = fmul float %mul4, %sub272
  %mul274 = fmul float %conv179, %mul273
  %add275 = fadd float %mul241, %mul264
  %mul276 = fmul float %add275, %tabscale
  %sub277 = fsub float %mul274, %mul276
  %mul278 = fmul float %conv179, %sub277
  %add279 = fadd float %vctot.01092, %mul270
  %mul280 = fmul float %sub, %mul278
  %mul281 = fmul float %sub108, %mul278
  %mul282 = fmul float %sub109, %mul278
  %add283 = fadd float %fix1.01090, %mul280
  %add284 = fadd float %fiy1.01089, %mul281
  %add285 = fadd float %fiz1.01088, %mul282
  %arrayidx287 = getelementptr inbounds float* %faction, i64 %idxprom82
  %41 = load float* %arrayidx287, align 4, !tbaa !3
  %sub288 = fsub float %41, %mul280
  %arrayidx291 = getelementptr inbounds float* %faction, i64 %idxprom85
  %42 = load float* %arrayidx291, align 4, !tbaa !3
  %sub292 = fsub float %42, %mul281
  %arrayidx295 = getelementptr inbounds float* %faction, i64 %idxprom88
  %43 = load float* %arrayidx295, align 4, !tbaa !3
  %sub296 = fsub float %43, %mul282
  %mul297 = fmul float %conv191, %conv191
  %mul298 = fmul float %add122, %krf
  %add299 = fadd float %mul298, %conv191
  %sub300 = fsub float %add299, %crf
  %mul301 = fmul float %mul6, %sub300
  %mul302 = fmul float %mul298, 2.000000e+00
  %sub303 = fsub float %conv191, %mul302
  %mul304 = fmul float %mul6, %sub303
  %mul305 = fmul float %mul297, %mul304
  %add306 = fadd float %add279, %mul301
  %mul307 = fmul float %sub115, %mul305
  %mul308 = fmul float %sub116, %mul305
  %mul309 = fmul float %sub117, %mul305
  %add310 = fadd float %mul307, %add283
  %add311 = fadd float %mul308, %add284
  %add312 = fadd float %mul309, %add285
  %arrayidx315 = getelementptr inbounds float* %faction, i64 %idxprom91
  %44 = load float* %arrayidx315, align 4, !tbaa !3
  %sub316 = fsub float %44, %mul307
  %arrayidx319 = getelementptr inbounds float* %faction, i64 %idxprom94
  %45 = load float* %arrayidx319, align 4, !tbaa !3
  %sub320 = fsub float %45, %mul308
  %arrayidx323 = getelementptr inbounds float* %faction, i64 %idxprom97
  %46 = load float* %arrayidx323, align 4, !tbaa !3
  %sub324 = fsub float %46, %mul309
  %mul325 = fmul float %conv203, %conv203
  %mul326 = fmul float %add130, %krf
  %add327 = fadd float %mul326, %conv203
  %sub328 = fsub float %add327, %crf
  %mul329 = fmul float %mul6, %sub328
  %mul330 = fmul float %mul326, 2.000000e+00
  %sub331 = fsub float %conv203, %mul330
  %mul332 = fmul float %mul6, %sub331
  %mul333 = fmul float %mul325, %mul332
  %add334 = fadd float %add306, %mul329
  %mul335 = fmul float %sub123, %mul333
  %mul336 = fmul float %sub124, %mul333
  %mul337 = fmul float %sub125, %mul333
  %add338 = fadd float %mul335, %add310
  %add339 = fadd float %mul336, %add311
  %add340 = fadd float %mul337, %add312
  %arrayidx343 = getelementptr inbounds float* %faction, i64 %idxprom100
  %47 = load float* %arrayidx343, align 4, !tbaa !3
  %sub344 = fsub float %47, %mul335
  %arrayidx347 = getelementptr inbounds float* %faction, i64 %idxprom103
  %48 = load float* %arrayidx347, align 4, !tbaa !3
  %sub348 = fsub float %48, %mul336
  %arrayidx351 = getelementptr inbounds float* %faction, i64 %idxprom106
  %49 = load float* %arrayidx351, align 4, !tbaa !3
  %sub352 = fsub float %49, %mul337
  %mul353 = fmul float %conv183, %conv183
  %mul354 = fmul float %add138, %krf
  %add355 = fadd float %mul354, %conv183
  %sub356 = fsub float %add355, %crf
  %mul357 = fmul float %mul6, %sub356
  %mul358 = fmul float %mul354, 2.000000e+00
  %sub359 = fsub float %conv183, %mul358
  %mul360 = fmul float %mul6, %sub359
  %mul361 = fmul float %mul353, %mul360
  %add362 = fadd float %mul357, %add334
  %mul363 = fmul float %sub131, %mul361
  %mul364 = fmul float %sub132, %mul361
  %mul365 = fmul float %sub133, %mul361
  %add366 = fadd float %fix2.01087, %mul363
  %add367 = fadd float %fiy2.01086, %mul364
  %add368 = fadd float %fiz2.01085, %mul365
  %sub369 = fsub float %sub288, %mul363
  %sub370 = fsub float %sub292, %mul364
  %sub371 = fsub float %sub296, %mul365
  %mul372 = fmul float %conv195, %conv195
  %mul373 = fmul float %add146, %krf
  %add374 = fadd float %mul373, %conv195
  %sub375 = fsub float %add374, %crf
  %mul376 = fmul float %mul8, %sub375
  %mul377 = fmul float %mul373, 2.000000e+00
  %sub378 = fsub float %conv195, %mul377
  %mul379 = fmul float %mul8, %sub378
  %mul380 = fmul float %mul372, %mul379
  %add381 = fadd float %mul376, %add362
  %mul382 = fmul float %sub139, %mul380
  %mul383 = fmul float %sub140, %mul380
  %mul384 = fmul float %sub141, %mul380
  %add385 = fadd float %add366, %mul382
  %add386 = fadd float %add367, %mul383
  %add387 = fadd float %add368, %mul384
  %sub388 = fsub float %sub316, %mul382
  %sub389 = fsub float %sub320, %mul383
  %sub390 = fsub float %sub324, %mul384
  %mul391 = fmul float %conv207, %conv207
  %mul392 = fmul float %add154, %krf
  %add393 = fadd float %mul392, %conv207
  %sub394 = fsub float %add393, %crf
  %mul395 = fmul float %mul8, %sub394
  %mul396 = fmul float %mul392, 2.000000e+00
  %sub397 = fsub float %conv207, %mul396
  %mul398 = fmul float %mul8, %sub397
  %mul399 = fmul float %mul391, %mul398
  %add400 = fadd float %mul395, %add381
  %mul401 = fmul float %sub147, %mul399
  %mul402 = fmul float %sub148, %mul399
  %mul403 = fmul float %sub149, %mul399
  %add404 = fadd float %add385, %mul401
  %add405 = fadd float %add386, %mul402
  %add406 = fadd float %add387, %mul403
  %sub407 = fsub float %sub344, %mul401
  %sub408 = fsub float %sub348, %mul402
  %sub409 = fsub float %sub352, %mul403
  %mul410 = fmul float %conv187, %conv187
  %mul411 = fmul float %add162, %krf
  %add412 = fadd float %mul411, %conv187
  %sub413 = fsub float %add412, %crf
  %mul414 = fmul float %mul6, %sub413
  %mul415 = fmul float %mul411, 2.000000e+00
  %sub416 = fsub float %conv187, %mul415
  %mul417 = fmul float %mul6, %sub416
  %mul418 = fmul float %mul410, %mul417
  %add419 = fadd float %mul414, %add400
  %mul420 = fmul float %sub155, %mul418
  %mul421 = fmul float %sub156, %mul418
  %mul422 = fmul float %sub157, %mul418
  %add423 = fadd float %fix3.01084, %mul420
  %add424 = fadd float %fiy3.01083, %mul421
  %add425 = fadd float %fiz3.01082, %mul422
  %sub426 = fsub float %sub369, %mul420
  store float %sub426, float* %arrayidx287, align 4, !tbaa !3
  %sub429 = fsub float %sub370, %mul421
  store float %sub429, float* %arrayidx291, align 4, !tbaa !3
  %sub433 = fsub float %sub371, %mul422
  store float %sub433, float* %arrayidx295, align 4, !tbaa !3
  %mul437 = fmul float %conv199, %conv199
  %mul438 = fmul float %add170, %krf
  %add439 = fadd float %mul438, %conv199
  %sub440 = fsub float %add439, %crf
  %mul441 = fmul float %mul8, %sub440
  %mul442 = fmul float %mul438, 2.000000e+00
  %sub443 = fsub float %conv199, %mul442
  %mul444 = fmul float %mul8, %sub443
  %mul445 = fmul float %mul437, %mul444
  %add446 = fadd float %mul441, %add419
  %mul447 = fmul float %sub163, %mul445
  %mul448 = fmul float %sub164, %mul445
  %mul449 = fmul float %sub165, %mul445
  %add450 = fadd float %add423, %mul447
  %add451 = fadd float %add424, %mul448
  %add452 = fadd float %add425, %mul449
  %sub453 = fsub float %sub388, %mul447
  store float %sub453, float* %arrayidx315, align 4, !tbaa !3
  %sub457 = fsub float %sub389, %mul448
  store float %sub457, float* %arrayidx319, align 4, !tbaa !3
  %sub461 = fsub float %sub390, %mul449
  store float %sub461, float* %arrayidx323, align 4, !tbaa !3
  %mul465 = fmul float %conv211, %conv211
  %mul466 = fmul float %add178, %krf
  %add467 = fadd float %mul466, %conv211
  %sub468 = fsub float %add467, %crf
  %mul469 = fmul float %mul8, %sub468
  %mul470 = fmul float %mul466, 2.000000e+00
  %sub471 = fsub float %conv211, %mul470
  %mul472 = fmul float %mul8, %sub471
  %mul473 = fmul float %mul465, %mul472
  %add474 = fadd float %mul469, %add446
  %mul475 = fmul float %sub171, %mul473
  %mul476 = fmul float %sub172, %mul473
  %mul477 = fmul float %sub173, %mul473
  %add478 = fadd float %add450, %mul475
  %add479 = fadd float %add451, %mul476
  %add480 = fadd float %add452, %mul477
  %sub481 = fsub float %sub407, %mul475
  store float %sub481, float* %arrayidx343, align 4, !tbaa !3
  %sub485 = fsub float %sub408, %mul476
  store float %sub485, float* %arrayidx347, align 4, !tbaa !3
  %sub489 = fsub float %sub409, %mul477
  store float %sub489, float* %arrayidx351, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %50 = trunc i64 %indvars.iv.next to i32
  %cmp77 = icmp slt i32 %50, %12
  br i1 %cmp77, label %for.body78, label %for.end

for.end:                                          ; preds = %for.body78, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add474, %for.body78 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add266, %for.body78 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add338, %for.body78 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add339, %for.body78 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add340, %for.body78 ]
  %fix2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add404, %for.body78 ]
  %fiy2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add405, %for.body78 ]
  %fiz2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add406, %for.body78 ]
  %fix3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add478, %for.body78 ]
  %fiy3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add479, %for.body78 ]
  %fiz3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add480, %for.body78 ]
  %arrayidx494 = getelementptr inbounds float* %faction, i64 %idxprom41
  %51 = load float* %arrayidx494, align 4, !tbaa !3
  %add495 = fadd float %fix1.0.lcssa, %51
  store float %add495, float* %arrayidx494, align 4, !tbaa !3
  %arrayidx500 = getelementptr inbounds float* %faction, i64 %idxprom45
  %52 = load float* %arrayidx500, align 4, !tbaa !3
  %add501 = fadd float %fiy1.0.lcssa, %52
  store float %add501, float* %arrayidx500, align 4, !tbaa !3
  %arrayidx507 = getelementptr inbounds float* %faction, i64 %idxprom49
  %53 = load float* %arrayidx507, align 4, !tbaa !3
  %add508 = fadd float %fiz1.0.lcssa, %53
  store float %add508, float* %arrayidx507, align 4, !tbaa !3
  %arrayidx514 = getelementptr inbounds float* %faction, i64 %idxprom53
  %54 = load float* %arrayidx514, align 4, !tbaa !3
  %add515 = fadd float %fix2.0.lcssa, %54
  store float %add515, float* %arrayidx514, align 4, !tbaa !3
  %arrayidx521 = getelementptr inbounds float* %faction, i64 %idxprom57
  %55 = load float* %arrayidx521, align 4, !tbaa !3
  %add522 = fadd float %fiy2.0.lcssa, %55
  store float %add522, float* %arrayidx521, align 4, !tbaa !3
  %arrayidx528 = getelementptr inbounds float* %faction, i64 %idxprom61
  %56 = load float* %arrayidx528, align 4, !tbaa !3
  %add529 = fadd float %fiz2.0.lcssa, %56
  store float %add529, float* %arrayidx528, align 4, !tbaa !3
  %arrayidx535 = getelementptr inbounds float* %faction, i64 %idxprom65
  %57 = load float* %arrayidx535, align 4, !tbaa !3
  %add536 = fadd float %fix3.0.lcssa, %57
  store float %add536, float* %arrayidx535, align 4, !tbaa !3
  %arrayidx542 = getelementptr inbounds float* %faction, i64 %idxprom69
  %58 = load float* %arrayidx542, align 4, !tbaa !3
  %add543 = fadd float %fiy3.0.lcssa, %58
  store float %add543, float* %arrayidx542, align 4, !tbaa !3
  %arrayidx549 = getelementptr inbounds float* %faction, i64 %idxprom73
  %59 = load float* %arrayidx549, align 4, !tbaa !3
  %add550 = fadd float %fiz3.0.lcssa, %59
  store float %add550, float* %arrayidx549, align 4, !tbaa !3
  %arrayidx555 = getelementptr inbounds float* %fshift, i64 %idxprom25
  %60 = load float* %arrayidx555, align 4, !tbaa !3
  %add556 = fadd float %fix1.0.lcssa, %60
  %add557 = fadd float %fix2.0.lcssa, %add556
  %add558 = fadd float %fix3.0.lcssa, %add557
  store float %add558, float* %arrayidx555, align 4, !tbaa !3
  %arrayidx563 = getelementptr inbounds float* %fshift, i64 %idxprom28
  %61 = load float* %arrayidx563, align 4, !tbaa !3
  %add564 = fadd float %fiy1.0.lcssa, %61
  %add565 = fadd float %fiy2.0.lcssa, %add564
  %add566 = fadd float %fiy3.0.lcssa, %add565
  store float %add566, float* %arrayidx563, align 4, !tbaa !3
  %arrayidx572 = getelementptr inbounds float* %fshift, i64 %idxprom31
  %62 = load float* %arrayidx572, align 4, !tbaa !3
  %add573 = fadd float %fiz1.0.lcssa, %62
  %add574 = fadd float %fiz2.0.lcssa, %add573
  %add575 = fadd float %fiz3.0.lcssa, %add574
  store float %add575, float* %arrayidx572, align 4, !tbaa !3
  %arrayidx580 = getelementptr inbounds i32* %gid, i64 %indvars.iv1106
  %63 = load i32* %arrayidx580, align 4, !tbaa !0
  %idxprom581 = sext i32 %63 to i64
  %arrayidx582 = getelementptr inbounds float* %Vc, i64 %idxprom581
  %64 = load float* %arrayidx582, align 4, !tbaa !3
  %add583 = fadd float %vctot.0.lcssa, %64
  store float %add583, float* %arrayidx582, align 4, !tbaa !3
  %arrayidx587 = getelementptr inbounds float* %Vnb, i64 %idxprom581
  %65 = load float* %arrayidx587, align 4, !tbaa !3
  %add588 = fadd float %vnbtot.0.lcssa, %65
  store float %add588, float* %arrayidx587, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next1107 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end593, label %for.end.for.body_crit_edge

for.end.for.body_crit_edge:                       ; preds = %for.end
  %arrayidx34.phi.trans.insert = getelementptr inbounds i32* %iinr, i64 %indvars.iv.next1107
  %.pre = load i32* %arrayidx34.phi.trans.insert, align 4, !tbaa !0
  br label %for.body

for.end593:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl2400(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, float %krf, float %crf, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab, float %exptabscale) #0 {
entry:
  %cmp393 = icmp sgt i32 %nri, 0
  br i1 %cmp393, label %for.body, label %for.end225

for.body:                                         ; preds = %for.end, %entry
  %indvars.iv395 = phi i64 [ 0, %entry ], [ %indvars.iv.next396, %for.end ]
  %arrayidx = getelementptr inbounds i32* %shift, i64 %indvars.iv395
  %0 = load i32* %arrayidx, align 4, !tbaa !0
  %mul = mul nsw i32 %0, 3
  %idxprom1 = sext i32 %mul to i64
  %arrayidx2 = getelementptr inbounds float* %shiftvec, i64 %idxprom1
  %1 = load float* %arrayidx2, align 4, !tbaa !3
  %add = add nsw i32 %mul, 1
  %idxprom3 = sext i32 %add to i64
  %arrayidx4 = getelementptr inbounds float* %shiftvec, i64 %idxprom3
  %2 = load float* %arrayidx4, align 4, !tbaa !3
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds float* %shiftvec, i64 %idxprom6
  %3 = load float* %arrayidx7, align 4, !tbaa !3
  %arrayidx9 = getelementptr inbounds i32* %iinr, i64 %indvars.iv395
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %arrayidx12 = getelementptr inbounds i32* %jindex, i64 %indvars.iv395
  %5 = load i32* %arrayidx12, align 4, !tbaa !0
  %indvars.iv.next396 = add i64 %indvars.iv395, 1
  %arrayidx15 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next396
  %6 = load i32* %arrayidx15, align 4, !tbaa !0
  %idxprom16 = sext i32 %mul10 to i64
  %arrayidx17 = getelementptr inbounds float* %pos, i64 %idxprom16
  %7 = load float* %arrayidx17, align 4, !tbaa !3
  %add18 = fadd float %1, %7
  %add19 = add nsw i32 %mul10, 1
  %idxprom20 = sext i32 %add19 to i64
  %arrayidx21 = getelementptr inbounds float* %pos, i64 %idxprom20
  %8 = load float* %arrayidx21, align 4, !tbaa !3
  %add22 = fadd float %2, %8
  %add23 = add nsw i32 %mul10, 2
  %idxprom24 = sext i32 %add23 to i64
  %arrayidx25 = getelementptr inbounds float* %pos, i64 %idxprom24
  %9 = load float* %arrayidx25, align 4, !tbaa !3
  %add26 = fadd float %3, %9
  %idxprom27 = sext i32 %4 to i64
  %arrayidx28 = getelementptr inbounds float* %charge, i64 %idxprom27
  %10 = load float* %arrayidx28, align 4, !tbaa !3
  %mul29 = fmul float %10, %facel
  %arrayidx32 = getelementptr inbounds i32* %type, i64 %idxprom27
  %11 = load i32* %arrayidx32, align 4, !tbaa !0
  %mul33 = mul i32 %11, %ntype
  %cmp35382 = icmp slt i32 %5, %6
  br i1 %cmp35382, label %for.body36.lr.ph, label %for.end

for.body36.lr.ph:                                 ; preds = %for.body
  %12 = sext i32 %5 to i64
  br label %for.body36

for.body36:                                       ; preds = %for.body36.lr.ph, %for.body36
  %indvars.iv = phi i64 [ %12, %for.body36.lr.ph ], [ %indvars.iv.next, %for.body36 ]
  %vctot.0387 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add147, %for.body36 ]
  %vnbtot.0386 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add130, %for.body36 ]
  %fix1.0385 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add151, %for.body36 ]
  %fiy1.0384 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add152, %for.body36 ]
  %fiz1.0383 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add153, %for.body36 ]
  %arrayidx38 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %13 = load i32* %arrayidx38, align 4, !tbaa !0
  %mul39 = mul nsw i32 %13, 3
  %idxprom40 = sext i32 %mul39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %14 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = add nsw i32 %mul39, 1
  %idxprom43 = sext i32 %add42 to i64
  %arrayidx44 = getelementptr inbounds float* %pos, i64 %idxprom43
  %15 = load float* %arrayidx44, align 4, !tbaa !3
  %add45 = add nsw i32 %mul39, 2
  %idxprom46 = sext i32 %add45 to i64
  %arrayidx47 = getelementptr inbounds float* %pos, i64 %idxprom46
  %16 = load float* %arrayidx47, align 4, !tbaa !3
  %sub = fsub float %add18, %14
  %sub48 = fsub float %add22, %15
  %sub49 = fsub float %add26, %16
  %mul50 = fmul float %sub, %sub
  %mul51 = fmul float %sub48, %sub48
  %add52 = fadd float %mul50, %mul51
  %mul53 = fmul float %sub49, %sub49
  %add54 = fadd float %add52, %mul53
  %conv = fpext float %add54 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv55 = fptrunc double %div to float
  %mul56 = fmul float %add54, %conv55
  %mul58 = fmul float %mul56, %tabscale
  %conv59 = fptosi float %mul58 to i32
  %conv60 = sitofp i32 %conv59 to float
  %sub61 = fsub float %mul58, %conv60
  %mul62 = fmul float %sub61, %sub61
  %mul63 = shl nsw i32 %conv59, 3
  %idxprom64 = sext i32 %13 to i64
  %arrayidx65 = getelementptr inbounds i32* %type, i64 %idxprom64
  %17 = load i32* %arrayidx65, align 4, !tbaa !0
  %tmp = add i32 %17, %mul33
  %tmp381 = mul i32 %tmp, 3
  %idxprom68 = sext i32 %tmp381 to i64
  %arrayidx69 = getelementptr inbounds float* %nbfp, i64 %idxprom68
  %18 = load float* %arrayidx69, align 4, !tbaa !3
  %add70 = add nsw i32 %tmp381, 1
  %idxprom71 = sext i32 %add70 to i64
  %arrayidx72 = getelementptr inbounds float* %nbfp, i64 %idxprom71
  %19 = load float* %arrayidx72, align 4, !tbaa !3
  %add73 = add nsw i32 %tmp381, 2
  %idxprom74 = sext i32 %add73 to i64
  %arrayidx75 = getelementptr inbounds float* %nbfp, i64 %idxprom74
  %20 = load float* %arrayidx75, align 4, !tbaa !3
  %idxprom76 = sext i32 %mul63 to i64
  %arrayidx77 = getelementptr inbounds float* %VFtab, i64 %idxprom76
  %21 = load float* %arrayidx77, align 4, !tbaa !3
  %add78374 = or i32 %mul63, 1
  %idxprom79 = sext i32 %add78374 to i64
  %arrayidx80 = getelementptr inbounds float* %VFtab, i64 %idxprom79
  %22 = load float* %arrayidx80, align 4, !tbaa !3
  %add81375 = or i32 %mul63, 2
  %idxprom82 = sext i32 %add81375 to i64
  %arrayidx83 = getelementptr inbounds float* %VFtab, i64 %idxprom82
  %23 = load float* %arrayidx83, align 4, !tbaa !3
  %mul84 = fmul float %sub61, %23
  %add85376 = or i32 %mul63, 3
  %idxprom86 = sext i32 %add85376 to i64
  %arrayidx87 = getelementptr inbounds float* %VFtab, i64 %idxprom86
  %24 = load float* %arrayidx87, align 4, !tbaa !3
  %mul88 = fmul float %mul62, %24
  %add89 = fadd float %22, %mul84
  %add90 = fadd float %add89, %mul88
  %mul91 = fmul float %sub61, %add90
  %add92 = fadd float %21, %mul91
  %add93 = fadd float %mul84, %add90
  %mul94 = fmul float %mul88, 2.000000e+00
  %add95 = fadd float %mul94, %add93
  %mul96 = fmul float %18, %add92
  %mul97 = fmul float %18, %add95
  %mul98 = fmul float %mul56, %20
  %mul99 = fmul float %mul98, %exptabscale
  %conv100 = fptosi float %mul99 to i32
  %conv101 = sitofp i32 %conv100 to float
  %sub102 = fsub float %mul99, %conv101
  %mul103 = fmul float %sub102, %sub102
  %mul104 = shl nsw i32 %conv100, 3
  %add105377 = or i32 %mul104, 4
  %idxprom106 = sext i32 %add105377 to i64
  %arrayidx107 = getelementptr inbounds float* %VFtab, i64 %idxprom106
  %25 = load float* %arrayidx107, align 4, !tbaa !3
  %add108378 = or i32 %mul104, 5
  %idxprom109 = sext i32 %add108378 to i64
  %arrayidx110 = getelementptr inbounds float* %VFtab, i64 %idxprom109
  %26 = load float* %arrayidx110, align 4, !tbaa !3
  %add111379 = or i32 %mul104, 6
  %idxprom112 = sext i32 %add111379 to i64
  %arrayidx113 = getelementptr inbounds float* %VFtab, i64 %idxprom112
  %27 = load float* %arrayidx113, align 4, !tbaa !3
  %mul114 = fmul float %sub102, %27
  %add115380 = or i32 %mul104, 7
  %idxprom116 = sext i32 %add115380 to i64
  %arrayidx117 = getelementptr inbounds float* %VFtab, i64 %idxprom116
  %28 = load float* %arrayidx117, align 4, !tbaa !3
  %mul118 = fmul float %mul103, %28
  %add119 = fadd float %26, %mul114
  %add120 = fadd float %add119, %mul118
  %mul121 = fmul float %sub102, %add120
  %add122 = fadd float %25, %mul121
  %add123 = fadd float %mul114, %add120
  %mul124 = fmul float %mul118, 2.000000e+00
  %add125 = fadd float %mul124, %add123
  %mul126 = fmul float %19, %add122
  %mul127 = fmul float %19, %20
  %mul128 = fmul float %mul127, %add125
  %add129 = fadd float %vnbtot.0386, %mul96
  %add130 = fadd float %add129, %mul126
  %arrayidx132 = getelementptr inbounds float* %charge, i64 %idxprom64
  %29 = load float* %arrayidx132, align 4, !tbaa !3
  %mul133 = fmul float %mul29, %29
  %mul134 = fmul float %add54, %krf
  %add135 = fadd float %conv55, %mul134
  %sub136 = fsub float %add135, %crf
  %mul137 = fmul float %sub136, %mul133
  %mul138 = fmul float %mul134, 2.000000e+00
  %sub139 = fsub float %conv55, %mul138
  %mul140 = fmul float %sub139, %mul133
  %mul141 = fmul float %conv55, %mul140
  %mul142 = fmul float %mul97, %tabscale
  %mul143 = fmul float %mul128, %exptabscale
  %add144 = fadd float %mul142, %mul143
  %sub145 = fsub float %mul141, %add144
  %mul146 = fmul float %conv55, %sub145
  %add147 = fadd float %vctot.0387, %mul137
  %mul148 = fmul float %sub, %mul146
  %mul149 = fmul float %sub48, %mul146
  %mul150 = fmul float %sub49, %mul146
  %add151 = fadd float %fix1.0385, %mul148
  %add152 = fadd float %fiy1.0384, %mul149
  %add153 = fadd float %fiz1.0383, %mul150
  %arrayidx155 = getelementptr inbounds float* %faction, i64 %idxprom40
  %30 = load float* %arrayidx155, align 4, !tbaa !3
  %sub156 = fsub float %30, %mul148
  store float %sub156, float* %arrayidx155, align 4, !tbaa !3
  %arrayidx161 = getelementptr inbounds float* %faction, i64 %idxprom43
  %31 = load float* %arrayidx161, align 4, !tbaa !3
  %sub162 = fsub float %31, %mul149
  store float %sub162, float* %arrayidx161, align 4, !tbaa !3
  %arrayidx168 = getelementptr inbounds float* %faction, i64 %idxprom46
  %32 = load float* %arrayidx168, align 4, !tbaa !3
  %sub169 = fsub float %32, %mul150
  store float %sub169, float* %arrayidx168, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %33 = trunc i64 %indvars.iv.next to i32
  %cmp35 = icmp slt i32 %33, %6
  br i1 %cmp35, label %for.body36, label %for.end

for.end:                                          ; preds = %for.body36, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add147, %for.body36 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add130, %for.body36 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add151, %for.body36 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add152, %for.body36 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add153, %for.body36 ]
  %arrayidx174 = getelementptr inbounds float* %faction, i64 %idxprom16
  %34 = load float* %arrayidx174, align 4, !tbaa !3
  %add175 = fadd float %fix1.0.lcssa, %34
  store float %add175, float* %arrayidx174, align 4, !tbaa !3
  %arrayidx180 = getelementptr inbounds float* %faction, i64 %idxprom20
  %35 = load float* %arrayidx180, align 4, !tbaa !3
  %add181 = fadd float %fiy1.0.lcssa, %35
  store float %add181, float* %arrayidx180, align 4, !tbaa !3
  %arrayidx187 = getelementptr inbounds float* %faction, i64 %idxprom24
  %36 = load float* %arrayidx187, align 4, !tbaa !3
  %add188 = fadd float %fiz1.0.lcssa, %36
  store float %add188, float* %arrayidx187, align 4, !tbaa !3
  %arrayidx193 = getelementptr inbounds float* %fshift, i64 %idxprom1
  %37 = load float* %arrayidx193, align 4, !tbaa !3
  %add194 = fadd float %fix1.0.lcssa, %37
  store float %add194, float* %arrayidx193, align 4, !tbaa !3
  %arrayidx199 = getelementptr inbounds float* %fshift, i64 %idxprom3
  %38 = load float* %arrayidx199, align 4, !tbaa !3
  %add200 = fadd float %fiy1.0.lcssa, %38
  store float %add200, float* %arrayidx199, align 4, !tbaa !3
  %arrayidx206 = getelementptr inbounds float* %fshift, i64 %idxprom6
  %39 = load float* %arrayidx206, align 4, !tbaa !3
  %add207 = fadd float %fiz1.0.lcssa, %39
  store float %add207, float* %arrayidx206, align 4, !tbaa !3
  %arrayidx212 = getelementptr inbounds i32* %gid, i64 %indvars.iv395
  %40 = load i32* %arrayidx212, align 4, !tbaa !0
  %idxprom213 = sext i32 %40 to i64
  %arrayidx214 = getelementptr inbounds float* %Vc, i64 %idxprom213
  %41 = load float* %arrayidx214, align 4, !tbaa !3
  %add215 = fadd float %vctot.0.lcssa, %41
  store float %add215, float* %arrayidx214, align 4, !tbaa !3
  %arrayidx219 = getelementptr inbounds float* %Vnb, i64 %idxprom213
  %42 = load float* %arrayidx219, align 4, !tbaa !3
  %add220 = fadd float %vnbtot.0.lcssa, %42
  store float %add220, float* %arrayidx219, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next396 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end225, label %for.body

for.end225:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl2410(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, float %krf, float %crf, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab, float %exptabscale, i32* nocapture %nsatoms) #0 {
entry:
  %cmp1102 = icmp sgt i32 %nri, 0
  br i1 %cmp1102, label %for.body, label %for.end570

for.body:                                         ; preds = %for.end555, %entry
  %indvars.iv1128 = phi i64 [ 0, %entry ], [ %indvars.iv.next1129, %for.end555 ]
  %0 = trunc i64 %indvars.iv1128 to i32
  %mul = mul nsw i32 %0, 3
  %idxprom = sext i32 %mul to i64
  %arrayidx = getelementptr inbounds i32* %nsatoms, i64 %idxprom
  %1 = load i32* %arrayidx, align 4, !tbaa !0
  %add = add nsw i32 %mul, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds i32* %nsatoms, i64 %idxprom2
  %2 = load i32* %arrayidx3, align 4, !tbaa !0
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds i32* %nsatoms, i64 %idxprom6
  %3 = load i32* %arrayidx7, align 4, !tbaa !0
  %arrayidx9 = getelementptr inbounds i32* %shift, i64 %indvars.iv1128
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %idxprom11 = sext i32 %mul10 to i64
  %arrayidx12 = getelementptr inbounds float* %shiftvec, i64 %idxprom11
  %5 = load float* %arrayidx12, align 4, !tbaa !3
  %add13 = add nsw i32 %mul10, 1
  %idxprom14 = sext i32 %add13 to i64
  %arrayidx15 = getelementptr inbounds float* %shiftvec, i64 %idxprom14
  %6 = load float* %arrayidx15, align 4, !tbaa !3
  %add16 = add nsw i32 %mul10, 2
  %idxprom17 = sext i32 %add16 to i64
  %arrayidx18 = getelementptr inbounds float* %shiftvec, i64 %idxprom17
  %7 = load float* %arrayidx18, align 4, !tbaa !3
  %arrayidx20 = getelementptr inbounds i32* %iinr, i64 %indvars.iv1128
  %8 = load i32* %arrayidx20, align 4, !tbaa !0
  %mul21 = mul i32 %8, 3
  %arrayidx23 = getelementptr inbounds i32* %jindex, i64 %indvars.iv1128
  %9 = load i32* %arrayidx23, align 4, !tbaa !0
  %indvars.iv.next1129 = add i64 %indvars.iv1128, 1
  %arrayidx26 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next1129
  %10 = load i32* %arrayidx26, align 4, !tbaa !0
  %cmp281058 = icmp sgt i32 %2, 0
  br i1 %cmp281058, label %for.body29.lr.ph, label %for.cond230.loopexit

for.body29.lr.ph:                                 ; preds = %for.body
  %cmp491047 = icmp slt i32 %9, %10
  %arrayidx207 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx213 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx220 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %11 = sext i32 %9 to i64
  %12 = sext i32 %8 to i64
  %13 = sext i32 %mul21 to i64
  %14 = add i32 %2, %8
  %15 = mul i32 %14, 3
  br label %for.body29

for.body29:                                       ; preds = %for.end, %for.body29.lr.ph
  %indvars.iv1106 = phi i64 [ %13, %for.body29.lr.ph ], [ %indvars.iv.next1107, %for.end ]
  %indvars.iv1104 = phi i64 [ %12, %for.body29.lr.ph ], [ %indvars.iv.next1105, %for.end ]
  %s.01061 = phi i32 [ 0, %for.body29.lr.ph ], [ %inc228, %for.end ]
  %vnbtot.01060 = phi float [ 0.000000e+00, %for.body29.lr.ph ], [ %vnbtot.1.lcssa, %for.end ]
  %vctot.01059 = phi float [ 0.000000e+00, %for.body29.lr.ph ], [ %vctot.1.lcssa, %for.end ]
  %arrayidx31 = getelementptr inbounds float* %pos, i64 %indvars.iv1106
  %16 = load float* %arrayidx31, align 4, !tbaa !3
  %add32 = fadd float %5, %16
  %17 = add nsw i64 %indvars.iv1106, 1
  %arrayidx35 = getelementptr inbounds float* %pos, i64 %17
  %18 = load float* %arrayidx35, align 4, !tbaa !3
  %add36 = fadd float %6, %18
  %19 = add nsw i64 %indvars.iv1106, 2
  %arrayidx39 = getelementptr inbounds float* %pos, i64 %19
  %20 = load float* %arrayidx39, align 4, !tbaa !3
  %add40 = fadd float %7, %20
  %arrayidx42 = getelementptr inbounds float* %charge, i64 %indvars.iv1104
  %21 = load float* %arrayidx42, align 4, !tbaa !3
  %mul43 = fmul float %21, %facel
  %arrayidx46 = getelementptr inbounds i32* %type, i64 %indvars.iv1104
  %22 = load i32* %arrayidx46, align 4, !tbaa !0
  %mul47 = mul i32 %22, %ntype
  br i1 %cmp491047, label %for.body50, label %for.end

for.body50:                                       ; preds = %for.body29, %for.body50
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body50 ], [ %11, %for.body29 ]
  %fiz1.01052 = phi float [ %add167, %for.body50 ], [ 0.000000e+00, %for.body29 ]
  %fiy1.01051 = phi float [ %add166, %for.body50 ], [ 0.000000e+00, %for.body29 ]
  %fix1.01050 = phi float [ %add165, %for.body50 ], [ 0.000000e+00, %for.body29 ]
  %vnbtot.11049 = phi float [ %add144, %for.body50 ], [ %vnbtot.01060, %for.body29 ]
  %vctot.11048 = phi float [ %add161, %for.body50 ], [ %vctot.01059, %for.body29 ]
  %arrayidx52 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %23 = load i32* %arrayidx52, align 4, !tbaa !0
  %mul53 = mul nsw i32 %23, 3
  %idxprom54 = sext i32 %mul53 to i64
  %arrayidx55 = getelementptr inbounds float* %pos, i64 %idxprom54
  %24 = load float* %arrayidx55, align 4, !tbaa !3
  %add56 = add nsw i32 %mul53, 1
  %idxprom57 = sext i32 %add56 to i64
  %arrayidx58 = getelementptr inbounds float* %pos, i64 %idxprom57
  %25 = load float* %arrayidx58, align 4, !tbaa !3
  %add59 = add nsw i32 %mul53, 2
  %idxprom60 = sext i32 %add59 to i64
  %arrayidx61 = getelementptr inbounds float* %pos, i64 %idxprom60
  %26 = load float* %arrayidx61, align 4, !tbaa !3
  %sub = fsub float %add32, %24
  %sub62 = fsub float %add36, %25
  %sub63 = fsub float %add40, %26
  %mul64 = fmul float %sub, %sub
  %mul65 = fmul float %sub62, %sub62
  %add66 = fadd float %mul64, %mul65
  %mul67 = fmul float %sub63, %sub63
  %add68 = fadd float %add66, %mul67
  %conv = fpext float %add68 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv69 = fptrunc double %div to float
  %mul70 = fmul float %add68, %conv69
  %mul72 = fmul float %mul70, %tabscale
  %conv73 = fptosi float %mul72 to i32
  %conv74 = sitofp i32 %conv73 to float
  %sub75 = fsub float %mul72, %conv74
  %mul76 = fmul float %sub75, %sub75
  %mul77 = shl nsw i32 %conv73, 3
  %idxprom78 = sext i32 %23 to i64
  %arrayidx79 = getelementptr inbounds i32* %type, i64 %idxprom78
  %27 = load i32* %arrayidx79, align 4, !tbaa !0
  %tmp = add i32 %27, %mul47
  %tmp1044 = mul i32 %tmp, 3
  %idxprom82 = sext i32 %tmp1044 to i64
  %arrayidx83 = getelementptr inbounds float* %nbfp, i64 %idxprom82
  %28 = load float* %arrayidx83, align 4, !tbaa !3
  %add84 = add nsw i32 %tmp1044, 1
  %idxprom85 = sext i32 %add84 to i64
  %arrayidx86 = getelementptr inbounds float* %nbfp, i64 %idxprom85
  %29 = load float* %arrayidx86, align 4, !tbaa !3
  %add87 = add nsw i32 %tmp1044, 2
  %idxprom88 = sext i32 %add87 to i64
  %arrayidx89 = getelementptr inbounds float* %nbfp, i64 %idxprom88
  %30 = load float* %arrayidx89, align 4, !tbaa !3
  %idxprom90 = sext i32 %mul77 to i64
  %arrayidx91 = getelementptr inbounds float* %VFtab, i64 %idxprom90
  %31 = load float* %arrayidx91, align 4, !tbaa !3
  %add921037 = or i32 %mul77, 1
  %idxprom93 = sext i32 %add921037 to i64
  %arrayidx94 = getelementptr inbounds float* %VFtab, i64 %idxprom93
  %32 = load float* %arrayidx94, align 4, !tbaa !3
  %add951038 = or i32 %mul77, 2
  %idxprom96 = sext i32 %add951038 to i64
  %arrayidx97 = getelementptr inbounds float* %VFtab, i64 %idxprom96
  %33 = load float* %arrayidx97, align 4, !tbaa !3
  %mul98 = fmul float %sub75, %33
  %add991039 = or i32 %mul77, 3
  %idxprom100 = sext i32 %add991039 to i64
  %arrayidx101 = getelementptr inbounds float* %VFtab, i64 %idxprom100
  %34 = load float* %arrayidx101, align 4, !tbaa !3
  %mul102 = fmul float %mul76, %34
  %add103 = fadd float %32, %mul98
  %add104 = fadd float %add103, %mul102
  %mul105 = fmul float %sub75, %add104
  %add106 = fadd float %31, %mul105
  %add107 = fadd float %mul98, %add104
  %mul108 = fmul float %mul102, 2.000000e+00
  %add109 = fadd float %mul108, %add107
  %mul110 = fmul float %28, %add106
  %mul111 = fmul float %28, %add109
  %mul112 = fmul float %mul70, %30
  %mul113 = fmul float %mul112, %exptabscale
  %conv114 = fptosi float %mul113 to i32
  %conv115 = sitofp i32 %conv114 to float
  %sub116 = fsub float %mul113, %conv115
  %mul117 = fmul float %sub116, %sub116
  %mul118 = shl nsw i32 %conv114, 3
  %add1191040 = or i32 %mul118, 4
  %idxprom120 = sext i32 %add1191040 to i64
  %arrayidx121 = getelementptr inbounds float* %VFtab, i64 %idxprom120
  %35 = load float* %arrayidx121, align 4, !tbaa !3
  %add1221041 = or i32 %mul118, 5
  %idxprom123 = sext i32 %add1221041 to i64
  %arrayidx124 = getelementptr inbounds float* %VFtab, i64 %idxprom123
  %36 = load float* %arrayidx124, align 4, !tbaa !3
  %add1251042 = or i32 %mul118, 6
  %idxprom126 = sext i32 %add1251042 to i64
  %arrayidx127 = getelementptr inbounds float* %VFtab, i64 %idxprom126
  %37 = load float* %arrayidx127, align 4, !tbaa !3
  %mul128 = fmul float %sub116, %37
  %add1291043 = or i32 %mul118, 7
  %idxprom130 = sext i32 %add1291043 to i64
  %arrayidx131 = getelementptr inbounds float* %VFtab, i64 %idxprom130
  %38 = load float* %arrayidx131, align 4, !tbaa !3
  %mul132 = fmul float %mul117, %38
  %add133 = fadd float %36, %mul128
  %add134 = fadd float %add133, %mul132
  %mul135 = fmul float %sub116, %add134
  %add136 = fadd float %35, %mul135
  %add137 = fadd float %mul128, %add134
  %mul138 = fmul float %mul132, 2.000000e+00
  %add139 = fadd float %mul138, %add137
  %mul140 = fmul float %29, %add136
  %mul141 = fmul float %29, %30
  %mul142 = fmul float %mul141, %add139
  %add143 = fadd float %vnbtot.11049, %mul110
  %add144 = fadd float %add143, %mul140
  %arrayidx146 = getelementptr inbounds float* %charge, i64 %idxprom78
  %39 = load float* %arrayidx146, align 4, !tbaa !3
  %mul147 = fmul float %mul43, %39
  %mul148 = fmul float %add68, %krf
  %add149 = fadd float %conv69, %mul148
  %sub150 = fsub float %add149, %crf
  %mul151 = fmul float %sub150, %mul147
  %mul152 = fmul float %mul148, 2.000000e+00
  %sub153 = fsub float %conv69, %mul152
  %mul154 = fmul float %sub153, %mul147
  %mul155 = fmul float %conv69, %mul154
  %mul156 = fmul float %mul111, %tabscale
  %mul157 = fmul float %mul142, %exptabscale
  %add158 = fadd float %mul156, %mul157
  %sub159 = fsub float %mul155, %add158
  %mul160 = fmul float %conv69, %sub159
  %add161 = fadd float %vctot.11048, %mul151
  %mul162 = fmul float %sub, %mul160
  %mul163 = fmul float %sub62, %mul160
  %mul164 = fmul float %sub63, %mul160
  %add165 = fadd float %fix1.01050, %mul162
  %add166 = fadd float %fiy1.01051, %mul163
  %add167 = fadd float %fiz1.01052, %mul164
  %arrayidx169 = getelementptr inbounds float* %faction, i64 %idxprom54
  %40 = load float* %arrayidx169, align 4, !tbaa !3
  %sub170 = fsub float %40, %mul162
  store float %sub170, float* %arrayidx169, align 4, !tbaa !3
  %arrayidx175 = getelementptr inbounds float* %faction, i64 %idxprom57
  %41 = load float* %arrayidx175, align 4, !tbaa !3
  %sub176 = fsub float %41, %mul163
  store float %sub176, float* %arrayidx175, align 4, !tbaa !3
  %arrayidx182 = getelementptr inbounds float* %faction, i64 %idxprom60
  %42 = load float* %arrayidx182, align 4, !tbaa !3
  %sub183 = fsub float %42, %mul164
  store float %sub183, float* %arrayidx182, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %43 = trunc i64 %indvars.iv.next to i32
  %cmp49 = icmp slt i32 %43, %10
  br i1 %cmp49, label %for.body50, label %for.end

for.end:                                          ; preds = %for.body50, %for.body29
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add167, %for.body50 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add166, %for.body50 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add165, %for.body50 ]
  %vnbtot.1.lcssa = phi float [ %vnbtot.01060, %for.body29 ], [ %add144, %for.body50 ]
  %vctot.1.lcssa = phi float [ %vctot.01059, %for.body29 ], [ %add161, %for.body50 ]
  %arrayidx188 = getelementptr inbounds float* %faction, i64 %indvars.iv1106
  %44 = load float* %arrayidx188, align 4, !tbaa !3
  %add189 = fadd float %fix1.0.lcssa, %44
  store float %add189, float* %arrayidx188, align 4, !tbaa !3
  %arrayidx194 = getelementptr inbounds float* %faction, i64 %17
  %45 = load float* %arrayidx194, align 4, !tbaa !3
  %add195 = fadd float %fiy1.0.lcssa, %45
  store float %add195, float* %arrayidx194, align 4, !tbaa !3
  %arrayidx201 = getelementptr inbounds float* %faction, i64 %19
  %46 = load float* %arrayidx201, align 4, !tbaa !3
  %add202 = fadd float %fiz1.0.lcssa, %46
  store float %add202, float* %arrayidx201, align 4, !tbaa !3
  %47 = load float* %arrayidx207, align 4, !tbaa !3
  %add208 = fadd float %fix1.0.lcssa, %47
  store float %add208, float* %arrayidx207, align 4, !tbaa !3
  %48 = load float* %arrayidx213, align 4, !tbaa !3
  %add214 = fadd float %fiy1.0.lcssa, %48
  store float %add214, float* %arrayidx213, align 4, !tbaa !3
  %49 = load float* %arrayidx220, align 4, !tbaa !3
  %add221 = fadd float %fiz1.0.lcssa, %49
  store float %add221, float* %arrayidx220, align 4, !tbaa !3
  %indvars.iv.next1105 = add i64 %indvars.iv1104, 1
  %indvars.iv.next1107 = add i64 %indvars.iv1106, 3
  %inc228 = add nsw i32 %s.01061, 1
  %exitcond = icmp eq i32 %inc228, %2
  br i1 %exitcond, label %for.cond27.for.cond230.loopexit_crit_edge, label %for.body29

for.cond27.for.cond230.loopexit_crit_edge:        ; preds = %for.end
  %50 = add i32 %2, %8
  br label %for.cond230.loopexit

for.cond230.loopexit:                             ; preds = %for.cond27.for.cond230.loopexit_crit_edge, %for.body
  %ii.0.lcssa = phi i32 [ %50, %for.cond27.for.cond230.loopexit_crit_edge ], [ %8, %for.body ]
  %ii3.0.lcssa = phi i32 [ %15, %for.cond27.for.cond230.loopexit_crit_edge ], [ %mul21, %for.body ]
  %vnbtot.0.lcssa = phi float [ %vnbtot.1.lcssa, %for.cond27.for.cond230.loopexit_crit_edge ], [ 0.000000e+00, %for.body ]
  %vctot.0.lcssa = phi float [ %vctot.1.lcssa, %for.cond27.for.cond230.loopexit_crit_edge ], [ 0.000000e+00, %for.body ]
  %cmp2311078 = icmp slt i32 %2, %3
  br i1 %cmp2311078, label %for.body233.lr.ph, label %for.cond359.loopexit

for.body233.lr.ph:                                ; preds = %for.cond230.loopexit
  %cmp2491068 = icmp slt i32 %9, %10
  %arrayidx336 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx342 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx349 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %51 = sext i32 %9 to i64
  %52 = sext i32 %ii.0.lcssa to i64
  %53 = sext i32 %ii3.0.lcssa to i64
  %54 = mul i32 %3, 3
  %55 = add i32 %ii.0.lcssa, %3
  br label %for.body233

for.body233:                                      ; preds = %for.end315, %for.body233.lr.ph
  %indvars.iv1114 = phi i64 [ %53, %for.body233.lr.ph ], [ %indvars.iv.next1115, %for.end315 ]
  %indvars.iv1112 = phi i64 [ %52, %for.body233.lr.ph ], [ %indvars.iv.next1113, %for.end315 ]
  %s.11080 = phi i32 [ %2, %for.body233.lr.ph ], [ %inc357, %for.end315 ]
  %vctot.21079 = phi float [ %vctot.0.lcssa, %for.body233.lr.ph ], [ %vctot.3.lcssa, %for.end315 ]
  %arrayidx235 = getelementptr inbounds float* %pos, i64 %indvars.iv1114
  %56 = load float* %arrayidx235, align 4, !tbaa !3
  %add236 = fadd float %5, %56
  %57 = add nsw i64 %indvars.iv1114, 1
  %arrayidx239 = getelementptr inbounds float* %pos, i64 %57
  %58 = load float* %arrayidx239, align 4, !tbaa !3
  %add240 = fadd float %6, %58
  %59 = add nsw i64 %indvars.iv1114, 2
  %arrayidx243 = getelementptr inbounds float* %pos, i64 %59
  %60 = load float* %arrayidx243, align 4, !tbaa !3
  %add244 = fadd float %7, %60
  %arrayidx246 = getelementptr inbounds float* %charge, i64 %indvars.iv1112
  %61 = load float* %arrayidx246, align 4, !tbaa !3
  %mul247 = fmul float %61, %facel
  br i1 %cmp2491068, label %for.body251, label %for.end315

for.body251:                                      ; preds = %for.body233, %for.body251
  %indvars.iv1110 = phi i64 [ %indvars.iv.next1111, %for.body251 ], [ %51, %for.body233 ]
  %fiz1.11072 = phi float [ %add293, %for.body251 ], [ 0.000000e+00, %for.body233 ]
  %fiy1.11071 = phi float [ %add292, %for.body251 ], [ 0.000000e+00, %for.body233 ]
  %fix1.11070 = phi float [ %add291, %for.body251 ], [ 0.000000e+00, %for.body233 ]
  %vctot.31069 = phi float [ %add287, %for.body251 ], [ %vctot.21079, %for.body233 ]
  %arrayidx253 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv1110
  %62 = load i32* %arrayidx253, align 4, !tbaa !0
  %mul254 = mul nsw i32 %62, 3
  %idxprom255 = sext i32 %mul254 to i64
  %arrayidx256 = getelementptr inbounds float* %pos, i64 %idxprom255
  %63 = load float* %arrayidx256, align 4, !tbaa !3
  %add257 = add nsw i32 %mul254, 1
  %idxprom258 = sext i32 %add257 to i64
  %arrayidx259 = getelementptr inbounds float* %pos, i64 %idxprom258
  %64 = load float* %arrayidx259, align 4, !tbaa !3
  %add260 = add nsw i32 %mul254, 2
  %idxprom261 = sext i32 %add260 to i64
  %arrayidx262 = getelementptr inbounds float* %pos, i64 %idxprom261
  %65 = load float* %arrayidx262, align 4, !tbaa !3
  %sub263 = fsub float %add236, %63
  %sub264 = fsub float %add240, %64
  %sub265 = fsub float %add244, %65
  %mul266 = fmul float %sub263, %sub263
  %mul267 = fmul float %sub264, %sub264
  %add268 = fadd float %mul266, %mul267
  %mul269 = fmul float %sub265, %sub265
  %add270 = fadd float %add268, %mul269
  %conv271 = fpext float %add270 to double
  %call272 = tail call double @sqrt(double %conv271) #2
  %div273 = fdiv double 1.000000e+00, %call272
  %conv274 = fptrunc double %div273 to float
  %mul275 = fmul float %conv274, %conv274
  %idxprom276 = sext i32 %62 to i64
  %arrayidx277 = getelementptr inbounds float* %charge, i64 %idxprom276
  %66 = load float* %arrayidx277, align 4, !tbaa !3
  %mul278 = fmul float %mul247, %66
  %mul279 = fmul float %add270, %krf
  %add280 = fadd float %conv274, %mul279
  %sub281 = fsub float %add280, %crf
  %mul282 = fmul float %mul278, %sub281
  %mul283 = fmul float %mul279, 2.000000e+00
  %sub284 = fsub float %conv274, %mul283
  %mul285 = fmul float %mul278, %sub284
  %mul286 = fmul float %mul275, %mul285
  %add287 = fadd float %vctot.31069, %mul282
  %mul288 = fmul float %sub263, %mul286
  %mul289 = fmul float %sub264, %mul286
  %mul290 = fmul float %sub265, %mul286
  %add291 = fadd float %fix1.11070, %mul288
  %add292 = fadd float %fiy1.11071, %mul289
  %add293 = fadd float %fiz1.11072, %mul290
  %arrayidx295 = getelementptr inbounds float* %faction, i64 %idxprom255
  %67 = load float* %arrayidx295, align 4, !tbaa !3
  %sub296 = fsub float %67, %mul288
  store float %sub296, float* %arrayidx295, align 4, !tbaa !3
  %arrayidx301 = getelementptr inbounds float* %faction, i64 %idxprom258
  %68 = load float* %arrayidx301, align 4, !tbaa !3
  %sub302 = fsub float %68, %mul289
  store float %sub302, float* %arrayidx301, align 4, !tbaa !3
  %arrayidx308 = getelementptr inbounds float* %faction, i64 %idxprom261
  %69 = load float* %arrayidx308, align 4, !tbaa !3
  %sub309 = fsub float %69, %mul290
  store float %sub309, float* %arrayidx308, align 4, !tbaa !3
  %indvars.iv.next1111 = add i64 %indvars.iv1110, 1
  %70 = trunc i64 %indvars.iv.next1111 to i32
  %cmp249 = icmp slt i32 %70, %10
  br i1 %cmp249, label %for.body251, label %for.end315

for.end315:                                       ; preds = %for.body251, %for.body233
  %fiz1.1.lcssa = phi float [ 0.000000e+00, %for.body233 ], [ %add293, %for.body251 ]
  %fiy1.1.lcssa = phi float [ 0.000000e+00, %for.body233 ], [ %add292, %for.body251 ]
  %fix1.1.lcssa = phi float [ 0.000000e+00, %for.body233 ], [ %add291, %for.body251 ]
  %vctot.3.lcssa = phi float [ %vctot.21079, %for.body233 ], [ %add287, %for.body251 ]
  %arrayidx317 = getelementptr inbounds float* %faction, i64 %indvars.iv1114
  %71 = load float* %arrayidx317, align 4, !tbaa !3
  %add318 = fadd float %fix1.1.lcssa, %71
  store float %add318, float* %arrayidx317, align 4, !tbaa !3
  %arrayidx323 = getelementptr inbounds float* %faction, i64 %57
  %72 = load float* %arrayidx323, align 4, !tbaa !3
  %add324 = fadd float %fiy1.1.lcssa, %72
  store float %add324, float* %arrayidx323, align 4, !tbaa !3
  %arrayidx330 = getelementptr inbounds float* %faction, i64 %59
  %73 = load float* %arrayidx330, align 4, !tbaa !3
  %add331 = fadd float %fiz1.1.lcssa, %73
  store float %add331, float* %arrayidx330, align 4, !tbaa !3
  %74 = load float* %arrayidx336, align 4, !tbaa !3
  %add337 = fadd float %fix1.1.lcssa, %74
  store float %add337, float* %arrayidx336, align 4, !tbaa !3
  %75 = load float* %arrayidx342, align 4, !tbaa !3
  %add343 = fadd float %fiy1.1.lcssa, %75
  store float %add343, float* %arrayidx342, align 4, !tbaa !3
  %76 = load float* %arrayidx349, align 4, !tbaa !3
  %add350 = fadd float %fiz1.1.lcssa, %76
  store float %add350, float* %arrayidx349, align 4, !tbaa !3
  %indvars.iv.next1113 = add i64 %indvars.iv1112, 1
  %indvars.iv.next1115 = add i64 %indvars.iv1114, 3
  %inc357 = add nsw i32 %s.11080, 1
  %exitcond1118 = icmp eq i32 %inc357, %3
  br i1 %exitcond1118, label %for.cond230.for.cond359.loopexit_crit_edge, label %for.body233

for.cond230.for.cond359.loopexit_crit_edge:       ; preds = %for.end315
  %77 = add i32 %ii3.0.lcssa, %54
  %78 = mul i32 %2, -3
  %79 = add i32 %77, %78
  %80 = sub i32 %55, %2
  br label %for.cond359.loopexit

for.cond359.loopexit:                             ; preds = %for.cond230.for.cond359.loopexit_crit_edge, %for.cond230.loopexit
  %ii.1.lcssa = phi i32 [ %80, %for.cond230.for.cond359.loopexit_crit_edge ], [ %ii.0.lcssa, %for.cond230.loopexit ]
  %ii3.1.lcssa = phi i32 [ %79, %for.cond230.for.cond359.loopexit_crit_edge ], [ %ii3.0.lcssa, %for.cond230.loopexit ]
  %vctot.2.lcssa = phi float [ %vctot.3.lcssa, %for.cond230.for.cond359.loopexit_crit_edge ], [ %vctot.0.lcssa, %for.cond230.loopexit ]
  %cmp3601096 = icmp slt i32 %3, %1
  br i1 %cmp3601096, label %for.body362.lr.ph, label %for.end555

for.body362.lr.ph:                                ; preds = %for.cond359.loopexit
  %cmp3791086 = icmp slt i32 %9, %10
  %arrayidx533 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx539 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx546 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %81 = sext i32 %9 to i64
  %82 = sext i32 %ii.1.lcssa to i64
  %83 = sext i32 %ii3.1.lcssa to i64
  br label %for.body362

for.body362:                                      ; preds = %for.end512, %for.body362.lr.ph
  %indvars.iv1123 = phi i64 [ %83, %for.body362.lr.ph ], [ %indvars.iv.next1124, %for.end512 ]
  %indvars.iv1121 = phi i64 [ %82, %for.body362.lr.ph ], [ %indvars.iv.next1122, %for.end512 ]
  %s.21098 = phi i32 [ %3, %for.body362.lr.ph ], [ %inc554, %for.end512 ]
  %vnbtot.21097 = phi float [ %vnbtot.0.lcssa, %for.body362.lr.ph ], [ %vnbtot.3.lcssa, %for.end512 ]
  %arrayidx364 = getelementptr inbounds float* %pos, i64 %indvars.iv1123
  %84 = load float* %arrayidx364, align 4, !tbaa !3
  %add365 = fadd float %5, %84
  %85 = add nsw i64 %indvars.iv1123, 1
  %arrayidx368 = getelementptr inbounds float* %pos, i64 %85
  %86 = load float* %arrayidx368, align 4, !tbaa !3
  %add369 = fadd float %6, %86
  %87 = add nsw i64 %indvars.iv1123, 2
  %arrayidx372 = getelementptr inbounds float* %pos, i64 %87
  %88 = load float* %arrayidx372, align 4, !tbaa !3
  %add373 = fadd float %7, %88
  %arrayidx376 = getelementptr inbounds i32* %type, i64 %indvars.iv1121
  %89 = load i32* %arrayidx376, align 4, !tbaa !0
  %mul377 = mul i32 %89, %ntype
  br i1 %cmp3791086, label %for.body381, label %for.end512

for.body381:                                      ; preds = %for.body362, %for.body381
  %indvars.iv1119 = phi i64 [ %indvars.iv.next1120, %for.body381 ], [ %81, %for.body362 ]
  %fiz1.21090 = phi float [ %add490, %for.body381 ], [ 0.000000e+00, %for.body362 ]
  %fiy1.21089 = phi float [ %add489, %for.body381 ], [ 0.000000e+00, %for.body362 ]
  %fix1.21088 = phi float [ %add488, %for.body381 ], [ 0.000000e+00, %for.body362 ]
  %vnbtot.31087 = phi float [ %add479, %for.body381 ], [ %vnbtot.21097, %for.body362 ]
  %arrayidx383 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv1119
  %90 = load i32* %arrayidx383, align 4, !tbaa !0
  %mul384 = mul nsw i32 %90, 3
  %idxprom385 = sext i32 %mul384 to i64
  %arrayidx386 = getelementptr inbounds float* %pos, i64 %idxprom385
  %91 = load float* %arrayidx386, align 4, !tbaa !3
  %add387 = add nsw i32 %mul384, 1
  %idxprom388 = sext i32 %add387 to i64
  %arrayidx389 = getelementptr inbounds float* %pos, i64 %idxprom388
  %92 = load float* %arrayidx389, align 4, !tbaa !3
  %add390 = add nsw i32 %mul384, 2
  %idxprom391 = sext i32 %add390 to i64
  %arrayidx392 = getelementptr inbounds float* %pos, i64 %idxprom391
  %93 = load float* %arrayidx392, align 4, !tbaa !3
  %sub393 = fsub float %add365, %91
  %sub394 = fsub float %add369, %92
  %sub395 = fsub float %add373, %93
  %mul396 = fmul float %sub393, %sub393
  %mul397 = fmul float %sub394, %sub394
  %add398 = fadd float %mul396, %mul397
  %mul399 = fmul float %sub395, %sub395
  %add400 = fadd float %add398, %mul399
  %conv401 = fpext float %add400 to double
  %call402 = tail call double @sqrt(double %conv401) #2
  %div403 = fdiv double 1.000000e+00, %call402
  %conv404 = fptrunc double %div403 to float
  %mul405 = fmul float %add400, %conv404
  %mul407 = fmul float %mul405, %tabscale
  %conv408 = fptosi float %mul407 to i32
  %conv409 = sitofp i32 %conv408 to float
  %sub410 = fsub float %mul407, %conv409
  %mul411 = fmul float %sub410, %sub410
  %mul412 = shl nsw i32 %conv408, 3
  %idxprom413 = sext i32 %90 to i64
  %arrayidx414 = getelementptr inbounds i32* %type, i64 %idxprom413
  %94 = load i32* %arrayidx414, align 4, !tbaa !0
  %tmp1045 = add i32 %94, %mul377
  %tmp1046 = mul i32 %tmp1045, 3
  %idxprom417 = sext i32 %tmp1046 to i64
  %arrayidx418 = getelementptr inbounds float* %nbfp, i64 %idxprom417
  %95 = load float* %arrayidx418, align 4, !tbaa !3
  %add419 = add nsw i32 %tmp1046, 1
  %idxprom420 = sext i32 %add419 to i64
  %arrayidx421 = getelementptr inbounds float* %nbfp, i64 %idxprom420
  %96 = load float* %arrayidx421, align 4, !tbaa !3
  %add422 = add nsw i32 %tmp1046, 2
  %idxprom423 = sext i32 %add422 to i64
  %arrayidx424 = getelementptr inbounds float* %nbfp, i64 %idxprom423
  %97 = load float* %arrayidx424, align 4, !tbaa !3
  %idxprom425 = sext i32 %mul412 to i64
  %arrayidx426 = getelementptr inbounds float* %VFtab, i64 %idxprom425
  %98 = load float* %arrayidx426, align 4, !tbaa !3
  %add4271030 = or i32 %mul412, 1
  %idxprom428 = sext i32 %add4271030 to i64
  %arrayidx429 = getelementptr inbounds float* %VFtab, i64 %idxprom428
  %99 = load float* %arrayidx429, align 4, !tbaa !3
  %add4301031 = or i32 %mul412, 2
  %idxprom431 = sext i32 %add4301031 to i64
  %arrayidx432 = getelementptr inbounds float* %VFtab, i64 %idxprom431
  %100 = load float* %arrayidx432, align 4, !tbaa !3
  %mul433 = fmul float %sub410, %100
  %add4341032 = or i32 %mul412, 3
  %idxprom435 = sext i32 %add4341032 to i64
  %arrayidx436 = getelementptr inbounds float* %VFtab, i64 %idxprom435
  %101 = load float* %arrayidx436, align 4, !tbaa !3
  %mul437 = fmul float %mul411, %101
  %add438 = fadd float %99, %mul433
  %add439 = fadd float %add438, %mul437
  %mul440 = fmul float %sub410, %add439
  %add441 = fadd float %98, %mul440
  %add442 = fadd float %mul433, %add439
  %mul443 = fmul float %mul437, 2.000000e+00
  %add444 = fadd float %mul443, %add442
  %mul445 = fmul float %95, %add441
  %mul446 = fmul float %95, %add444
  %mul447 = fmul float %mul405, %97
  %mul448 = fmul float %mul447, %exptabscale
  %conv449 = fptosi float %mul448 to i32
  %conv450 = sitofp i32 %conv449 to float
  %sub451 = fsub float %mul448, %conv450
  %mul452 = fmul float %sub451, %sub451
  %mul453 = shl nsw i32 %conv449, 3
  %add4541033 = or i32 %mul453, 4
  %idxprom455 = sext i32 %add4541033 to i64
  %arrayidx456 = getelementptr inbounds float* %VFtab, i64 %idxprom455
  %102 = load float* %arrayidx456, align 4, !tbaa !3
  %add4571034 = or i32 %mul453, 5
  %idxprom458 = sext i32 %add4571034 to i64
  %arrayidx459 = getelementptr inbounds float* %VFtab, i64 %idxprom458
  %103 = load float* %arrayidx459, align 4, !tbaa !3
  %add4601035 = or i32 %mul453, 6
  %idxprom461 = sext i32 %add4601035 to i64
  %arrayidx462 = getelementptr inbounds float* %VFtab, i64 %idxprom461
  %104 = load float* %arrayidx462, align 4, !tbaa !3
  %mul463 = fmul float %sub451, %104
  %add4641036 = or i32 %mul453, 7
  %idxprom465 = sext i32 %add4641036 to i64
  %arrayidx466 = getelementptr inbounds float* %VFtab, i64 %idxprom465
  %105 = load float* %arrayidx466, align 4, !tbaa !3
  %mul467 = fmul float %mul452, %105
  %add468 = fadd float %103, %mul463
  %add469 = fadd float %add468, %mul467
  %mul470 = fmul float %sub451, %add469
  %add471 = fadd float %102, %mul470
  %add472 = fadd float %mul463, %add469
  %mul473 = fmul float %mul467, 2.000000e+00
  %add474 = fadd float %mul473, %add472
  %mul475 = fmul float %96, %add471
  %mul476 = fmul float %96, %97
  %mul477 = fmul float %mul476, %add474
  %add478 = fadd float %vnbtot.31087, %mul445
  %add479 = fadd float %add478, %mul475
  %mul480 = fmul float %mul446, %tabscale
  %mul481 = fmul float %mul477, %exptabscale
  %add482 = fadd float %mul480, %mul481
  %106 = fmul float %conv404, %add482
  %mul484 = fsub float -0.000000e+00, %106
  %mul485 = fmul float %sub393, %mul484
  %mul486 = fmul float %sub394, %mul484
  %mul487 = fmul float %sub395, %mul484
  %add488 = fadd float %fix1.21088, %mul485
  %add489 = fadd float %fiy1.21089, %mul486
  %add490 = fadd float %fiz1.21090, %mul487
  %arrayidx492 = getelementptr inbounds float* %faction, i64 %idxprom385
  %107 = load float* %arrayidx492, align 4, !tbaa !3
  %sub493 = fsub float %107, %mul485
  store float %sub493, float* %arrayidx492, align 4, !tbaa !3
  %arrayidx498 = getelementptr inbounds float* %faction, i64 %idxprom388
  %108 = load float* %arrayidx498, align 4, !tbaa !3
  %sub499 = fsub float %108, %mul486
  store float %sub499, float* %arrayidx498, align 4, !tbaa !3
  %arrayidx505 = getelementptr inbounds float* %faction, i64 %idxprom391
  %109 = load float* %arrayidx505, align 4, !tbaa !3
  %sub506 = fsub float %109, %mul487
  store float %sub506, float* %arrayidx505, align 4, !tbaa !3
  %indvars.iv.next1120 = add i64 %indvars.iv1119, 1
  %110 = trunc i64 %indvars.iv.next1120 to i32
  %cmp379 = icmp slt i32 %110, %10
  br i1 %cmp379, label %for.body381, label %for.end512

for.end512:                                       ; preds = %for.body381, %for.body362
  %fiz1.2.lcssa = phi float [ 0.000000e+00, %for.body362 ], [ %add490, %for.body381 ]
  %fiy1.2.lcssa = phi float [ 0.000000e+00, %for.body362 ], [ %add489, %for.body381 ]
  %fix1.2.lcssa = phi float [ 0.000000e+00, %for.body362 ], [ %add488, %for.body381 ]
  %vnbtot.3.lcssa = phi float [ %vnbtot.21097, %for.body362 ], [ %add479, %for.body381 ]
  %arrayidx514 = getelementptr inbounds float* %faction, i64 %indvars.iv1123
  %111 = load float* %arrayidx514, align 4, !tbaa !3
  %add515 = fadd float %fix1.2.lcssa, %111
  store float %add515, float* %arrayidx514, align 4, !tbaa !3
  %arrayidx520 = getelementptr inbounds float* %faction, i64 %85
  %112 = load float* %arrayidx520, align 4, !tbaa !3
  %add521 = fadd float %fiy1.2.lcssa, %112
  store float %add521, float* %arrayidx520, align 4, !tbaa !3
  %arrayidx527 = getelementptr inbounds float* %faction, i64 %87
  %113 = load float* %arrayidx527, align 4, !tbaa !3
  %add528 = fadd float %fiz1.2.lcssa, %113
  store float %add528, float* %arrayidx527, align 4, !tbaa !3
  %114 = load float* %arrayidx533, align 4, !tbaa !3
  %add534 = fadd float %fix1.2.lcssa, %114
  store float %add534, float* %arrayidx533, align 4, !tbaa !3
  %115 = load float* %arrayidx539, align 4, !tbaa !3
  %add540 = fadd float %fiy1.2.lcssa, %115
  store float %add540, float* %arrayidx539, align 4, !tbaa !3
  %116 = load float* %arrayidx546, align 4, !tbaa !3
  %add547 = fadd float %fiz1.2.lcssa, %116
  store float %add547, float* %arrayidx546, align 4, !tbaa !3
  %indvars.iv.next1122 = add i64 %indvars.iv1121, 1
  %indvars.iv.next1124 = add i64 %indvars.iv1123, 3
  %inc554 = add nsw i32 %s.21098, 1
  %exitcond1127 = icmp eq i32 %inc554, %1
  br i1 %exitcond1127, label %for.end555, label %for.body362

for.end555:                                       ; preds = %for.end512, %for.cond359.loopexit
  %vnbtot.2.lcssa = phi float [ %vnbtot.0.lcssa, %for.cond359.loopexit ], [ %vnbtot.3.lcssa, %for.end512 ]
  %arrayidx557 = getelementptr inbounds i32* %gid, i64 %indvars.iv1128
  %117 = load i32* %arrayidx557, align 4, !tbaa !0
  %idxprom558 = sext i32 %117 to i64
  %arrayidx559 = getelementptr inbounds float* %Vc, i64 %idxprom558
  %118 = load float* %arrayidx559, align 4, !tbaa !3
  %add560 = fadd float %vctot.2.lcssa, %118
  store float %add560, float* %arrayidx559, align 4, !tbaa !3
  %arrayidx564 = getelementptr inbounds float* %Vnb, i64 %idxprom558
  %119 = load float* %arrayidx564, align 4, !tbaa !3
  %add565 = fadd float %vnbtot.2.lcssa, %119
  store float %add565, float* %arrayidx564, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next1129 to i32
  %exitcond1130 = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond1130, label %for.end570, label %for.body

for.end570:                                       ; preds = %for.end555, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl2420(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, float %krf, float %crf, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab, float %exptabscale) #0 {
entry:
  %0 = load i32* %iinr, align 4, !tbaa !0
  %idxprom = sext i32 %0 to i64
  %arrayidx1 = getelementptr inbounds float* %charge, i64 %idxprom
  %1 = load float* %arrayidx1, align 4, !tbaa !3
  %add = add nsw i32 %0, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds float* %charge, i64 %idxprom2
  %2 = load float* %arrayidx3, align 4, !tbaa !3
  %mul = fmul float %1, %facel
  %mul4 = fmul float %2, %facel
  %arrayidx7 = getelementptr inbounds i32* %type, i64 %idxprom
  %3 = load i32* %arrayidx7, align 4, !tbaa !0
  %mul8 = mul i32 %3, %ntype
  %cmp670 = icmp sgt i32 %nri, 0
  br i1 %cmp670, label %for.body, label %for.end370

for.body:                                         ; preds = %entry, %for.end.for.body_crit_edge
  %4 = phi i32 [ %.pre, %for.end.for.body_crit_edge ], [ %0, %entry ]
  %indvars.iv672 = phi i64 [ %indvars.iv.next673, %for.end.for.body_crit_edge ], [ 0, %entry ]
  %arrayidx10 = getelementptr inbounds i32* %shift, i64 %indvars.iv672
  %5 = load i32* %arrayidx10, align 4, !tbaa !0
  %mul11 = mul nsw i32 %5, 3
  %idxprom12 = sext i32 %mul11 to i64
  %arrayidx13 = getelementptr inbounds float* %shiftvec, i64 %idxprom12
  %6 = load float* %arrayidx13, align 4, !tbaa !3
  %add14 = add nsw i32 %mul11, 1
  %idxprom15 = sext i32 %add14 to i64
  %arrayidx16 = getelementptr inbounds float* %shiftvec, i64 %idxprom15
  %7 = load float* %arrayidx16, align 4, !tbaa !3
  %add17 = add nsw i32 %mul11, 2
  %idxprom18 = sext i32 %add17 to i64
  %arrayidx19 = getelementptr inbounds float* %shiftvec, i64 %idxprom18
  %8 = load float* %arrayidx19, align 4, !tbaa !3
  %mul22 = mul nsw i32 %4, 3
  %arrayidx24 = getelementptr inbounds i32* %jindex, i64 %indvars.iv672
  %9 = load i32* %arrayidx24, align 4, !tbaa !0
  %indvars.iv.next673 = add i64 %indvars.iv672, 1
  %arrayidx27 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next673
  %10 = load i32* %arrayidx27, align 4, !tbaa !0
  %idxprom28 = sext i32 %mul22 to i64
  %arrayidx29 = getelementptr inbounds float* %pos, i64 %idxprom28
  %11 = load float* %arrayidx29, align 4, !tbaa !3
  %add30 = fadd float %6, %11
  %add31 = add nsw i32 %mul22, 1
  %idxprom32 = sext i32 %add31 to i64
  %arrayidx33 = getelementptr inbounds float* %pos, i64 %idxprom32
  %12 = load float* %arrayidx33, align 4, !tbaa !3
  %add34 = fadd float %7, %12
  %add35 = add nsw i32 %mul22, 2
  %idxprom36 = sext i32 %add35 to i64
  %arrayidx37 = getelementptr inbounds float* %pos, i64 %idxprom36
  %13 = load float* %arrayidx37, align 4, !tbaa !3
  %add38 = fadd float %8, %13
  %add39 = add nsw i32 %mul22, 3
  %idxprom40 = sext i32 %add39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %14 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = fadd float %6, %14
  %add43 = add nsw i32 %mul22, 4
  %idxprom44 = sext i32 %add43 to i64
  %arrayidx45 = getelementptr inbounds float* %pos, i64 %idxprom44
  %15 = load float* %arrayidx45, align 4, !tbaa !3
  %add46 = fadd float %7, %15
  %add47 = add nsw i32 %mul22, 5
  %idxprom48 = sext i32 %add47 to i64
  %arrayidx49 = getelementptr inbounds float* %pos, i64 %idxprom48
  %16 = load float* %arrayidx49, align 4, !tbaa !3
  %add50 = fadd float %8, %16
  %add51 = add nsw i32 %mul22, 6
  %idxprom52 = sext i32 %add51 to i64
  %arrayidx53 = getelementptr inbounds float* %pos, i64 %idxprom52
  %17 = load float* %arrayidx53, align 4, !tbaa !3
  %add54 = fadd float %6, %17
  %add55 = add nsw i32 %mul22, 7
  %idxprom56 = sext i32 %add55 to i64
  %arrayidx57 = getelementptr inbounds float* %pos, i64 %idxprom56
  %18 = load float* %arrayidx57, align 4, !tbaa !3
  %add58 = fadd float %7, %18
  %add59 = add nsw i32 %mul22, 8
  %idxprom60 = sext i32 %add59 to i64
  %arrayidx61 = getelementptr inbounds float* %pos, i64 %idxprom60
  %19 = load float* %arrayidx61, align 4, !tbaa !3
  %add62 = fadd float %8, %19
  %cmp64647 = icmp slt i32 %9, %10
  br i1 %cmp64647, label %for.body65.lr.ph, label %for.end

for.body65.lr.ph:                                 ; preds = %for.body
  %20 = sext i32 %9 to i64
  br label %for.body65

for.body65:                                       ; preds = %for.body65.lr.ph, %for.body65
  %indvars.iv = phi i64 [ %20, %for.body65.lr.ph ], [ %indvars.iv.next, %for.body65 ]
  %vctot.0658 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add252, %for.body65 ]
  %vnbtot.0657 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add183, %for.body65 ]
  %fix1.0656 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add204, %for.body65 ]
  %fiy1.0655 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add205, %for.body65 ]
  %fiz1.0654 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add206, %for.body65 ]
  %fix2.0653 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add234, %for.body65 ]
  %fiy2.0652 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add235, %for.body65 ]
  %fiz2.0651 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add236, %for.body65 ]
  %fix3.0650 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add256, %for.body65 ]
  %fiy3.0649 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add257, %for.body65 ]
  %fiz3.0648 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add258, %for.body65 ]
  %arrayidx67 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %21 = load i32* %arrayidx67, align 4, !tbaa !0
  %mul68 = mul nsw i32 %21, 3
  %idxprom69 = sext i32 %mul68 to i64
  %arrayidx70 = getelementptr inbounds float* %pos, i64 %idxprom69
  %22 = load float* %arrayidx70, align 4, !tbaa !3
  %add71 = add nsw i32 %mul68, 1
  %idxprom72 = sext i32 %add71 to i64
  %arrayidx73 = getelementptr inbounds float* %pos, i64 %idxprom72
  %23 = load float* %arrayidx73, align 4, !tbaa !3
  %add74 = add nsw i32 %mul68, 2
  %idxprom75 = sext i32 %add74 to i64
  %arrayidx76 = getelementptr inbounds float* %pos, i64 %idxprom75
  %24 = load float* %arrayidx76, align 4, !tbaa !3
  %sub = fsub float %add30, %22
  %sub77 = fsub float %add34, %23
  %sub78 = fsub float %add38, %24
  %mul79 = fmul float %sub, %sub
  %mul80 = fmul float %sub77, %sub77
  %add81 = fadd float %mul79, %mul80
  %mul82 = fmul float %sub78, %sub78
  %add83 = fadd float %add81, %mul82
  %sub84 = fsub float %add42, %22
  %sub85 = fsub float %add46, %23
  %sub86 = fsub float %add50, %24
  %mul87 = fmul float %sub84, %sub84
  %mul88 = fmul float %sub85, %sub85
  %add89 = fadd float %mul87, %mul88
  %mul90 = fmul float %sub86, %sub86
  %add91 = fadd float %add89, %mul90
  %sub92 = fsub float %add54, %22
  %sub93 = fsub float %add58, %23
  %sub94 = fsub float %add62, %24
  %mul95 = fmul float %sub92, %sub92
  %mul96 = fmul float %sub93, %sub93
  %add97 = fadd float %mul95, %mul96
  %mul98 = fmul float %sub94, %sub94
  %add99 = fadd float %add97, %mul98
  %conv = fpext float %add83 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv100 = fptrunc double %div to float
  %conv101 = fpext float %add91 to double
  %call102 = tail call double @sqrt(double %conv101) #2
  %div103 = fdiv double 1.000000e+00, %call102
  %conv104 = fptrunc double %div103 to float
  %conv105 = fpext float %add99 to double
  %call106 = tail call double @sqrt(double %conv105) #2
  %div107 = fdiv double 1.000000e+00, %call106
  %conv108 = fptrunc double %div107 to float
  %mul109 = fmul float %add83, %conv100
  %mul111 = fmul float %mul109, %tabscale
  %conv112 = fptosi float %mul111 to i32
  %conv113 = sitofp i32 %conv112 to float
  %sub114 = fsub float %mul111, %conv113
  %mul115 = fmul float %sub114, %sub114
  %mul116 = shl nsw i32 %conv112, 3
  %idxprom117 = sext i32 %21 to i64
  %arrayidx118 = getelementptr inbounds i32* %type, i64 %idxprom117
  %25 = load i32* %arrayidx118, align 4, !tbaa !0
  %tmp = add i32 %25, %mul8
  %tmp646 = mul i32 %tmp, 3
  %idxprom121 = sext i32 %tmp646 to i64
  %arrayidx122 = getelementptr inbounds float* %nbfp, i64 %idxprom121
  %26 = load float* %arrayidx122, align 4, !tbaa !3
  %add123 = add nsw i32 %tmp646, 1
  %idxprom124 = sext i32 %add123 to i64
  %arrayidx125 = getelementptr inbounds float* %nbfp, i64 %idxprom124
  %27 = load float* %arrayidx125, align 4, !tbaa !3
  %add126 = add nsw i32 %tmp646, 2
  %idxprom127 = sext i32 %add126 to i64
  %arrayidx128 = getelementptr inbounds float* %nbfp, i64 %idxprom127
  %28 = load float* %arrayidx128, align 4, !tbaa !3
  %idxprom129 = sext i32 %mul116 to i64
  %arrayidx130 = getelementptr inbounds float* %VFtab, i64 %idxprom129
  %29 = load float* %arrayidx130, align 4, !tbaa !3
  %add131639 = or i32 %mul116, 1
  %idxprom132 = sext i32 %add131639 to i64
  %arrayidx133 = getelementptr inbounds float* %VFtab, i64 %idxprom132
  %30 = load float* %arrayidx133, align 4, !tbaa !3
  %add134640 = or i32 %mul116, 2
  %idxprom135 = sext i32 %add134640 to i64
  %arrayidx136 = getelementptr inbounds float* %VFtab, i64 %idxprom135
  %31 = load float* %arrayidx136, align 4, !tbaa !3
  %mul137 = fmul float %sub114, %31
  %add138641 = or i32 %mul116, 3
  %idxprom139 = sext i32 %add138641 to i64
  %arrayidx140 = getelementptr inbounds float* %VFtab, i64 %idxprom139
  %32 = load float* %arrayidx140, align 4, !tbaa !3
  %mul141 = fmul float %mul115, %32
  %add142 = fadd float %30, %mul137
  %add143 = fadd float %add142, %mul141
  %mul144 = fmul float %sub114, %add143
  %add145 = fadd float %29, %mul144
  %add146 = fadd float %mul137, %add143
  %mul147 = fmul float %mul141, 2.000000e+00
  %add148 = fadd float %mul147, %add146
  %mul149 = fmul float %26, %add145
  %mul150 = fmul float %26, %add148
  %mul151 = fmul float %mul109, %28
  %mul152 = fmul float %mul151, %exptabscale
  %conv153 = fptosi float %mul152 to i32
  %conv154 = sitofp i32 %conv153 to float
  %sub155 = fsub float %mul152, %conv154
  %mul156 = fmul float %sub155, %sub155
  %mul157 = shl nsw i32 %conv153, 3
  %add158642 = or i32 %mul157, 4
  %idxprom159 = sext i32 %add158642 to i64
  %arrayidx160 = getelementptr inbounds float* %VFtab, i64 %idxprom159
  %33 = load float* %arrayidx160, align 4, !tbaa !3
  %add161643 = or i32 %mul157, 5
  %idxprom162 = sext i32 %add161643 to i64
  %arrayidx163 = getelementptr inbounds float* %VFtab, i64 %idxprom162
  %34 = load float* %arrayidx163, align 4, !tbaa !3
  %add164644 = or i32 %mul157, 6
  %idxprom165 = sext i32 %add164644 to i64
  %arrayidx166 = getelementptr inbounds float* %VFtab, i64 %idxprom165
  %35 = load float* %arrayidx166, align 4, !tbaa !3
  %mul167 = fmul float %sub155, %35
  %add168645 = or i32 %mul157, 7
  %idxprom169 = sext i32 %add168645 to i64
  %arrayidx170 = getelementptr inbounds float* %VFtab, i64 %idxprom169
  %36 = load float* %arrayidx170, align 4, !tbaa !3
  %mul171 = fmul float %mul156, %36
  %add172 = fadd float %34, %mul167
  %add173 = fadd float %add172, %mul171
  %mul174 = fmul float %sub155, %add173
  %add175 = fadd float %33, %mul174
  %add176 = fadd float %mul167, %add173
  %mul177 = fmul float %mul171, 2.000000e+00
  %add178 = fadd float %mul177, %add176
  %mul179 = fmul float %27, %add175
  %mul180 = fmul float %27, %28
  %mul181 = fmul float %mul180, %add178
  %add182 = fadd float %vnbtot.0657, %mul149
  %add183 = fadd float %add182, %mul179
  %arrayidx185 = getelementptr inbounds float* %charge, i64 %idxprom117
  %37 = load float* %arrayidx185, align 4, !tbaa !3
  %mul186 = fmul float %mul, %37
  %mul187 = fmul float %add83, %krf
  %add188 = fadd float %conv100, %mul187
  %sub189 = fsub float %add188, %crf
  %mul190 = fmul float %sub189, %mul186
  %mul191 = fmul float %mul187, 2.000000e+00
  %sub192 = fsub float %conv100, %mul191
  %mul193 = fmul float %sub192, %mul186
  %mul194 = fmul float %conv100, %mul193
  %mul195 = fmul float %mul150, %tabscale
  %mul196 = fmul float %mul181, %exptabscale
  %add197 = fadd float %mul195, %mul196
  %sub198 = fsub float %mul194, %add197
  %mul199 = fmul float %conv100, %sub198
  %add200 = fadd float %vctot.0658, %mul190
  %mul201 = fmul float %sub, %mul199
  %mul202 = fmul float %sub77, %mul199
  %mul203 = fmul float %sub78, %mul199
  %add204 = fadd float %fix1.0656, %mul201
  %add205 = fadd float %fiy1.0655, %mul202
  %add206 = fadd float %fiz1.0654, %mul203
  %arrayidx208 = getelementptr inbounds float* %faction, i64 %idxprom69
  %38 = load float* %arrayidx208, align 4, !tbaa !3
  %sub209 = fsub float %38, %mul201
  %arrayidx212 = getelementptr inbounds float* %faction, i64 %idxprom72
  %39 = load float* %arrayidx212, align 4, !tbaa !3
  %sub213 = fsub float %39, %mul202
  %arrayidx216 = getelementptr inbounds float* %faction, i64 %idxprom75
  %40 = load float* %arrayidx216, align 4, !tbaa !3
  %sub217 = fsub float %40, %mul203
  %mul218 = fmul float %conv104, %conv104
  %mul221 = fmul float %mul4, %37
  %mul222 = fmul float %add91, %krf
  %add223 = fadd float %mul222, %conv104
  %sub224 = fsub float %add223, %crf
  %mul225 = fmul float %sub224, %mul221
  %mul226 = fmul float %mul222, 2.000000e+00
  %sub227 = fsub float %conv104, %mul226
  %mul228 = fmul float %sub227, %mul221
  %mul229 = fmul float %mul218, %mul228
  %add230 = fadd float %mul225, %add200
  %mul231 = fmul float %sub84, %mul229
  %mul232 = fmul float %sub85, %mul229
  %mul233 = fmul float %sub86, %mul229
  %add234 = fadd float %fix2.0653, %mul231
  %add235 = fadd float %fiy2.0652, %mul232
  %add236 = fadd float %fiz2.0651, %mul233
  %sub237 = fsub float %sub209, %mul231
  %sub238 = fsub float %sub213, %mul232
  %sub239 = fsub float %sub217, %mul233
  %mul240 = fmul float %conv108, %conv108
  %mul244 = fmul float %add99, %krf
  %add245 = fadd float %mul244, %conv108
  %sub246 = fsub float %add245, %crf
  %mul247 = fmul float %sub246, %mul221
  %mul248 = fmul float %mul244, 2.000000e+00
  %sub249 = fsub float %conv108, %mul248
  %mul250 = fmul float %sub249, %mul221
  %mul251 = fmul float %mul240, %mul250
  %add252 = fadd float %mul247, %add230
  %mul253 = fmul float %sub92, %mul251
  %mul254 = fmul float %sub93, %mul251
  %mul255 = fmul float %sub94, %mul251
  %add256 = fadd float %fix3.0650, %mul253
  %add257 = fadd float %fiy3.0649, %mul254
  %add258 = fadd float %fiz3.0648, %mul255
  %sub259 = fsub float %sub237, %mul253
  store float %sub259, float* %arrayidx208, align 4, !tbaa !3
  %sub262 = fsub float %sub238, %mul254
  store float %sub262, float* %arrayidx212, align 4, !tbaa !3
  %sub266 = fsub float %sub239, %mul255
  store float %sub266, float* %arrayidx216, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %41 = trunc i64 %indvars.iv.next to i32
  %cmp64 = icmp slt i32 %41, %10
  br i1 %cmp64, label %for.body65, label %for.end

for.end:                                          ; preds = %for.body65, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add252, %for.body65 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add183, %for.body65 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add204, %for.body65 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add205, %for.body65 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add206, %for.body65 ]
  %fix2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add234, %for.body65 ]
  %fiy2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add235, %for.body65 ]
  %fiz2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add236, %for.body65 ]
  %fix3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add256, %for.body65 ]
  %fiy3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add257, %for.body65 ]
  %fiz3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add258, %for.body65 ]
  %arrayidx271 = getelementptr inbounds float* %faction, i64 %idxprom28
  %42 = load float* %arrayidx271, align 4, !tbaa !3
  %add272 = fadd float %fix1.0.lcssa, %42
  store float %add272, float* %arrayidx271, align 4, !tbaa !3
  %arrayidx277 = getelementptr inbounds float* %faction, i64 %idxprom32
  %43 = load float* %arrayidx277, align 4, !tbaa !3
  %add278 = fadd float %fiy1.0.lcssa, %43
  store float %add278, float* %arrayidx277, align 4, !tbaa !3
  %arrayidx284 = getelementptr inbounds float* %faction, i64 %idxprom36
  %44 = load float* %arrayidx284, align 4, !tbaa !3
  %add285 = fadd float %fiz1.0.lcssa, %44
  store float %add285, float* %arrayidx284, align 4, !tbaa !3
  %arrayidx291 = getelementptr inbounds float* %faction, i64 %idxprom40
  %45 = load float* %arrayidx291, align 4, !tbaa !3
  %add292 = fadd float %fix2.0.lcssa, %45
  store float %add292, float* %arrayidx291, align 4, !tbaa !3
  %arrayidx298 = getelementptr inbounds float* %faction, i64 %idxprom44
  %46 = load float* %arrayidx298, align 4, !tbaa !3
  %add299 = fadd float %fiy2.0.lcssa, %46
  store float %add299, float* %arrayidx298, align 4, !tbaa !3
  %arrayidx305 = getelementptr inbounds float* %faction, i64 %idxprom48
  %47 = load float* %arrayidx305, align 4, !tbaa !3
  %add306 = fadd float %fiz2.0.lcssa, %47
  store float %add306, float* %arrayidx305, align 4, !tbaa !3
  %arrayidx312 = getelementptr inbounds float* %faction, i64 %idxprom52
  %48 = load float* %arrayidx312, align 4, !tbaa !3
  %add313 = fadd float %fix3.0.lcssa, %48
  store float %add313, float* %arrayidx312, align 4, !tbaa !3
  %arrayidx319 = getelementptr inbounds float* %faction, i64 %idxprom56
  %49 = load float* %arrayidx319, align 4, !tbaa !3
  %add320 = fadd float %fiy3.0.lcssa, %49
  store float %add320, float* %arrayidx319, align 4, !tbaa !3
  %arrayidx326 = getelementptr inbounds float* %faction, i64 %idxprom60
  %50 = load float* %arrayidx326, align 4, !tbaa !3
  %add327 = fadd float %fiz3.0.lcssa, %50
  store float %add327, float* %arrayidx326, align 4, !tbaa !3
  %arrayidx332 = getelementptr inbounds float* %fshift, i64 %idxprom12
  %51 = load float* %arrayidx332, align 4, !tbaa !3
  %add333 = fadd float %fix1.0.lcssa, %51
  %add334 = fadd float %fix2.0.lcssa, %add333
  %add335 = fadd float %fix3.0.lcssa, %add334
  store float %add335, float* %arrayidx332, align 4, !tbaa !3
  %arrayidx340 = getelementptr inbounds float* %fshift, i64 %idxprom15
  %52 = load float* %arrayidx340, align 4, !tbaa !3
  %add341 = fadd float %fiy1.0.lcssa, %52
  %add342 = fadd float %fiy2.0.lcssa, %add341
  %add343 = fadd float %fiy3.0.lcssa, %add342
  store float %add343, float* %arrayidx340, align 4, !tbaa !3
  %arrayidx349 = getelementptr inbounds float* %fshift, i64 %idxprom18
  %53 = load float* %arrayidx349, align 4, !tbaa !3
  %add350 = fadd float %fiz1.0.lcssa, %53
  %add351 = fadd float %fiz2.0.lcssa, %add350
  %add352 = fadd float %fiz3.0.lcssa, %add351
  store float %add352, float* %arrayidx349, align 4, !tbaa !3
  %arrayidx357 = getelementptr inbounds i32* %gid, i64 %indvars.iv672
  %54 = load i32* %arrayidx357, align 4, !tbaa !0
  %idxprom358 = sext i32 %54 to i64
  %arrayidx359 = getelementptr inbounds float* %Vc, i64 %idxprom358
  %55 = load float* %arrayidx359, align 4, !tbaa !3
  %add360 = fadd float %vctot.0.lcssa, %55
  store float %add360, float* %arrayidx359, align 4, !tbaa !3
  %arrayidx364 = getelementptr inbounds float* %Vnb, i64 %idxprom358
  %56 = load float* %arrayidx364, align 4, !tbaa !3
  %add365 = fadd float %vnbtot.0.lcssa, %56
  store float %add365, float* %arrayidx364, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next673 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end370, label %for.end.for.body_crit_edge

for.end.for.body_crit_edge:                       ; preds = %for.end
  %arrayidx21.phi.trans.insert = getelementptr inbounds i32* %iinr, i64 %indvars.iv.next673
  %.pre = load i32* %arrayidx21.phi.trans.insert, align 4, !tbaa !0
  br label %for.body

for.end370:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl2430(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, float %krf, float %crf, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab, float %exptabscale) #0 {
entry:
  %0 = load i32* %iinr, align 4, !tbaa !0
  %idxprom = sext i32 %0 to i64
  %arrayidx1 = getelementptr inbounds float* %charge, i64 %idxprom
  %1 = load float* %arrayidx1, align 4, !tbaa !3
  %add = add nsw i32 %0, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds float* %charge, i64 %idxprom2
  %2 = load float* %arrayidx3, align 4, !tbaa !3
  %mul = fmul float %1, %facel
  %mul4 = fmul float %1, %mul
  %mul6 = fmul float %mul, %2
  %mul7 = fmul float %2, %facel
  %mul8 = fmul float %2, %mul7
  %mul9 = mul nsw i32 %ntype, 3
  %arrayidx11 = getelementptr inbounds i32* %type, i64 %idxprom
  %3 = load i32* %arrayidx11, align 4, !tbaa !0
  %mul121096 = add i32 %mul9, 3
  %add16 = mul i32 %3, %mul121096
  %idxprom17 = sext i32 %add16 to i64
  %arrayidx18 = getelementptr inbounds float* %nbfp, i64 %idxprom17
  %4 = load float* %arrayidx18, align 4, !tbaa !3
  %add19 = add nsw i32 %add16, 1
  %idxprom20 = sext i32 %add19 to i64
  %arrayidx21 = getelementptr inbounds float* %nbfp, i64 %idxprom20
  %5 = load float* %arrayidx21, align 4, !tbaa !3
  %add22 = add nsw i32 %add16, 2
  %idxprom23 = sext i32 %add22 to i64
  %arrayidx24 = getelementptr inbounds float* %nbfp, i64 %idxprom23
  %6 = load float* %arrayidx24, align 4, !tbaa !3
  %cmp1127 = icmp sgt i32 %nri, 0
  br i1 %cmp1127, label %for.body.lr.ph, label %for.end605

for.body.lr.ph:                                   ; preds = %entry
  %mul274 = fmul float %5, %6
  br label %for.body

for.body:                                         ; preds = %for.end.for.body_crit_edge, %for.body.lr.ph
  %7 = phi i32 [ %0, %for.body.lr.ph ], [ %.pre, %for.end.for.body_crit_edge ]
  %indvars.iv1129 = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next1130, %for.end.for.body_crit_edge ]
  %arrayidx26 = getelementptr inbounds i32* %shift, i64 %indvars.iv1129
  %8 = load i32* %arrayidx26, align 4, !tbaa !0
  %mul27 = mul nsw i32 %8, 3
  %idxprom28 = sext i32 %mul27 to i64
  %arrayidx29 = getelementptr inbounds float* %shiftvec, i64 %idxprom28
  %9 = load float* %arrayidx29, align 4, !tbaa !3
  %add30 = add nsw i32 %mul27, 1
  %idxprom31 = sext i32 %add30 to i64
  %arrayidx32 = getelementptr inbounds float* %shiftvec, i64 %idxprom31
  %10 = load float* %arrayidx32, align 4, !tbaa !3
  %add33 = add nsw i32 %mul27, 2
  %idxprom34 = sext i32 %add33 to i64
  %arrayidx35 = getelementptr inbounds float* %shiftvec, i64 %idxprom34
  %11 = load float* %arrayidx35, align 4, !tbaa !3
  %mul38 = mul nsw i32 %7, 3
  %arrayidx40 = getelementptr inbounds i32* %jindex, i64 %indvars.iv1129
  %12 = load i32* %arrayidx40, align 4, !tbaa !0
  %indvars.iv.next1130 = add i64 %indvars.iv1129, 1
  %arrayidx43 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next1130
  %13 = load i32* %arrayidx43, align 4, !tbaa !0
  %idxprom44 = sext i32 %mul38 to i64
  %arrayidx45 = getelementptr inbounds float* %pos, i64 %idxprom44
  %14 = load float* %arrayidx45, align 4, !tbaa !3
  %add46 = fadd float %9, %14
  %add47 = add nsw i32 %mul38, 1
  %idxprom48 = sext i32 %add47 to i64
  %arrayidx49 = getelementptr inbounds float* %pos, i64 %idxprom48
  %15 = load float* %arrayidx49, align 4, !tbaa !3
  %add50 = fadd float %10, %15
  %add51 = add nsw i32 %mul38, 2
  %idxprom52 = sext i32 %add51 to i64
  %arrayidx53 = getelementptr inbounds float* %pos, i64 %idxprom52
  %16 = load float* %arrayidx53, align 4, !tbaa !3
  %add54 = fadd float %11, %16
  %add55 = add nsw i32 %mul38, 3
  %idxprom56 = sext i32 %add55 to i64
  %arrayidx57 = getelementptr inbounds float* %pos, i64 %idxprom56
  %17 = load float* %arrayidx57, align 4, !tbaa !3
  %add58 = fadd float %9, %17
  %add59 = add nsw i32 %mul38, 4
  %idxprom60 = sext i32 %add59 to i64
  %arrayidx61 = getelementptr inbounds float* %pos, i64 %idxprom60
  %18 = load float* %arrayidx61, align 4, !tbaa !3
  %add62 = fadd float %10, %18
  %add63 = add nsw i32 %mul38, 5
  %idxprom64 = sext i32 %add63 to i64
  %arrayidx65 = getelementptr inbounds float* %pos, i64 %idxprom64
  %19 = load float* %arrayidx65, align 4, !tbaa !3
  %add66 = fadd float %11, %19
  %add67 = add nsw i32 %mul38, 6
  %idxprom68 = sext i32 %add67 to i64
  %arrayidx69 = getelementptr inbounds float* %pos, i64 %idxprom68
  %20 = load float* %arrayidx69, align 4, !tbaa !3
  %add70 = fadd float %9, %20
  %add71 = add nsw i32 %mul38, 7
  %idxprom72 = sext i32 %add71 to i64
  %arrayidx73 = getelementptr inbounds float* %pos, i64 %idxprom72
  %21 = load float* %arrayidx73, align 4, !tbaa !3
  %add74 = fadd float %10, %21
  %add75 = add nsw i32 %mul38, 8
  %idxprom76 = sext i32 %add75 to i64
  %arrayidx77 = getelementptr inbounds float* %pos, i64 %idxprom76
  %22 = load float* %arrayidx77, align 4, !tbaa !3
  %add78 = fadd float %11, %22
  %cmp801104 = icmp slt i32 %12, %13
  br i1 %cmp801104, label %for.body81.lr.ph, label %for.end

for.body81.lr.ph:                                 ; preds = %for.body
  %23 = sext i32 %12 to i64
  br label %for.body81

for.body81:                                       ; preds = %for.body81.lr.ph, %for.body81
  %indvars.iv = phi i64 [ %23, %for.body81.lr.ph ], [ %indvars.iv.next, %for.body81 ]
  %vctot.01115 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add486, %for.body81 ]
  %vnbtot.01114 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add277, %for.body81 ]
  %fix1.01113 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add350, %for.body81 ]
  %fiy1.01112 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add351, %for.body81 ]
  %fiz1.01111 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add352, %for.body81 ]
  %fix2.01110 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add416, %for.body81 ]
  %fiy2.01109 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add417, %for.body81 ]
  %fiz2.01108 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add418, %for.body81 ]
  %fix3.01107 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add490, %for.body81 ]
  %fiy3.01106 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add491, %for.body81 ]
  %fiz3.01105 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add492, %for.body81 ]
  %arrayidx83 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %24 = load i32* %arrayidx83, align 4, !tbaa !0
  %mul84 = mul nsw i32 %24, 3
  %idxprom85 = sext i32 %mul84 to i64
  %arrayidx86 = getelementptr inbounds float* %pos, i64 %idxprom85
  %25 = load float* %arrayidx86, align 4, !tbaa !3
  %add87 = add nsw i32 %mul84, 1
  %idxprom88 = sext i32 %add87 to i64
  %arrayidx89 = getelementptr inbounds float* %pos, i64 %idxprom88
  %26 = load float* %arrayidx89, align 4, !tbaa !3
  %add90 = add nsw i32 %mul84, 2
  %idxprom91 = sext i32 %add90 to i64
  %arrayidx92 = getelementptr inbounds float* %pos, i64 %idxprom91
  %27 = load float* %arrayidx92, align 4, !tbaa !3
  %add93 = add nsw i32 %mul84, 3
  %idxprom94 = sext i32 %add93 to i64
  %arrayidx95 = getelementptr inbounds float* %pos, i64 %idxprom94
  %28 = load float* %arrayidx95, align 4, !tbaa !3
  %add96 = add nsw i32 %mul84, 4
  %idxprom97 = sext i32 %add96 to i64
  %arrayidx98 = getelementptr inbounds float* %pos, i64 %idxprom97
  %29 = load float* %arrayidx98, align 4, !tbaa !3
  %add99 = add nsw i32 %mul84, 5
  %idxprom100 = sext i32 %add99 to i64
  %arrayidx101 = getelementptr inbounds float* %pos, i64 %idxprom100
  %30 = load float* %arrayidx101, align 4, !tbaa !3
  %add102 = add nsw i32 %mul84, 6
  %idxprom103 = sext i32 %add102 to i64
  %arrayidx104 = getelementptr inbounds float* %pos, i64 %idxprom103
  %31 = load float* %arrayidx104, align 4, !tbaa !3
  %add105 = add nsw i32 %mul84, 7
  %idxprom106 = sext i32 %add105 to i64
  %arrayidx107 = getelementptr inbounds float* %pos, i64 %idxprom106
  %32 = load float* %arrayidx107, align 4, !tbaa !3
  %add108 = add nsw i32 %mul84, 8
  %idxprom109 = sext i32 %add108 to i64
  %arrayidx110 = getelementptr inbounds float* %pos, i64 %idxprom109
  %33 = load float* %arrayidx110, align 4, !tbaa !3
  %sub = fsub float %add46, %25
  %sub111 = fsub float %add50, %26
  %sub112 = fsub float %add54, %27
  %mul113 = fmul float %sub, %sub
  %mul114 = fmul float %sub111, %sub111
  %add115 = fadd float %mul113, %mul114
  %mul116 = fmul float %sub112, %sub112
  %add117 = fadd float %add115, %mul116
  %sub118 = fsub float %add46, %28
  %sub119 = fsub float %add50, %29
  %sub120 = fsub float %add54, %30
  %mul121 = fmul float %sub118, %sub118
  %mul122 = fmul float %sub119, %sub119
  %add123 = fadd float %mul121, %mul122
  %mul124 = fmul float %sub120, %sub120
  %add125 = fadd float %add123, %mul124
  %sub126 = fsub float %add46, %31
  %sub127 = fsub float %add50, %32
  %sub128 = fsub float %add54, %33
  %mul129 = fmul float %sub126, %sub126
  %mul130 = fmul float %sub127, %sub127
  %add131 = fadd float %mul129, %mul130
  %mul132 = fmul float %sub128, %sub128
  %add133 = fadd float %add131, %mul132
  %sub134 = fsub float %add58, %25
  %sub135 = fsub float %add62, %26
  %sub136 = fsub float %add66, %27
  %mul137 = fmul float %sub134, %sub134
  %mul138 = fmul float %sub135, %sub135
  %add139 = fadd float %mul137, %mul138
  %mul140 = fmul float %sub136, %sub136
  %add141 = fadd float %add139, %mul140
  %sub142 = fsub float %add58, %28
  %sub143 = fsub float %add62, %29
  %sub144 = fsub float %add66, %30
  %mul145 = fmul float %sub142, %sub142
  %mul146 = fmul float %sub143, %sub143
  %add147 = fadd float %mul145, %mul146
  %mul148 = fmul float %sub144, %sub144
  %add149 = fadd float %add147, %mul148
  %sub150 = fsub float %add58, %31
  %sub151 = fsub float %add62, %32
  %sub152 = fsub float %add66, %33
  %mul153 = fmul float %sub150, %sub150
  %mul154 = fmul float %sub151, %sub151
  %add155 = fadd float %mul153, %mul154
  %mul156 = fmul float %sub152, %sub152
  %add157 = fadd float %add155, %mul156
  %sub158 = fsub float %add70, %25
  %sub159 = fsub float %add74, %26
  %sub160 = fsub float %add78, %27
  %mul161 = fmul float %sub158, %sub158
  %mul162 = fmul float %sub159, %sub159
  %add163 = fadd float %mul161, %mul162
  %mul164 = fmul float %sub160, %sub160
  %add165 = fadd float %add163, %mul164
  %sub166 = fsub float %add70, %28
  %sub167 = fsub float %add74, %29
  %sub168 = fsub float %add78, %30
  %mul169 = fmul float %sub166, %sub166
  %mul170 = fmul float %sub167, %sub167
  %add171 = fadd float %mul169, %mul170
  %mul172 = fmul float %sub168, %sub168
  %add173 = fadd float %add171, %mul172
  %sub174 = fsub float %add70, %31
  %sub175 = fsub float %add74, %32
  %sub176 = fsub float %add78, %33
  %mul177 = fmul float %sub174, %sub174
  %mul178 = fmul float %sub175, %sub175
  %add179 = fadd float %mul177, %mul178
  %mul180 = fmul float %sub176, %sub176
  %add181 = fadd float %add179, %mul180
  %conv = fpext float %add117 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv182 = fptrunc double %div to float
  %conv183 = fpext float %add141 to double
  %call184 = tail call double @sqrt(double %conv183) #2
  %div185 = fdiv double 1.000000e+00, %call184
  %conv186 = fptrunc double %div185 to float
  %conv187 = fpext float %add165 to double
  %call188 = tail call double @sqrt(double %conv187) #2
  %div189 = fdiv double 1.000000e+00, %call188
  %conv190 = fptrunc double %div189 to float
  %conv191 = fpext float %add125 to double
  %call192 = tail call double @sqrt(double %conv191) #2
  %div193 = fdiv double 1.000000e+00, %call192
  %conv194 = fptrunc double %div193 to float
  %conv195 = fpext float %add149 to double
  %call196 = tail call double @sqrt(double %conv195) #2
  %div197 = fdiv double 1.000000e+00, %call196
  %conv198 = fptrunc double %div197 to float
  %conv199 = fpext float %add173 to double
  %call200 = tail call double @sqrt(double %conv199) #2
  %div201 = fdiv double 1.000000e+00, %call200
  %conv202 = fptrunc double %div201 to float
  %conv203 = fpext float %add133 to double
  %call204 = tail call double @sqrt(double %conv203) #2
  %div205 = fdiv double 1.000000e+00, %call204
  %conv206 = fptrunc double %div205 to float
  %conv207 = fpext float %add157 to double
  %call208 = tail call double @sqrt(double %conv207) #2
  %div209 = fdiv double 1.000000e+00, %call208
  %conv210 = fptrunc double %div209 to float
  %conv211 = fpext float %add181 to double
  %call212 = tail call double @sqrt(double %conv211) #2
  %div213 = fdiv double 1.000000e+00, %call212
  %conv214 = fptrunc double %div213 to float
  %mul215 = fmul float %add117, %conv182
  %mul217 = fmul float %mul215, %tabscale
  %conv218 = fptosi float %mul217 to i32
  %conv219 = sitofp i32 %conv218 to float
  %sub220 = fsub float %mul217, %conv219
  %mul221 = fmul float %sub220, %sub220
  %mul222 = shl nsw i32 %conv218, 3
  %idxprom223 = sext i32 %mul222 to i64
  %arrayidx224 = getelementptr inbounds float* %VFtab, i64 %idxprom223
  %34 = load float* %arrayidx224, align 4, !tbaa !3
  %add2251097 = or i32 %mul222, 1
  %idxprom226 = sext i32 %add2251097 to i64
  %arrayidx227 = getelementptr inbounds float* %VFtab, i64 %idxprom226
  %35 = load float* %arrayidx227, align 4, !tbaa !3
  %add2281098 = or i32 %mul222, 2
  %idxprom229 = sext i32 %add2281098 to i64
  %arrayidx230 = getelementptr inbounds float* %VFtab, i64 %idxprom229
  %36 = load float* %arrayidx230, align 4, !tbaa !3
  %mul231 = fmul float %sub220, %36
  %add2321099 = or i32 %mul222, 3
  %idxprom233 = sext i32 %add2321099 to i64
  %arrayidx234 = getelementptr inbounds float* %VFtab, i64 %idxprom233
  %37 = load float* %arrayidx234, align 4, !tbaa !3
  %mul235 = fmul float %mul221, %37
  %add236 = fadd float %35, %mul231
  %add237 = fadd float %add236, %mul235
  %mul238 = fmul float %sub220, %add237
  %add239 = fadd float %34, %mul238
  %add240 = fadd float %mul231, %add237
  %mul241 = fmul float %mul235, 2.000000e+00
  %add242 = fadd float %mul241, %add240
  %mul243 = fmul float %4, %add239
  %mul244 = fmul float %4, %add242
  %mul245 = fmul float %6, %mul215
  %mul246 = fmul float %mul245, %exptabscale
  %conv247 = fptosi float %mul246 to i32
  %conv248 = sitofp i32 %conv247 to float
  %sub249 = fsub float %mul246, %conv248
  %mul250 = fmul float %sub249, %sub249
  %mul251 = shl nsw i32 %conv247, 3
  %add2521100 = or i32 %mul251, 4
  %idxprom253 = sext i32 %add2521100 to i64
  %arrayidx254 = getelementptr inbounds float* %VFtab, i64 %idxprom253
  %38 = load float* %arrayidx254, align 4, !tbaa !3
  %add2551101 = or i32 %mul251, 5
  %idxprom256 = sext i32 %add2551101 to i64
  %arrayidx257 = getelementptr inbounds float* %VFtab, i64 %idxprom256
  %39 = load float* %arrayidx257, align 4, !tbaa !3
  %add2581102 = or i32 %mul251, 6
  %idxprom259 = sext i32 %add2581102 to i64
  %arrayidx260 = getelementptr inbounds float* %VFtab, i64 %idxprom259
  %40 = load float* %arrayidx260, align 4, !tbaa !3
  %mul261 = fmul float %sub249, %40
  %add2621103 = or i32 %mul251, 7
  %idxprom263 = sext i32 %add2621103 to i64
  %arrayidx264 = getelementptr inbounds float* %VFtab, i64 %idxprom263
  %41 = load float* %arrayidx264, align 4, !tbaa !3
  %mul265 = fmul float %mul250, %41
  %add266 = fadd float %39, %mul261
  %add267 = fadd float %add266, %mul265
  %mul268 = fmul float %sub249, %add267
  %add269 = fadd float %38, %mul268
  %add270 = fadd float %mul261, %add267
  %mul271 = fmul float %mul265, 2.000000e+00
  %add272 = fadd float %mul271, %add270
  %mul273 = fmul float %5, %add269
  %mul275 = fmul float %mul274, %add272
  %add276 = fadd float %vnbtot.01114, %mul243
  %add277 = fadd float %add276, %mul273
  %mul278 = fmul float %add117, %krf
  %add279 = fadd float %mul278, %conv182
  %sub280 = fsub float %add279, %crf
  %mul281 = fmul float %mul4, %sub280
  %mul282 = fmul float %mul278, 2.000000e+00
  %sub283 = fsub float %conv182, %mul282
  %mul284 = fmul float %mul4, %sub283
  %mul285 = fmul float %conv182, %mul284
  %mul286 = fmul float %mul244, %tabscale
  %mul287 = fmul float %mul275, %exptabscale
  %add288 = fadd float %mul286, %mul287
  %sub289 = fsub float %mul285, %add288
  %mul290 = fmul float %conv182, %sub289
  %add291 = fadd float %vctot.01115, %mul281
  %mul292 = fmul float %sub, %mul290
  %mul293 = fmul float %sub111, %mul290
  %mul294 = fmul float %sub112, %mul290
  %add295 = fadd float %fix1.01113, %mul292
  %add296 = fadd float %fiy1.01112, %mul293
  %add297 = fadd float %fiz1.01111, %mul294
  %arrayidx299 = getelementptr inbounds float* %faction, i64 %idxprom85
  %42 = load float* %arrayidx299, align 4, !tbaa !3
  %sub300 = fsub float %42, %mul292
  %arrayidx303 = getelementptr inbounds float* %faction, i64 %idxprom88
  %43 = load float* %arrayidx303, align 4, !tbaa !3
  %sub304 = fsub float %43, %mul293
  %arrayidx307 = getelementptr inbounds float* %faction, i64 %idxprom91
  %44 = load float* %arrayidx307, align 4, !tbaa !3
  %sub308 = fsub float %44, %mul294
  %mul309 = fmul float %conv194, %conv194
  %mul310 = fmul float %add125, %krf
  %add311 = fadd float %mul310, %conv194
  %sub312 = fsub float %add311, %crf
  %mul313 = fmul float %mul6, %sub312
  %mul314 = fmul float %mul310, 2.000000e+00
  %sub315 = fsub float %conv194, %mul314
  %mul316 = fmul float %mul6, %sub315
  %mul317 = fmul float %mul309, %mul316
  %add318 = fadd float %add291, %mul313
  %mul319 = fmul float %sub118, %mul317
  %mul320 = fmul float %sub119, %mul317
  %mul321 = fmul float %sub120, %mul317
  %add322 = fadd float %mul319, %add295
  %add323 = fadd float %mul320, %add296
  %add324 = fadd float %mul321, %add297
  %arrayidx327 = getelementptr inbounds float* %faction, i64 %idxprom94
  %45 = load float* %arrayidx327, align 4, !tbaa !3
  %sub328 = fsub float %45, %mul319
  %arrayidx331 = getelementptr inbounds float* %faction, i64 %idxprom97
  %46 = load float* %arrayidx331, align 4, !tbaa !3
  %sub332 = fsub float %46, %mul320
  %arrayidx335 = getelementptr inbounds float* %faction, i64 %idxprom100
  %47 = load float* %arrayidx335, align 4, !tbaa !3
  %sub336 = fsub float %47, %mul321
  %mul337 = fmul float %conv206, %conv206
  %mul338 = fmul float %add133, %krf
  %add339 = fadd float %mul338, %conv206
  %sub340 = fsub float %add339, %crf
  %mul341 = fmul float %mul6, %sub340
  %mul342 = fmul float %mul338, 2.000000e+00
  %sub343 = fsub float %conv206, %mul342
  %mul344 = fmul float %mul6, %sub343
  %mul345 = fmul float %mul337, %mul344
  %add346 = fadd float %add318, %mul341
  %mul347 = fmul float %sub126, %mul345
  %mul348 = fmul float %sub127, %mul345
  %mul349 = fmul float %sub128, %mul345
  %add350 = fadd float %mul347, %add322
  %add351 = fadd float %mul348, %add323
  %add352 = fadd float %mul349, %add324
  %arrayidx355 = getelementptr inbounds float* %faction, i64 %idxprom103
  %48 = load float* %arrayidx355, align 4, !tbaa !3
  %sub356 = fsub float %48, %mul347
  %arrayidx359 = getelementptr inbounds float* %faction, i64 %idxprom106
  %49 = load float* %arrayidx359, align 4, !tbaa !3
  %sub360 = fsub float %49, %mul348
  %arrayidx363 = getelementptr inbounds float* %faction, i64 %idxprom109
  %50 = load float* %arrayidx363, align 4, !tbaa !3
  %sub364 = fsub float %50, %mul349
  %mul365 = fmul float %conv186, %conv186
  %mul366 = fmul float %add141, %krf
  %add367 = fadd float %mul366, %conv186
  %sub368 = fsub float %add367, %crf
  %mul369 = fmul float %mul6, %sub368
  %mul370 = fmul float %mul366, 2.000000e+00
  %sub371 = fsub float %conv186, %mul370
  %mul372 = fmul float %mul6, %sub371
  %mul373 = fmul float %mul365, %mul372
  %add374 = fadd float %mul369, %add346
  %mul375 = fmul float %sub134, %mul373
  %mul376 = fmul float %sub135, %mul373
  %mul377 = fmul float %sub136, %mul373
  %add378 = fadd float %fix2.01110, %mul375
  %add379 = fadd float %fiy2.01109, %mul376
  %add380 = fadd float %fiz2.01108, %mul377
  %sub381 = fsub float %sub300, %mul375
  %sub382 = fsub float %sub304, %mul376
  %sub383 = fsub float %sub308, %mul377
  %mul384 = fmul float %conv198, %conv198
  %mul385 = fmul float %add149, %krf
  %add386 = fadd float %mul385, %conv198
  %sub387 = fsub float %add386, %crf
  %mul388 = fmul float %mul8, %sub387
  %mul389 = fmul float %mul385, 2.000000e+00
  %sub390 = fsub float %conv198, %mul389
  %mul391 = fmul float %mul8, %sub390
  %mul392 = fmul float %mul384, %mul391
  %add393 = fadd float %mul388, %add374
  %mul394 = fmul float %sub142, %mul392
  %mul395 = fmul float %sub143, %mul392
  %mul396 = fmul float %sub144, %mul392
  %add397 = fadd float %add378, %mul394
  %add398 = fadd float %add379, %mul395
  %add399 = fadd float %add380, %mul396
  %sub400 = fsub float %sub328, %mul394
  %sub401 = fsub float %sub332, %mul395
  %sub402 = fsub float %sub336, %mul396
  %mul403 = fmul float %conv210, %conv210
  %mul404 = fmul float %add157, %krf
  %add405 = fadd float %mul404, %conv210
  %sub406 = fsub float %add405, %crf
  %mul407 = fmul float %mul8, %sub406
  %mul408 = fmul float %mul404, 2.000000e+00
  %sub409 = fsub float %conv210, %mul408
  %mul410 = fmul float %mul8, %sub409
  %mul411 = fmul float %mul403, %mul410
  %add412 = fadd float %mul407, %add393
  %mul413 = fmul float %sub150, %mul411
  %mul414 = fmul float %sub151, %mul411
  %mul415 = fmul float %sub152, %mul411
  %add416 = fadd float %add397, %mul413
  %add417 = fadd float %add398, %mul414
  %add418 = fadd float %add399, %mul415
  %sub419 = fsub float %sub356, %mul413
  %sub420 = fsub float %sub360, %mul414
  %sub421 = fsub float %sub364, %mul415
  %mul422 = fmul float %conv190, %conv190
  %mul423 = fmul float %add165, %krf
  %add424 = fadd float %mul423, %conv190
  %sub425 = fsub float %add424, %crf
  %mul426 = fmul float %mul6, %sub425
  %mul427 = fmul float %mul423, 2.000000e+00
  %sub428 = fsub float %conv190, %mul427
  %mul429 = fmul float %mul6, %sub428
  %mul430 = fmul float %mul422, %mul429
  %add431 = fadd float %mul426, %add412
  %mul432 = fmul float %sub158, %mul430
  %mul433 = fmul float %sub159, %mul430
  %mul434 = fmul float %sub160, %mul430
  %add435 = fadd float %fix3.01107, %mul432
  %add436 = fadd float %fiy3.01106, %mul433
  %add437 = fadd float %fiz3.01105, %mul434
  %sub438 = fsub float %sub381, %mul432
  store float %sub438, float* %arrayidx299, align 4, !tbaa !3
  %sub441 = fsub float %sub382, %mul433
  store float %sub441, float* %arrayidx303, align 4, !tbaa !3
  %sub445 = fsub float %sub383, %mul434
  store float %sub445, float* %arrayidx307, align 4, !tbaa !3
  %mul449 = fmul float %conv202, %conv202
  %mul450 = fmul float %add173, %krf
  %add451 = fadd float %mul450, %conv202
  %sub452 = fsub float %add451, %crf
  %mul453 = fmul float %mul8, %sub452
  %mul454 = fmul float %mul450, 2.000000e+00
  %sub455 = fsub float %conv202, %mul454
  %mul456 = fmul float %mul8, %sub455
  %mul457 = fmul float %mul449, %mul456
  %add458 = fadd float %mul453, %add431
  %mul459 = fmul float %sub166, %mul457
  %mul460 = fmul float %sub167, %mul457
  %mul461 = fmul float %sub168, %mul457
  %add462 = fadd float %add435, %mul459
  %add463 = fadd float %add436, %mul460
  %add464 = fadd float %add437, %mul461
  %sub465 = fsub float %sub400, %mul459
  store float %sub465, float* %arrayidx327, align 4, !tbaa !3
  %sub469 = fsub float %sub401, %mul460
  store float %sub469, float* %arrayidx331, align 4, !tbaa !3
  %sub473 = fsub float %sub402, %mul461
  store float %sub473, float* %arrayidx335, align 4, !tbaa !3
  %mul477 = fmul float %conv214, %conv214
  %mul478 = fmul float %add181, %krf
  %add479 = fadd float %mul478, %conv214
  %sub480 = fsub float %add479, %crf
  %mul481 = fmul float %mul8, %sub480
  %mul482 = fmul float %mul478, 2.000000e+00
  %sub483 = fsub float %conv214, %mul482
  %mul484 = fmul float %mul8, %sub483
  %mul485 = fmul float %mul477, %mul484
  %add486 = fadd float %mul481, %add458
  %mul487 = fmul float %sub174, %mul485
  %mul488 = fmul float %sub175, %mul485
  %mul489 = fmul float %sub176, %mul485
  %add490 = fadd float %add462, %mul487
  %add491 = fadd float %add463, %mul488
  %add492 = fadd float %add464, %mul489
  %sub493 = fsub float %sub419, %mul487
  store float %sub493, float* %arrayidx355, align 4, !tbaa !3
  %sub497 = fsub float %sub420, %mul488
  store float %sub497, float* %arrayidx359, align 4, !tbaa !3
  %sub501 = fsub float %sub421, %mul489
  store float %sub501, float* %arrayidx363, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %51 = trunc i64 %indvars.iv.next to i32
  %cmp80 = icmp slt i32 %51, %13
  br i1 %cmp80, label %for.body81, label %for.end

for.end:                                          ; preds = %for.body81, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add486, %for.body81 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add277, %for.body81 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add350, %for.body81 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add351, %for.body81 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add352, %for.body81 ]
  %fix2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add416, %for.body81 ]
  %fiy2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add417, %for.body81 ]
  %fiz2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add418, %for.body81 ]
  %fix3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add490, %for.body81 ]
  %fiy3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add491, %for.body81 ]
  %fiz3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add492, %for.body81 ]
  %arrayidx506 = getelementptr inbounds float* %faction, i64 %idxprom44
  %52 = load float* %arrayidx506, align 4, !tbaa !3
  %add507 = fadd float %fix1.0.lcssa, %52
  store float %add507, float* %arrayidx506, align 4, !tbaa !3
  %arrayidx512 = getelementptr inbounds float* %faction, i64 %idxprom48
  %53 = load float* %arrayidx512, align 4, !tbaa !3
  %add513 = fadd float %fiy1.0.lcssa, %53
  store float %add513, float* %arrayidx512, align 4, !tbaa !3
  %arrayidx519 = getelementptr inbounds float* %faction, i64 %idxprom52
  %54 = load float* %arrayidx519, align 4, !tbaa !3
  %add520 = fadd float %fiz1.0.lcssa, %54
  store float %add520, float* %arrayidx519, align 4, !tbaa !3
  %arrayidx526 = getelementptr inbounds float* %faction, i64 %idxprom56
  %55 = load float* %arrayidx526, align 4, !tbaa !3
  %add527 = fadd float %fix2.0.lcssa, %55
  store float %add527, float* %arrayidx526, align 4, !tbaa !3
  %arrayidx533 = getelementptr inbounds float* %faction, i64 %idxprom60
  %56 = load float* %arrayidx533, align 4, !tbaa !3
  %add534 = fadd float %fiy2.0.lcssa, %56
  store float %add534, float* %arrayidx533, align 4, !tbaa !3
  %arrayidx540 = getelementptr inbounds float* %faction, i64 %idxprom64
  %57 = load float* %arrayidx540, align 4, !tbaa !3
  %add541 = fadd float %fiz2.0.lcssa, %57
  store float %add541, float* %arrayidx540, align 4, !tbaa !3
  %arrayidx547 = getelementptr inbounds float* %faction, i64 %idxprom68
  %58 = load float* %arrayidx547, align 4, !tbaa !3
  %add548 = fadd float %fix3.0.lcssa, %58
  store float %add548, float* %arrayidx547, align 4, !tbaa !3
  %arrayidx554 = getelementptr inbounds float* %faction, i64 %idxprom72
  %59 = load float* %arrayidx554, align 4, !tbaa !3
  %add555 = fadd float %fiy3.0.lcssa, %59
  store float %add555, float* %arrayidx554, align 4, !tbaa !3
  %arrayidx561 = getelementptr inbounds float* %faction, i64 %idxprom76
  %60 = load float* %arrayidx561, align 4, !tbaa !3
  %add562 = fadd float %fiz3.0.lcssa, %60
  store float %add562, float* %arrayidx561, align 4, !tbaa !3
  %arrayidx567 = getelementptr inbounds float* %fshift, i64 %idxprom28
  %61 = load float* %arrayidx567, align 4, !tbaa !3
  %add568 = fadd float %fix1.0.lcssa, %61
  %add569 = fadd float %fix2.0.lcssa, %add568
  %add570 = fadd float %fix3.0.lcssa, %add569
  store float %add570, float* %arrayidx567, align 4, !tbaa !3
  %arrayidx575 = getelementptr inbounds float* %fshift, i64 %idxprom31
  %62 = load float* %arrayidx575, align 4, !tbaa !3
  %add576 = fadd float %fiy1.0.lcssa, %62
  %add577 = fadd float %fiy2.0.lcssa, %add576
  %add578 = fadd float %fiy3.0.lcssa, %add577
  store float %add578, float* %arrayidx575, align 4, !tbaa !3
  %arrayidx584 = getelementptr inbounds float* %fshift, i64 %idxprom34
  %63 = load float* %arrayidx584, align 4, !tbaa !3
  %add585 = fadd float %fiz1.0.lcssa, %63
  %add586 = fadd float %fiz2.0.lcssa, %add585
  %add587 = fadd float %fiz3.0.lcssa, %add586
  store float %add587, float* %arrayidx584, align 4, !tbaa !3
  %arrayidx592 = getelementptr inbounds i32* %gid, i64 %indvars.iv1129
  %64 = load i32* %arrayidx592, align 4, !tbaa !0
  %idxprom593 = sext i32 %64 to i64
  %arrayidx594 = getelementptr inbounds float* %Vc, i64 %idxprom593
  %65 = load float* %arrayidx594, align 4, !tbaa !3
  %add595 = fadd float %vctot.0.lcssa, %65
  store float %add595, float* %arrayidx594, align 4, !tbaa !3
  %arrayidx599 = getelementptr inbounds float* %Vnb, i64 %idxprom593
  %66 = load float* %arrayidx599, align 4, !tbaa !3
  %add600 = fadd float %vnbtot.0.lcssa, %66
  store float %add600, float* %arrayidx599, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next1130 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end605, label %for.end.for.body_crit_edge

for.end.for.body_crit_edge:                       ; preds = %for.end
  %arrayidx37.phi.trans.insert = getelementptr inbounds i32* %iinr, i64 %indvars.iv.next1130
  %.pre = load i32* %arrayidx37.phi.trans.insert, align 4, !tbaa !0
  br label %for.body

for.end605:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl3000(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, float %tabscale, float* nocapture %VFtab) #0 {
entry:
  %cmp270 = icmp sgt i32 %nri, 0
  br i1 %cmp270, label %for.body, label %for.end160

for.body:                                         ; preds = %for.end, %entry
  %indvars.iv272 = phi i64 [ 0, %entry ], [ %indvars.iv.next273, %for.end ]
  %arrayidx = getelementptr inbounds i32* %shift, i64 %indvars.iv272
  %0 = load i32* %arrayidx, align 4, !tbaa !0
  %mul = mul nsw i32 %0, 3
  %idxprom1 = sext i32 %mul to i64
  %arrayidx2 = getelementptr inbounds float* %shiftvec, i64 %idxprom1
  %1 = load float* %arrayidx2, align 4, !tbaa !3
  %add = add nsw i32 %mul, 1
  %idxprom3 = sext i32 %add to i64
  %arrayidx4 = getelementptr inbounds float* %shiftvec, i64 %idxprom3
  %2 = load float* %arrayidx4, align 4, !tbaa !3
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds float* %shiftvec, i64 %idxprom6
  %3 = load float* %arrayidx7, align 4, !tbaa !3
  %arrayidx9 = getelementptr inbounds i32* %iinr, i64 %indvars.iv272
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %arrayidx12 = getelementptr inbounds i32* %jindex, i64 %indvars.iv272
  %5 = load i32* %arrayidx12, align 4, !tbaa !0
  %indvars.iv.next273 = add i64 %indvars.iv272, 1
  %arrayidx15 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next273
  %6 = load i32* %arrayidx15, align 4, !tbaa !0
  %idxprom16 = sext i32 %mul10 to i64
  %arrayidx17 = getelementptr inbounds float* %pos, i64 %idxprom16
  %7 = load float* %arrayidx17, align 4, !tbaa !3
  %add18 = fadd float %1, %7
  %add19 = add nsw i32 %mul10, 1
  %idxprom20 = sext i32 %add19 to i64
  %arrayidx21 = getelementptr inbounds float* %pos, i64 %idxprom20
  %8 = load float* %arrayidx21, align 4, !tbaa !3
  %add22 = fadd float %2, %8
  %add23 = add nsw i32 %mul10, 2
  %idxprom24 = sext i32 %add23 to i64
  %arrayidx25 = getelementptr inbounds float* %pos, i64 %idxprom24
  %9 = load float* %arrayidx25, align 4, !tbaa !3
  %add26 = fadd float %3, %9
  %idxprom27 = sext i32 %4 to i64
  %arrayidx28 = getelementptr inbounds float* %charge, i64 %idxprom27
  %10 = load float* %arrayidx28, align 4, !tbaa !3
  %mul29 = fmul float %10, %facel
  %cmp31261 = icmp slt i32 %5, %6
  br i1 %cmp31261, label %for.body32.lr.ph, label %for.end

for.body32.lr.ph:                                 ; preds = %for.body
  %11 = sext i32 %5 to i64
  br label %for.body32

for.body32:                                       ; preds = %for.body32.lr.ph, %for.body32
  %indvars.iv = phi i64 [ %11, %for.body32.lr.ph ], [ %indvars.iv.next, %for.body32 ]
  %vctot.0265 = phi float [ 0.000000e+00, %for.body32.lr.ph ], [ %add87, %for.body32 ]
  %fix1.0264 = phi float [ 0.000000e+00, %for.body32.lr.ph ], [ %add91, %for.body32 ]
  %fiy1.0263 = phi float [ 0.000000e+00, %for.body32.lr.ph ], [ %add92, %for.body32 ]
  %fiz1.0262 = phi float [ 0.000000e+00, %for.body32.lr.ph ], [ %add93, %for.body32 ]
  %arrayidx34 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %12 = load i32* %arrayidx34, align 4, !tbaa !0
  %mul35 = mul nsw i32 %12, 3
  %idxprom36 = sext i32 %mul35 to i64
  %arrayidx37 = getelementptr inbounds float* %pos, i64 %idxprom36
  %13 = load float* %arrayidx37, align 4, !tbaa !3
  %add38 = add nsw i32 %mul35, 1
  %idxprom39 = sext i32 %add38 to i64
  %arrayidx40 = getelementptr inbounds float* %pos, i64 %idxprom39
  %14 = load float* %arrayidx40, align 4, !tbaa !3
  %add41 = add nsw i32 %mul35, 2
  %idxprom42 = sext i32 %add41 to i64
  %arrayidx43 = getelementptr inbounds float* %pos, i64 %idxprom42
  %15 = load float* %arrayidx43, align 4, !tbaa !3
  %sub = fsub float %add18, %13
  %sub44 = fsub float %add22, %14
  %sub45 = fsub float %add26, %15
  %mul46 = fmul float %sub, %sub
  %mul47 = fmul float %sub44, %sub44
  %add48 = fadd float %mul46, %mul47
  %mul49 = fmul float %sub45, %sub45
  %add50 = fadd float %add48, %mul49
  %conv = fpext float %add50 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv51 = fptrunc double %div to float
  %mul52 = fmul float %add50, %conv51
  %mul53 = fmul float %mul52, %tabscale
  %conv54 = fptosi float %mul53 to i32
  %conv55 = sitofp i32 %conv54 to float
  %sub56 = fsub float %mul53, %conv55
  %mul57 = fmul float %sub56, %sub56
  %mul58 = shl nsw i32 %conv54, 2
  %idxprom59 = sext i32 %12 to i64
  %arrayidx60 = getelementptr inbounds float* %charge, i64 %idxprom59
  %16 = load float* %arrayidx60, align 4, !tbaa !3
  %mul61 = fmul float %mul29, %16
  %idxprom62 = sext i32 %mul58 to i64
  %arrayidx63 = getelementptr inbounds float* %VFtab, i64 %idxprom62
  %17 = load float* %arrayidx63, align 4, !tbaa !3
  %add64258 = or i32 %mul58, 1
  %idxprom65 = sext i32 %add64258 to i64
  %arrayidx66 = getelementptr inbounds float* %VFtab, i64 %idxprom65
  %18 = load float* %arrayidx66, align 4, !tbaa !3
  %add67259 = or i32 %mul58, 2
  %idxprom68 = sext i32 %add67259 to i64
  %arrayidx69 = getelementptr inbounds float* %VFtab, i64 %idxprom68
  %19 = load float* %arrayidx69, align 4, !tbaa !3
  %mul70 = fmul float %19, %sub56
  %add71260 = or i32 %mul58, 3
  %idxprom72 = sext i32 %add71260 to i64
  %arrayidx73 = getelementptr inbounds float* %VFtab, i64 %idxprom72
  %20 = load float* %arrayidx73, align 4, !tbaa !3
  %mul74 = fmul float %20, %mul57
  %add75 = fadd float %18, %mul70
  %add76 = fadd float %add75, %mul74
  %mul77 = fmul float %sub56, %add76
  %add78 = fadd float %17, %mul77
  %add79 = fadd float %mul70, %add76
  %mul80 = fmul float %mul74, 2.000000e+00
  %add81 = fadd float %mul80, %add79
  %mul82 = fmul float %mul61, %add78
  %mul83 = fmul float %mul61, %add81
  %mul84 = fmul float %mul83, %tabscale
  %21 = fmul float %conv51, %mul84
  %mul86 = fsub float -0.000000e+00, %21
  %add87 = fadd float %vctot.0265, %mul82
  %mul88 = fmul float %sub, %mul86
  %mul89 = fmul float %sub44, %mul86
  %mul90 = fmul float %sub45, %mul86
  %add91 = fadd float %fix1.0264, %mul88
  %add92 = fadd float %fiy1.0263, %mul89
  %add93 = fadd float %fiz1.0262, %mul90
  %arrayidx95 = getelementptr inbounds float* %faction, i64 %idxprom36
  %22 = load float* %arrayidx95, align 4, !tbaa !3
  %sub96 = fsub float %22, %mul88
  store float %sub96, float* %arrayidx95, align 4, !tbaa !3
  %arrayidx101 = getelementptr inbounds float* %faction, i64 %idxprom39
  %23 = load float* %arrayidx101, align 4, !tbaa !3
  %sub102 = fsub float %23, %mul89
  store float %sub102, float* %arrayidx101, align 4, !tbaa !3
  %arrayidx108 = getelementptr inbounds float* %faction, i64 %idxprom42
  %24 = load float* %arrayidx108, align 4, !tbaa !3
  %sub109 = fsub float %24, %mul90
  store float %sub109, float* %arrayidx108, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %25 = trunc i64 %indvars.iv.next to i32
  %cmp31 = icmp slt i32 %25, %6
  br i1 %cmp31, label %for.body32, label %for.end

for.end:                                          ; preds = %for.body32, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add87, %for.body32 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add91, %for.body32 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add92, %for.body32 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add93, %for.body32 ]
  %arrayidx114 = getelementptr inbounds float* %faction, i64 %idxprom16
  %26 = load float* %arrayidx114, align 4, !tbaa !3
  %add115 = fadd float %fix1.0.lcssa, %26
  store float %add115, float* %arrayidx114, align 4, !tbaa !3
  %arrayidx120 = getelementptr inbounds float* %faction, i64 %idxprom20
  %27 = load float* %arrayidx120, align 4, !tbaa !3
  %add121 = fadd float %fiy1.0.lcssa, %27
  store float %add121, float* %arrayidx120, align 4, !tbaa !3
  %arrayidx127 = getelementptr inbounds float* %faction, i64 %idxprom24
  %28 = load float* %arrayidx127, align 4, !tbaa !3
  %add128 = fadd float %fiz1.0.lcssa, %28
  store float %add128, float* %arrayidx127, align 4, !tbaa !3
  %arrayidx133 = getelementptr inbounds float* %fshift, i64 %idxprom1
  %29 = load float* %arrayidx133, align 4, !tbaa !3
  %add134 = fadd float %fix1.0.lcssa, %29
  store float %add134, float* %arrayidx133, align 4, !tbaa !3
  %arrayidx139 = getelementptr inbounds float* %fshift, i64 %idxprom3
  %30 = load float* %arrayidx139, align 4, !tbaa !3
  %add140 = fadd float %fiy1.0.lcssa, %30
  store float %add140, float* %arrayidx139, align 4, !tbaa !3
  %arrayidx146 = getelementptr inbounds float* %fshift, i64 %idxprom6
  %31 = load float* %arrayidx146, align 4, !tbaa !3
  %add147 = fadd float %fiz1.0.lcssa, %31
  store float %add147, float* %arrayidx146, align 4, !tbaa !3
  %arrayidx152 = getelementptr inbounds i32* %gid, i64 %indvars.iv272
  %32 = load i32* %arrayidx152, align 4, !tbaa !0
  %idxprom153 = sext i32 %32 to i64
  %arrayidx154 = getelementptr inbounds float* %Vc, i64 %idxprom153
  %33 = load float* %arrayidx154, align 4, !tbaa !3
  %add155 = fadd float %vctot.0.lcssa, %33
  store float %add155, float* %arrayidx154, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next273 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end160, label %for.body

for.end160:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl3001(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, float %tabscale, float* nocapture %VFtab, float %lambda, float* nocapture %dvdlambda, float* nocapture %chargeB) #0 {
entry:
  %sub = fsub float 1.000000e+00, %lambda
  %cmp296 = icmp sgt i32 %nri, 0
  br i1 %cmp296, label %for.body, label %for.end173

for.body:                                         ; preds = %for.end, %entry
  %indvars.iv300 = phi i64 [ 0, %entry ], [ %indvars.iv.next301, %for.end ]
  %dvdl.0297 = phi float [ 0.000000e+00, %entry ], [ %dvdl.1.lcssa, %for.end ]
  %arrayidx = getelementptr inbounds i32* %shift, i64 %indvars.iv300
  %0 = load i32* %arrayidx, align 4, !tbaa !0
  %mul = mul nsw i32 %0, 3
  %idxprom1 = sext i32 %mul to i64
  %arrayidx2 = getelementptr inbounds float* %shiftvec, i64 %idxprom1
  %1 = load float* %arrayidx2, align 4, !tbaa !3
  %add = add nsw i32 %mul, 1
  %idxprom3 = sext i32 %add to i64
  %arrayidx4 = getelementptr inbounds float* %shiftvec, i64 %idxprom3
  %2 = load float* %arrayidx4, align 4, !tbaa !3
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds float* %shiftvec, i64 %idxprom6
  %3 = load float* %arrayidx7, align 4, !tbaa !3
  %arrayidx9 = getelementptr inbounds i32* %iinr, i64 %indvars.iv300
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %arrayidx12 = getelementptr inbounds i32* %jindex, i64 %indvars.iv300
  %5 = load i32* %arrayidx12, align 4, !tbaa !0
  %indvars.iv.next301 = add i64 %indvars.iv300, 1
  %arrayidx15 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next301
  %6 = load i32* %arrayidx15, align 4, !tbaa !0
  %idxprom16 = sext i32 %mul10 to i64
  %arrayidx17 = getelementptr inbounds float* %pos, i64 %idxprom16
  %7 = load float* %arrayidx17, align 4, !tbaa !3
  %add18 = fadd float %1, %7
  %add19 = add nsw i32 %mul10, 1
  %idxprom20 = sext i32 %add19 to i64
  %arrayidx21 = getelementptr inbounds float* %pos, i64 %idxprom20
  %8 = load float* %arrayidx21, align 4, !tbaa !3
  %add22 = fadd float %2, %8
  %add23 = add nsw i32 %mul10, 2
  %idxprom24 = sext i32 %add23 to i64
  %arrayidx25 = getelementptr inbounds float* %pos, i64 %idxprom24
  %9 = load float* %arrayidx25, align 4, !tbaa !3
  %add26 = fadd float %3, %9
  %idxprom27 = sext i32 %4 to i64
  %arrayidx28 = getelementptr inbounds float* %charge, i64 %idxprom27
  %10 = load float* %arrayidx28, align 4, !tbaa !3
  %mul29 = fmul float %10, %facel
  %arrayidx31 = getelementptr inbounds float* %chargeB, i64 %idxprom27
  %11 = load float* %arrayidx31, align 4, !tbaa !3
  %mul32 = fmul float %11, %facel
  %cmp34285 = icmp slt i32 %5, %6
  br i1 %cmp34285, label %for.body35.lr.ph, label %for.end

for.body35.lr.ph:                                 ; preds = %for.body
  %12 = sext i32 %5 to i64
  br label %for.body35

for.body35:                                       ; preds = %for.body35.lr.ph, %for.body35
  %indvars.iv = phi i64 [ %12, %for.body35.lr.ph ], [ %indvars.iv.next, %for.body35 ]
  %vctot.0290 = phi float [ 0.000000e+00, %for.body35.lr.ph ], [ %add100, %for.body35 ]
  %dvdl.1289 = phi float [ %dvdl.0297, %for.body35.lr.ph ], [ %add96, %for.body35 ]
  %fix1.0288 = phi float [ 0.000000e+00, %for.body35.lr.ph ], [ %add104, %for.body35 ]
  %fiy1.0287 = phi float [ 0.000000e+00, %for.body35.lr.ph ], [ %add105, %for.body35 ]
  %fiz1.0286 = phi float [ 0.000000e+00, %for.body35.lr.ph ], [ %add106, %for.body35 ]
  %arrayidx37 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %13 = load i32* %arrayidx37, align 4, !tbaa !0
  %mul38 = mul nsw i32 %13, 3
  %idxprom39 = sext i32 %mul38 to i64
  %arrayidx40 = getelementptr inbounds float* %pos, i64 %idxprom39
  %14 = load float* %arrayidx40, align 4, !tbaa !3
  %add41 = add nsw i32 %mul38, 1
  %idxprom42 = sext i32 %add41 to i64
  %arrayidx43 = getelementptr inbounds float* %pos, i64 %idxprom42
  %15 = load float* %arrayidx43, align 4, !tbaa !3
  %add44 = add nsw i32 %mul38, 2
  %idxprom45 = sext i32 %add44 to i64
  %arrayidx46 = getelementptr inbounds float* %pos, i64 %idxprom45
  %16 = load float* %arrayidx46, align 4, !tbaa !3
  %sub47 = fsub float %add18, %14
  %sub48 = fsub float %add22, %15
  %sub49 = fsub float %add26, %16
  %mul50 = fmul float %sub47, %sub47
  %mul51 = fmul float %sub48, %sub48
  %add52 = fadd float %mul50, %mul51
  %mul53 = fmul float %sub49, %sub49
  %add54 = fadd float %add52, %mul53
  %conv = fpext float %add54 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv55 = fptrunc double %div to float
  %mul56 = fmul float %add54, %conv55
  %mul57 = fmul float %mul56, %tabscale
  %conv58 = fptosi float %mul57 to i32
  %conv59 = sitofp i32 %conv58 to float
  %sub60 = fsub float %mul57, %conv59
  %mul61 = fmul float %sub60, %sub60
  %mul62 = shl nsw i32 %conv58, 2
  %idxprom63 = sext i32 %13 to i64
  %arrayidx64 = getelementptr inbounds float* %charge, i64 %idxprom63
  %17 = load float* %arrayidx64, align 4, !tbaa !3
  %mul65 = fmul float %mul29, %17
  %arrayidx67 = getelementptr inbounds float* %chargeB, i64 %idxprom63
  %18 = load float* %arrayidx67, align 4, !tbaa !3
  %mul68 = fmul float %mul32, %18
  %mul69 = fmul float %sub, %mul65
  %mul70 = fmul float %mul68, %lambda
  %add71 = fadd float %mul69, %mul70
  %idxprom72 = sext i32 %mul62 to i64
  %arrayidx73 = getelementptr inbounds float* %VFtab, i64 %idxprom72
  %19 = load float* %arrayidx73, align 4, !tbaa !3
  %add74282 = or i32 %mul62, 1
  %idxprom75 = sext i32 %add74282 to i64
  %arrayidx76 = getelementptr inbounds float* %VFtab, i64 %idxprom75
  %20 = load float* %arrayidx76, align 4, !tbaa !3
  %add77283 = or i32 %mul62, 2
  %idxprom78 = sext i32 %add77283 to i64
  %arrayidx79 = getelementptr inbounds float* %VFtab, i64 %idxprom78
  %21 = load float* %arrayidx79, align 4, !tbaa !3
  %mul80 = fmul float %21, %sub60
  %add81284 = or i32 %mul62, 3
  %idxprom82 = sext i32 %add81284 to i64
  %arrayidx83 = getelementptr inbounds float* %VFtab, i64 %idxprom82
  %22 = load float* %arrayidx83, align 4, !tbaa !3
  %mul84 = fmul float %22, %mul61
  %add85 = fadd float %20, %mul80
  %add86 = fadd float %add85, %mul84
  %mul87 = fmul float %sub60, %add86
  %add88 = fadd float %19, %mul87
  %add89 = fadd float %mul80, %add86
  %mul90 = fmul float %mul84, 2.000000e+00
  %add91 = fadd float %mul90, %add89
  %mul92 = fmul float %add71, %add88
  %mul93 = fmul float %add71, %add91
  %sub94 = fsub float %mul68, %mul65
  %mul95 = fmul float %sub94, %add88
  %add96 = fadd float %dvdl.1289, %mul95
  %mul97 = fmul float %mul93, %tabscale
  %23 = fmul float %conv55, %mul97
  %mul99 = fsub float -0.000000e+00, %23
  %add100 = fadd float %vctot.0290, %mul92
  %mul101 = fmul float %sub47, %mul99
  %mul102 = fmul float %sub48, %mul99
  %mul103 = fmul float %sub49, %mul99
  %add104 = fadd float %fix1.0288, %mul101
  %add105 = fadd float %fiy1.0287, %mul102
  %add106 = fadd float %fiz1.0286, %mul103
  %arrayidx108 = getelementptr inbounds float* %faction, i64 %idxprom39
  %24 = load float* %arrayidx108, align 4, !tbaa !3
  %sub109 = fsub float %24, %mul101
  store float %sub109, float* %arrayidx108, align 4, !tbaa !3
  %arrayidx114 = getelementptr inbounds float* %faction, i64 %idxprom42
  %25 = load float* %arrayidx114, align 4, !tbaa !3
  %sub115 = fsub float %25, %mul102
  store float %sub115, float* %arrayidx114, align 4, !tbaa !3
  %arrayidx121 = getelementptr inbounds float* %faction, i64 %idxprom45
  %26 = load float* %arrayidx121, align 4, !tbaa !3
  %sub122 = fsub float %26, %mul103
  store float %sub122, float* %arrayidx121, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %27 = trunc i64 %indvars.iv.next to i32
  %cmp34 = icmp slt i32 %27, %6
  br i1 %cmp34, label %for.body35, label %for.end

for.end:                                          ; preds = %for.body35, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add100, %for.body35 ]
  %dvdl.1.lcssa = phi float [ %dvdl.0297, %for.body ], [ %add96, %for.body35 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add104, %for.body35 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add105, %for.body35 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add106, %for.body35 ]
  %arrayidx127 = getelementptr inbounds float* %faction, i64 %idxprom16
  %28 = load float* %arrayidx127, align 4, !tbaa !3
  %add128 = fadd float %fix1.0.lcssa, %28
  store float %add128, float* %arrayidx127, align 4, !tbaa !3
  %arrayidx133 = getelementptr inbounds float* %faction, i64 %idxprom20
  %29 = load float* %arrayidx133, align 4, !tbaa !3
  %add134 = fadd float %fiy1.0.lcssa, %29
  store float %add134, float* %arrayidx133, align 4, !tbaa !3
  %arrayidx140 = getelementptr inbounds float* %faction, i64 %idxprom24
  %30 = load float* %arrayidx140, align 4, !tbaa !3
  %add141 = fadd float %fiz1.0.lcssa, %30
  store float %add141, float* %arrayidx140, align 4, !tbaa !3
  %arrayidx146 = getelementptr inbounds float* %fshift, i64 %idxprom1
  %31 = load float* %arrayidx146, align 4, !tbaa !3
  %add147 = fadd float %fix1.0.lcssa, %31
  store float %add147, float* %arrayidx146, align 4, !tbaa !3
  %arrayidx152 = getelementptr inbounds float* %fshift, i64 %idxprom3
  %32 = load float* %arrayidx152, align 4, !tbaa !3
  %add153 = fadd float %fiy1.0.lcssa, %32
  store float %add153, float* %arrayidx152, align 4, !tbaa !3
  %arrayidx159 = getelementptr inbounds float* %fshift, i64 %idxprom6
  %33 = load float* %arrayidx159, align 4, !tbaa !3
  %add160 = fadd float %fiz1.0.lcssa, %33
  store float %add160, float* %arrayidx159, align 4, !tbaa !3
  %arrayidx165 = getelementptr inbounds i32* %gid, i64 %indvars.iv300
  %34 = load i32* %arrayidx165, align 4, !tbaa !0
  %idxprom166 = sext i32 %34 to i64
  %arrayidx167 = getelementptr inbounds float* %Vc, i64 %idxprom166
  %35 = load float* %arrayidx167, align 4, !tbaa !3
  %add168 = fadd float %vctot.0.lcssa, %35
  store float %add168, float* %arrayidx167, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next301 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end173, label %for.body

for.end173:                                       ; preds = %for.end, %entry
  %dvdl.0.lcssa = phi float [ 0.000000e+00, %entry ], [ %dvdl.1.lcssa, %for.end ]
  %36 = load float* %dvdlambda, align 4, !tbaa !3
  %add174 = fadd float %dvdl.0.lcssa, %36
  store float %add174, float* %dvdlambda, align 4, !tbaa !3
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl3002(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float %tabscale, float* nocapture %VFtab, float %lambda, float* nocapture %dvdlambda, float* nocapture %chargeB, i32* nocapture %typeB, float %Alpha, float %defsigma6) #0 {
entry:
  %sub = fsub float 1.000000e+00, %lambda
  %mul = fmul float %lambda, %lambda
  %mul1 = fmul float %sub, %sub
  %cmp503 = icmp sgt i32 %nri, 0
  br i1 %cmp503, label %for.body.lr.ph, label %for.end295

for.body.lr.ph:                                   ; preds = %entry
  %mul35 = shl nsw i32 %ntype, 1
  %mul212 = fmul float %Alpha, 0x3FD5555560000000
  %mul213 = fmul float %mul212, %lambda
  %mul214 = fmul float %sub, %mul213
  br label %for.body

for.body:                                         ; preds = %for.end, %for.body.lr.ph
  %indvars.iv507 = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next508, %for.end ]
  %dvdl.0504 = phi float [ 0.000000e+00, %for.body.lr.ph ], [ %dvdl.1.lcssa, %for.end ]
  %arrayidx = getelementptr inbounds i32* %shift, i64 %indvars.iv507
  %0 = load i32* %arrayidx, align 4, !tbaa !0
  %mul2 = mul nsw i32 %0, 3
  %idxprom3 = sext i32 %mul2 to i64
  %arrayidx4 = getelementptr inbounds float* %shiftvec, i64 %idxprom3
  %1 = load float* %arrayidx4, align 4, !tbaa !3
  %add = add nsw i32 %mul2, 1
  %idxprom5 = sext i32 %add to i64
  %arrayidx6 = getelementptr inbounds float* %shiftvec, i64 %idxprom5
  %2 = load float* %arrayidx6, align 4, !tbaa !3
  %add7 = add nsw i32 %mul2, 2
  %idxprom8 = sext i32 %add7 to i64
  %arrayidx9 = getelementptr inbounds float* %shiftvec, i64 %idxprom8
  %3 = load float* %arrayidx9, align 4, !tbaa !3
  %arrayidx11 = getelementptr inbounds i32* %iinr, i64 %indvars.iv507
  %4 = load i32* %arrayidx11, align 4, !tbaa !0
  %mul12 = mul nsw i32 %4, 3
  %arrayidx14 = getelementptr inbounds i32* %jindex, i64 %indvars.iv507
  %5 = load i32* %arrayidx14, align 4, !tbaa !0
  %indvars.iv.next508 = add i64 %indvars.iv507, 1
  %arrayidx17 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next508
  %6 = load i32* %arrayidx17, align 4, !tbaa !0
  %idxprom18 = sext i32 %mul12 to i64
  %arrayidx19 = getelementptr inbounds float* %pos, i64 %idxprom18
  %7 = load float* %arrayidx19, align 4, !tbaa !3
  %add20 = fadd float %1, %7
  %add21 = add nsw i32 %mul12, 1
  %idxprom22 = sext i32 %add21 to i64
  %arrayidx23 = getelementptr inbounds float* %pos, i64 %idxprom22
  %8 = load float* %arrayidx23, align 4, !tbaa !3
  %add24 = fadd float %2, %8
  %add25 = add nsw i32 %mul12, 2
  %idxprom26 = sext i32 %add25 to i64
  %arrayidx27 = getelementptr inbounds float* %pos, i64 %idxprom26
  %9 = load float* %arrayidx27, align 4, !tbaa !3
  %add28 = fadd float %3, %9
  %idxprom29 = sext i32 %4 to i64
  %arrayidx30 = getelementptr inbounds float* %charge, i64 %idxprom29
  %10 = load float* %arrayidx30, align 4, !tbaa !3
  %mul31 = fmul float %10, %facel
  %arrayidx33 = getelementptr inbounds float* %chargeB, i64 %idxprom29
  %11 = load float* %arrayidx33, align 4, !tbaa !3
  %mul34 = fmul float %11, %facel
  %arrayidx37 = getelementptr inbounds i32* %type, i64 %idxprom29
  %12 = load i32* %arrayidx37, align 4, !tbaa !0
  %mul38 = mul nsw i32 %12, %mul35
  %arrayidx41 = getelementptr inbounds i32* %typeB, i64 %idxprom29
  %13 = load i32* %arrayidx41, align 4, !tbaa !0
  %mul42 = mul nsw i32 %13, %mul35
  %cmp44492 = icmp slt i32 %5, %6
  br i1 %cmp44492, label %for.body45.lr.ph, label %for.end

for.body45.lr.ph:                                 ; preds = %for.body
  %14 = sext i32 %5 to i64
  br label %for.body45

for.body45:                                       ; preds = %for.body45.lr.ph, %if.end198
  %indvars.iv = phi i64 [ %14, %for.body45.lr.ph ], [ %indvars.iv.next, %if.end198 ]
  %vctot.0497 = phi float [ 0.000000e+00, %for.body45.lr.ph ], [ %add222, %if.end198 ]
  %fiz1.0496 = phi float [ 0.000000e+00, %for.body45.lr.ph ], [ %add228, %if.end198 ]
  %fiy1.0495 = phi float [ 0.000000e+00, %for.body45.lr.ph ], [ %add227, %if.end198 ]
  %fix1.0494 = phi float [ 0.000000e+00, %for.body45.lr.ph ], [ %add226, %if.end198 ]
  %dvdl.1493 = phi float [ %dvdl.0504, %for.body45.lr.ph ], [ %add221, %if.end198 ]
  %arrayidx47 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %15 = load i32* %arrayidx47, align 4, !tbaa !0
  %mul48 = mul nsw i32 %15, 3
  %idxprom49 = sext i32 %mul48 to i64
  %arrayidx50 = getelementptr inbounds float* %pos, i64 %idxprom49
  %16 = load float* %arrayidx50, align 4, !tbaa !3
  %add51 = add nsw i32 %mul48, 1
  %idxprom52 = sext i32 %add51 to i64
  %arrayidx53 = getelementptr inbounds float* %pos, i64 %idxprom52
  %17 = load float* %arrayidx53, align 4, !tbaa !3
  %add54 = add nsw i32 %mul48, 2
  %idxprom55 = sext i32 %add54 to i64
  %arrayidx56 = getelementptr inbounds float* %pos, i64 %idxprom55
  %18 = load float* %arrayidx56, align 4, !tbaa !3
  %sub57 = fsub float %add20, %16
  %sub58 = fsub float %add24, %17
  %sub59 = fsub float %add28, %18
  %mul60 = fmul float %sub57, %sub57
  %mul61 = fmul float %sub58, %sub58
  %add62 = fadd float %mul60, %mul61
  %mul63 = fmul float %sub59, %sub59
  %add64 = fadd float %add62, %mul63
  %conv = fpext float %add64 to double
  %call = tail call double @sqrt(double %conv) #2
  %idxprom67 = sext i32 %15 to i64
  %arrayidx68 = getelementptr inbounds i32* %type, i64 %idxprom67
  %19 = load i32* %arrayidx68, align 4, !tbaa !0
  %mul69 = shl nsw i32 %19, 1
  %add70 = add nsw i32 %mul69, %mul38
  %arrayidx72 = getelementptr inbounds i32* %typeB, i64 %idxprom67
  %20 = load i32* %arrayidx72, align 4, !tbaa !0
  %mul73 = shl nsw i32 %20, 1
  %add74 = add nsw i32 %mul73, %mul42
  %idxprom75 = sext i32 %add70 to i64
  %arrayidx76 = getelementptr inbounds float* %nbfp, i64 %idxprom75
  %21 = load float* %arrayidx76, align 4, !tbaa !3
  %idxprom77 = sext i32 %add74 to i64
  %arrayidx78 = getelementptr inbounds float* %nbfp, i64 %idxprom77
  %22 = load float* %arrayidx78, align 4, !tbaa !3
  %add79483 = or i32 %add70, 1
  %idxprom80 = sext i32 %add79483 to i64
  %arrayidx81 = getelementptr inbounds float* %nbfp, i64 %idxprom80
  %23 = load float* %arrayidx81, align 4, !tbaa !3
  %add82484 = or i32 %add74, 1
  %idxprom83 = sext i32 %add82484 to i64
  %arrayidx84 = getelementptr inbounds float* %nbfp, i64 %idxprom83
  %24 = load float* %arrayidx84, align 4, !tbaa !3
  %cmp85 = fcmp ogt float %21, 0.000000e+00
  %cmp87 = fcmp ogt float %23, 0.000000e+00
  %or.cond = and i1 %cmp85, %cmp87
  br i1 %or.cond, label %if.then, label %if.end

if.then:                                          ; preds = %for.body45
  %div89 = fdiv float %23, %21
  br label %if.end

if.end:                                           ; preds = %for.body45, %if.then
  %sigma6a.0 = phi float [ %div89, %if.then ], [ %defsigma6, %for.body45 ]
  %cmp90 = fcmp ogt float %22, 0.000000e+00
  %cmp93 = fcmp ogt float %24, 0.000000e+00
  %or.cond491 = and i1 %cmp90, %cmp93
  br i1 %or.cond491, label %if.then95, label %if.end98

if.then95:                                        ; preds = %if.end
  %div96 = fdiv float %24, %22
  br label %if.end98

if.end98:                                         ; preds = %if.end, %if.then95
  %sigma6b.0 = phi float [ %div96, %if.then95 ], [ %defsigma6, %if.end ]
  %mul99 = fmul float %add64, %add64
  %mul100 = fmul float %add64, %mul99
  %arrayidx102 = getelementptr inbounds float* %charge, i64 %idxprom67
  %25 = load float* %arrayidx102, align 4, !tbaa !3
  %mul103 = fmul float %mul31, %25
  %cmp104 = fcmp une float %mul103, 0.000000e+00
  br i1 %cmp104, label %if.then106, label %if.end149

if.then106:                                       ; preds = %if.end98
  %mul107 = fmul float %sigma6a.0, %Alpha
  %mul108 = fmul float %mul, %mul107
  %add109 = fadd float %mul100, %mul108
  %conv110 = fpext float %add109 to double
  %call111 = tail call double @pow(double %conv110, double 0x3FC5555560000000) #2
  %conv112 = fptrunc double %call111 to float
  %conv115 = fdiv float 1.000000e+00, %conv112
  %mul116 = fmul float %conv115, %conv115
  %mul117 = fmul float %mul116, %mul116
  %mul118 = fmul float %conv115, %mul117
  %mul119 = fmul float %conv112, %tabscale
  %conv120 = fptosi float %mul119 to i32
  %conv121 = sitofp i32 %conv120 to float
  %sub122 = fsub float %mul119, %conv121
  %mul123 = fmul float %sub122, %sub122
  %mul124 = shl nsw i32 %conv120, 2
  %idxprom125 = sext i32 %mul124 to i64
  %arrayidx126 = getelementptr inbounds float* %VFtab, i64 %idxprom125
  %26 = load float* %arrayidx126, align 4, !tbaa !3
  %add127488 = or i32 %mul124, 1
  %idxprom128 = sext i32 %add127488 to i64
  %arrayidx129 = getelementptr inbounds float* %VFtab, i64 %idxprom128
  %27 = load float* %arrayidx129, align 4, !tbaa !3
  %add130489 = or i32 %mul124, 2
  %idxprom131 = sext i32 %add130489 to i64
  %arrayidx132 = getelementptr inbounds float* %VFtab, i64 %idxprom131
  %28 = load float* %arrayidx132, align 4, !tbaa !3
  %mul133 = fmul float %28, %sub122
  %add134490 = or i32 %mul124, 3
  %idxprom135 = sext i32 %add134490 to i64
  %arrayidx136 = getelementptr inbounds float* %VFtab, i64 %idxprom135
  %29 = load float* %arrayidx136, align 4, !tbaa !3
  %mul137 = fmul float %29, %mul123
  %add138 = fadd float %27, %mul133
  %add139 = fadd float %add138, %mul137
  %mul140 = fmul float %sub122, %add139
  %add141 = fadd float %26, %mul140
  %add142 = fadd float %mul133, %add139
  %mul143 = fmul float %mul137, 2.000000e+00
  %add144 = fadd float %mul143, %add142
  %mul145 = fmul float %mul103, %add141
  %mul146 = fmul float %mul103, %tabscale
  %mul147 = fmul float %mul146, %add144
  br label %if.end149

if.end149:                                        ; preds = %if.end98, %if.then106
  %FFCa.0 = phi float [ %mul147, %if.then106 ], [ 0.000000e+00, %if.end98 ]
  %VVCa.0 = phi float [ %mul145, %if.then106 ], [ 0.000000e+00, %if.end98 ]
  %rinv5a.0 = phi float [ %mul118, %if.then106 ], [ 0.000000e+00, %if.end98 ]
  %arrayidx151 = getelementptr inbounds float* %chargeB, i64 %idxprom67
  %30 = load float* %arrayidx151, align 4, !tbaa !3
  %mul152 = fmul float %mul34, %30
  %cmp153 = fcmp une float %mul152, 0.000000e+00
  br i1 %cmp153, label %if.then155, label %if.end198

if.then155:                                       ; preds = %if.end149
  %mul156 = fmul float %sigma6b.0, %Alpha
  %mul157 = fmul float %mul1, %mul156
  %add158 = fadd float %mul100, %mul157
  %conv159 = fpext float %add158 to double
  %call160 = tail call double @pow(double %conv159, double 0x3FC5555560000000) #2
  %conv161 = fptrunc double %call160 to float
  %conv164 = fdiv float 1.000000e+00, %conv161
  %mul165 = fmul float %conv164, %conv164
  %mul166 = fmul float %mul165, %mul165
  %mul167 = fmul float %conv164, %mul166
  %mul168 = fmul float %conv161, %tabscale
  %conv169 = fptosi float %mul168 to i32
  %conv170 = sitofp i32 %conv169 to float
  %sub171 = fsub float %mul168, %conv170
  %mul172 = fmul float %sub171, %sub171
  %mul173 = shl nsw i32 %conv169, 2
  %idxprom174 = sext i32 %mul173 to i64
  %arrayidx175 = getelementptr inbounds float* %VFtab, i64 %idxprom174
  %31 = load float* %arrayidx175, align 4, !tbaa !3
  %add176485 = or i32 %mul173, 1
  %idxprom177 = sext i32 %add176485 to i64
  %arrayidx178 = getelementptr inbounds float* %VFtab, i64 %idxprom177
  %32 = load float* %arrayidx178, align 4, !tbaa !3
  %add179486 = or i32 %mul173, 2
  %idxprom180 = sext i32 %add179486 to i64
  %arrayidx181 = getelementptr inbounds float* %VFtab, i64 %idxprom180
  %33 = load float* %arrayidx181, align 4, !tbaa !3
  %mul182 = fmul float %33, %sub171
  %add183487 = or i32 %mul173, 3
  %idxprom184 = sext i32 %add183487 to i64
  %arrayidx185 = getelementptr inbounds float* %VFtab, i64 %idxprom184
  %34 = load float* %arrayidx185, align 4, !tbaa !3
  %mul186 = fmul float %34, %mul172
  %add187 = fadd float %32, %mul182
  %add188 = fadd float %add187, %mul186
  %mul189 = fmul float %sub171, %add188
  %add190 = fadd float %31, %mul189
  %add191 = fadd float %mul182, %add188
  %mul192 = fmul float %mul186, 2.000000e+00
  %add193 = fadd float %mul192, %add191
  %mul194 = fmul float %mul152, %add190
  %mul195 = fmul float %mul152, %tabscale
  %mul196 = fmul float %mul195, %add193
  br label %if.end198

if.end198:                                        ; preds = %if.end149, %if.then155
  %FFCb.0 = phi float [ %mul196, %if.then155 ], [ 0.000000e+00, %if.end149 ]
  %VVCb.0 = phi float [ %mul194, %if.then155 ], [ 0.000000e+00, %if.end149 ]
  %rinv5b.0 = phi float [ %mul167, %if.then155 ], [ 0.000000e+00, %if.end149 ]
  %mul199 = fmul float %VVCb.0, %lambda
  %mul200 = fmul float %sub, %VVCa.0
  %add201 = fadd float %mul200, %mul199
  %sub202 = fsub float -0.000000e+00, %FFCa.0
  %sub203 = fsub float -0.000000e+00, %FFCb.0
  %mul204 = fmul float %sub, %sub202
  %mul205 = fmul float %mul204, %rinv5a.0
  %mul206 = fmul float %lambda, %sub203
  %mul207 = fmul float %mul206, %rinv5b.0
  %add208 = fadd float %mul205, %mul207
  %mul209 = fmul float %mul99, %add208
  %add210 = fadd float %dvdl.1493, %VVCb.0
  %sub211 = fsub float %add210, %VVCa.0
  %mul215 = fmul float %sigma6b.0, %sub203
  %mul216 = fmul float %mul215, %rinv5b.0
  %mul217 = fmul float %sigma6a.0, %sub202
  %mul218 = fmul float %mul217, %rinv5a.0
  %sub219 = fsub float %mul216, %mul218
  %mul220 = fmul float %mul214, %sub219
  %add221 = fadd float %sub211, %mul220
  %add222 = fadd float %vctot.0497, %add201
  %mul223 = fmul float %sub57, %mul209
  %mul224 = fmul float %sub58, %mul209
  %mul225 = fmul float %sub59, %mul209
  %add226 = fadd float %fix1.0494, %mul223
  %add227 = fadd float %fiy1.0495, %mul224
  %add228 = fadd float %fiz1.0496, %mul225
  %arrayidx230 = getelementptr inbounds float* %faction, i64 %idxprom49
  %35 = load float* %arrayidx230, align 4, !tbaa !3
  %sub231 = fsub float %35, %mul223
  store float %sub231, float* %arrayidx230, align 4, !tbaa !3
  %arrayidx236 = getelementptr inbounds float* %faction, i64 %idxprom52
  %36 = load float* %arrayidx236, align 4, !tbaa !3
  %sub237 = fsub float %36, %mul224
  store float %sub237, float* %arrayidx236, align 4, !tbaa !3
  %arrayidx243 = getelementptr inbounds float* %faction, i64 %idxprom55
  %37 = load float* %arrayidx243, align 4, !tbaa !3
  %sub244 = fsub float %37, %mul225
  store float %sub244, float* %arrayidx243, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %38 = trunc i64 %indvars.iv.next to i32
  %cmp44 = icmp slt i32 %38, %6
  br i1 %cmp44, label %for.body45, label %for.end

for.end:                                          ; preds = %if.end198, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add222, %if.end198 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add228, %if.end198 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add227, %if.end198 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add226, %if.end198 ]
  %dvdl.1.lcssa = phi float [ %dvdl.0504, %for.body ], [ %add221, %if.end198 ]
  %arrayidx249 = getelementptr inbounds float* %faction, i64 %idxprom18
  %39 = load float* %arrayidx249, align 4, !tbaa !3
  %add250 = fadd float %fix1.0.lcssa, %39
  store float %add250, float* %arrayidx249, align 4, !tbaa !3
  %arrayidx255 = getelementptr inbounds float* %faction, i64 %idxprom22
  %40 = load float* %arrayidx255, align 4, !tbaa !3
  %add256 = fadd float %fiy1.0.lcssa, %40
  store float %add256, float* %arrayidx255, align 4, !tbaa !3
  %arrayidx262 = getelementptr inbounds float* %faction, i64 %idxprom26
  %41 = load float* %arrayidx262, align 4, !tbaa !3
  %add263 = fadd float %fiz1.0.lcssa, %41
  store float %add263, float* %arrayidx262, align 4, !tbaa !3
  %arrayidx268 = getelementptr inbounds float* %fshift, i64 %idxprom3
  %42 = load float* %arrayidx268, align 4, !tbaa !3
  %add269 = fadd float %fix1.0.lcssa, %42
  store float %add269, float* %arrayidx268, align 4, !tbaa !3
  %arrayidx274 = getelementptr inbounds float* %fshift, i64 %idxprom5
  %43 = load float* %arrayidx274, align 4, !tbaa !3
  %add275 = fadd float %fiy1.0.lcssa, %43
  store float %add275, float* %arrayidx274, align 4, !tbaa !3
  %arrayidx281 = getelementptr inbounds float* %fshift, i64 %idxprom8
  %44 = load float* %arrayidx281, align 4, !tbaa !3
  %add282 = fadd float %fiz1.0.lcssa, %44
  store float %add282, float* %arrayidx281, align 4, !tbaa !3
  %arrayidx287 = getelementptr inbounds i32* %gid, i64 %indvars.iv507
  %45 = load i32* %arrayidx287, align 4, !tbaa !0
  %idxprom288 = sext i32 %45 to i64
  %arrayidx289 = getelementptr inbounds float* %Vc, i64 %idxprom288
  %46 = load float* %arrayidx289, align 4, !tbaa !3
  %add290 = fadd float %vctot.0.lcssa, %46
  store float %add290, float* %arrayidx289, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next508 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end295, label %for.body

for.end295:                                       ; preds = %for.end, %entry
  %dvdl.0.lcssa = phi float [ 0.000000e+00, %entry ], [ %dvdl.1.lcssa, %for.end ]
  %47 = load float* %dvdlambda, align 4, !tbaa !3
  %add296 = fadd float %dvdl.0.lcssa, %47
  store float %add296, float* %dvdlambda, align 4, !tbaa !3
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl3010(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, float %tabscale, float* nocapture %VFtab, i32* nocapture %nsatoms) #0 {
entry:
  %cmp303 = icmp sgt i32 %nri, 0
  br i1 %cmp303, label %for.body, label %for.end179

for.body:                                         ; preds = %for.end169, %entry
  %indvars.iv311 = phi i64 [ 0, %entry ], [ %indvars.iv.next312, %for.end169 ]
  %add5 = mul i64 %indvars.iv311, 12884901888
  %sext = add i64 %add5, 8589934592
  %idxprom6 = ashr exact i64 %sext, 32
  %arrayidx7 = getelementptr inbounds i32* %nsatoms, i64 %idxprom6
  %0 = load i32* %arrayidx7, align 4, !tbaa !0
  %arrayidx9 = getelementptr inbounds i32* %shift, i64 %indvars.iv311
  %1 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %1, 3
  %idxprom11 = sext i32 %mul10 to i64
  %arrayidx12 = getelementptr inbounds float* %shiftvec, i64 %idxprom11
  %2 = load float* %arrayidx12, align 4, !tbaa !3
  %add13 = add nsw i32 %mul10, 1
  %idxprom14 = sext i32 %add13 to i64
  %arrayidx15 = getelementptr inbounds float* %shiftvec, i64 %idxprom14
  %3 = load float* %arrayidx15, align 4, !tbaa !3
  %add16 = add nsw i32 %mul10, 2
  %idxprom17 = sext i32 %add16 to i64
  %arrayidx18 = getelementptr inbounds float* %shiftvec, i64 %idxprom17
  %4 = load float* %arrayidx18, align 4, !tbaa !3
  %arrayidx20 = getelementptr inbounds i32* %iinr, i64 %indvars.iv311
  %5 = load i32* %arrayidx20, align 4, !tbaa !0
  %arrayidx23 = getelementptr inbounds i32* %jindex, i64 %indvars.iv311
  %6 = load i32* %arrayidx23, align 4, !tbaa !0
  %indvars.iv.next312 = add i64 %indvars.iv311, 1
  %arrayidx26 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next312
  %7 = load i32* %arrayidx26, align 4, !tbaa !0
  %cmp28297 = icmp sgt i32 %0, 0
  br i1 %cmp28297, label %for.body29.lr.ph, label %for.end169

for.body29.lr.ph:                                 ; preds = %for.body
  %cmp45288 = icmp slt i32 %6, %7
  %arrayidx147 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx153 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx160 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %8 = sext i32 %6 to i64
  %9 = sext i32 %5 to i64
  %10 = mul i32 %5, 3
  %11 = sext i32 %10 to i64
  br label %for.body29

for.body29:                                       ; preds = %for.end, %for.body29.lr.ph
  %indvars.iv307 = phi i64 [ %11, %for.body29.lr.ph ], [ %indvars.iv.next308, %for.end ]
  %indvars.iv305 = phi i64 [ %9, %for.body29.lr.ph ], [ %indvars.iv.next306, %for.end ]
  %s.0299 = phi i32 [ 0, %for.body29.lr.ph ], [ %inc168, %for.end ]
  %vctot.0298 = phi float [ 0.000000e+00, %for.body29.lr.ph ], [ %vctot.1.lcssa, %for.end ]
  %arrayidx31 = getelementptr inbounds float* %pos, i64 %indvars.iv307
  %12 = load float* %arrayidx31, align 4, !tbaa !3
  %add32 = fadd float %2, %12
  %13 = add nsw i64 %indvars.iv307, 1
  %arrayidx35 = getelementptr inbounds float* %pos, i64 %13
  %14 = load float* %arrayidx35, align 4, !tbaa !3
  %add36 = fadd float %3, %14
  %15 = add nsw i64 %indvars.iv307, 2
  %arrayidx39 = getelementptr inbounds float* %pos, i64 %15
  %16 = load float* %arrayidx39, align 4, !tbaa !3
  %add40 = fadd float %4, %16
  %arrayidx42 = getelementptr inbounds float* %charge, i64 %indvars.iv305
  %17 = load float* %arrayidx42, align 4, !tbaa !3
  %mul43 = fmul float %17, %facel
  br i1 %cmp45288, label %for.body46, label %for.end

for.body46:                                       ; preds = %for.body29, %for.body46
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body46 ], [ %8, %for.body29 ]
  %vctot.1292 = phi float [ %add101, %for.body46 ], [ %vctot.0298, %for.body29 ]
  %fix1.0291 = phi float [ %add105, %for.body46 ], [ 0.000000e+00, %for.body29 ]
  %fiy1.0290 = phi float [ %add106, %for.body46 ], [ 0.000000e+00, %for.body29 ]
  %fiz1.0289 = phi float [ %add107, %for.body46 ], [ 0.000000e+00, %for.body29 ]
  %arrayidx48 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %18 = load i32* %arrayidx48, align 4, !tbaa !0
  %mul49 = mul nsw i32 %18, 3
  %idxprom50 = sext i32 %mul49 to i64
  %arrayidx51 = getelementptr inbounds float* %pos, i64 %idxprom50
  %19 = load float* %arrayidx51, align 4, !tbaa !3
  %add52 = add nsw i32 %mul49, 1
  %idxprom53 = sext i32 %add52 to i64
  %arrayidx54 = getelementptr inbounds float* %pos, i64 %idxprom53
  %20 = load float* %arrayidx54, align 4, !tbaa !3
  %add55 = add nsw i32 %mul49, 2
  %idxprom56 = sext i32 %add55 to i64
  %arrayidx57 = getelementptr inbounds float* %pos, i64 %idxprom56
  %21 = load float* %arrayidx57, align 4, !tbaa !3
  %sub = fsub float %add32, %19
  %sub58 = fsub float %add36, %20
  %sub59 = fsub float %add40, %21
  %mul60 = fmul float %sub, %sub
  %mul61 = fmul float %sub58, %sub58
  %add62 = fadd float %mul60, %mul61
  %mul63 = fmul float %sub59, %sub59
  %add64 = fadd float %add62, %mul63
  %conv = fpext float %add64 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv65 = fptrunc double %div to float
  %mul66 = fmul float %add64, %conv65
  %mul67 = fmul float %mul66, %tabscale
  %conv68 = fptosi float %mul67 to i32
  %conv69 = sitofp i32 %conv68 to float
  %sub70 = fsub float %mul67, %conv69
  %mul71 = fmul float %sub70, %sub70
  %mul72 = shl nsw i32 %conv68, 2
  %idxprom73 = sext i32 %18 to i64
  %arrayidx74 = getelementptr inbounds float* %charge, i64 %idxprom73
  %22 = load float* %arrayidx74, align 4, !tbaa !3
  %mul75 = fmul float %mul43, %22
  %idxprom76 = sext i32 %mul72 to i64
  %arrayidx77 = getelementptr inbounds float* %VFtab, i64 %idxprom76
  %23 = load float* %arrayidx77, align 4, !tbaa !3
  %add78285 = or i32 %mul72, 1
  %idxprom79 = sext i32 %add78285 to i64
  %arrayidx80 = getelementptr inbounds float* %VFtab, i64 %idxprom79
  %24 = load float* %arrayidx80, align 4, !tbaa !3
  %add81286 = or i32 %mul72, 2
  %idxprom82 = sext i32 %add81286 to i64
  %arrayidx83 = getelementptr inbounds float* %VFtab, i64 %idxprom82
  %25 = load float* %arrayidx83, align 4, !tbaa !3
  %mul84 = fmul float %25, %sub70
  %add85287 = or i32 %mul72, 3
  %idxprom86 = sext i32 %add85287 to i64
  %arrayidx87 = getelementptr inbounds float* %VFtab, i64 %idxprom86
  %26 = load float* %arrayidx87, align 4, !tbaa !3
  %mul88 = fmul float %26, %mul71
  %add89 = fadd float %24, %mul84
  %add90 = fadd float %add89, %mul88
  %mul91 = fmul float %sub70, %add90
  %add92 = fadd float %23, %mul91
  %add93 = fadd float %mul84, %add90
  %mul94 = fmul float %mul88, 2.000000e+00
  %add95 = fadd float %mul94, %add93
  %mul96 = fmul float %mul75, %add92
  %mul97 = fmul float %mul75, %add95
  %mul98 = fmul float %mul97, %tabscale
  %27 = fmul float %conv65, %mul98
  %mul100 = fsub float -0.000000e+00, %27
  %add101 = fadd float %vctot.1292, %mul96
  %mul102 = fmul float %sub, %mul100
  %mul103 = fmul float %sub58, %mul100
  %mul104 = fmul float %sub59, %mul100
  %add105 = fadd float %fix1.0291, %mul102
  %add106 = fadd float %fiy1.0290, %mul103
  %add107 = fadd float %fiz1.0289, %mul104
  %arrayidx109 = getelementptr inbounds float* %faction, i64 %idxprom50
  %28 = load float* %arrayidx109, align 4, !tbaa !3
  %sub110 = fsub float %28, %mul102
  store float %sub110, float* %arrayidx109, align 4, !tbaa !3
  %arrayidx115 = getelementptr inbounds float* %faction, i64 %idxprom53
  %29 = load float* %arrayidx115, align 4, !tbaa !3
  %sub116 = fsub float %29, %mul103
  store float %sub116, float* %arrayidx115, align 4, !tbaa !3
  %arrayidx122 = getelementptr inbounds float* %faction, i64 %idxprom56
  %30 = load float* %arrayidx122, align 4, !tbaa !3
  %sub123 = fsub float %30, %mul104
  store float %sub123, float* %arrayidx122, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %31 = trunc i64 %indvars.iv.next to i32
  %cmp45 = icmp slt i32 %31, %7
  br i1 %cmp45, label %for.body46, label %for.end

for.end:                                          ; preds = %for.body46, %for.body29
  %vctot.1.lcssa = phi float [ %vctot.0298, %for.body29 ], [ %add101, %for.body46 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add105, %for.body46 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add106, %for.body46 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add107, %for.body46 ]
  %arrayidx128 = getelementptr inbounds float* %faction, i64 %indvars.iv307
  %32 = load float* %arrayidx128, align 4, !tbaa !3
  %add129 = fadd float %fix1.0.lcssa, %32
  store float %add129, float* %arrayidx128, align 4, !tbaa !3
  %arrayidx134 = getelementptr inbounds float* %faction, i64 %13
  %33 = load float* %arrayidx134, align 4, !tbaa !3
  %add135 = fadd float %fiy1.0.lcssa, %33
  store float %add135, float* %arrayidx134, align 4, !tbaa !3
  %arrayidx141 = getelementptr inbounds float* %faction, i64 %15
  %34 = load float* %arrayidx141, align 4, !tbaa !3
  %add142 = fadd float %fiz1.0.lcssa, %34
  store float %add142, float* %arrayidx141, align 4, !tbaa !3
  %35 = load float* %arrayidx147, align 4, !tbaa !3
  %add148 = fadd float %fix1.0.lcssa, %35
  store float %add148, float* %arrayidx147, align 4, !tbaa !3
  %36 = load float* %arrayidx153, align 4, !tbaa !3
  %add154 = fadd float %fiy1.0.lcssa, %36
  store float %add154, float* %arrayidx153, align 4, !tbaa !3
  %37 = load float* %arrayidx160, align 4, !tbaa !3
  %add161 = fadd float %fiz1.0.lcssa, %37
  store float %add161, float* %arrayidx160, align 4, !tbaa !3
  %indvars.iv.next306 = add i64 %indvars.iv305, 1
  %indvars.iv.next308 = add i64 %indvars.iv307, 3
  %inc168 = add nsw i32 %s.0299, 1
  %exitcond = icmp eq i32 %inc168, %0
  br i1 %exitcond, label %for.end169, label %for.body29

for.end169:                                       ; preds = %for.end, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %vctot.1.lcssa, %for.end ]
  %arrayidx171 = getelementptr inbounds i32* %gid, i64 %indvars.iv311
  %38 = load i32* %arrayidx171, align 4, !tbaa !0
  %idxprom172 = sext i32 %38 to i64
  %arrayidx173 = getelementptr inbounds float* %Vc, i64 %idxprom172
  %39 = load float* %arrayidx173, align 4, !tbaa !3
  %add174 = fadd float %vctot.0.lcssa, %39
  store float %add174, float* %arrayidx173, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next312 to i32
  %exitcond313 = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond313, label %for.end179, label %for.body

for.end179:                                       ; preds = %for.end169, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl3020(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, float %tabscale, float* nocapture %VFtab) #0 {
entry:
  %0 = load i32* %iinr, align 4, !tbaa !0
  %idxprom = sext i32 %0 to i64
  %arrayidx1 = getelementptr inbounds float* %charge, i64 %idxprom
  %1 = load float* %arrayidx1, align 4, !tbaa !3
  %add = add nsw i32 %0, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds float* %charge, i64 %idxprom2
  %2 = load float* %arrayidx3, align 4, !tbaa !3
  %mul = fmul float %1, %facel
  %mul4 = fmul float %2, %facel
  %cmp649 = icmp sgt i32 %nri, 0
  br i1 %cmp649, label %for.body, label %for.end351

for.body:                                         ; preds = %entry, %for.end.for.body_crit_edge
  %3 = phi i32 [ %.pre, %for.end.for.body_crit_edge ], [ %0, %entry ]
  %indvars.iv651 = phi i64 [ %indvars.iv.next652, %for.end.for.body_crit_edge ], [ 0, %entry ]
  %arrayidx6 = getelementptr inbounds i32* %shift, i64 %indvars.iv651
  %4 = load i32* %arrayidx6, align 4, !tbaa !0
  %mul7 = mul nsw i32 %4, 3
  %idxprom8 = sext i32 %mul7 to i64
  %arrayidx9 = getelementptr inbounds float* %shiftvec, i64 %idxprom8
  %5 = load float* %arrayidx9, align 4, !tbaa !3
  %add10 = add nsw i32 %mul7, 1
  %idxprom11 = sext i32 %add10 to i64
  %arrayidx12 = getelementptr inbounds float* %shiftvec, i64 %idxprom11
  %6 = load float* %arrayidx12, align 4, !tbaa !3
  %add13 = add nsw i32 %mul7, 2
  %idxprom14 = sext i32 %add13 to i64
  %arrayidx15 = getelementptr inbounds float* %shiftvec, i64 %idxprom14
  %7 = load float* %arrayidx15, align 4, !tbaa !3
  %mul18 = mul nsw i32 %3, 3
  %arrayidx20 = getelementptr inbounds i32* %jindex, i64 %indvars.iv651
  %8 = load i32* %arrayidx20, align 4, !tbaa !0
  %indvars.iv.next652 = add i64 %indvars.iv651, 1
  %arrayidx23 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next652
  %9 = load i32* %arrayidx23, align 4, !tbaa !0
  %idxprom24 = sext i32 %mul18 to i64
  %arrayidx25 = getelementptr inbounds float* %pos, i64 %idxprom24
  %10 = load float* %arrayidx25, align 4, !tbaa !3
  %add26 = fadd float %5, %10
  %add27 = add nsw i32 %mul18, 1
  %idxprom28 = sext i32 %add27 to i64
  %arrayidx29 = getelementptr inbounds float* %pos, i64 %idxprom28
  %11 = load float* %arrayidx29, align 4, !tbaa !3
  %add30 = fadd float %6, %11
  %add31 = add nsw i32 %mul18, 2
  %idxprom32 = sext i32 %add31 to i64
  %arrayidx33 = getelementptr inbounds float* %pos, i64 %idxprom32
  %12 = load float* %arrayidx33, align 4, !tbaa !3
  %add34 = fadd float %7, %12
  %add35 = add nsw i32 %mul18, 3
  %idxprom36 = sext i32 %add35 to i64
  %arrayidx37 = getelementptr inbounds float* %pos, i64 %idxprom36
  %13 = load float* %arrayidx37, align 4, !tbaa !3
  %add38 = fadd float %5, %13
  %add39 = add nsw i32 %mul18, 4
  %idxprom40 = sext i32 %add39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %14 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = fadd float %6, %14
  %add43 = add nsw i32 %mul18, 5
  %idxprom44 = sext i32 %add43 to i64
  %arrayidx45 = getelementptr inbounds float* %pos, i64 %idxprom44
  %15 = load float* %arrayidx45, align 4, !tbaa !3
  %add46 = fadd float %7, %15
  %add47 = add nsw i32 %mul18, 6
  %idxprom48 = sext i32 %add47 to i64
  %arrayidx49 = getelementptr inbounds float* %pos, i64 %idxprom48
  %16 = load float* %arrayidx49, align 4, !tbaa !3
  %add50 = fadd float %5, %16
  %add51 = add nsw i32 %mul18, 7
  %idxprom52 = sext i32 %add51 to i64
  %arrayidx53 = getelementptr inbounds float* %pos, i64 %idxprom52
  %17 = load float* %arrayidx53, align 4, !tbaa !3
  %add54 = fadd float %6, %17
  %add55 = add nsw i32 %mul18, 8
  %idxprom56 = sext i32 %add55 to i64
  %arrayidx57 = getelementptr inbounds float* %pos, i64 %idxprom56
  %18 = load float* %arrayidx57, align 4, !tbaa !3
  %add58 = fadd float %7, %18
  %cmp60628 = icmp slt i32 %8, %9
  br i1 %cmp60628, label %for.body61.lr.ph, label %for.end

for.body61.lr.ph:                                 ; preds = %for.body
  %19 = sext i32 %8 to i64
  br label %for.body61

for.body61:                                       ; preds = %for.body61.lr.ph, %for.body61
  %indvars.iv = phi i64 [ %19, %for.body61.lr.ph ], [ %indvars.iv.next, %for.body61 ]
  %vctot.0638 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add238, %for.body61 ]
  %fix1.0637 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add144, %for.body61 ]
  %fiy1.0636 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add145, %for.body61 ]
  %fiz1.0635 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add146, %for.body61 ]
  %fix2.0634 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add197, %for.body61 ]
  %fiy2.0633 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add198, %for.body61 ]
  %fiz2.0632 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add199, %for.body61 ]
  %fix3.0631 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add242, %for.body61 ]
  %fiy3.0630 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add243, %for.body61 ]
  %fiz3.0629 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add244, %for.body61 ]
  %arrayidx63 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %20 = load i32* %arrayidx63, align 4, !tbaa !0
  %mul64 = mul nsw i32 %20, 3
  %idxprom65 = sext i32 %mul64 to i64
  %arrayidx66 = getelementptr inbounds float* %pos, i64 %idxprom65
  %21 = load float* %arrayidx66, align 4, !tbaa !3
  %add67 = add nsw i32 %mul64, 1
  %idxprom68 = sext i32 %add67 to i64
  %arrayidx69 = getelementptr inbounds float* %pos, i64 %idxprom68
  %22 = load float* %arrayidx69, align 4, !tbaa !3
  %add70 = add nsw i32 %mul64, 2
  %idxprom71 = sext i32 %add70 to i64
  %arrayidx72 = getelementptr inbounds float* %pos, i64 %idxprom71
  %23 = load float* %arrayidx72, align 4, !tbaa !3
  %sub = fsub float %add26, %21
  %sub73 = fsub float %add30, %22
  %sub74 = fsub float %add34, %23
  %mul75 = fmul float %sub, %sub
  %mul76 = fmul float %sub73, %sub73
  %add77 = fadd float %mul75, %mul76
  %mul78 = fmul float %sub74, %sub74
  %add79 = fadd float %add77, %mul78
  %sub80 = fsub float %add38, %21
  %sub81 = fsub float %add42, %22
  %sub82 = fsub float %add46, %23
  %mul83 = fmul float %sub80, %sub80
  %mul84 = fmul float %sub81, %sub81
  %add85 = fadd float %mul83, %mul84
  %mul86 = fmul float %sub82, %sub82
  %add87 = fadd float %add85, %mul86
  %sub88 = fsub float %add50, %21
  %sub89 = fsub float %add54, %22
  %sub90 = fsub float %add58, %23
  %mul91 = fmul float %sub88, %sub88
  %mul92 = fmul float %sub89, %sub89
  %add93 = fadd float %mul91, %mul92
  %mul94 = fmul float %sub90, %sub90
  %add95 = fadd float %add93, %mul94
  %conv = fpext float %add79 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv96 = fptrunc double %div to float
  %conv97 = fpext float %add87 to double
  %call98 = tail call double @sqrt(double %conv97) #2
  %div99 = fdiv double 1.000000e+00, %call98
  %conv100 = fptrunc double %div99 to float
  %conv101 = fpext float %add95 to double
  %call102 = tail call double @sqrt(double %conv101) #2
  %div103 = fdiv double 1.000000e+00, %call102
  %conv104 = fptrunc double %div103 to float
  %mul105 = fmul float %add79, %conv96
  %mul106 = fmul float %mul105, %tabscale
  %conv107 = fptosi float %mul106 to i32
  %conv108 = sitofp i32 %conv107 to float
  %sub109 = fsub float %mul106, %conv108
  %mul110 = fmul float %sub109, %sub109
  %mul111 = shl nsw i32 %conv107, 2
  %idxprom112 = sext i32 %20 to i64
  %arrayidx113 = getelementptr inbounds float* %charge, i64 %idxprom112
  %24 = load float* %arrayidx113, align 4, !tbaa !3
  %mul114 = fmul float %mul, %24
  %idxprom115 = sext i32 %mul111 to i64
  %arrayidx116 = getelementptr inbounds float* %VFtab, i64 %idxprom115
  %25 = load float* %arrayidx116, align 4, !tbaa !3
  %add117619 = or i32 %mul111, 1
  %idxprom118 = sext i32 %add117619 to i64
  %arrayidx119 = getelementptr inbounds float* %VFtab, i64 %idxprom118
  %26 = load float* %arrayidx119, align 4, !tbaa !3
  %add120620 = or i32 %mul111, 2
  %idxprom121 = sext i32 %add120620 to i64
  %arrayidx122 = getelementptr inbounds float* %VFtab, i64 %idxprom121
  %27 = load float* %arrayidx122, align 4, !tbaa !3
  %mul123 = fmul float %sub109, %27
  %add124621 = or i32 %mul111, 3
  %idxprom125 = sext i32 %add124621 to i64
  %arrayidx126 = getelementptr inbounds float* %VFtab, i64 %idxprom125
  %28 = load float* %arrayidx126, align 4, !tbaa !3
  %mul127 = fmul float %mul110, %28
  %add128 = fadd float %26, %mul123
  %add129 = fadd float %add128, %mul127
  %mul130 = fmul float %sub109, %add129
  %add131 = fadd float %25, %mul130
  %add132 = fadd float %mul123, %add129
  %mul133 = fmul float %mul127, 2.000000e+00
  %add134 = fadd float %mul133, %add132
  %mul135 = fmul float %mul114, %add131
  %mul136 = fmul float %mul114, %add134
  %mul137 = fmul float %mul136, %tabscale
  %29 = fmul float %conv96, %mul137
  %mul139 = fsub float -0.000000e+00, %29
  %add140 = fadd float %vctot.0638, %mul135
  %mul141 = fmul float %sub, %mul139
  %mul142 = fmul float %sub73, %mul139
  %mul143 = fmul float %sub74, %mul139
  %add144 = fadd float %fix1.0637, %mul141
  %add145 = fadd float %fiy1.0636, %mul142
  %add146 = fadd float %fiz1.0635, %mul143
  %arrayidx148 = getelementptr inbounds float* %faction, i64 %idxprom65
  %30 = load float* %arrayidx148, align 4, !tbaa !3
  %sub149 = fsub float %30, %mul141
  %arrayidx152 = getelementptr inbounds float* %faction, i64 %idxprom68
  %31 = load float* %arrayidx152, align 4, !tbaa !3
  %sub153 = fsub float %31, %mul142
  %arrayidx156 = getelementptr inbounds float* %faction, i64 %idxprom71
  %32 = load float* %arrayidx156, align 4, !tbaa !3
  %sub157 = fsub float %32, %mul143
  %mul158 = fmul float %add87, %conv100
  %mul159 = fmul float %mul158, %tabscale
  %conv160 = fptosi float %mul159 to i32
  %conv161 = sitofp i32 %conv160 to float
  %sub162 = fsub float %mul159, %conv161
  %mul163 = fmul float %sub162, %sub162
  %mul164 = shl nsw i32 %conv160, 2
  %mul167 = fmul float %mul4, %24
  %idxprom168 = sext i32 %mul164 to i64
  %arrayidx169 = getelementptr inbounds float* %VFtab, i64 %idxprom168
  %33 = load float* %arrayidx169, align 4, !tbaa !3
  %add170622 = or i32 %mul164, 1
  %idxprom171 = sext i32 %add170622 to i64
  %arrayidx172 = getelementptr inbounds float* %VFtab, i64 %idxprom171
  %34 = load float* %arrayidx172, align 4, !tbaa !3
  %add173623 = or i32 %mul164, 2
  %idxprom174 = sext i32 %add173623 to i64
  %arrayidx175 = getelementptr inbounds float* %VFtab, i64 %idxprom174
  %35 = load float* %arrayidx175, align 4, !tbaa !3
  %mul176 = fmul float %sub162, %35
  %add177624 = or i32 %mul164, 3
  %idxprom178 = sext i32 %add177624 to i64
  %arrayidx179 = getelementptr inbounds float* %VFtab, i64 %idxprom178
  %36 = load float* %arrayidx179, align 4, !tbaa !3
  %mul180 = fmul float %mul163, %36
  %add181 = fadd float %34, %mul176
  %add182 = fadd float %add181, %mul180
  %mul183 = fmul float %sub162, %add182
  %add184 = fadd float %33, %mul183
  %add185 = fadd float %mul176, %add182
  %mul186 = fmul float %mul180, 2.000000e+00
  %add187 = fadd float %mul186, %add185
  %mul188 = fmul float %mul167, %add184
  %mul189 = fmul float %mul167, %add187
  %mul190 = fmul float %mul189, %tabscale
  %37 = fmul float %conv100, %mul190
  %mul192 = fsub float -0.000000e+00, %37
  %add193 = fadd float %add140, %mul188
  %mul194 = fmul float %sub80, %mul192
  %mul195 = fmul float %sub81, %mul192
  %mul196 = fmul float %sub82, %mul192
  %add197 = fadd float %fix2.0634, %mul194
  %add198 = fadd float %fiy2.0633, %mul195
  %add199 = fadd float %fiz2.0632, %mul196
  %sub200 = fsub float %sub149, %mul194
  %sub201 = fsub float %sub153, %mul195
  %sub202 = fsub float %sub157, %mul196
  %mul203 = fmul float %add95, %conv104
  %mul204 = fmul float %mul203, %tabscale
  %conv205 = fptosi float %mul204 to i32
  %conv206 = sitofp i32 %conv205 to float
  %sub207 = fsub float %mul204, %conv206
  %mul208 = fmul float %sub207, %sub207
  %mul209 = shl nsw i32 %conv205, 2
  %idxprom213 = sext i32 %mul209 to i64
  %arrayidx214 = getelementptr inbounds float* %VFtab, i64 %idxprom213
  %38 = load float* %arrayidx214, align 4, !tbaa !3
  %add215625 = or i32 %mul209, 1
  %idxprom216 = sext i32 %add215625 to i64
  %arrayidx217 = getelementptr inbounds float* %VFtab, i64 %idxprom216
  %39 = load float* %arrayidx217, align 4, !tbaa !3
  %add218626 = or i32 %mul209, 2
  %idxprom219 = sext i32 %add218626 to i64
  %arrayidx220 = getelementptr inbounds float* %VFtab, i64 %idxprom219
  %40 = load float* %arrayidx220, align 4, !tbaa !3
  %mul221 = fmul float %sub207, %40
  %add222627 = or i32 %mul209, 3
  %idxprom223 = sext i32 %add222627 to i64
  %arrayidx224 = getelementptr inbounds float* %VFtab, i64 %idxprom223
  %41 = load float* %arrayidx224, align 4, !tbaa !3
  %mul225 = fmul float %mul208, %41
  %add226 = fadd float %39, %mul221
  %add227 = fadd float %add226, %mul225
  %mul228 = fmul float %sub207, %add227
  %add229 = fadd float %38, %mul228
  %add230 = fadd float %mul221, %add227
  %mul231 = fmul float %mul225, 2.000000e+00
  %add232 = fadd float %mul231, %add230
  %mul233 = fmul float %mul167, %add229
  %mul234 = fmul float %mul167, %add232
  %mul235 = fmul float %mul234, %tabscale
  %42 = fmul float %conv104, %mul235
  %mul237 = fsub float -0.000000e+00, %42
  %add238 = fadd float %add193, %mul233
  %mul239 = fmul float %sub88, %mul237
  %mul240 = fmul float %sub89, %mul237
  %mul241 = fmul float %sub90, %mul237
  %add242 = fadd float %fix3.0631, %mul239
  %add243 = fadd float %fiy3.0630, %mul240
  %add244 = fadd float %fiz3.0629, %mul241
  %sub245 = fsub float %sub200, %mul239
  store float %sub245, float* %arrayidx148, align 4, !tbaa !3
  %sub248 = fsub float %sub201, %mul240
  store float %sub248, float* %arrayidx152, align 4, !tbaa !3
  %sub252 = fsub float %sub202, %mul241
  store float %sub252, float* %arrayidx156, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %43 = trunc i64 %indvars.iv.next to i32
  %cmp60 = icmp slt i32 %43, %9
  br i1 %cmp60, label %for.body61, label %for.end

for.end:                                          ; preds = %for.body61, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add238, %for.body61 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add144, %for.body61 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add145, %for.body61 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add146, %for.body61 ]
  %fix2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add197, %for.body61 ]
  %fiy2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add198, %for.body61 ]
  %fiz2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add199, %for.body61 ]
  %fix3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add242, %for.body61 ]
  %fiy3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add243, %for.body61 ]
  %fiz3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add244, %for.body61 ]
  %arrayidx257 = getelementptr inbounds float* %faction, i64 %idxprom24
  %44 = load float* %arrayidx257, align 4, !tbaa !3
  %add258 = fadd float %fix1.0.lcssa, %44
  store float %add258, float* %arrayidx257, align 4, !tbaa !3
  %arrayidx263 = getelementptr inbounds float* %faction, i64 %idxprom28
  %45 = load float* %arrayidx263, align 4, !tbaa !3
  %add264 = fadd float %fiy1.0.lcssa, %45
  store float %add264, float* %arrayidx263, align 4, !tbaa !3
  %arrayidx270 = getelementptr inbounds float* %faction, i64 %idxprom32
  %46 = load float* %arrayidx270, align 4, !tbaa !3
  %add271 = fadd float %fiz1.0.lcssa, %46
  store float %add271, float* %arrayidx270, align 4, !tbaa !3
  %arrayidx277 = getelementptr inbounds float* %faction, i64 %idxprom36
  %47 = load float* %arrayidx277, align 4, !tbaa !3
  %add278 = fadd float %fix2.0.lcssa, %47
  store float %add278, float* %arrayidx277, align 4, !tbaa !3
  %arrayidx284 = getelementptr inbounds float* %faction, i64 %idxprom40
  %48 = load float* %arrayidx284, align 4, !tbaa !3
  %add285 = fadd float %fiy2.0.lcssa, %48
  store float %add285, float* %arrayidx284, align 4, !tbaa !3
  %arrayidx291 = getelementptr inbounds float* %faction, i64 %idxprom44
  %49 = load float* %arrayidx291, align 4, !tbaa !3
  %add292 = fadd float %fiz2.0.lcssa, %49
  store float %add292, float* %arrayidx291, align 4, !tbaa !3
  %arrayidx298 = getelementptr inbounds float* %faction, i64 %idxprom48
  %50 = load float* %arrayidx298, align 4, !tbaa !3
  %add299 = fadd float %fix3.0.lcssa, %50
  store float %add299, float* %arrayidx298, align 4, !tbaa !3
  %arrayidx305 = getelementptr inbounds float* %faction, i64 %idxprom52
  %51 = load float* %arrayidx305, align 4, !tbaa !3
  %add306 = fadd float %fiy3.0.lcssa, %51
  store float %add306, float* %arrayidx305, align 4, !tbaa !3
  %arrayidx312 = getelementptr inbounds float* %faction, i64 %idxprom56
  %52 = load float* %arrayidx312, align 4, !tbaa !3
  %add313 = fadd float %fiz3.0.lcssa, %52
  store float %add313, float* %arrayidx312, align 4, !tbaa !3
  %arrayidx318 = getelementptr inbounds float* %fshift, i64 %idxprom8
  %53 = load float* %arrayidx318, align 4, !tbaa !3
  %add319 = fadd float %fix1.0.lcssa, %53
  %add320 = fadd float %fix2.0.lcssa, %add319
  %add321 = fadd float %fix3.0.lcssa, %add320
  store float %add321, float* %arrayidx318, align 4, !tbaa !3
  %arrayidx326 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %54 = load float* %arrayidx326, align 4, !tbaa !3
  %add327 = fadd float %fiy1.0.lcssa, %54
  %add328 = fadd float %fiy2.0.lcssa, %add327
  %add329 = fadd float %fiy3.0.lcssa, %add328
  store float %add329, float* %arrayidx326, align 4, !tbaa !3
  %arrayidx335 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %55 = load float* %arrayidx335, align 4, !tbaa !3
  %add336 = fadd float %fiz1.0.lcssa, %55
  %add337 = fadd float %fiz2.0.lcssa, %add336
  %add338 = fadd float %fiz3.0.lcssa, %add337
  store float %add338, float* %arrayidx335, align 4, !tbaa !3
  %arrayidx343 = getelementptr inbounds i32* %gid, i64 %indvars.iv651
  %56 = load i32* %arrayidx343, align 4, !tbaa !0
  %idxprom344 = sext i32 %56 to i64
  %arrayidx345 = getelementptr inbounds float* %Vc, i64 %idxprom344
  %57 = load float* %arrayidx345, align 4, !tbaa !3
  %add346 = fadd float %vctot.0.lcssa, %57
  store float %add346, float* %arrayidx345, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next652 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end351, label %for.end.for.body_crit_edge

for.end.for.body_crit_edge:                       ; preds = %for.end
  %arrayidx17.phi.trans.insert = getelementptr inbounds i32* %iinr, i64 %indvars.iv.next652
  %.pre = load i32* %arrayidx17.phi.trans.insert, align 4, !tbaa !0
  br label %for.body

for.end351:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl3030(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, float %tabscale, float* %VFtab) #0 {
entry:
  %0 = load i32* %iinr, align 4, !tbaa !0
  %idxprom = sext i32 %0 to i64
  %arrayidx1 = getelementptr inbounds float* %charge, i64 %idxprom
  %1 = load float* %arrayidx1, align 4, !tbaa !3
  %add = add nsw i32 %0, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds float* %charge, i64 %idxprom2
  %2 = load float* %arrayidx3, align 4, !tbaa !3
  %mul = fmul float %1, %facel
  %mul4 = fmul float %1, %mul
  %mul6 = fmul float %mul, %2
  %mul7 = fmul float %2, %facel
  %mul8 = fmul float %2, %mul7
  %cmp1412 = icmp sgt i32 %nri, 0
  br i1 %cmp1412, label %for.body, label %for.end724

for.body:                                         ; preds = %entry, %for.end.for.body_crit_edge
  %3 = phi i32 [ %.pre, %for.end.for.body_crit_edge ], [ %0, %entry ]
  %indvars.iv1414 = phi i64 [ %indvars.iv.next1415, %for.end.for.body_crit_edge ], [ 0, %entry ]
  %arrayidx10 = getelementptr inbounds i32* %shift, i64 %indvars.iv1414
  %4 = load i32* %arrayidx10, align 4, !tbaa !0
  %mul11 = mul nsw i32 %4, 3
  %idxprom12 = sext i32 %mul11 to i64
  %arrayidx13 = getelementptr inbounds float* %shiftvec, i64 %idxprom12
  %5 = load float* %arrayidx13, align 4, !tbaa !3
  %add14 = add nsw i32 %mul11, 1
  %idxprom15 = sext i32 %add14 to i64
  %arrayidx16 = getelementptr inbounds float* %shiftvec, i64 %idxprom15
  %6 = load float* %arrayidx16, align 4, !tbaa !3
  %add17 = add nsw i32 %mul11, 2
  %idxprom18 = sext i32 %add17 to i64
  %arrayidx19 = getelementptr inbounds float* %shiftvec, i64 %idxprom18
  %7 = load float* %arrayidx19, align 4, !tbaa !3
  %mul22 = mul nsw i32 %3, 3
  %arrayidx24 = getelementptr inbounds i32* %jindex, i64 %indvars.iv1414
  %8 = load i32* %arrayidx24, align 4, !tbaa !0
  %indvars.iv.next1415 = add i64 %indvars.iv1414, 1
  %arrayidx27 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next1415
  %9 = load i32* %arrayidx27, align 4, !tbaa !0
  %idxprom28 = sext i32 %mul22 to i64
  %arrayidx29 = getelementptr inbounds float* %pos, i64 %idxprom28
  %10 = load float* %arrayidx29, align 4, !tbaa !3
  %add30 = fadd float %5, %10
  %add31 = add nsw i32 %mul22, 1
  %idxprom32 = sext i32 %add31 to i64
  %arrayidx33 = getelementptr inbounds float* %pos, i64 %idxprom32
  %11 = load float* %arrayidx33, align 4, !tbaa !3
  %add34 = fadd float %6, %11
  %add35 = add nsw i32 %mul22, 2
  %idxprom36 = sext i32 %add35 to i64
  %arrayidx37 = getelementptr inbounds float* %pos, i64 %idxprom36
  %12 = load float* %arrayidx37, align 4, !tbaa !3
  %add38 = fadd float %7, %12
  %add39 = add nsw i32 %mul22, 3
  %idxprom40 = sext i32 %add39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %13 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = fadd float %5, %13
  %add43 = add nsw i32 %mul22, 4
  %idxprom44 = sext i32 %add43 to i64
  %arrayidx45 = getelementptr inbounds float* %pos, i64 %idxprom44
  %14 = load float* %arrayidx45, align 4, !tbaa !3
  %add46 = fadd float %6, %14
  %add47 = add nsw i32 %mul22, 5
  %idxprom48 = sext i32 %add47 to i64
  %arrayidx49 = getelementptr inbounds float* %pos, i64 %idxprom48
  %15 = load float* %arrayidx49, align 4, !tbaa !3
  %add50 = fadd float %7, %15
  %add51 = add nsw i32 %mul22, 6
  %idxprom52 = sext i32 %add51 to i64
  %arrayidx53 = getelementptr inbounds float* %pos, i64 %idxprom52
  %16 = load float* %arrayidx53, align 4, !tbaa !3
  %add54 = fadd float %5, %16
  %add55 = add nsw i32 %mul22, 7
  %idxprom56 = sext i32 %add55 to i64
  %arrayidx57 = getelementptr inbounds float* %pos, i64 %idxprom56
  %17 = load float* %arrayidx57, align 4, !tbaa !3
  %add58 = fadd float %6, %17
  %add59 = add nsw i32 %mul22, 8
  %idxprom60 = sext i32 %add59 to i64
  %arrayidx61 = getelementptr inbounds float* %pos, i64 %idxprom60
  %18 = load float* %arrayidx61, align 4, !tbaa !3
  %add62 = fadd float %7, %18
  %cmp641391 = icmp slt i32 %8, %9
  br i1 %cmp641391, label %for.body65.lr.ph, label %for.end

for.body65.lr.ph:                                 ; preds = %for.body
  %19 = sext i32 %8 to i64
  br label %for.body65

for.body65:                                       ; preds = %for.body65.lr.ph, %for.body65
  %indvars.iv = phi i64 [ %19, %for.body65.lr.ph ], [ %indvars.iv.next, %for.body65 ]
  %vctot.01401 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add610, %for.body65 ]
  %fix1.01400 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add336, %for.body65 ]
  %fiy1.01399 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add337, %for.body65 ]
  %fiz1.01398 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add338, %for.body65 ]
  %fix2.01397 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add471, %for.body65 ]
  %fiy2.01396 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add472, %for.body65 ]
  %fiz2.01395 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add473, %for.body65 ]
  %fix3.01394 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add614, %for.body65 ]
  %fiy3.01393 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add615, %for.body65 ]
  %fiz3.01392 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add616, %for.body65 ]
  %arrayidx67 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %20 = load i32* %arrayidx67, align 4, !tbaa !0
  %mul68 = mul nsw i32 %20, 3
  %idxprom69 = sext i32 %mul68 to i64
  %arrayidx70 = getelementptr inbounds float* %pos, i64 %idxprom69
  %21 = load float* %arrayidx70, align 4, !tbaa !3
  %add71 = add nsw i32 %mul68, 1
  %idxprom72 = sext i32 %add71 to i64
  %arrayidx73 = getelementptr inbounds float* %pos, i64 %idxprom72
  %22 = load float* %arrayidx73, align 4, !tbaa !3
  %add74 = add nsw i32 %mul68, 2
  %idxprom75 = sext i32 %add74 to i64
  %arrayidx76 = getelementptr inbounds float* %pos, i64 %idxprom75
  %23 = load float* %arrayidx76, align 4, !tbaa !3
  %add77 = add nsw i32 %mul68, 3
  %idxprom78 = sext i32 %add77 to i64
  %arrayidx79 = getelementptr inbounds float* %pos, i64 %idxprom78
  %24 = load float* %arrayidx79, align 4, !tbaa !3
  %add80 = add nsw i32 %mul68, 4
  %idxprom81 = sext i32 %add80 to i64
  %arrayidx82 = getelementptr inbounds float* %pos, i64 %idxprom81
  %25 = load float* %arrayidx82, align 4, !tbaa !3
  %add83 = add nsw i32 %mul68, 5
  %idxprom84 = sext i32 %add83 to i64
  %arrayidx85 = getelementptr inbounds float* %pos, i64 %idxprom84
  %26 = load float* %arrayidx85, align 4, !tbaa !3
  %add86 = add nsw i32 %mul68, 6
  %idxprom87 = sext i32 %add86 to i64
  %arrayidx88 = getelementptr inbounds float* %pos, i64 %idxprom87
  %27 = load float* %arrayidx88, align 4, !tbaa !3
  %add89 = add nsw i32 %mul68, 7
  %idxprom90 = sext i32 %add89 to i64
  %arrayidx91 = getelementptr inbounds float* %pos, i64 %idxprom90
  %28 = load float* %arrayidx91, align 4, !tbaa !3
  %add92 = add nsw i32 %mul68, 8
  %idxprom93 = sext i32 %add92 to i64
  %arrayidx94 = getelementptr inbounds float* %pos, i64 %idxprom93
  %29 = load float* %arrayidx94, align 4, !tbaa !3
  %sub = fsub float %add30, %21
  %sub95 = fsub float %add34, %22
  %sub96 = fsub float %add38, %23
  %mul97 = fmul float %sub, %sub
  %mul98 = fmul float %sub95, %sub95
  %add99 = fadd float %mul97, %mul98
  %mul100 = fmul float %sub96, %sub96
  %add101 = fadd float %add99, %mul100
  %sub102 = fsub float %add30, %24
  %sub103 = fsub float %add34, %25
  %sub104 = fsub float %add38, %26
  %mul105 = fmul float %sub102, %sub102
  %mul106 = fmul float %sub103, %sub103
  %add107 = fadd float %mul105, %mul106
  %mul108 = fmul float %sub104, %sub104
  %add109 = fadd float %add107, %mul108
  %sub110 = fsub float %add30, %27
  %sub111 = fsub float %add34, %28
  %sub112 = fsub float %add38, %29
  %mul113 = fmul float %sub110, %sub110
  %mul114 = fmul float %sub111, %sub111
  %add115 = fadd float %mul113, %mul114
  %mul116 = fmul float %sub112, %sub112
  %add117 = fadd float %add115, %mul116
  %sub118 = fsub float %add42, %21
  %sub119 = fsub float %add46, %22
  %sub120 = fsub float %add50, %23
  %mul121 = fmul float %sub118, %sub118
  %mul122 = fmul float %sub119, %sub119
  %add123 = fadd float %mul121, %mul122
  %mul124 = fmul float %sub120, %sub120
  %add125 = fadd float %add123, %mul124
  %sub126 = fsub float %add42, %24
  %sub127 = fsub float %add46, %25
  %sub128 = fsub float %add50, %26
  %mul129 = fmul float %sub126, %sub126
  %mul130 = fmul float %sub127, %sub127
  %add131 = fadd float %mul129, %mul130
  %mul132 = fmul float %sub128, %sub128
  %add133 = fadd float %add131, %mul132
  %sub134 = fsub float %add42, %27
  %sub135 = fsub float %add46, %28
  %sub136 = fsub float %add50, %29
  %mul137 = fmul float %sub134, %sub134
  %mul138 = fmul float %sub135, %sub135
  %add139 = fadd float %mul137, %mul138
  %mul140 = fmul float %sub136, %sub136
  %add141 = fadd float %add139, %mul140
  %sub142 = fsub float %add54, %21
  %sub143 = fsub float %add58, %22
  %sub144 = fsub float %add62, %23
  %mul145 = fmul float %sub142, %sub142
  %mul146 = fmul float %sub143, %sub143
  %add147 = fadd float %mul145, %mul146
  %mul148 = fmul float %sub144, %sub144
  %add149 = fadd float %add147, %mul148
  %sub150 = fsub float %add54, %24
  %sub151 = fsub float %add58, %25
  %sub152 = fsub float %add62, %26
  %mul153 = fmul float %sub150, %sub150
  %mul154 = fmul float %sub151, %sub151
  %add155 = fadd float %mul153, %mul154
  %mul156 = fmul float %sub152, %sub152
  %add157 = fadd float %add155, %mul156
  %sub158 = fsub float %add54, %27
  %sub159 = fsub float %add58, %28
  %sub160 = fsub float %add62, %29
  %mul161 = fmul float %sub158, %sub158
  %mul162 = fmul float %sub159, %sub159
  %add163 = fadd float %mul161, %mul162
  %mul164 = fmul float %sub160, %sub160
  %add165 = fadd float %add163, %mul164
  %conv = fpext float %add101 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv166 = fptrunc double %div to float
  %conv167 = fpext float %add125 to double
  %call168 = tail call double @sqrt(double %conv167) #2
  %div169 = fdiv double 1.000000e+00, %call168
  %conv170 = fptrunc double %div169 to float
  %conv171 = fpext float %add149 to double
  %call172 = tail call double @sqrt(double %conv171) #2
  %div173 = fdiv double 1.000000e+00, %call172
  %conv174 = fptrunc double %div173 to float
  %conv175 = fpext float %add109 to double
  %call176 = tail call double @sqrt(double %conv175) #2
  %div177 = fdiv double 1.000000e+00, %call176
  %conv178 = fptrunc double %div177 to float
  %conv179 = fpext float %add133 to double
  %call180 = tail call double @sqrt(double %conv179) #2
  %div181 = fdiv double 1.000000e+00, %call180
  %conv182 = fptrunc double %div181 to float
  %conv183 = fpext float %add157 to double
  %call184 = tail call double @sqrt(double %conv183) #2
  %div185 = fdiv double 1.000000e+00, %call184
  %conv186 = fptrunc double %div185 to float
  %conv187 = fpext float %add117 to double
  %call188 = tail call double @sqrt(double %conv187) #2
  %div189 = fdiv double 1.000000e+00, %call188
  %conv190 = fptrunc double %div189 to float
  %conv191 = fpext float %add141 to double
  %call192 = tail call double @sqrt(double %conv191) #2
  %div193 = fdiv double 1.000000e+00, %call192
  %conv194 = fptrunc double %div193 to float
  %conv195 = fpext float %add165 to double
  %call196 = tail call double @sqrt(double %conv195) #2
  %div197 = fdiv double 1.000000e+00, %call196
  %conv198 = fptrunc double %div197 to float
  %mul199 = fmul float %add101, %conv166
  %mul200 = fmul float %mul199, %tabscale
  %conv201 = fptosi float %mul200 to i32
  %conv202 = sitofp i32 %conv201 to float
  %sub203 = fsub float %mul200, %conv202
  %mul204 = fmul float %sub203, %sub203
  %mul205 = shl nsw i32 %conv201, 2
  %idxprom206 = sext i32 %mul205 to i64
  %arrayidx207 = getelementptr inbounds float* %VFtab, i64 %idxprom206
  %30 = load float* %arrayidx207, align 4, !tbaa !3
  %add2081364 = or i32 %mul205, 1
  %idxprom209 = sext i32 %add2081364 to i64
  %arrayidx210 = getelementptr inbounds float* %VFtab, i64 %idxprom209
  %31 = load float* %arrayidx210, align 4, !tbaa !3
  %add2111365 = or i32 %mul205, 2
  %idxprom212 = sext i32 %add2111365 to i64
  %arrayidx213 = getelementptr inbounds float* %VFtab, i64 %idxprom212
  %32 = load float* %arrayidx213, align 4, !tbaa !3
  %mul214 = fmul float %sub203, %32
  %add2151366 = or i32 %mul205, 3
  %idxprom216 = sext i32 %add2151366 to i64
  %arrayidx217 = getelementptr inbounds float* %VFtab, i64 %idxprom216
  %33 = load float* %arrayidx217, align 4, !tbaa !3
  %mul218 = fmul float %mul204, %33
  %add219 = fadd float %31, %mul214
  %add220 = fadd float %add219, %mul218
  %mul221 = fmul float %sub203, %add220
  %add222 = fadd float %30, %mul221
  %add223 = fadd float %mul214, %add220
  %mul224 = fmul float %mul218, 2.000000e+00
  %add225 = fadd float %mul224, %add223
  %mul226 = fmul float %mul4, %add222
  %mul227 = fmul float %mul4, %add225
  %mul228 = fmul float %mul227, %tabscale
  %34 = fmul float %conv166, %mul228
  %mul230 = fsub float -0.000000e+00, %34
  %add231 = fadd float %vctot.01401, %mul226
  %mul232 = fmul float %sub, %mul230
  %mul233 = fmul float %sub95, %mul230
  %mul234 = fmul float %sub96, %mul230
  %add235 = fadd float %fix1.01400, %mul232
  %add236 = fadd float %fiy1.01399, %mul233
  %add237 = fadd float %fiz1.01398, %mul234
  %arrayidx239 = getelementptr inbounds float* %faction, i64 %idxprom69
  %35 = load float* %arrayidx239, align 4, !tbaa !3
  %sub240 = fsub float %35, %mul232
  %arrayidx243 = getelementptr inbounds float* %faction, i64 %idxprom72
  %36 = load float* %arrayidx243, align 4, !tbaa !3
  %sub244 = fsub float %36, %mul233
  %arrayidx247 = getelementptr inbounds float* %faction, i64 %idxprom75
  %37 = load float* %arrayidx247, align 4, !tbaa !3
  %sub248 = fsub float %37, %mul234
  %mul249 = fmul float %add109, %conv178
  %mul250 = fmul float %mul249, %tabscale
  %conv251 = fptosi float %mul250 to i32
  %conv252 = sitofp i32 %conv251 to float
  %sub253 = fsub float %mul250, %conv252
  %mul254 = fmul float %sub253, %sub253
  %mul255 = shl nsw i32 %conv251, 2
  %idxprom256 = sext i32 %mul255 to i64
  %arrayidx257 = getelementptr inbounds float* %VFtab, i64 %idxprom256
  %38 = load float* %arrayidx257, align 4, !tbaa !3
  %add2581367 = or i32 %mul255, 1
  %idxprom259 = sext i32 %add2581367 to i64
  %arrayidx260 = getelementptr inbounds float* %VFtab, i64 %idxprom259
  %39 = load float* %arrayidx260, align 4, !tbaa !3
  %add2611368 = or i32 %mul255, 2
  %idxprom262 = sext i32 %add2611368 to i64
  %arrayidx263 = getelementptr inbounds float* %VFtab, i64 %idxprom262
  %40 = load float* %arrayidx263, align 4, !tbaa !3
  %mul264 = fmul float %sub253, %40
  %add2651369 = or i32 %mul255, 3
  %idxprom266 = sext i32 %add2651369 to i64
  %arrayidx267 = getelementptr inbounds float* %VFtab, i64 %idxprom266
  %41 = load float* %arrayidx267, align 4, !tbaa !3
  %mul268 = fmul float %mul254, %41
  %add269 = fadd float %39, %mul264
  %add270 = fadd float %add269, %mul268
  %mul271 = fmul float %sub253, %add270
  %add272 = fadd float %38, %mul271
  %add273 = fadd float %mul264, %add270
  %mul274 = fmul float %mul268, 2.000000e+00
  %add275 = fadd float %mul274, %add273
  %mul276 = fmul float %mul6, %add272
  %mul277 = fmul float %mul6, %add275
  %mul278 = fmul float %mul277, %tabscale
  %42 = fmul float %conv178, %mul278
  %mul280 = fsub float -0.000000e+00, %42
  %add281 = fadd float %add231, %mul276
  %mul282 = fmul float %sub102, %mul280
  %mul283 = fmul float %sub103, %mul280
  %mul284 = fmul float %sub104, %mul280
  %add285 = fadd float %add235, %mul282
  %add286 = fadd float %add236, %mul283
  %add287 = fadd float %add237, %mul284
  %arrayidx290 = getelementptr inbounds float* %faction, i64 %idxprom78
  %43 = load float* %arrayidx290, align 4, !tbaa !3
  %sub291 = fsub float %43, %mul282
  %arrayidx294 = getelementptr inbounds float* %faction, i64 %idxprom81
  %44 = load float* %arrayidx294, align 4, !tbaa !3
  %sub295 = fsub float %44, %mul283
  %arrayidx298 = getelementptr inbounds float* %faction, i64 %idxprom84
  %45 = load float* %arrayidx298, align 4, !tbaa !3
  %sub299 = fsub float %45, %mul284
  %mul300 = fmul float %add117, %conv190
  %mul301 = fmul float %mul300, %tabscale
  %conv302 = fptosi float %mul301 to i32
  %conv303 = sitofp i32 %conv302 to float
  %sub304 = fsub float %mul301, %conv303
  %mul305 = fmul float %sub304, %sub304
  %mul306 = shl nsw i32 %conv302, 2
  %idxprom307 = sext i32 %mul306 to i64
  %arrayidx308 = getelementptr inbounds float* %VFtab, i64 %idxprom307
  %46 = load float* %arrayidx308, align 4, !tbaa !3
  %add3091370 = or i32 %mul306, 1
  %idxprom310 = sext i32 %add3091370 to i64
  %arrayidx311 = getelementptr inbounds float* %VFtab, i64 %idxprom310
  %47 = load float* %arrayidx311, align 4, !tbaa !3
  %add3121371 = or i32 %mul306, 2
  %idxprom313 = sext i32 %add3121371 to i64
  %arrayidx314 = getelementptr inbounds float* %VFtab, i64 %idxprom313
  %48 = load float* %arrayidx314, align 4, !tbaa !3
  %mul315 = fmul float %sub304, %48
  %add3161372 = or i32 %mul306, 3
  %idxprom317 = sext i32 %add3161372 to i64
  %arrayidx318 = getelementptr inbounds float* %VFtab, i64 %idxprom317
  %49 = load float* %arrayidx318, align 4, !tbaa !3
  %mul319 = fmul float %mul305, %49
  %add320 = fadd float %47, %mul315
  %add321 = fadd float %add320, %mul319
  %mul322 = fmul float %sub304, %add321
  %add323 = fadd float %46, %mul322
  %add324 = fadd float %mul315, %add321
  %mul325 = fmul float %mul319, 2.000000e+00
  %add326 = fadd float %mul325, %add324
  %mul327 = fmul float %mul6, %add323
  %mul328 = fmul float %mul6, %add326
  %mul329 = fmul float %mul328, %tabscale
  %50 = fmul float %conv190, %mul329
  %mul331 = fsub float -0.000000e+00, %50
  %add332 = fadd float %add281, %mul327
  %mul333 = fmul float %sub110, %mul331
  %mul334 = fmul float %sub111, %mul331
  %mul335 = fmul float %sub112, %mul331
  %add336 = fadd float %add285, %mul333
  %add337 = fadd float %add286, %mul334
  %add338 = fadd float %add287, %mul335
  %arrayidx341 = getelementptr inbounds float* %faction, i64 %idxprom87
  %51 = load float* %arrayidx341, align 4, !tbaa !3
  %sub342 = fsub float %51, %mul333
  %arrayidx345 = getelementptr inbounds float* %faction, i64 %idxprom90
  %52 = load float* %arrayidx345, align 4, !tbaa !3
  %sub346 = fsub float %52, %mul334
  %arrayidx349 = getelementptr inbounds float* %faction, i64 %idxprom93
  %53 = load float* %arrayidx349, align 4, !tbaa !3
  %sub350 = fsub float %53, %mul335
  %mul351 = fmul float %add125, %conv170
  %mul352 = fmul float %mul351, %tabscale
  %conv353 = fptosi float %mul352 to i32
  %conv354 = sitofp i32 %conv353 to float
  %sub355 = fsub float %mul352, %conv354
  %mul356 = fmul float %sub355, %sub355
  %mul357 = shl nsw i32 %conv353, 2
  %idxprom358 = sext i32 %mul357 to i64
  %arrayidx359 = getelementptr inbounds float* %VFtab, i64 %idxprom358
  %54 = load float* %arrayidx359, align 4, !tbaa !3
  %add3601373 = or i32 %mul357, 1
  %idxprom361 = sext i32 %add3601373 to i64
  %arrayidx362 = getelementptr inbounds float* %VFtab, i64 %idxprom361
  %55 = load float* %arrayidx362, align 4, !tbaa !3
  %add3631374 = or i32 %mul357, 2
  %idxprom364 = sext i32 %add3631374 to i64
  %arrayidx365 = getelementptr inbounds float* %VFtab, i64 %idxprom364
  %56 = load float* %arrayidx365, align 4, !tbaa !3
  %mul366 = fmul float %sub355, %56
  %add3671375 = or i32 %mul357, 3
  %idxprom368 = sext i32 %add3671375 to i64
  %arrayidx369 = getelementptr inbounds float* %VFtab, i64 %idxprom368
  %57 = load float* %arrayidx369, align 4, !tbaa !3
  %mul370 = fmul float %mul356, %57
  %add371 = fadd float %55, %mul366
  %add372 = fadd float %add371, %mul370
  %mul373 = fmul float %sub355, %add372
  %add374 = fadd float %54, %mul373
  %add375 = fadd float %mul366, %add372
  %mul376 = fmul float %mul370, 2.000000e+00
  %add377 = fadd float %mul376, %add375
  %mul378 = fmul float %mul6, %add374
  %mul379 = fmul float %mul6, %add377
  %mul380 = fmul float %mul379, %tabscale
  %58 = fmul float %conv170, %mul380
  %mul382 = fsub float -0.000000e+00, %58
  %add383 = fadd float %add332, %mul378
  %mul384 = fmul float %sub118, %mul382
  %mul385 = fmul float %sub119, %mul382
  %mul386 = fmul float %sub120, %mul382
  %add387 = fadd float %fix2.01397, %mul384
  %add388 = fadd float %fiy2.01396, %mul385
  %add389 = fadd float %fiz2.01395, %mul386
  %sub390 = fsub float %sub240, %mul384
  %sub391 = fsub float %sub244, %mul385
  %sub392 = fsub float %sub248, %mul386
  %mul393 = fmul float %add133, %conv182
  %mul394 = fmul float %mul393, %tabscale
  %conv395 = fptosi float %mul394 to i32
  %conv396 = sitofp i32 %conv395 to float
  %sub397 = fsub float %mul394, %conv396
  %mul398 = fmul float %sub397, %sub397
  %mul399 = shl nsw i32 %conv395, 2
  %idxprom400 = sext i32 %mul399 to i64
  %arrayidx401 = getelementptr inbounds float* %VFtab, i64 %idxprom400
  %59 = load float* %arrayidx401, align 4, !tbaa !3
  %add4021376 = or i32 %mul399, 1
  %idxprom403 = sext i32 %add4021376 to i64
  %arrayidx404 = getelementptr inbounds float* %VFtab, i64 %idxprom403
  %60 = load float* %arrayidx404, align 4, !tbaa !3
  %add4051377 = or i32 %mul399, 2
  %idxprom406 = sext i32 %add4051377 to i64
  %arrayidx407 = getelementptr inbounds float* %VFtab, i64 %idxprom406
  %61 = load float* %arrayidx407, align 4, !tbaa !3
  %mul408 = fmul float %sub397, %61
  %add4091378 = or i32 %mul399, 3
  %idxprom410 = sext i32 %add4091378 to i64
  %arrayidx411 = getelementptr inbounds float* %VFtab, i64 %idxprom410
  %62 = load float* %arrayidx411, align 4, !tbaa !3
  %mul412 = fmul float %mul398, %62
  %add413 = fadd float %60, %mul408
  %add414 = fadd float %add413, %mul412
  %mul415 = fmul float %sub397, %add414
  %add416 = fadd float %59, %mul415
  %add417 = fadd float %mul408, %add414
  %mul418 = fmul float %mul412, 2.000000e+00
  %add419 = fadd float %mul418, %add417
  %mul420 = fmul float %mul8, %add416
  %mul421 = fmul float %mul8, %add419
  %mul422 = fmul float %mul421, %tabscale
  %63 = fmul float %conv182, %mul422
  %mul424 = fsub float -0.000000e+00, %63
  %add425 = fadd float %add383, %mul420
  %mul426 = fmul float %sub126, %mul424
  %mul427 = fmul float %sub127, %mul424
  %mul428 = fmul float %sub128, %mul424
  %add429 = fadd float %add387, %mul426
  %add430 = fadd float %add388, %mul427
  %add431 = fadd float %add389, %mul428
  %sub432 = fsub float %sub291, %mul426
  %sub433 = fsub float %sub295, %mul427
  %sub434 = fsub float %sub299, %mul428
  %mul435 = fmul float %add141, %conv194
  %mul436 = fmul float %mul435, %tabscale
  %conv437 = fptosi float %mul436 to i32
  %conv438 = sitofp i32 %conv437 to float
  %sub439 = fsub float %mul436, %conv438
  %mul440 = fmul float %sub439, %sub439
  %mul441 = shl nsw i32 %conv437, 2
  %idxprom442 = sext i32 %mul441 to i64
  %arrayidx443 = getelementptr inbounds float* %VFtab, i64 %idxprom442
  %64 = load float* %arrayidx443, align 4, !tbaa !3
  %add4441379 = or i32 %mul441, 1
  %idxprom445 = sext i32 %add4441379 to i64
  %arrayidx446 = getelementptr inbounds float* %VFtab, i64 %idxprom445
  %65 = load float* %arrayidx446, align 4, !tbaa !3
  %add4471380 = or i32 %mul441, 2
  %idxprom448 = sext i32 %add4471380 to i64
  %arrayidx449 = getelementptr inbounds float* %VFtab, i64 %idxprom448
  %66 = load float* %arrayidx449, align 4, !tbaa !3
  %mul450 = fmul float %sub439, %66
  %add4511381 = or i32 %mul441, 3
  %idxprom452 = sext i32 %add4511381 to i64
  %arrayidx453 = getelementptr inbounds float* %VFtab, i64 %idxprom452
  %67 = load float* %arrayidx453, align 4, !tbaa !3
  %mul454 = fmul float %mul440, %67
  %add455 = fadd float %65, %mul450
  %add456 = fadd float %add455, %mul454
  %mul457 = fmul float %sub439, %add456
  %add458 = fadd float %64, %mul457
  %add459 = fadd float %mul450, %add456
  %mul460 = fmul float %mul454, 2.000000e+00
  %add461 = fadd float %mul460, %add459
  %mul462 = fmul float %mul8, %add458
  %mul463 = fmul float %mul8, %add461
  %mul464 = fmul float %mul463, %tabscale
  %68 = fmul float %conv194, %mul464
  %mul466 = fsub float -0.000000e+00, %68
  %add467 = fadd float %add425, %mul462
  %mul468 = fmul float %sub134, %mul466
  %mul469 = fmul float %sub135, %mul466
  %mul470 = fmul float %sub136, %mul466
  %add471 = fadd float %add429, %mul468
  %add472 = fadd float %add430, %mul469
  %add473 = fadd float %add431, %mul470
  %sub474 = fsub float %sub342, %mul468
  %sub475 = fsub float %sub346, %mul469
  %sub476 = fsub float %sub350, %mul470
  %mul477 = fmul float %add149, %conv174
  %mul478 = fmul float %mul477, %tabscale
  %conv479 = fptosi float %mul478 to i32
  %conv480 = sitofp i32 %conv479 to float
  %sub481 = fsub float %mul478, %conv480
  %mul482 = fmul float %sub481, %sub481
  %mul483 = shl nsw i32 %conv479, 2
  %idxprom484 = sext i32 %mul483 to i64
  %arrayidx485 = getelementptr inbounds float* %VFtab, i64 %idxprom484
  %69 = load float* %arrayidx485, align 4, !tbaa !3
  %add4861382 = or i32 %mul483, 1
  %idxprom487 = sext i32 %add4861382 to i64
  %arrayidx488 = getelementptr inbounds float* %VFtab, i64 %idxprom487
  %70 = load float* %arrayidx488, align 4, !tbaa !3
  %add4891383 = or i32 %mul483, 2
  %idxprom490 = sext i32 %add4891383 to i64
  %arrayidx491 = getelementptr inbounds float* %VFtab, i64 %idxprom490
  %71 = load float* %arrayidx491, align 4, !tbaa !3
  %mul492 = fmul float %sub481, %71
  %add4931384 = or i32 %mul483, 3
  %idxprom494 = sext i32 %add4931384 to i64
  %arrayidx495 = getelementptr inbounds float* %VFtab, i64 %idxprom494
  %72 = load float* %arrayidx495, align 4, !tbaa !3
  %mul496 = fmul float %mul482, %72
  %add497 = fadd float %70, %mul492
  %add498 = fadd float %add497, %mul496
  %mul499 = fmul float %sub481, %add498
  %add500 = fadd float %69, %mul499
  %add501 = fadd float %mul492, %add498
  %mul502 = fmul float %mul496, 2.000000e+00
  %add503 = fadd float %mul502, %add501
  %mul504 = fmul float %mul6, %add500
  %mul505 = fmul float %mul6, %add503
  %mul506 = fmul float %mul505, %tabscale
  %73 = fmul float %conv174, %mul506
  %mul508 = fsub float -0.000000e+00, %73
  %add509 = fadd float %add467, %mul504
  %mul510 = fmul float %sub142, %mul508
  %mul511 = fmul float %sub143, %mul508
  %mul512 = fmul float %sub144, %mul508
  %add513 = fadd float %fix3.01394, %mul510
  %add514 = fadd float %fiy3.01393, %mul511
  %add515 = fadd float %fiz3.01392, %mul512
  %sub516 = fsub float %sub390, %mul510
  store float %sub516, float* %arrayidx239, align 4, !tbaa !3
  %sub519 = fsub float %sub391, %mul511
  store float %sub519, float* %arrayidx243, align 4, !tbaa !3
  %sub523 = fsub float %sub392, %mul512
  store float %sub523, float* %arrayidx247, align 4, !tbaa !3
  %mul527 = fmul float %add157, %conv186
  %mul528 = fmul float %mul527, %tabscale
  %conv529 = fptosi float %mul528 to i32
  %conv530 = sitofp i32 %conv529 to float
  %sub531 = fsub float %mul528, %conv530
  %mul532 = fmul float %sub531, %sub531
  %mul533 = shl nsw i32 %conv529, 2
  %idxprom534 = sext i32 %mul533 to i64
  %arrayidx535 = getelementptr inbounds float* %VFtab, i64 %idxprom534
  %74 = load float* %arrayidx535, align 4, !tbaa !3
  %add5361385 = or i32 %mul533, 1
  %idxprom537 = sext i32 %add5361385 to i64
  %arrayidx538 = getelementptr inbounds float* %VFtab, i64 %idxprom537
  %75 = load float* %arrayidx538, align 4, !tbaa !3
  %add5391386 = or i32 %mul533, 2
  %idxprom540 = sext i32 %add5391386 to i64
  %arrayidx541 = getelementptr inbounds float* %VFtab, i64 %idxprom540
  %76 = load float* %arrayidx541, align 4, !tbaa !3
  %mul542 = fmul float %sub531, %76
  %add5431387 = or i32 %mul533, 3
  %idxprom544 = sext i32 %add5431387 to i64
  %arrayidx545 = getelementptr inbounds float* %VFtab, i64 %idxprom544
  %77 = load float* %arrayidx545, align 4, !tbaa !3
  %mul546 = fmul float %mul532, %77
  %add547 = fadd float %75, %mul542
  %add548 = fadd float %add547, %mul546
  %mul549 = fmul float %sub531, %add548
  %add550 = fadd float %74, %mul549
  %add551 = fadd float %mul542, %add548
  %mul552 = fmul float %mul546, 2.000000e+00
  %add553 = fadd float %mul552, %add551
  %mul554 = fmul float %mul8, %add550
  %mul555 = fmul float %mul8, %add553
  %mul556 = fmul float %mul555, %tabscale
  %78 = fmul float %conv186, %mul556
  %mul558 = fsub float -0.000000e+00, %78
  %add559 = fadd float %add509, %mul554
  %mul560 = fmul float %sub150, %mul558
  %mul561 = fmul float %sub151, %mul558
  %mul562 = fmul float %sub152, %mul558
  %add563 = fadd float %add513, %mul560
  %add564 = fadd float %add514, %mul561
  %add565 = fadd float %add515, %mul562
  %sub566 = fsub float %sub432, %mul560
  store float %sub566, float* %arrayidx290, align 4, !tbaa !3
  %sub570 = fsub float %sub433, %mul561
  store float %sub570, float* %arrayidx294, align 4, !tbaa !3
  %sub574 = fsub float %sub434, %mul562
  store float %sub574, float* %arrayidx298, align 4, !tbaa !3
  %mul578 = fmul float %add165, %conv198
  %mul579 = fmul float %mul578, %tabscale
  %conv580 = fptosi float %mul579 to i32
  %conv581 = sitofp i32 %conv580 to float
  %sub582 = fsub float %mul579, %conv581
  %mul583 = fmul float %sub582, %sub582
  %mul584 = shl nsw i32 %conv580, 2
  %idxprom585 = sext i32 %mul584 to i64
  %arrayidx586 = getelementptr inbounds float* %VFtab, i64 %idxprom585
  %79 = load float* %arrayidx586, align 4, !tbaa !3
  %add5871388 = or i32 %mul584, 1
  %idxprom588 = sext i32 %add5871388 to i64
  %arrayidx589 = getelementptr inbounds float* %VFtab, i64 %idxprom588
  %80 = load float* %arrayidx589, align 4, !tbaa !3
  %add5901389 = or i32 %mul584, 2
  %idxprom591 = sext i32 %add5901389 to i64
  %arrayidx592 = getelementptr inbounds float* %VFtab, i64 %idxprom591
  %81 = load float* %arrayidx592, align 4, !tbaa !3
  %mul593 = fmul float %sub582, %81
  %add5941390 = or i32 %mul584, 3
  %idxprom595 = sext i32 %add5941390 to i64
  %arrayidx596 = getelementptr inbounds float* %VFtab, i64 %idxprom595
  %82 = load float* %arrayidx596, align 4, !tbaa !3
  %mul597 = fmul float %mul583, %82
  %add598 = fadd float %80, %mul593
  %add599 = fadd float %add598, %mul597
  %mul600 = fmul float %sub582, %add599
  %add601 = fadd float %79, %mul600
  %add602 = fadd float %mul593, %add599
  %mul603 = fmul float %mul597, 2.000000e+00
  %add604 = fadd float %mul603, %add602
  %mul605 = fmul float %mul8, %add601
  %mul606 = fmul float %mul8, %add604
  %mul607 = fmul float %mul606, %tabscale
  %83 = fmul float %conv198, %mul607
  %mul609 = fsub float -0.000000e+00, %83
  %add610 = fadd float %add559, %mul605
  %mul611 = fmul float %sub158, %mul609
  %mul612 = fmul float %sub159, %mul609
  %mul613 = fmul float %sub160, %mul609
  %add614 = fadd float %add563, %mul611
  %add615 = fadd float %add564, %mul612
  %add616 = fadd float %add565, %mul613
  %sub617 = fsub float %sub474, %mul611
  store float %sub617, float* %arrayidx341, align 4, !tbaa !3
  %sub621 = fsub float %sub475, %mul612
  store float %sub621, float* %arrayidx345, align 4, !tbaa !3
  %sub625 = fsub float %sub476, %mul613
  store float %sub625, float* %arrayidx349, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %84 = trunc i64 %indvars.iv.next to i32
  %cmp64 = icmp slt i32 %84, %9
  br i1 %cmp64, label %for.body65, label %for.end

for.end:                                          ; preds = %for.body65, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add610, %for.body65 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add336, %for.body65 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add337, %for.body65 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add338, %for.body65 ]
  %fix2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add471, %for.body65 ]
  %fiy2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add472, %for.body65 ]
  %fiz2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add473, %for.body65 ]
  %fix3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add614, %for.body65 ]
  %fiy3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add615, %for.body65 ]
  %fiz3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add616, %for.body65 ]
  %arrayidx630 = getelementptr inbounds float* %faction, i64 %idxprom28
  %85 = load float* %arrayidx630, align 4, !tbaa !3
  %add631 = fadd float %fix1.0.lcssa, %85
  store float %add631, float* %arrayidx630, align 4, !tbaa !3
  %arrayidx636 = getelementptr inbounds float* %faction, i64 %idxprom32
  %86 = load float* %arrayidx636, align 4, !tbaa !3
  %add637 = fadd float %fiy1.0.lcssa, %86
  store float %add637, float* %arrayidx636, align 4, !tbaa !3
  %arrayidx643 = getelementptr inbounds float* %faction, i64 %idxprom36
  %87 = load float* %arrayidx643, align 4, !tbaa !3
  %add644 = fadd float %fiz1.0.lcssa, %87
  store float %add644, float* %arrayidx643, align 4, !tbaa !3
  %arrayidx650 = getelementptr inbounds float* %faction, i64 %idxprom40
  %88 = load float* %arrayidx650, align 4, !tbaa !3
  %add651 = fadd float %fix2.0.lcssa, %88
  store float %add651, float* %arrayidx650, align 4, !tbaa !3
  %arrayidx657 = getelementptr inbounds float* %faction, i64 %idxprom44
  %89 = load float* %arrayidx657, align 4, !tbaa !3
  %add658 = fadd float %fiy2.0.lcssa, %89
  store float %add658, float* %arrayidx657, align 4, !tbaa !3
  %arrayidx664 = getelementptr inbounds float* %faction, i64 %idxprom48
  %90 = load float* %arrayidx664, align 4, !tbaa !3
  %add665 = fadd float %fiz2.0.lcssa, %90
  store float %add665, float* %arrayidx664, align 4, !tbaa !3
  %arrayidx671 = getelementptr inbounds float* %faction, i64 %idxprom52
  %91 = load float* %arrayidx671, align 4, !tbaa !3
  %add672 = fadd float %fix3.0.lcssa, %91
  store float %add672, float* %arrayidx671, align 4, !tbaa !3
  %arrayidx678 = getelementptr inbounds float* %faction, i64 %idxprom56
  %92 = load float* %arrayidx678, align 4, !tbaa !3
  %add679 = fadd float %fiy3.0.lcssa, %92
  store float %add679, float* %arrayidx678, align 4, !tbaa !3
  %arrayidx685 = getelementptr inbounds float* %faction, i64 %idxprom60
  %93 = load float* %arrayidx685, align 4, !tbaa !3
  %add686 = fadd float %fiz3.0.lcssa, %93
  store float %add686, float* %arrayidx685, align 4, !tbaa !3
  %arrayidx691 = getelementptr inbounds float* %fshift, i64 %idxprom12
  %94 = load float* %arrayidx691, align 4, !tbaa !3
  %add692 = fadd float %fix1.0.lcssa, %94
  %add693 = fadd float %fix2.0.lcssa, %add692
  %add694 = fadd float %fix3.0.lcssa, %add693
  store float %add694, float* %arrayidx691, align 4, !tbaa !3
  %arrayidx699 = getelementptr inbounds float* %fshift, i64 %idxprom15
  %95 = load float* %arrayidx699, align 4, !tbaa !3
  %add700 = fadd float %fiy1.0.lcssa, %95
  %add701 = fadd float %fiy2.0.lcssa, %add700
  %add702 = fadd float %fiy3.0.lcssa, %add701
  store float %add702, float* %arrayidx699, align 4, !tbaa !3
  %arrayidx708 = getelementptr inbounds float* %fshift, i64 %idxprom18
  %96 = load float* %arrayidx708, align 4, !tbaa !3
  %add709 = fadd float %fiz1.0.lcssa, %96
  %add710 = fadd float %fiz2.0.lcssa, %add709
  %add711 = fadd float %fiz3.0.lcssa, %add710
  store float %add711, float* %arrayidx708, align 4, !tbaa !3
  %arrayidx716 = getelementptr inbounds i32* %gid, i64 %indvars.iv1414
  %97 = load i32* %arrayidx716, align 4, !tbaa !0
  %idxprom717 = sext i32 %97 to i64
  %arrayidx718 = getelementptr inbounds float* %Vc, i64 %idxprom717
  %98 = load float* %arrayidx718, align 4, !tbaa !3
  %add719 = fadd float %vctot.0.lcssa, %98
  store float %add719, float* %arrayidx718, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next1415 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end724, label %for.end.for.body_crit_edge

for.end.for.body_crit_edge:                       ; preds = %for.end
  %arrayidx21.phi.trans.insert = getelementptr inbounds i32* %iinr, i64 %indvars.iv.next1415
  %.pre = load i32* %arrayidx21.phi.trans.insert, align 4, !tbaa !0
  br label %for.body

for.end724:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl3100(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab) #0 {
entry:
  %cmp321 = icmp sgt i32 %nri, 0
  br i1 %cmp321, label %for.body.lr.ph, label %for.end190

for.body.lr.ph:                                   ; preds = %entry
  %mul30 = shl i32 %ntype, 1
  br label %for.body

for.body:                                         ; preds = %for.end, %for.body.lr.ph
  %indvars.iv323 = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next324, %for.end ]
  %arrayidx = getelementptr inbounds i32* %shift, i64 %indvars.iv323
  %0 = load i32* %arrayidx, align 4, !tbaa !0
  %mul = mul nsw i32 %0, 3
  %idxprom1 = sext i32 %mul to i64
  %arrayidx2 = getelementptr inbounds float* %shiftvec, i64 %idxprom1
  %1 = load float* %arrayidx2, align 4, !tbaa !3
  %add = add nsw i32 %mul, 1
  %idxprom3 = sext i32 %add to i64
  %arrayidx4 = getelementptr inbounds float* %shiftvec, i64 %idxprom3
  %2 = load float* %arrayidx4, align 4, !tbaa !3
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds float* %shiftvec, i64 %idxprom6
  %3 = load float* %arrayidx7, align 4, !tbaa !3
  %arrayidx9 = getelementptr inbounds i32* %iinr, i64 %indvars.iv323
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %arrayidx12 = getelementptr inbounds i32* %jindex, i64 %indvars.iv323
  %5 = load i32* %arrayidx12, align 4, !tbaa !0
  %indvars.iv.next324 = add i64 %indvars.iv323, 1
  %arrayidx15 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next324
  %6 = load i32* %arrayidx15, align 4, !tbaa !0
  %idxprom16 = sext i32 %mul10 to i64
  %arrayidx17 = getelementptr inbounds float* %pos, i64 %idxprom16
  %7 = load float* %arrayidx17, align 4, !tbaa !3
  %add18 = fadd float %1, %7
  %add19 = add nsw i32 %mul10, 1
  %idxprom20 = sext i32 %add19 to i64
  %arrayidx21 = getelementptr inbounds float* %pos, i64 %idxprom20
  %8 = load float* %arrayidx21, align 4, !tbaa !3
  %add22 = fadd float %2, %8
  %add23 = add nsw i32 %mul10, 2
  %idxprom24 = sext i32 %add23 to i64
  %arrayidx25 = getelementptr inbounds float* %pos, i64 %idxprom24
  %9 = load float* %arrayidx25, align 4, !tbaa !3
  %add26 = fadd float %3, %9
  %idxprom27 = sext i32 %4 to i64
  %arrayidx28 = getelementptr inbounds float* %charge, i64 %idxprom27
  %10 = load float* %arrayidx28, align 4, !tbaa !3
  %mul29 = fmul float %10, %facel
  %arrayidx32 = getelementptr inbounds i32* %type, i64 %idxprom27
  %11 = load i32* %arrayidx32, align 4, !tbaa !0
  %mul33 = mul nsw i32 %mul30, %11
  %cmp35310 = icmp slt i32 %5, %6
  br i1 %cmp35310, label %for.body36.lr.ph, label %for.end

for.body36.lr.ph:                                 ; preds = %for.body
  %12 = sext i32 %5 to i64
  br label %for.body36

for.body36:                                       ; preds = %for.body36.lr.ph, %for.body36
  %indvars.iv = phi i64 [ %12, %for.body36.lr.ph ], [ %indvars.iv.next, %for.body36 ]
  %vctot.0315 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add112, %for.body36 ]
  %vnbtot.0314 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %sub73, %for.body36 ]
  %fix1.0313 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add116, %for.body36 ]
  %fiy1.0312 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add117, %for.body36 ]
  %fiz1.0311 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add118, %for.body36 ]
  %arrayidx38 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %13 = load i32* %arrayidx38, align 4, !tbaa !0
  %mul39 = mul nsw i32 %13, 3
  %idxprom40 = sext i32 %mul39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %14 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = add nsw i32 %mul39, 1
  %idxprom43 = sext i32 %add42 to i64
  %arrayidx44 = getelementptr inbounds float* %pos, i64 %idxprom43
  %15 = load float* %arrayidx44, align 4, !tbaa !3
  %add45 = add nsw i32 %mul39, 2
  %idxprom46 = sext i32 %add45 to i64
  %arrayidx47 = getelementptr inbounds float* %pos, i64 %idxprom46
  %16 = load float* %arrayidx47, align 4, !tbaa !3
  %sub = fsub float %add18, %14
  %sub48 = fsub float %add22, %15
  %sub49 = fsub float %add26, %16
  %mul50 = fmul float %sub, %sub
  %mul51 = fmul float %sub48, %sub48
  %add52 = fadd float %mul50, %mul51
  %mul53 = fmul float %sub49, %sub49
  %add54 = fadd float %add52, %mul53
  %conv = fpext float %add54 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv55 = fptrunc double %div to float
  %mul56 = fmul float %add54, %conv55
  %mul57 = fmul float %conv55, %conv55
  %mul58 = fmul float %mul57, %mul57
  %mul59 = fmul float %mul57, %mul58
  %idxprom60 = sext i32 %13 to i64
  %arrayidx61 = getelementptr inbounds i32* %type, i64 %idxprom60
  %17 = load i32* %arrayidx61, align 4, !tbaa !0
  %mul62 = shl nsw i32 %17, 1
  %add63 = add nsw i32 %mul62, %mul33
  %idxprom64 = sext i32 %add63 to i64
  %arrayidx65 = getelementptr inbounds float* %nbfp, i64 %idxprom64
  %18 = load float* %arrayidx65, align 4, !tbaa !3
  %mul66 = fmul float %18, %mul59
  %mul67 = fmul float %mul59, %mul59
  %add68306 = or i32 %add63, 1
  %idxprom69 = sext i32 %add68306 to i64
  %arrayidx70 = getelementptr inbounds float* %nbfp, i64 %idxprom69
  %19 = load float* %arrayidx70, align 4, !tbaa !3
  %mul71 = fmul float %19, %mul67
  %add72 = fadd float %vnbtot.0314, %mul71
  %sub73 = fsub float %add72, %mul66
  %mul74 = fmul float %mul56, %tabscale
  %conv75 = fptosi float %mul74 to i32
  %conv76 = sitofp i32 %conv75 to float
  %sub77 = fsub float %mul74, %conv76
  %mul78 = fmul float %sub77, %sub77
  %mul79 = shl nsw i32 %conv75, 2
  %arrayidx81 = getelementptr inbounds float* %charge, i64 %idxprom60
  %20 = load float* %arrayidx81, align 4, !tbaa !3
  %mul82 = fmul float %mul29, %20
  %idxprom83 = sext i32 %mul79 to i64
  %arrayidx84 = getelementptr inbounds float* %VFtab, i64 %idxprom83
  %21 = load float* %arrayidx84, align 4, !tbaa !3
  %add85307 = or i32 %mul79, 1
  %idxprom86 = sext i32 %add85307 to i64
  %arrayidx87 = getelementptr inbounds float* %VFtab, i64 %idxprom86
  %22 = load float* %arrayidx87, align 4, !tbaa !3
  %add88308 = or i32 %mul79, 2
  %idxprom89 = sext i32 %add88308 to i64
  %arrayidx90 = getelementptr inbounds float* %VFtab, i64 %idxprom89
  %23 = load float* %arrayidx90, align 4, !tbaa !3
  %mul91 = fmul float %sub77, %23
  %add92309 = or i32 %mul79, 3
  %idxprom93 = sext i32 %add92309 to i64
  %arrayidx94 = getelementptr inbounds float* %VFtab, i64 %idxprom93
  %24 = load float* %arrayidx94, align 4, !tbaa !3
  %mul95 = fmul float %mul78, %24
  %add96 = fadd float %22, %mul91
  %add97 = fadd float %add96, %mul95
  %mul98 = fmul float %sub77, %add97
  %add99 = fadd float %21, %mul98
  %add100 = fadd float %mul91, %add97
  %mul101 = fmul float %mul95, 2.000000e+00
  %add102 = fadd float %mul101, %add100
  %mul103 = fmul float %mul82, %add99
  %mul104 = fmul float %mul82, %add102
  %mul105 = fmul float %mul71, 1.200000e+01
  %mul106 = fmul float %mul66, 6.000000e+00
  %sub107 = fsub float %mul105, %mul106
  %mul108 = fmul float %conv55, %sub107
  %mul109 = fmul float %mul104, %tabscale
  %sub110 = fsub float %mul108, %mul109
  %mul111 = fmul float %conv55, %sub110
  %add112 = fadd float %vctot.0315, %mul103
  %mul113 = fmul float %sub, %mul111
  %mul114 = fmul float %sub48, %mul111
  %mul115 = fmul float %sub49, %mul111
  %add116 = fadd float %fix1.0313, %mul113
  %add117 = fadd float %fiy1.0312, %mul114
  %add118 = fadd float %fiz1.0311, %mul115
  %arrayidx120 = getelementptr inbounds float* %faction, i64 %idxprom40
  %25 = load float* %arrayidx120, align 4, !tbaa !3
  %sub121 = fsub float %25, %mul113
  store float %sub121, float* %arrayidx120, align 4, !tbaa !3
  %arrayidx126 = getelementptr inbounds float* %faction, i64 %idxprom43
  %26 = load float* %arrayidx126, align 4, !tbaa !3
  %sub127 = fsub float %26, %mul114
  store float %sub127, float* %arrayidx126, align 4, !tbaa !3
  %arrayidx133 = getelementptr inbounds float* %faction, i64 %idxprom46
  %27 = load float* %arrayidx133, align 4, !tbaa !3
  %sub134 = fsub float %27, %mul115
  store float %sub134, float* %arrayidx133, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %28 = trunc i64 %indvars.iv.next to i32
  %cmp35 = icmp slt i32 %28, %6
  br i1 %cmp35, label %for.body36, label %for.end

for.end:                                          ; preds = %for.body36, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add112, %for.body36 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %sub73, %for.body36 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add116, %for.body36 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add117, %for.body36 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add118, %for.body36 ]
  %arrayidx139 = getelementptr inbounds float* %faction, i64 %idxprom16
  %29 = load float* %arrayidx139, align 4, !tbaa !3
  %add140 = fadd float %fix1.0.lcssa, %29
  store float %add140, float* %arrayidx139, align 4, !tbaa !3
  %arrayidx145 = getelementptr inbounds float* %faction, i64 %idxprom20
  %30 = load float* %arrayidx145, align 4, !tbaa !3
  %add146 = fadd float %fiy1.0.lcssa, %30
  store float %add146, float* %arrayidx145, align 4, !tbaa !3
  %arrayidx152 = getelementptr inbounds float* %faction, i64 %idxprom24
  %31 = load float* %arrayidx152, align 4, !tbaa !3
  %add153 = fadd float %fiz1.0.lcssa, %31
  store float %add153, float* %arrayidx152, align 4, !tbaa !3
  %arrayidx158 = getelementptr inbounds float* %fshift, i64 %idxprom1
  %32 = load float* %arrayidx158, align 4, !tbaa !3
  %add159 = fadd float %fix1.0.lcssa, %32
  store float %add159, float* %arrayidx158, align 4, !tbaa !3
  %arrayidx164 = getelementptr inbounds float* %fshift, i64 %idxprom3
  %33 = load float* %arrayidx164, align 4, !tbaa !3
  %add165 = fadd float %fiy1.0.lcssa, %33
  store float %add165, float* %arrayidx164, align 4, !tbaa !3
  %arrayidx171 = getelementptr inbounds float* %fshift, i64 %idxprom6
  %34 = load float* %arrayidx171, align 4, !tbaa !3
  %add172 = fadd float %fiz1.0.lcssa, %34
  store float %add172, float* %arrayidx171, align 4, !tbaa !3
  %arrayidx177 = getelementptr inbounds i32* %gid, i64 %indvars.iv323
  %35 = load i32* %arrayidx177, align 4, !tbaa !0
  %idxprom178 = sext i32 %35 to i64
  %arrayidx179 = getelementptr inbounds float* %Vc, i64 %idxprom178
  %36 = load float* %arrayidx179, align 4, !tbaa !3
  %add180 = fadd float %vctot.0.lcssa, %36
  store float %add180, float* %arrayidx179, align 4, !tbaa !3
  %arrayidx184 = getelementptr inbounds float* %Vnb, i64 %idxprom178
  %37 = load float* %arrayidx184, align 4, !tbaa !3
  %add185 = fadd float %vnbtot.0.lcssa, %37
  store float %add185, float* %arrayidx184, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next324 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end190, label %for.body

for.end190:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl3110(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab, i32* nocapture %nsatoms) #0 {
entry:
  %cmp954 = icmp sgt i32 %nri, 0
  br i1 %cmp954, label %for.body.lr.ph, label %for.end498

for.body.lr.ph:                                   ; preds = %entry
  %mul362 = shl i32 %ntype, 1
  br label %for.body

for.body:                                         ; preds = %for.end483, %for.body.lr.ph
  %indvars.iv981 = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next982, %for.end483 ]
  %0 = trunc i64 %indvars.iv981 to i32
  %mul = mul nsw i32 %0, 3
  %idxprom = sext i32 %mul to i64
  %arrayidx = getelementptr inbounds i32* %nsatoms, i64 %idxprom
  %1 = load i32* %arrayidx, align 4, !tbaa !0
  %add = add nsw i32 %mul, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds i32* %nsatoms, i64 %idxprom2
  %2 = load i32* %arrayidx3, align 4, !tbaa !0
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds i32* %nsatoms, i64 %idxprom6
  %3 = load i32* %arrayidx7, align 4, !tbaa !0
  %arrayidx9 = getelementptr inbounds i32* %shift, i64 %indvars.iv981
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %idxprom11 = sext i32 %mul10 to i64
  %arrayidx12 = getelementptr inbounds float* %shiftvec, i64 %idxprom11
  %5 = load float* %arrayidx12, align 4, !tbaa !3
  %add13 = add nsw i32 %mul10, 1
  %idxprom14 = sext i32 %add13 to i64
  %arrayidx15 = getelementptr inbounds float* %shiftvec, i64 %idxprom14
  %6 = load float* %arrayidx15, align 4, !tbaa !3
  %add16 = add nsw i32 %mul10, 2
  %idxprom17 = sext i32 %add16 to i64
  %arrayidx18 = getelementptr inbounds float* %shiftvec, i64 %idxprom17
  %7 = load float* %arrayidx18, align 4, !tbaa !3
  %arrayidx20 = getelementptr inbounds i32* %iinr, i64 %indvars.iv981
  %8 = load i32* %arrayidx20, align 4, !tbaa !0
  %mul21 = mul i32 %8, 3
  %arrayidx23 = getelementptr inbounds i32* %jindex, i64 %indvars.iv981
  %9 = load i32* %arrayidx23, align 4, !tbaa !0
  %indvars.iv.next982 = add i64 %indvars.iv981, 1
  %arrayidx26 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next982
  %10 = load i32* %arrayidx26, align 4, !tbaa !0
  %cmp28905 = icmp sgt i32 %2, 0
  br i1 %cmp28905, label %for.body29.lr.ph, label %for.cond195.loopexit

for.body29.lr.ph:                                 ; preds = %for.body
  %cmp49893 = icmp slt i32 %9, %10
  %arrayidx172 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx178 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx185 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %11 = sext i32 %9 to i64
  %12 = sext i32 %8 to i64
  %13 = sext i32 %mul21 to i64
  %14 = add i32 %2, %8
  %15 = mul i32 %14, 3
  br label %for.body29

for.body29:                                       ; preds = %for.end, %for.body29.lr.ph
  %indvars.iv959 = phi i64 [ %13, %for.body29.lr.ph ], [ %indvars.iv.next960, %for.end ]
  %indvars.iv957 = phi i64 [ %12, %for.body29.lr.ph ], [ %indvars.iv.next958, %for.end ]
  %s.0908 = phi i32 [ 0, %for.body29.lr.ph ], [ %inc193, %for.end ]
  %vnbtot.0907 = phi float [ 0.000000e+00, %for.body29.lr.ph ], [ %vnbtot.1.lcssa, %for.end ]
  %vctot.0906 = phi float [ 0.000000e+00, %for.body29.lr.ph ], [ %vctot.1.lcssa, %for.end ]
  %arrayidx31 = getelementptr inbounds float* %pos, i64 %indvars.iv959
  %16 = load float* %arrayidx31, align 4, !tbaa !3
  %add32 = fadd float %5, %16
  %17 = add nsw i64 %indvars.iv959, 1
  %arrayidx35 = getelementptr inbounds float* %pos, i64 %17
  %18 = load float* %arrayidx35, align 4, !tbaa !3
  %add36 = fadd float %6, %18
  %19 = add nsw i64 %indvars.iv959, 2
  %arrayidx39 = getelementptr inbounds float* %pos, i64 %19
  %20 = load float* %arrayidx39, align 4, !tbaa !3
  %add40 = fadd float %7, %20
  %arrayidx42 = getelementptr inbounds float* %charge, i64 %indvars.iv957
  %21 = load float* %arrayidx42, align 4, !tbaa !3
  %mul43 = fmul float %21, %facel
  %arrayidx46 = getelementptr inbounds i32* %type, i64 %indvars.iv957
  %22 = load i32* %arrayidx46, align 4, !tbaa !0
  %mul47 = mul nsw i32 %mul362, %22
  br i1 %cmp49893, label %for.body50, label %for.end

for.body50:                                       ; preds = %for.body29, %for.body50
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body50 ], [ %11, %for.body29 ]
  %fiz1.0898 = phi float [ %add132, %for.body50 ], [ 0.000000e+00, %for.body29 ]
  %fiy1.0897 = phi float [ %add131, %for.body50 ], [ 0.000000e+00, %for.body29 ]
  %fix1.0896 = phi float [ %add130, %for.body50 ], [ 0.000000e+00, %for.body29 ]
  %vnbtot.1895 = phi float [ %sub87, %for.body50 ], [ %vnbtot.0907, %for.body29 ]
  %vctot.1894 = phi float [ %add126, %for.body50 ], [ %vctot.0906, %for.body29 ]
  %arrayidx52 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %23 = load i32* %arrayidx52, align 4, !tbaa !0
  %mul53 = mul nsw i32 %23, 3
  %idxprom54 = sext i32 %mul53 to i64
  %arrayidx55 = getelementptr inbounds float* %pos, i64 %idxprom54
  %24 = load float* %arrayidx55, align 4, !tbaa !3
  %add56 = add nsw i32 %mul53, 1
  %idxprom57 = sext i32 %add56 to i64
  %arrayidx58 = getelementptr inbounds float* %pos, i64 %idxprom57
  %25 = load float* %arrayidx58, align 4, !tbaa !3
  %add59 = add nsw i32 %mul53, 2
  %idxprom60 = sext i32 %add59 to i64
  %arrayidx61 = getelementptr inbounds float* %pos, i64 %idxprom60
  %26 = load float* %arrayidx61, align 4, !tbaa !3
  %sub = fsub float %add32, %24
  %sub62 = fsub float %add36, %25
  %sub63 = fsub float %add40, %26
  %mul64 = fmul float %sub, %sub
  %mul65 = fmul float %sub62, %sub62
  %add66 = fadd float %mul64, %mul65
  %mul67 = fmul float %sub63, %sub63
  %add68 = fadd float %add66, %mul67
  %conv = fpext float %add68 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv69 = fptrunc double %div to float
  %mul70 = fmul float %add68, %conv69
  %mul71 = fmul float %conv69, %conv69
  %mul72 = fmul float %mul71, %mul71
  %mul73 = fmul float %mul71, %mul72
  %idxprom74 = sext i32 %23 to i64
  %arrayidx75 = getelementptr inbounds i32* %type, i64 %idxprom74
  %27 = load i32* %arrayidx75, align 4, !tbaa !0
  %mul76 = shl nsw i32 %27, 1
  %add77 = add nsw i32 %mul76, %mul47
  %idxprom78 = sext i32 %add77 to i64
  %arrayidx79 = getelementptr inbounds float* %nbfp, i64 %idxprom78
  %28 = load float* %arrayidx79, align 4, !tbaa !3
  %mul80 = fmul float %28, %mul73
  %mul81 = fmul float %mul73, %mul73
  %add82889 = or i32 %add77, 1
  %idxprom83 = sext i32 %add82889 to i64
  %arrayidx84 = getelementptr inbounds float* %nbfp, i64 %idxprom83
  %29 = load float* %arrayidx84, align 4, !tbaa !3
  %mul85 = fmul float %29, %mul81
  %add86 = fadd float %vnbtot.1895, %mul85
  %sub87 = fsub float %add86, %mul80
  %mul88 = fmul float %mul70, %tabscale
  %conv89 = fptosi float %mul88 to i32
  %conv90 = sitofp i32 %conv89 to float
  %sub91 = fsub float %mul88, %conv90
  %mul92 = fmul float %sub91, %sub91
  %mul93 = shl nsw i32 %conv89, 2
  %arrayidx95 = getelementptr inbounds float* %charge, i64 %idxprom74
  %30 = load float* %arrayidx95, align 4, !tbaa !3
  %mul96 = fmul float %mul43, %30
  %idxprom97 = sext i32 %mul93 to i64
  %arrayidx98 = getelementptr inbounds float* %VFtab, i64 %idxprom97
  %31 = load float* %arrayidx98, align 4, !tbaa !3
  %add99890 = or i32 %mul93, 1
  %idxprom100 = sext i32 %add99890 to i64
  %arrayidx101 = getelementptr inbounds float* %VFtab, i64 %idxprom100
  %32 = load float* %arrayidx101, align 4, !tbaa !3
  %add102891 = or i32 %mul93, 2
  %idxprom103 = sext i32 %add102891 to i64
  %arrayidx104 = getelementptr inbounds float* %VFtab, i64 %idxprom103
  %33 = load float* %arrayidx104, align 4, !tbaa !3
  %mul105 = fmul float %sub91, %33
  %add106892 = or i32 %mul93, 3
  %idxprom107 = sext i32 %add106892 to i64
  %arrayidx108 = getelementptr inbounds float* %VFtab, i64 %idxprom107
  %34 = load float* %arrayidx108, align 4, !tbaa !3
  %mul109 = fmul float %mul92, %34
  %add110 = fadd float %32, %mul105
  %add111 = fadd float %add110, %mul109
  %mul112 = fmul float %sub91, %add111
  %add113 = fadd float %31, %mul112
  %add114 = fadd float %mul105, %add111
  %mul115 = fmul float %mul109, 2.000000e+00
  %add116 = fadd float %mul115, %add114
  %mul117 = fmul float %mul96, %add113
  %mul118 = fmul float %mul96, %add116
  %mul119 = fmul float %mul85, 1.200000e+01
  %mul120 = fmul float %mul80, 6.000000e+00
  %sub121 = fsub float %mul119, %mul120
  %mul122 = fmul float %conv69, %sub121
  %mul123 = fmul float %mul118, %tabscale
  %sub124 = fsub float %mul122, %mul123
  %mul125 = fmul float %conv69, %sub124
  %add126 = fadd float %vctot.1894, %mul117
  %mul127 = fmul float %sub, %mul125
  %mul128 = fmul float %sub62, %mul125
  %mul129 = fmul float %sub63, %mul125
  %add130 = fadd float %fix1.0896, %mul127
  %add131 = fadd float %fiy1.0897, %mul128
  %add132 = fadd float %fiz1.0898, %mul129
  %arrayidx134 = getelementptr inbounds float* %faction, i64 %idxprom54
  %35 = load float* %arrayidx134, align 4, !tbaa !3
  %sub135 = fsub float %35, %mul127
  store float %sub135, float* %arrayidx134, align 4, !tbaa !3
  %arrayidx140 = getelementptr inbounds float* %faction, i64 %idxprom57
  %36 = load float* %arrayidx140, align 4, !tbaa !3
  %sub141 = fsub float %36, %mul128
  store float %sub141, float* %arrayidx140, align 4, !tbaa !3
  %arrayidx147 = getelementptr inbounds float* %faction, i64 %idxprom60
  %37 = load float* %arrayidx147, align 4, !tbaa !3
  %sub148 = fsub float %37, %mul129
  store float %sub148, float* %arrayidx147, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %38 = trunc i64 %indvars.iv.next to i32
  %cmp49 = icmp slt i32 %38, %10
  br i1 %cmp49, label %for.body50, label %for.end

for.end:                                          ; preds = %for.body50, %for.body29
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add132, %for.body50 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add131, %for.body50 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add130, %for.body50 ]
  %vnbtot.1.lcssa = phi float [ %vnbtot.0907, %for.body29 ], [ %sub87, %for.body50 ]
  %vctot.1.lcssa = phi float [ %vctot.0906, %for.body29 ], [ %add126, %for.body50 ]
  %arrayidx153 = getelementptr inbounds float* %faction, i64 %indvars.iv959
  %39 = load float* %arrayidx153, align 4, !tbaa !3
  %add154 = fadd float %fix1.0.lcssa, %39
  store float %add154, float* %arrayidx153, align 4, !tbaa !3
  %arrayidx159 = getelementptr inbounds float* %faction, i64 %17
  %40 = load float* %arrayidx159, align 4, !tbaa !3
  %add160 = fadd float %fiy1.0.lcssa, %40
  store float %add160, float* %arrayidx159, align 4, !tbaa !3
  %arrayidx166 = getelementptr inbounds float* %faction, i64 %19
  %41 = load float* %arrayidx166, align 4, !tbaa !3
  %add167 = fadd float %fiz1.0.lcssa, %41
  store float %add167, float* %arrayidx166, align 4, !tbaa !3
  %42 = load float* %arrayidx172, align 4, !tbaa !3
  %add173 = fadd float %fix1.0.lcssa, %42
  store float %add173, float* %arrayidx172, align 4, !tbaa !3
  %43 = load float* %arrayidx178, align 4, !tbaa !3
  %add179 = fadd float %fiy1.0.lcssa, %43
  store float %add179, float* %arrayidx178, align 4, !tbaa !3
  %44 = load float* %arrayidx185, align 4, !tbaa !3
  %add186 = fadd float %fiz1.0.lcssa, %44
  store float %add186, float* %arrayidx185, align 4, !tbaa !3
  %indvars.iv.next958 = add i64 %indvars.iv957, 1
  %indvars.iv.next960 = add i64 %indvars.iv959, 3
  %inc193 = add nsw i32 %s.0908, 1
  %exitcond = icmp eq i32 %inc193, %2
  br i1 %exitcond, label %for.cond27.for.cond195.loopexit_crit_edge, label %for.body29

for.cond27.for.cond195.loopexit_crit_edge:        ; preds = %for.end
  %45 = add i32 %2, %8
  br label %for.cond195.loopexit

for.cond195.loopexit:                             ; preds = %for.cond27.for.cond195.loopexit_crit_edge, %for.body
  %ii.0.lcssa = phi i32 [ %45, %for.cond27.for.cond195.loopexit_crit_edge ], [ %8, %for.body ]
  %ii3.0.lcssa = phi i32 [ %15, %for.cond27.for.cond195.loopexit_crit_edge ], [ %mul21, %for.body ]
  %vnbtot.0.lcssa = phi float [ %vnbtot.1.lcssa, %for.cond27.for.cond195.loopexit_crit_edge ], [ 0.000000e+00, %for.body ]
  %vctot.0.lcssa = phi float [ %vctot.1.lcssa, %for.cond27.for.cond195.loopexit_crit_edge ], [ 0.000000e+00, %for.body ]
  %cmp196928 = icmp slt i32 %2, %3
  br i1 %cmp196928, label %for.body198.lr.ph, label %for.cond347.loopexit

for.body198.lr.ph:                                ; preds = %for.cond195.loopexit
  %cmp214917 = icmp slt i32 %9, %10
  %arrayidx324 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx330 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx337 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %46 = sext i32 %9 to i64
  %47 = sext i32 %ii.0.lcssa to i64
  %48 = sext i32 %ii3.0.lcssa to i64
  %49 = mul i32 %3, 3
  %50 = add i32 %ii.0.lcssa, %3
  br label %for.body198

for.body198:                                      ; preds = %for.end303, %for.body198.lr.ph
  %indvars.iv967 = phi i64 [ %48, %for.body198.lr.ph ], [ %indvars.iv.next968, %for.end303 ]
  %indvars.iv965 = phi i64 [ %47, %for.body198.lr.ph ], [ %indvars.iv.next966, %for.end303 ]
  %s.1930 = phi i32 [ %2, %for.body198.lr.ph ], [ %inc345, %for.end303 ]
  %vctot.2929 = phi float [ %vctot.0.lcssa, %for.body198.lr.ph ], [ %vctot.3.lcssa, %for.end303 ]
  %arrayidx200 = getelementptr inbounds float* %pos, i64 %indvars.iv967
  %51 = load float* %arrayidx200, align 4, !tbaa !3
  %add201 = fadd float %5, %51
  %52 = add nsw i64 %indvars.iv967, 1
  %arrayidx204 = getelementptr inbounds float* %pos, i64 %52
  %53 = load float* %arrayidx204, align 4, !tbaa !3
  %add205 = fadd float %6, %53
  %54 = add nsw i64 %indvars.iv967, 2
  %arrayidx208 = getelementptr inbounds float* %pos, i64 %54
  %55 = load float* %arrayidx208, align 4, !tbaa !3
  %add209 = fadd float %7, %55
  %arrayidx211 = getelementptr inbounds float* %charge, i64 %indvars.iv965
  %56 = load float* %arrayidx211, align 4, !tbaa !3
  %mul212 = fmul float %56, %facel
  br i1 %cmp214917, label %for.body216, label %for.end303

for.body216:                                      ; preds = %for.body198, %for.body216
  %indvars.iv963 = phi i64 [ %indvars.iv.next964, %for.body216 ], [ %46, %for.body198 ]
  %fiz1.1921 = phi float [ %add281, %for.body216 ], [ 0.000000e+00, %for.body198 ]
  %fiy1.1920 = phi float [ %add280, %for.body216 ], [ 0.000000e+00, %for.body198 ]
  %fix1.1919 = phi float [ %add279, %for.body216 ], [ 0.000000e+00, %for.body198 ]
  %vctot.3918 = phi float [ %add275, %for.body216 ], [ %vctot.2929, %for.body198 ]
  %arrayidx218 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv963
  %57 = load i32* %arrayidx218, align 4, !tbaa !0
  %mul219 = mul nsw i32 %57, 3
  %idxprom220 = sext i32 %mul219 to i64
  %arrayidx221 = getelementptr inbounds float* %pos, i64 %idxprom220
  %58 = load float* %arrayidx221, align 4, !tbaa !3
  %add222 = add nsw i32 %mul219, 1
  %idxprom223 = sext i32 %add222 to i64
  %arrayidx224 = getelementptr inbounds float* %pos, i64 %idxprom223
  %59 = load float* %arrayidx224, align 4, !tbaa !3
  %add225 = add nsw i32 %mul219, 2
  %idxprom226 = sext i32 %add225 to i64
  %arrayidx227 = getelementptr inbounds float* %pos, i64 %idxprom226
  %60 = load float* %arrayidx227, align 4, !tbaa !3
  %sub228 = fsub float %add201, %58
  %sub229 = fsub float %add205, %59
  %sub230 = fsub float %add209, %60
  %mul231 = fmul float %sub228, %sub228
  %mul232 = fmul float %sub229, %sub229
  %add233 = fadd float %mul231, %mul232
  %mul234 = fmul float %sub230, %sub230
  %add235 = fadd float %add233, %mul234
  %conv236 = fpext float %add235 to double
  %call237 = tail call double @sqrt(double %conv236) #2
  %div238 = fdiv double 1.000000e+00, %call237
  %conv239 = fptrunc double %div238 to float
  %mul240 = fmul float %add235, %conv239
  %mul241 = fmul float %mul240, %tabscale
  %conv242 = fptosi float %mul241 to i32
  %conv243 = sitofp i32 %conv242 to float
  %sub244 = fsub float %mul241, %conv243
  %mul245 = fmul float %sub244, %sub244
  %mul246 = shl nsw i32 %conv242, 2
  %idxprom247 = sext i32 %57 to i64
  %arrayidx248 = getelementptr inbounds float* %charge, i64 %idxprom247
  %61 = load float* %arrayidx248, align 4, !tbaa !3
  %mul249 = fmul float %mul212, %61
  %idxprom250 = sext i32 %mul246 to i64
  %arrayidx251 = getelementptr inbounds float* %VFtab, i64 %idxprom250
  %62 = load float* %arrayidx251, align 4, !tbaa !3
  %add252886 = or i32 %mul246, 1
  %idxprom253 = sext i32 %add252886 to i64
  %arrayidx254 = getelementptr inbounds float* %VFtab, i64 %idxprom253
  %63 = load float* %arrayidx254, align 4, !tbaa !3
  %add255887 = or i32 %mul246, 2
  %idxprom256 = sext i32 %add255887 to i64
  %arrayidx257 = getelementptr inbounds float* %VFtab, i64 %idxprom256
  %64 = load float* %arrayidx257, align 4, !tbaa !3
  %mul258 = fmul float %64, %sub244
  %add259888 = or i32 %mul246, 3
  %idxprom260 = sext i32 %add259888 to i64
  %arrayidx261 = getelementptr inbounds float* %VFtab, i64 %idxprom260
  %65 = load float* %arrayidx261, align 4, !tbaa !3
  %mul262 = fmul float %65, %mul245
  %add263 = fadd float %63, %mul258
  %add264 = fadd float %add263, %mul262
  %mul265 = fmul float %sub244, %add264
  %add266 = fadd float %62, %mul265
  %add267 = fadd float %mul258, %add264
  %mul268 = fmul float %mul262, 2.000000e+00
  %add269 = fadd float %mul268, %add267
  %mul270 = fmul float %mul249, %add266
  %mul271 = fmul float %mul249, %add269
  %mul272 = fmul float %mul271, %tabscale
  %66 = fmul float %conv239, %mul272
  %mul274 = fsub float -0.000000e+00, %66
  %add275 = fadd float %vctot.3918, %mul270
  %mul276 = fmul float %sub228, %mul274
  %mul277 = fmul float %sub229, %mul274
  %mul278 = fmul float %sub230, %mul274
  %add279 = fadd float %fix1.1919, %mul276
  %add280 = fadd float %fiy1.1920, %mul277
  %add281 = fadd float %fiz1.1921, %mul278
  %arrayidx283 = getelementptr inbounds float* %faction, i64 %idxprom220
  %67 = load float* %arrayidx283, align 4, !tbaa !3
  %sub284 = fsub float %67, %mul276
  store float %sub284, float* %arrayidx283, align 4, !tbaa !3
  %arrayidx289 = getelementptr inbounds float* %faction, i64 %idxprom223
  %68 = load float* %arrayidx289, align 4, !tbaa !3
  %sub290 = fsub float %68, %mul277
  store float %sub290, float* %arrayidx289, align 4, !tbaa !3
  %arrayidx296 = getelementptr inbounds float* %faction, i64 %idxprom226
  %69 = load float* %arrayidx296, align 4, !tbaa !3
  %sub297 = fsub float %69, %mul278
  store float %sub297, float* %arrayidx296, align 4, !tbaa !3
  %indvars.iv.next964 = add i64 %indvars.iv963, 1
  %70 = trunc i64 %indvars.iv.next964 to i32
  %cmp214 = icmp slt i32 %70, %10
  br i1 %cmp214, label %for.body216, label %for.end303

for.end303:                                       ; preds = %for.body216, %for.body198
  %fiz1.1.lcssa = phi float [ 0.000000e+00, %for.body198 ], [ %add281, %for.body216 ]
  %fiy1.1.lcssa = phi float [ 0.000000e+00, %for.body198 ], [ %add280, %for.body216 ]
  %fix1.1.lcssa = phi float [ 0.000000e+00, %for.body198 ], [ %add279, %for.body216 ]
  %vctot.3.lcssa = phi float [ %vctot.2929, %for.body198 ], [ %add275, %for.body216 ]
  %arrayidx305 = getelementptr inbounds float* %faction, i64 %indvars.iv967
  %71 = load float* %arrayidx305, align 4, !tbaa !3
  %add306 = fadd float %fix1.1.lcssa, %71
  store float %add306, float* %arrayidx305, align 4, !tbaa !3
  %arrayidx311 = getelementptr inbounds float* %faction, i64 %52
  %72 = load float* %arrayidx311, align 4, !tbaa !3
  %add312 = fadd float %fiy1.1.lcssa, %72
  store float %add312, float* %arrayidx311, align 4, !tbaa !3
  %arrayidx318 = getelementptr inbounds float* %faction, i64 %54
  %73 = load float* %arrayidx318, align 4, !tbaa !3
  %add319 = fadd float %fiz1.1.lcssa, %73
  store float %add319, float* %arrayidx318, align 4, !tbaa !3
  %74 = load float* %arrayidx324, align 4, !tbaa !3
  %add325 = fadd float %fix1.1.lcssa, %74
  store float %add325, float* %arrayidx324, align 4, !tbaa !3
  %75 = load float* %arrayidx330, align 4, !tbaa !3
  %add331 = fadd float %fiy1.1.lcssa, %75
  store float %add331, float* %arrayidx330, align 4, !tbaa !3
  %76 = load float* %arrayidx337, align 4, !tbaa !3
  %add338 = fadd float %fiz1.1.lcssa, %76
  store float %add338, float* %arrayidx337, align 4, !tbaa !3
  %indvars.iv.next966 = add i64 %indvars.iv965, 1
  %indvars.iv.next968 = add i64 %indvars.iv967, 3
  %inc345 = add nsw i32 %s.1930, 1
  %exitcond971 = icmp eq i32 %inc345, %3
  br i1 %exitcond971, label %for.cond195.for.cond347.loopexit_crit_edge, label %for.body198

for.cond195.for.cond347.loopexit_crit_edge:       ; preds = %for.end303
  %77 = add i32 %ii3.0.lcssa, %49
  %78 = mul i32 %2, -3
  %79 = add i32 %77, %78
  %80 = sub i32 %50, %2
  br label %for.cond347.loopexit

for.cond347.loopexit:                             ; preds = %for.cond195.for.cond347.loopexit_crit_edge, %for.cond195.loopexit
  %ii.1.lcssa = phi i32 [ %80, %for.cond195.for.cond347.loopexit_crit_edge ], [ %ii.0.lcssa, %for.cond195.loopexit ]
  %ii3.1.lcssa = phi i32 [ %79, %for.cond195.for.cond347.loopexit_crit_edge ], [ %ii3.0.lcssa, %for.cond195.loopexit ]
  %vctot.2.lcssa = phi float [ %vctot.3.lcssa, %for.cond195.for.cond347.loopexit_crit_edge ], [ %vctot.0.lcssa, %for.cond195.loopexit ]
  %cmp348948 = icmp slt i32 %3, %1
  br i1 %cmp348948, label %for.body350.lr.ph, label %for.end483

for.body350.lr.ph:                                ; preds = %for.cond347.loopexit
  %cmp367938 = icmp slt i32 %9, %10
  %arrayidx461 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx467 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx474 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %81 = sext i32 %9 to i64
  %82 = sext i32 %ii.1.lcssa to i64
  %83 = sext i32 %ii3.1.lcssa to i64
  br label %for.body350

for.body350:                                      ; preds = %for.end440, %for.body350.lr.ph
  %indvars.iv976 = phi i64 [ %83, %for.body350.lr.ph ], [ %indvars.iv.next977, %for.end440 ]
  %indvars.iv974 = phi i64 [ %82, %for.body350.lr.ph ], [ %indvars.iv.next975, %for.end440 ]
  %s.2950 = phi i32 [ %3, %for.body350.lr.ph ], [ %inc482, %for.end440 ]
  %vnbtot.2949 = phi float [ %vnbtot.0.lcssa, %for.body350.lr.ph ], [ %vnbtot.3.lcssa, %for.end440 ]
  %arrayidx352 = getelementptr inbounds float* %pos, i64 %indvars.iv976
  %84 = load float* %arrayidx352, align 4, !tbaa !3
  %add353 = fadd float %5, %84
  %85 = add nsw i64 %indvars.iv976, 1
  %arrayidx356 = getelementptr inbounds float* %pos, i64 %85
  %86 = load float* %arrayidx356, align 4, !tbaa !3
  %add357 = fadd float %6, %86
  %87 = add nsw i64 %indvars.iv976, 2
  %arrayidx360 = getelementptr inbounds float* %pos, i64 %87
  %88 = load float* %arrayidx360, align 4, !tbaa !3
  %add361 = fadd float %7, %88
  %arrayidx364 = getelementptr inbounds i32* %type, i64 %indvars.iv974
  %89 = load i32* %arrayidx364, align 4, !tbaa !0
  %mul365 = mul nsw i32 %mul362, %89
  br i1 %cmp367938, label %for.body369, label %for.end440

for.body369:                                      ; preds = %for.body350, %for.body369
  %indvars.iv972 = phi i64 [ %indvars.iv.next973, %for.body369 ], [ %81, %for.body350 ]
  %fiz1.2942 = phi float [ %add418, %for.body369 ], [ 0.000000e+00, %for.body350 ]
  %fiy1.2941 = phi float [ %add417, %for.body369 ], [ 0.000000e+00, %for.body350 ]
  %fix1.2940 = phi float [ %add416, %for.body369 ], [ 0.000000e+00, %for.body350 ]
  %vnbtot.3939 = phi float [ %sub408, %for.body369 ], [ %vnbtot.2949, %for.body350 ]
  %arrayidx371 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv972
  %90 = load i32* %arrayidx371, align 4, !tbaa !0
  %mul372 = mul nsw i32 %90, 3
  %idxprom373 = sext i32 %mul372 to i64
  %arrayidx374 = getelementptr inbounds float* %pos, i64 %idxprom373
  %91 = load float* %arrayidx374, align 4, !tbaa !3
  %add375 = add nsw i32 %mul372, 1
  %idxprom376 = sext i32 %add375 to i64
  %arrayidx377 = getelementptr inbounds float* %pos, i64 %idxprom376
  %92 = load float* %arrayidx377, align 4, !tbaa !3
  %add378 = add nsw i32 %mul372, 2
  %idxprom379 = sext i32 %add378 to i64
  %arrayidx380 = getelementptr inbounds float* %pos, i64 %idxprom379
  %93 = load float* %arrayidx380, align 4, !tbaa !3
  %sub381 = fsub float %add353, %91
  %sub382 = fsub float %add357, %92
  %sub383 = fsub float %add361, %93
  %mul384 = fmul float %sub381, %sub381
  %mul385 = fmul float %sub382, %sub382
  %add386 = fadd float %mul384, %mul385
  %mul387 = fmul float %sub383, %sub383
  %add388 = fadd float %add386, %mul387
  %conv391 = fdiv float 1.000000e+00, %add388
  %mul393 = fmul float %conv391, %conv391
  %mul394 = fmul float %conv391, %mul393
  %idxprom395 = sext i32 %90 to i64
  %arrayidx396 = getelementptr inbounds i32* %type, i64 %idxprom395
  %94 = load i32* %arrayidx396, align 4, !tbaa !0
  %mul397 = shl nsw i32 %94, 1
  %add398 = add nsw i32 %mul397, %mul365
  %idxprom399 = sext i32 %add398 to i64
  %arrayidx400 = getelementptr inbounds float* %nbfp, i64 %idxprom399
  %95 = load float* %arrayidx400, align 4, !tbaa !3
  %mul401 = fmul float %mul394, %95
  %mul402 = fmul float %mul394, %mul394
  %add403885 = or i32 %add398, 1
  %idxprom404 = sext i32 %add403885 to i64
  %arrayidx405 = getelementptr inbounds float* %nbfp, i64 %idxprom404
  %96 = load float* %arrayidx405, align 4, !tbaa !3
  %mul406 = fmul float %mul402, %96
  %add407 = fadd float %vnbtot.3939, %mul406
  %sub408 = fsub float %add407, %mul401
  %mul409 = fmul float %mul406, 1.200000e+01
  %mul410 = fmul float %mul401, 6.000000e+00
  %sub411 = fsub float %mul409, %mul410
  %mul412 = fmul float %conv391, %sub411
  %mul413 = fmul float %sub381, %mul412
  %mul414 = fmul float %sub382, %mul412
  %mul415 = fmul float %sub383, %mul412
  %add416 = fadd float %fix1.2940, %mul413
  %add417 = fadd float %fiy1.2941, %mul414
  %add418 = fadd float %fiz1.2942, %mul415
  %arrayidx420 = getelementptr inbounds float* %faction, i64 %idxprom373
  %97 = load float* %arrayidx420, align 4, !tbaa !3
  %sub421 = fsub float %97, %mul413
  store float %sub421, float* %arrayidx420, align 4, !tbaa !3
  %arrayidx426 = getelementptr inbounds float* %faction, i64 %idxprom376
  %98 = load float* %arrayidx426, align 4, !tbaa !3
  %sub427 = fsub float %98, %mul414
  store float %sub427, float* %arrayidx426, align 4, !tbaa !3
  %arrayidx433 = getelementptr inbounds float* %faction, i64 %idxprom379
  %99 = load float* %arrayidx433, align 4, !tbaa !3
  %sub434 = fsub float %99, %mul415
  store float %sub434, float* %arrayidx433, align 4, !tbaa !3
  %indvars.iv.next973 = add i64 %indvars.iv972, 1
  %100 = trunc i64 %indvars.iv.next973 to i32
  %cmp367 = icmp slt i32 %100, %10
  br i1 %cmp367, label %for.body369, label %for.end440

for.end440:                                       ; preds = %for.body369, %for.body350
  %fiz1.2.lcssa = phi float [ 0.000000e+00, %for.body350 ], [ %add418, %for.body369 ]
  %fiy1.2.lcssa = phi float [ 0.000000e+00, %for.body350 ], [ %add417, %for.body369 ]
  %fix1.2.lcssa = phi float [ 0.000000e+00, %for.body350 ], [ %add416, %for.body369 ]
  %vnbtot.3.lcssa = phi float [ %vnbtot.2949, %for.body350 ], [ %sub408, %for.body369 ]
  %arrayidx442 = getelementptr inbounds float* %faction, i64 %indvars.iv976
  %101 = load float* %arrayidx442, align 4, !tbaa !3
  %add443 = fadd float %fix1.2.lcssa, %101
  store float %add443, float* %arrayidx442, align 4, !tbaa !3
  %arrayidx448 = getelementptr inbounds float* %faction, i64 %85
  %102 = load float* %arrayidx448, align 4, !tbaa !3
  %add449 = fadd float %fiy1.2.lcssa, %102
  store float %add449, float* %arrayidx448, align 4, !tbaa !3
  %arrayidx455 = getelementptr inbounds float* %faction, i64 %87
  %103 = load float* %arrayidx455, align 4, !tbaa !3
  %add456 = fadd float %fiz1.2.lcssa, %103
  store float %add456, float* %arrayidx455, align 4, !tbaa !3
  %104 = load float* %arrayidx461, align 4, !tbaa !3
  %add462 = fadd float %fix1.2.lcssa, %104
  store float %add462, float* %arrayidx461, align 4, !tbaa !3
  %105 = load float* %arrayidx467, align 4, !tbaa !3
  %add468 = fadd float %fiy1.2.lcssa, %105
  store float %add468, float* %arrayidx467, align 4, !tbaa !3
  %106 = load float* %arrayidx474, align 4, !tbaa !3
  %add475 = fadd float %fiz1.2.lcssa, %106
  store float %add475, float* %arrayidx474, align 4, !tbaa !3
  %indvars.iv.next975 = add i64 %indvars.iv974, 1
  %indvars.iv.next977 = add i64 %indvars.iv976, 3
  %inc482 = add nsw i32 %s.2950, 1
  %exitcond980 = icmp eq i32 %inc482, %1
  br i1 %exitcond980, label %for.end483, label %for.body350

for.end483:                                       ; preds = %for.end440, %for.cond347.loopexit
  %vnbtot.2.lcssa = phi float [ %vnbtot.0.lcssa, %for.cond347.loopexit ], [ %vnbtot.3.lcssa, %for.end440 ]
  %arrayidx485 = getelementptr inbounds i32* %gid, i64 %indvars.iv981
  %107 = load i32* %arrayidx485, align 4, !tbaa !0
  %idxprom486 = sext i32 %107 to i64
  %arrayidx487 = getelementptr inbounds float* %Vc, i64 %idxprom486
  %108 = load float* %arrayidx487, align 4, !tbaa !3
  %add488 = fadd float %vctot.2.lcssa, %108
  store float %add488, float* %arrayidx487, align 4, !tbaa !3
  %arrayidx492 = getelementptr inbounds float* %Vnb, i64 %idxprom486
  %109 = load float* %arrayidx492, align 4, !tbaa !3
  %add493 = fadd float %vnbtot.2.lcssa, %109
  store float %add493, float* %arrayidx492, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next982 to i32
  %exitcond983 = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond983, label %for.end498, label %for.body

for.end498:                                       ; preds = %for.end483, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl3120(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab) #0 {
entry:
  %0 = load i32* %iinr, align 4, !tbaa !0
  %idxprom = sext i32 %0 to i64
  %arrayidx1 = getelementptr inbounds float* %charge, i64 %idxprom
  %1 = load float* %arrayidx1, align 4, !tbaa !3
  %add = add nsw i32 %0, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds float* %charge, i64 %idxprom2
  %2 = load float* %arrayidx3, align 4, !tbaa !3
  %mul = fmul float %1, %facel
  %mul4 = fmul float %2, %facel
  %mul5 = shl i32 %ntype, 1
  %arrayidx7 = getelementptr inbounds i32* %type, i64 %idxprom
  %3 = load i32* %arrayidx7, align 4, !tbaa !0
  %mul8 = mul nsw i32 %mul5, %3
  %cmp700 = icmp sgt i32 %nri, 0
  br i1 %cmp700, label %for.body, label %for.end381

for.body:                                         ; preds = %entry, %for.end.for.body_crit_edge
  %4 = phi i32 [ %.pre, %for.end.for.body_crit_edge ], [ %0, %entry ]
  %indvars.iv702 = phi i64 [ %indvars.iv.next703, %for.end.for.body_crit_edge ], [ 0, %entry ]
  %arrayidx10 = getelementptr inbounds i32* %shift, i64 %indvars.iv702
  %5 = load i32* %arrayidx10, align 4, !tbaa !0
  %mul11 = mul nsw i32 %5, 3
  %idxprom12 = sext i32 %mul11 to i64
  %arrayidx13 = getelementptr inbounds float* %shiftvec, i64 %idxprom12
  %6 = load float* %arrayidx13, align 4, !tbaa !3
  %add14 = add nsw i32 %mul11, 1
  %idxprom15 = sext i32 %add14 to i64
  %arrayidx16 = getelementptr inbounds float* %shiftvec, i64 %idxprom15
  %7 = load float* %arrayidx16, align 4, !tbaa !3
  %add17 = add nsw i32 %mul11, 2
  %idxprom18 = sext i32 %add17 to i64
  %arrayidx19 = getelementptr inbounds float* %shiftvec, i64 %idxprom18
  %8 = load float* %arrayidx19, align 4, !tbaa !3
  %mul22 = mul nsw i32 %4, 3
  %arrayidx24 = getelementptr inbounds i32* %jindex, i64 %indvars.iv702
  %9 = load i32* %arrayidx24, align 4, !tbaa !0
  %indvars.iv.next703 = add i64 %indvars.iv702, 1
  %arrayidx27 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next703
  %10 = load i32* %arrayidx27, align 4, !tbaa !0
  %idxprom28 = sext i32 %mul22 to i64
  %arrayidx29 = getelementptr inbounds float* %pos, i64 %idxprom28
  %11 = load float* %arrayidx29, align 4, !tbaa !3
  %add30 = fadd float %6, %11
  %add31 = add nsw i32 %mul22, 1
  %idxprom32 = sext i32 %add31 to i64
  %arrayidx33 = getelementptr inbounds float* %pos, i64 %idxprom32
  %12 = load float* %arrayidx33, align 4, !tbaa !3
  %add34 = fadd float %7, %12
  %add35 = add nsw i32 %mul22, 2
  %idxprom36 = sext i32 %add35 to i64
  %arrayidx37 = getelementptr inbounds float* %pos, i64 %idxprom36
  %13 = load float* %arrayidx37, align 4, !tbaa !3
  %add38 = fadd float %8, %13
  %add39 = add nsw i32 %mul22, 3
  %idxprom40 = sext i32 %add39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %14 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = fadd float %6, %14
  %add43 = add nsw i32 %mul22, 4
  %idxprom44 = sext i32 %add43 to i64
  %arrayidx45 = getelementptr inbounds float* %pos, i64 %idxprom44
  %15 = load float* %arrayidx45, align 4, !tbaa !3
  %add46 = fadd float %7, %15
  %add47 = add nsw i32 %mul22, 5
  %idxprom48 = sext i32 %add47 to i64
  %arrayidx49 = getelementptr inbounds float* %pos, i64 %idxprom48
  %16 = load float* %arrayidx49, align 4, !tbaa !3
  %add50 = fadd float %8, %16
  %add51 = add nsw i32 %mul22, 6
  %idxprom52 = sext i32 %add51 to i64
  %arrayidx53 = getelementptr inbounds float* %pos, i64 %idxprom52
  %17 = load float* %arrayidx53, align 4, !tbaa !3
  %add54 = fadd float %6, %17
  %add55 = add nsw i32 %mul22, 7
  %idxprom56 = sext i32 %add55 to i64
  %arrayidx57 = getelementptr inbounds float* %pos, i64 %idxprom56
  %18 = load float* %arrayidx57, align 4, !tbaa !3
  %add58 = fadd float %7, %18
  %add59 = add nsw i32 %mul22, 8
  %idxprom60 = sext i32 %add59 to i64
  %arrayidx61 = getelementptr inbounds float* %pos, i64 %idxprom60
  %19 = load float* %arrayidx61, align 4, !tbaa !3
  %add62 = fadd float %8, %19
  %cmp64677 = icmp slt i32 %9, %10
  br i1 %cmp64677, label %for.body65.lr.ph, label %for.end

for.body65.lr.ph:                                 ; preds = %for.body
  %20 = sext i32 %9 to i64
  br label %for.body65

for.body65:                                       ; preds = %for.body65.lr.ph, %for.body65
  %indvars.iv = phi i64 [ %20, %for.body65.lr.ph ], [ %indvars.iv.next, %for.body65 ]
  %vctot.0688 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add263, %for.body65 ]
  %vnbtot.0687 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %sub126, %for.body65 ]
  %fix1.0686 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add169, %for.body65 ]
  %fiy1.0685 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add170, %for.body65 ]
  %fiz1.0684 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add171, %for.body65 ]
  %fix2.0683 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add222, %for.body65 ]
  %fiy2.0682 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add223, %for.body65 ]
  %fiz2.0681 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add224, %for.body65 ]
  %fix3.0680 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add267, %for.body65 ]
  %fiy3.0679 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add268, %for.body65 ]
  %fiz3.0678 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add269, %for.body65 ]
  %arrayidx67 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %21 = load i32* %arrayidx67, align 4, !tbaa !0
  %mul68 = mul nsw i32 %21, 3
  %idxprom69 = sext i32 %mul68 to i64
  %arrayidx70 = getelementptr inbounds float* %pos, i64 %idxprom69
  %22 = load float* %arrayidx70, align 4, !tbaa !3
  %add71 = add nsw i32 %mul68, 1
  %idxprom72 = sext i32 %add71 to i64
  %arrayidx73 = getelementptr inbounds float* %pos, i64 %idxprom72
  %23 = load float* %arrayidx73, align 4, !tbaa !3
  %add74 = add nsw i32 %mul68, 2
  %idxprom75 = sext i32 %add74 to i64
  %arrayidx76 = getelementptr inbounds float* %pos, i64 %idxprom75
  %24 = load float* %arrayidx76, align 4, !tbaa !3
  %sub = fsub float %add30, %22
  %sub77 = fsub float %add34, %23
  %sub78 = fsub float %add38, %24
  %mul79 = fmul float %sub, %sub
  %mul80 = fmul float %sub77, %sub77
  %add81 = fadd float %mul79, %mul80
  %mul82 = fmul float %sub78, %sub78
  %add83 = fadd float %add81, %mul82
  %sub84 = fsub float %add42, %22
  %sub85 = fsub float %add46, %23
  %sub86 = fsub float %add50, %24
  %mul87 = fmul float %sub84, %sub84
  %mul88 = fmul float %sub85, %sub85
  %add89 = fadd float %mul87, %mul88
  %mul90 = fmul float %sub86, %sub86
  %add91 = fadd float %add89, %mul90
  %sub92 = fsub float %add54, %22
  %sub93 = fsub float %add58, %23
  %sub94 = fsub float %add62, %24
  %mul95 = fmul float %sub92, %sub92
  %mul96 = fmul float %sub93, %sub93
  %add97 = fadd float %mul95, %mul96
  %mul98 = fmul float %sub94, %sub94
  %add99 = fadd float %add97, %mul98
  %conv = fpext float %add83 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv100 = fptrunc double %div to float
  %conv101 = fpext float %add91 to double
  %call102 = tail call double @sqrt(double %conv101) #2
  %div103 = fdiv double 1.000000e+00, %call102
  %conv104 = fptrunc double %div103 to float
  %conv105 = fpext float %add99 to double
  %call106 = tail call double @sqrt(double %conv105) #2
  %div107 = fdiv double 1.000000e+00, %call106
  %conv108 = fptrunc double %div107 to float
  %mul109 = fmul float %add83, %conv100
  %mul110 = fmul float %conv100, %conv100
  %mul111 = fmul float %mul110, %mul110
  %mul112 = fmul float %mul110, %mul111
  %idxprom113 = sext i32 %21 to i64
  %arrayidx114 = getelementptr inbounds i32* %type, i64 %idxprom113
  %25 = load i32* %arrayidx114, align 4, !tbaa !0
  %mul115 = shl nsw i32 %25, 1
  %add116 = add nsw i32 %mul115, %mul8
  %idxprom117 = sext i32 %add116 to i64
  %arrayidx118 = getelementptr inbounds float* %nbfp, i64 %idxprom117
  %26 = load float* %arrayidx118, align 4, !tbaa !3
  %mul119 = fmul float %mul112, %26
  %mul120 = fmul float %mul112, %mul112
  %add121667 = or i32 %add116, 1
  %idxprom122 = sext i32 %add121667 to i64
  %arrayidx123 = getelementptr inbounds float* %nbfp, i64 %idxprom122
  %27 = load float* %arrayidx123, align 4, !tbaa !3
  %mul124 = fmul float %mul120, %27
  %add125 = fadd float %vnbtot.0687, %mul124
  %sub126 = fsub float %add125, %mul119
  %mul127 = fmul float %mul109, %tabscale
  %conv128 = fptosi float %mul127 to i32
  %conv129 = sitofp i32 %conv128 to float
  %sub130 = fsub float %mul127, %conv129
  %mul131 = fmul float %sub130, %sub130
  %mul132 = shl nsw i32 %conv128, 2
  %arrayidx134 = getelementptr inbounds float* %charge, i64 %idxprom113
  %28 = load float* %arrayidx134, align 4, !tbaa !3
  %mul135 = fmul float %mul, %28
  %idxprom136 = sext i32 %mul132 to i64
  %arrayidx137 = getelementptr inbounds float* %VFtab, i64 %idxprom136
  %29 = load float* %arrayidx137, align 4, !tbaa !3
  %add138668 = or i32 %mul132, 1
  %idxprom139 = sext i32 %add138668 to i64
  %arrayidx140 = getelementptr inbounds float* %VFtab, i64 %idxprom139
  %30 = load float* %arrayidx140, align 4, !tbaa !3
  %add141669 = or i32 %mul132, 2
  %idxprom142 = sext i32 %add141669 to i64
  %arrayidx143 = getelementptr inbounds float* %VFtab, i64 %idxprom142
  %31 = load float* %arrayidx143, align 4, !tbaa !3
  %mul144 = fmul float %sub130, %31
  %add145670 = or i32 %mul132, 3
  %idxprom146 = sext i32 %add145670 to i64
  %arrayidx147 = getelementptr inbounds float* %VFtab, i64 %idxprom146
  %32 = load float* %arrayidx147, align 4, !tbaa !3
  %mul148 = fmul float %mul131, %32
  %add149 = fadd float %30, %mul144
  %add150 = fadd float %add149, %mul148
  %mul151 = fmul float %sub130, %add150
  %add152 = fadd float %29, %mul151
  %add153 = fadd float %mul144, %add150
  %mul154 = fmul float %mul148, 2.000000e+00
  %add155 = fadd float %mul154, %add153
  %mul156 = fmul float %mul135, %add152
  %mul157 = fmul float %mul135, %add155
  %mul158 = fmul float %mul124, 1.200000e+01
  %mul159 = fmul float %mul119, 6.000000e+00
  %sub160 = fsub float %mul158, %mul159
  %mul161 = fmul float %conv100, %sub160
  %mul162 = fmul float %mul157, %tabscale
  %sub163 = fsub float %mul161, %mul162
  %mul164 = fmul float %conv100, %sub163
  %add165 = fadd float %vctot.0688, %mul156
  %mul166 = fmul float %sub, %mul164
  %mul167 = fmul float %sub77, %mul164
  %mul168 = fmul float %sub78, %mul164
  %add169 = fadd float %fix1.0686, %mul166
  %add170 = fadd float %fiy1.0685, %mul167
  %add171 = fadd float %fiz1.0684, %mul168
  %arrayidx173 = getelementptr inbounds float* %faction, i64 %idxprom69
  %33 = load float* %arrayidx173, align 4, !tbaa !3
  %sub174 = fsub float %33, %mul166
  %arrayidx177 = getelementptr inbounds float* %faction, i64 %idxprom72
  %34 = load float* %arrayidx177, align 4, !tbaa !3
  %sub178 = fsub float %34, %mul167
  %arrayidx181 = getelementptr inbounds float* %faction, i64 %idxprom75
  %35 = load float* %arrayidx181, align 4, !tbaa !3
  %sub182 = fsub float %35, %mul168
  %mul183 = fmul float %add91, %conv104
  %mul184 = fmul float %mul183, %tabscale
  %conv185 = fptosi float %mul184 to i32
  %conv186 = sitofp i32 %conv185 to float
  %sub187 = fsub float %mul184, %conv186
  %mul188 = fmul float %sub187, %sub187
  %mul189 = shl nsw i32 %conv185, 2
  %mul192 = fmul float %mul4, %28
  %idxprom193 = sext i32 %mul189 to i64
  %arrayidx194 = getelementptr inbounds float* %VFtab, i64 %idxprom193
  %36 = load float* %arrayidx194, align 4, !tbaa !3
  %add195671 = or i32 %mul189, 1
  %idxprom196 = sext i32 %add195671 to i64
  %arrayidx197 = getelementptr inbounds float* %VFtab, i64 %idxprom196
  %37 = load float* %arrayidx197, align 4, !tbaa !3
  %add198672 = or i32 %mul189, 2
  %idxprom199 = sext i32 %add198672 to i64
  %arrayidx200 = getelementptr inbounds float* %VFtab, i64 %idxprom199
  %38 = load float* %arrayidx200, align 4, !tbaa !3
  %mul201 = fmul float %sub187, %38
  %add202673 = or i32 %mul189, 3
  %idxprom203 = sext i32 %add202673 to i64
  %arrayidx204 = getelementptr inbounds float* %VFtab, i64 %idxprom203
  %39 = load float* %arrayidx204, align 4, !tbaa !3
  %mul205 = fmul float %mul188, %39
  %add206 = fadd float %37, %mul201
  %add207 = fadd float %add206, %mul205
  %mul208 = fmul float %sub187, %add207
  %add209 = fadd float %36, %mul208
  %add210 = fadd float %mul201, %add207
  %mul211 = fmul float %mul205, 2.000000e+00
  %add212 = fadd float %mul211, %add210
  %mul213 = fmul float %mul192, %add209
  %mul214 = fmul float %mul192, %add212
  %mul215 = fmul float %mul214, %tabscale
  %40 = fmul float %conv104, %mul215
  %mul217 = fsub float -0.000000e+00, %40
  %add218 = fadd float %add165, %mul213
  %mul219 = fmul float %sub84, %mul217
  %mul220 = fmul float %sub85, %mul217
  %mul221 = fmul float %sub86, %mul217
  %add222 = fadd float %fix2.0683, %mul219
  %add223 = fadd float %fiy2.0682, %mul220
  %add224 = fadd float %fiz2.0681, %mul221
  %sub225 = fsub float %sub174, %mul219
  %sub226 = fsub float %sub178, %mul220
  %sub227 = fsub float %sub182, %mul221
  %mul228 = fmul float %add99, %conv108
  %mul229 = fmul float %mul228, %tabscale
  %conv230 = fptosi float %mul229 to i32
  %conv231 = sitofp i32 %conv230 to float
  %sub232 = fsub float %mul229, %conv231
  %mul233 = fmul float %sub232, %sub232
  %mul234 = shl nsw i32 %conv230, 2
  %idxprom238 = sext i32 %mul234 to i64
  %arrayidx239 = getelementptr inbounds float* %VFtab, i64 %idxprom238
  %41 = load float* %arrayidx239, align 4, !tbaa !3
  %add240674 = or i32 %mul234, 1
  %idxprom241 = sext i32 %add240674 to i64
  %arrayidx242 = getelementptr inbounds float* %VFtab, i64 %idxprom241
  %42 = load float* %arrayidx242, align 4, !tbaa !3
  %add243675 = or i32 %mul234, 2
  %idxprom244 = sext i32 %add243675 to i64
  %arrayidx245 = getelementptr inbounds float* %VFtab, i64 %idxprom244
  %43 = load float* %arrayidx245, align 4, !tbaa !3
  %mul246 = fmul float %sub232, %43
  %add247676 = or i32 %mul234, 3
  %idxprom248 = sext i32 %add247676 to i64
  %arrayidx249 = getelementptr inbounds float* %VFtab, i64 %idxprom248
  %44 = load float* %arrayidx249, align 4, !tbaa !3
  %mul250 = fmul float %mul233, %44
  %add251 = fadd float %42, %mul246
  %add252 = fadd float %add251, %mul250
  %mul253 = fmul float %sub232, %add252
  %add254 = fadd float %41, %mul253
  %add255 = fadd float %mul246, %add252
  %mul256 = fmul float %mul250, 2.000000e+00
  %add257 = fadd float %mul256, %add255
  %mul258 = fmul float %mul192, %add254
  %mul259 = fmul float %mul192, %add257
  %mul260 = fmul float %mul259, %tabscale
  %45 = fmul float %conv108, %mul260
  %mul262 = fsub float -0.000000e+00, %45
  %add263 = fadd float %add218, %mul258
  %mul264 = fmul float %sub92, %mul262
  %mul265 = fmul float %sub93, %mul262
  %mul266 = fmul float %sub94, %mul262
  %add267 = fadd float %fix3.0680, %mul264
  %add268 = fadd float %fiy3.0679, %mul265
  %add269 = fadd float %fiz3.0678, %mul266
  %sub270 = fsub float %sub225, %mul264
  store float %sub270, float* %arrayidx173, align 4, !tbaa !3
  %sub273 = fsub float %sub226, %mul265
  store float %sub273, float* %arrayidx177, align 4, !tbaa !3
  %sub277 = fsub float %sub227, %mul266
  store float %sub277, float* %arrayidx181, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %46 = trunc i64 %indvars.iv.next to i32
  %cmp64 = icmp slt i32 %46, %10
  br i1 %cmp64, label %for.body65, label %for.end

for.end:                                          ; preds = %for.body65, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add263, %for.body65 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %sub126, %for.body65 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add169, %for.body65 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add170, %for.body65 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add171, %for.body65 ]
  %fix2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add222, %for.body65 ]
  %fiy2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add223, %for.body65 ]
  %fiz2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add224, %for.body65 ]
  %fix3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add267, %for.body65 ]
  %fiy3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add268, %for.body65 ]
  %fiz3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add269, %for.body65 ]
  %arrayidx282 = getelementptr inbounds float* %faction, i64 %idxprom28
  %47 = load float* %arrayidx282, align 4, !tbaa !3
  %add283 = fadd float %fix1.0.lcssa, %47
  store float %add283, float* %arrayidx282, align 4, !tbaa !3
  %arrayidx288 = getelementptr inbounds float* %faction, i64 %idxprom32
  %48 = load float* %arrayidx288, align 4, !tbaa !3
  %add289 = fadd float %fiy1.0.lcssa, %48
  store float %add289, float* %arrayidx288, align 4, !tbaa !3
  %arrayidx295 = getelementptr inbounds float* %faction, i64 %idxprom36
  %49 = load float* %arrayidx295, align 4, !tbaa !3
  %add296 = fadd float %fiz1.0.lcssa, %49
  store float %add296, float* %arrayidx295, align 4, !tbaa !3
  %arrayidx302 = getelementptr inbounds float* %faction, i64 %idxprom40
  %50 = load float* %arrayidx302, align 4, !tbaa !3
  %add303 = fadd float %fix2.0.lcssa, %50
  store float %add303, float* %arrayidx302, align 4, !tbaa !3
  %arrayidx309 = getelementptr inbounds float* %faction, i64 %idxprom44
  %51 = load float* %arrayidx309, align 4, !tbaa !3
  %add310 = fadd float %fiy2.0.lcssa, %51
  store float %add310, float* %arrayidx309, align 4, !tbaa !3
  %arrayidx316 = getelementptr inbounds float* %faction, i64 %idxprom48
  %52 = load float* %arrayidx316, align 4, !tbaa !3
  %add317 = fadd float %fiz2.0.lcssa, %52
  store float %add317, float* %arrayidx316, align 4, !tbaa !3
  %arrayidx323 = getelementptr inbounds float* %faction, i64 %idxprom52
  %53 = load float* %arrayidx323, align 4, !tbaa !3
  %add324 = fadd float %fix3.0.lcssa, %53
  store float %add324, float* %arrayidx323, align 4, !tbaa !3
  %arrayidx330 = getelementptr inbounds float* %faction, i64 %idxprom56
  %54 = load float* %arrayidx330, align 4, !tbaa !3
  %add331 = fadd float %fiy3.0.lcssa, %54
  store float %add331, float* %arrayidx330, align 4, !tbaa !3
  %arrayidx337 = getelementptr inbounds float* %faction, i64 %idxprom60
  %55 = load float* %arrayidx337, align 4, !tbaa !3
  %add338 = fadd float %fiz3.0.lcssa, %55
  store float %add338, float* %arrayidx337, align 4, !tbaa !3
  %arrayidx343 = getelementptr inbounds float* %fshift, i64 %idxprom12
  %56 = load float* %arrayidx343, align 4, !tbaa !3
  %add344 = fadd float %fix1.0.lcssa, %56
  %add345 = fadd float %fix2.0.lcssa, %add344
  %add346 = fadd float %fix3.0.lcssa, %add345
  store float %add346, float* %arrayidx343, align 4, !tbaa !3
  %arrayidx351 = getelementptr inbounds float* %fshift, i64 %idxprom15
  %57 = load float* %arrayidx351, align 4, !tbaa !3
  %add352 = fadd float %fiy1.0.lcssa, %57
  %add353 = fadd float %fiy2.0.lcssa, %add352
  %add354 = fadd float %fiy3.0.lcssa, %add353
  store float %add354, float* %arrayidx351, align 4, !tbaa !3
  %arrayidx360 = getelementptr inbounds float* %fshift, i64 %idxprom18
  %58 = load float* %arrayidx360, align 4, !tbaa !3
  %add361 = fadd float %fiz1.0.lcssa, %58
  %add362 = fadd float %fiz2.0.lcssa, %add361
  %add363 = fadd float %fiz3.0.lcssa, %add362
  store float %add363, float* %arrayidx360, align 4, !tbaa !3
  %arrayidx368 = getelementptr inbounds i32* %gid, i64 %indvars.iv702
  %59 = load i32* %arrayidx368, align 4, !tbaa !0
  %idxprom369 = sext i32 %59 to i64
  %arrayidx370 = getelementptr inbounds float* %Vc, i64 %idxprom369
  %60 = load float* %arrayidx370, align 4, !tbaa !3
  %add371 = fadd float %vctot.0.lcssa, %60
  store float %add371, float* %arrayidx370, align 4, !tbaa !3
  %arrayidx375 = getelementptr inbounds float* %Vnb, i64 %idxprom369
  %61 = load float* %arrayidx375, align 4, !tbaa !3
  %add376 = fadd float %vnbtot.0.lcssa, %61
  store float %add376, float* %arrayidx375, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next703 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end381, label %for.end.for.body_crit_edge

for.end.for.body_crit_edge:                       ; preds = %for.end
  %arrayidx21.phi.trans.insert = getelementptr inbounds i32* %iinr, i64 %indvars.iv.next703
  %.pre = load i32* %arrayidx21.phi.trans.insert, align 4, !tbaa !0
  br label %for.body

for.end381:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl3130(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* %VFtab) #0 {
entry:
  %0 = load i32* %iinr, align 4, !tbaa !0
  %idxprom = sext i32 %0 to i64
  %arrayidx1 = getelementptr inbounds float* %charge, i64 %idxprom
  %1 = load float* %arrayidx1, align 4, !tbaa !3
  %add = add nsw i32 %0, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds float* %charge, i64 %idxprom2
  %2 = load float* %arrayidx3, align 4, !tbaa !3
  %mul = fmul float %1, %facel
  %mul4 = fmul float %1, %mul
  %mul6 = fmul float %mul, %2
  %mul7 = fmul float %2, %facel
  %mul8 = fmul float %2, %mul7
  %mul9 = shl i32 %ntype, 1
  %arrayidx11 = getelementptr inbounds i32* %type, i64 %idxprom
  %3 = load i32* %arrayidx11, align 4, !tbaa !0
  %mul12 = mul nsw i32 %mul9, %3
  %mul15 = shl nsw i32 %3, 1
  %add16 = add nsw i32 %mul12, %mul15
  %idxprom17 = sext i32 %add16 to i64
  %arrayidx18 = getelementptr inbounds float* %nbfp, i64 %idxprom17
  %4 = load float* %arrayidx18, align 4, !tbaa !3
  %add191412 = or i32 %add16, 1
  %idxprom20 = sext i32 %add191412 to i64
  %arrayidx21 = getelementptr inbounds float* %nbfp, i64 %idxprom20
  %5 = load float* %arrayidx21, align 4, !tbaa !3
  %cmp1463 = icmp sgt i32 %nri, 0
  br i1 %cmp1463, label %for.body, label %for.end754

for.body:                                         ; preds = %entry, %for.end.for.body_crit_edge
  %6 = phi i32 [ %.pre, %for.end.for.body_crit_edge ], [ %0, %entry ]
  %indvars.iv1465 = phi i64 [ %indvars.iv.next1466, %for.end.for.body_crit_edge ], [ 0, %entry ]
  %arrayidx23 = getelementptr inbounds i32* %shift, i64 %indvars.iv1465
  %7 = load i32* %arrayidx23, align 4, !tbaa !0
  %mul24 = mul nsw i32 %7, 3
  %idxprom25 = sext i32 %mul24 to i64
  %arrayidx26 = getelementptr inbounds float* %shiftvec, i64 %idxprom25
  %8 = load float* %arrayidx26, align 4, !tbaa !3
  %add27 = add nsw i32 %mul24, 1
  %idxprom28 = sext i32 %add27 to i64
  %arrayidx29 = getelementptr inbounds float* %shiftvec, i64 %idxprom28
  %9 = load float* %arrayidx29, align 4, !tbaa !3
  %add30 = add nsw i32 %mul24, 2
  %idxprom31 = sext i32 %add30 to i64
  %arrayidx32 = getelementptr inbounds float* %shiftvec, i64 %idxprom31
  %10 = load float* %arrayidx32, align 4, !tbaa !3
  %mul35 = mul nsw i32 %6, 3
  %arrayidx37 = getelementptr inbounds i32* %jindex, i64 %indvars.iv1465
  %11 = load i32* %arrayidx37, align 4, !tbaa !0
  %indvars.iv.next1466 = add i64 %indvars.iv1465, 1
  %arrayidx40 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next1466
  %12 = load i32* %arrayidx40, align 4, !tbaa !0
  %idxprom41 = sext i32 %mul35 to i64
  %arrayidx42 = getelementptr inbounds float* %pos, i64 %idxprom41
  %13 = load float* %arrayidx42, align 4, !tbaa !3
  %add43 = fadd float %8, %13
  %add44 = add nsw i32 %mul35, 1
  %idxprom45 = sext i32 %add44 to i64
  %arrayidx46 = getelementptr inbounds float* %pos, i64 %idxprom45
  %14 = load float* %arrayidx46, align 4, !tbaa !3
  %add47 = fadd float %9, %14
  %add48 = add nsw i32 %mul35, 2
  %idxprom49 = sext i32 %add48 to i64
  %arrayidx50 = getelementptr inbounds float* %pos, i64 %idxprom49
  %15 = load float* %arrayidx50, align 4, !tbaa !3
  %add51 = fadd float %10, %15
  %add52 = add nsw i32 %mul35, 3
  %idxprom53 = sext i32 %add52 to i64
  %arrayidx54 = getelementptr inbounds float* %pos, i64 %idxprom53
  %16 = load float* %arrayidx54, align 4, !tbaa !3
  %add55 = fadd float %8, %16
  %add56 = add nsw i32 %mul35, 4
  %idxprom57 = sext i32 %add56 to i64
  %arrayidx58 = getelementptr inbounds float* %pos, i64 %idxprom57
  %17 = load float* %arrayidx58, align 4, !tbaa !3
  %add59 = fadd float %9, %17
  %add60 = add nsw i32 %mul35, 5
  %idxprom61 = sext i32 %add60 to i64
  %arrayidx62 = getelementptr inbounds float* %pos, i64 %idxprom61
  %18 = load float* %arrayidx62, align 4, !tbaa !3
  %add63 = fadd float %10, %18
  %add64 = add nsw i32 %mul35, 6
  %idxprom65 = sext i32 %add64 to i64
  %arrayidx66 = getelementptr inbounds float* %pos, i64 %idxprom65
  %19 = load float* %arrayidx66, align 4, !tbaa !3
  %add67 = fadd float %8, %19
  %add68 = add nsw i32 %mul35, 7
  %idxprom69 = sext i32 %add68 to i64
  %arrayidx70 = getelementptr inbounds float* %pos, i64 %idxprom69
  %20 = load float* %arrayidx70, align 4, !tbaa !3
  %add71 = fadd float %9, %20
  %add72 = add nsw i32 %mul35, 8
  %idxprom73 = sext i32 %add72 to i64
  %arrayidx74 = getelementptr inbounds float* %pos, i64 %idxprom73
  %21 = load float* %arrayidx74, align 4, !tbaa !3
  %add75 = fadd float %10, %21
  %cmp771440 = icmp slt i32 %11, %12
  br i1 %cmp771440, label %for.body78.lr.ph, label %for.end

for.body78.lr.ph:                                 ; preds = %for.body
  %22 = sext i32 %11 to i64
  br label %for.body78

for.body78:                                       ; preds = %for.body78.lr.ph, %for.body78
  %indvars.iv = phi i64 [ %22, %for.body78.lr.ph ], [ %indvars.iv.next, %for.body78 ]
  %vctot.01451 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add635, %for.body78 ]
  %vnbtot.01450 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %sub220, %for.body78 ]
  %fix1.01449 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add361, %for.body78 ]
  %fiy1.01448 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add362, %for.body78 ]
  %fiz1.01447 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add363, %for.body78 ]
  %fix2.01446 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add496, %for.body78 ]
  %fiy2.01445 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add497, %for.body78 ]
  %fiz2.01444 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add498, %for.body78 ]
  %fix3.01443 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add639, %for.body78 ]
  %fiy3.01442 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add640, %for.body78 ]
  %fiz3.01441 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add641, %for.body78 ]
  %arrayidx80 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %23 = load i32* %arrayidx80, align 4, !tbaa !0
  %mul81 = mul nsw i32 %23, 3
  %idxprom82 = sext i32 %mul81 to i64
  %arrayidx83 = getelementptr inbounds float* %pos, i64 %idxprom82
  %24 = load float* %arrayidx83, align 4, !tbaa !3
  %add84 = add nsw i32 %mul81, 1
  %idxprom85 = sext i32 %add84 to i64
  %arrayidx86 = getelementptr inbounds float* %pos, i64 %idxprom85
  %25 = load float* %arrayidx86, align 4, !tbaa !3
  %add87 = add nsw i32 %mul81, 2
  %idxprom88 = sext i32 %add87 to i64
  %arrayidx89 = getelementptr inbounds float* %pos, i64 %idxprom88
  %26 = load float* %arrayidx89, align 4, !tbaa !3
  %add90 = add nsw i32 %mul81, 3
  %idxprom91 = sext i32 %add90 to i64
  %arrayidx92 = getelementptr inbounds float* %pos, i64 %idxprom91
  %27 = load float* %arrayidx92, align 4, !tbaa !3
  %add93 = add nsw i32 %mul81, 4
  %idxprom94 = sext i32 %add93 to i64
  %arrayidx95 = getelementptr inbounds float* %pos, i64 %idxprom94
  %28 = load float* %arrayidx95, align 4, !tbaa !3
  %add96 = add nsw i32 %mul81, 5
  %idxprom97 = sext i32 %add96 to i64
  %arrayidx98 = getelementptr inbounds float* %pos, i64 %idxprom97
  %29 = load float* %arrayidx98, align 4, !tbaa !3
  %add99 = add nsw i32 %mul81, 6
  %idxprom100 = sext i32 %add99 to i64
  %arrayidx101 = getelementptr inbounds float* %pos, i64 %idxprom100
  %30 = load float* %arrayidx101, align 4, !tbaa !3
  %add102 = add nsw i32 %mul81, 7
  %idxprom103 = sext i32 %add102 to i64
  %arrayidx104 = getelementptr inbounds float* %pos, i64 %idxprom103
  %31 = load float* %arrayidx104, align 4, !tbaa !3
  %add105 = add nsw i32 %mul81, 8
  %idxprom106 = sext i32 %add105 to i64
  %arrayidx107 = getelementptr inbounds float* %pos, i64 %idxprom106
  %32 = load float* %arrayidx107, align 4, !tbaa !3
  %sub = fsub float %add43, %24
  %sub108 = fsub float %add47, %25
  %sub109 = fsub float %add51, %26
  %mul110 = fmul float %sub, %sub
  %mul111 = fmul float %sub108, %sub108
  %add112 = fadd float %mul110, %mul111
  %mul113 = fmul float %sub109, %sub109
  %add114 = fadd float %add112, %mul113
  %sub115 = fsub float %add43, %27
  %sub116 = fsub float %add47, %28
  %sub117 = fsub float %add51, %29
  %mul118 = fmul float %sub115, %sub115
  %mul119 = fmul float %sub116, %sub116
  %add120 = fadd float %mul118, %mul119
  %mul121 = fmul float %sub117, %sub117
  %add122 = fadd float %add120, %mul121
  %sub123 = fsub float %add43, %30
  %sub124 = fsub float %add47, %31
  %sub125 = fsub float %add51, %32
  %mul126 = fmul float %sub123, %sub123
  %mul127 = fmul float %sub124, %sub124
  %add128 = fadd float %mul126, %mul127
  %mul129 = fmul float %sub125, %sub125
  %add130 = fadd float %add128, %mul129
  %sub131 = fsub float %add55, %24
  %sub132 = fsub float %add59, %25
  %sub133 = fsub float %add63, %26
  %mul134 = fmul float %sub131, %sub131
  %mul135 = fmul float %sub132, %sub132
  %add136 = fadd float %mul134, %mul135
  %mul137 = fmul float %sub133, %sub133
  %add138 = fadd float %add136, %mul137
  %sub139 = fsub float %add55, %27
  %sub140 = fsub float %add59, %28
  %sub141 = fsub float %add63, %29
  %mul142 = fmul float %sub139, %sub139
  %mul143 = fmul float %sub140, %sub140
  %add144 = fadd float %mul142, %mul143
  %mul145 = fmul float %sub141, %sub141
  %add146 = fadd float %add144, %mul145
  %sub147 = fsub float %add55, %30
  %sub148 = fsub float %add59, %31
  %sub149 = fsub float %add63, %32
  %mul150 = fmul float %sub147, %sub147
  %mul151 = fmul float %sub148, %sub148
  %add152 = fadd float %mul150, %mul151
  %mul153 = fmul float %sub149, %sub149
  %add154 = fadd float %add152, %mul153
  %sub155 = fsub float %add67, %24
  %sub156 = fsub float %add71, %25
  %sub157 = fsub float %add75, %26
  %mul158 = fmul float %sub155, %sub155
  %mul159 = fmul float %sub156, %sub156
  %add160 = fadd float %mul158, %mul159
  %mul161 = fmul float %sub157, %sub157
  %add162 = fadd float %add160, %mul161
  %sub163 = fsub float %add67, %27
  %sub164 = fsub float %add71, %28
  %sub165 = fsub float %add75, %29
  %mul166 = fmul float %sub163, %sub163
  %mul167 = fmul float %sub164, %sub164
  %add168 = fadd float %mul166, %mul167
  %mul169 = fmul float %sub165, %sub165
  %add170 = fadd float %add168, %mul169
  %sub171 = fsub float %add67, %30
  %sub172 = fsub float %add71, %31
  %sub173 = fsub float %add75, %32
  %mul174 = fmul float %sub171, %sub171
  %mul175 = fmul float %sub172, %sub172
  %add176 = fadd float %mul174, %mul175
  %mul177 = fmul float %sub173, %sub173
  %add178 = fadd float %add176, %mul177
  %conv = fpext float %add114 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv179 = fptrunc double %div to float
  %conv180 = fpext float %add138 to double
  %call181 = tail call double @sqrt(double %conv180) #2
  %div182 = fdiv double 1.000000e+00, %call181
  %conv183 = fptrunc double %div182 to float
  %conv184 = fpext float %add162 to double
  %call185 = tail call double @sqrt(double %conv184) #2
  %div186 = fdiv double 1.000000e+00, %call185
  %conv187 = fptrunc double %div186 to float
  %conv188 = fpext float %add122 to double
  %call189 = tail call double @sqrt(double %conv188) #2
  %div190 = fdiv double 1.000000e+00, %call189
  %conv191 = fptrunc double %div190 to float
  %conv192 = fpext float %add146 to double
  %call193 = tail call double @sqrt(double %conv192) #2
  %div194 = fdiv double 1.000000e+00, %call193
  %conv195 = fptrunc double %div194 to float
  %conv196 = fpext float %add170 to double
  %call197 = tail call double @sqrt(double %conv196) #2
  %div198 = fdiv double 1.000000e+00, %call197
  %conv199 = fptrunc double %div198 to float
  %conv200 = fpext float %add130 to double
  %call201 = tail call double @sqrt(double %conv200) #2
  %div202 = fdiv double 1.000000e+00, %call201
  %conv203 = fptrunc double %div202 to float
  %conv204 = fpext float %add154 to double
  %call205 = tail call double @sqrt(double %conv204) #2
  %div206 = fdiv double 1.000000e+00, %call205
  %conv207 = fptrunc double %div206 to float
  %conv208 = fpext float %add178 to double
  %call209 = tail call double @sqrt(double %conv208) #2
  %div210 = fdiv double 1.000000e+00, %call209
  %conv211 = fptrunc double %div210 to float
  %mul212 = fmul float %add114, %conv179
  %mul213 = fmul float %conv179, %conv179
  %mul214 = fmul float %mul213, %mul213
  %mul215 = fmul float %mul213, %mul214
  %mul216 = fmul float %4, %mul215
  %mul217 = fmul float %5, %mul215
  %mul218 = fmul float %mul215, %mul217
  %add219 = fadd float %vnbtot.01450, %mul218
  %sub220 = fsub float %add219, %mul216
  %mul221 = fmul float %mul212, %tabscale
  %conv222 = fptosi float %mul221 to i32
  %conv223 = sitofp i32 %conv222 to float
  %sub224 = fsub float %mul221, %conv223
  %mul225 = fmul float %sub224, %sub224
  %mul226 = shl nsw i32 %conv222, 2
  %idxprom227 = sext i32 %mul226 to i64
  %arrayidx228 = getelementptr inbounds float* %VFtab, i64 %idxprom227
  %33 = load float* %arrayidx228, align 4, !tbaa !3
  %add2291413 = or i32 %mul226, 1
  %idxprom230 = sext i32 %add2291413 to i64
  %arrayidx231 = getelementptr inbounds float* %VFtab, i64 %idxprom230
  %34 = load float* %arrayidx231, align 4, !tbaa !3
  %add2321414 = or i32 %mul226, 2
  %idxprom233 = sext i32 %add2321414 to i64
  %arrayidx234 = getelementptr inbounds float* %VFtab, i64 %idxprom233
  %35 = load float* %arrayidx234, align 4, !tbaa !3
  %mul235 = fmul float %sub224, %35
  %add2361415 = or i32 %mul226, 3
  %idxprom237 = sext i32 %add2361415 to i64
  %arrayidx238 = getelementptr inbounds float* %VFtab, i64 %idxprom237
  %36 = load float* %arrayidx238, align 4, !tbaa !3
  %mul239 = fmul float %mul225, %36
  %add240 = fadd float %34, %mul235
  %add241 = fadd float %add240, %mul239
  %mul242 = fmul float %sub224, %add241
  %add243 = fadd float %33, %mul242
  %add244 = fadd float %mul235, %add241
  %mul245 = fmul float %mul239, 2.000000e+00
  %add246 = fadd float %mul245, %add244
  %mul247 = fmul float %mul4, %add243
  %mul248 = fmul float %mul4, %add246
  %mul249 = fmul float %mul218, 1.200000e+01
  %mul250 = fmul float %mul216, 6.000000e+00
  %sub251 = fsub float %mul249, %mul250
  %mul252 = fmul float %conv179, %sub251
  %mul253 = fmul float %mul248, %tabscale
  %sub254 = fsub float %mul252, %mul253
  %mul255 = fmul float %conv179, %sub254
  %add256 = fadd float %vctot.01451, %mul247
  %mul257 = fmul float %sub, %mul255
  %mul258 = fmul float %sub108, %mul255
  %mul259 = fmul float %sub109, %mul255
  %add260 = fadd float %fix1.01449, %mul257
  %add261 = fadd float %fiy1.01448, %mul258
  %add262 = fadd float %fiz1.01447, %mul259
  %arrayidx264 = getelementptr inbounds float* %faction, i64 %idxprom82
  %37 = load float* %arrayidx264, align 4, !tbaa !3
  %sub265 = fsub float %37, %mul257
  %arrayidx268 = getelementptr inbounds float* %faction, i64 %idxprom85
  %38 = load float* %arrayidx268, align 4, !tbaa !3
  %sub269 = fsub float %38, %mul258
  %arrayidx272 = getelementptr inbounds float* %faction, i64 %idxprom88
  %39 = load float* %arrayidx272, align 4, !tbaa !3
  %sub273 = fsub float %39, %mul259
  %mul274 = fmul float %add122, %conv191
  %mul275 = fmul float %mul274, %tabscale
  %conv276 = fptosi float %mul275 to i32
  %conv277 = sitofp i32 %conv276 to float
  %sub278 = fsub float %mul275, %conv277
  %mul279 = fmul float %sub278, %sub278
  %mul280 = shl nsw i32 %conv276, 2
  %idxprom281 = sext i32 %mul280 to i64
  %arrayidx282 = getelementptr inbounds float* %VFtab, i64 %idxprom281
  %40 = load float* %arrayidx282, align 4, !tbaa !3
  %add2831416 = or i32 %mul280, 1
  %idxprom284 = sext i32 %add2831416 to i64
  %arrayidx285 = getelementptr inbounds float* %VFtab, i64 %idxprom284
  %41 = load float* %arrayidx285, align 4, !tbaa !3
  %add2861417 = or i32 %mul280, 2
  %idxprom287 = sext i32 %add2861417 to i64
  %arrayidx288 = getelementptr inbounds float* %VFtab, i64 %idxprom287
  %42 = load float* %arrayidx288, align 4, !tbaa !3
  %mul289 = fmul float %sub278, %42
  %add2901418 = or i32 %mul280, 3
  %idxprom291 = sext i32 %add2901418 to i64
  %arrayidx292 = getelementptr inbounds float* %VFtab, i64 %idxprom291
  %43 = load float* %arrayidx292, align 4, !tbaa !3
  %mul293 = fmul float %mul279, %43
  %add294 = fadd float %41, %mul289
  %add295 = fadd float %add294, %mul293
  %mul296 = fmul float %sub278, %add295
  %add297 = fadd float %40, %mul296
  %add298 = fadd float %mul289, %add295
  %mul299 = fmul float %mul293, 2.000000e+00
  %add300 = fadd float %mul299, %add298
  %mul301 = fmul float %mul6, %add297
  %mul302 = fmul float %mul6, %add300
  %mul303 = fmul float %mul302, %tabscale
  %44 = fmul float %conv191, %mul303
  %mul305 = fsub float -0.000000e+00, %44
  %add306 = fadd float %add256, %mul301
  %mul307 = fmul float %sub115, %mul305
  %mul308 = fmul float %sub116, %mul305
  %mul309 = fmul float %sub117, %mul305
  %add310 = fadd float %add260, %mul307
  %add311 = fadd float %add261, %mul308
  %add312 = fadd float %add262, %mul309
  %arrayidx315 = getelementptr inbounds float* %faction, i64 %idxprom91
  %45 = load float* %arrayidx315, align 4, !tbaa !3
  %sub316 = fsub float %45, %mul307
  %arrayidx319 = getelementptr inbounds float* %faction, i64 %idxprom94
  %46 = load float* %arrayidx319, align 4, !tbaa !3
  %sub320 = fsub float %46, %mul308
  %arrayidx323 = getelementptr inbounds float* %faction, i64 %idxprom97
  %47 = load float* %arrayidx323, align 4, !tbaa !3
  %sub324 = fsub float %47, %mul309
  %mul325 = fmul float %add130, %conv203
  %mul326 = fmul float %mul325, %tabscale
  %conv327 = fptosi float %mul326 to i32
  %conv328 = sitofp i32 %conv327 to float
  %sub329 = fsub float %mul326, %conv328
  %mul330 = fmul float %sub329, %sub329
  %mul331 = shl nsw i32 %conv327, 2
  %idxprom332 = sext i32 %mul331 to i64
  %arrayidx333 = getelementptr inbounds float* %VFtab, i64 %idxprom332
  %48 = load float* %arrayidx333, align 4, !tbaa !3
  %add3341419 = or i32 %mul331, 1
  %idxprom335 = sext i32 %add3341419 to i64
  %arrayidx336 = getelementptr inbounds float* %VFtab, i64 %idxprom335
  %49 = load float* %arrayidx336, align 4, !tbaa !3
  %add3371420 = or i32 %mul331, 2
  %idxprom338 = sext i32 %add3371420 to i64
  %arrayidx339 = getelementptr inbounds float* %VFtab, i64 %idxprom338
  %50 = load float* %arrayidx339, align 4, !tbaa !3
  %mul340 = fmul float %sub329, %50
  %add3411421 = or i32 %mul331, 3
  %idxprom342 = sext i32 %add3411421 to i64
  %arrayidx343 = getelementptr inbounds float* %VFtab, i64 %idxprom342
  %51 = load float* %arrayidx343, align 4, !tbaa !3
  %mul344 = fmul float %mul330, %51
  %add345 = fadd float %49, %mul340
  %add346 = fadd float %add345, %mul344
  %mul347 = fmul float %sub329, %add346
  %add348 = fadd float %48, %mul347
  %add349 = fadd float %mul340, %add346
  %mul350 = fmul float %mul344, 2.000000e+00
  %add351 = fadd float %mul350, %add349
  %mul352 = fmul float %mul6, %add348
  %mul353 = fmul float %mul6, %add351
  %mul354 = fmul float %mul353, %tabscale
  %52 = fmul float %conv203, %mul354
  %mul356 = fsub float -0.000000e+00, %52
  %add357 = fadd float %add306, %mul352
  %mul358 = fmul float %sub123, %mul356
  %mul359 = fmul float %sub124, %mul356
  %mul360 = fmul float %sub125, %mul356
  %add361 = fadd float %add310, %mul358
  %add362 = fadd float %add311, %mul359
  %add363 = fadd float %add312, %mul360
  %arrayidx366 = getelementptr inbounds float* %faction, i64 %idxprom100
  %53 = load float* %arrayidx366, align 4, !tbaa !3
  %sub367 = fsub float %53, %mul358
  %arrayidx370 = getelementptr inbounds float* %faction, i64 %idxprom103
  %54 = load float* %arrayidx370, align 4, !tbaa !3
  %sub371 = fsub float %54, %mul359
  %arrayidx374 = getelementptr inbounds float* %faction, i64 %idxprom106
  %55 = load float* %arrayidx374, align 4, !tbaa !3
  %sub375 = fsub float %55, %mul360
  %mul376 = fmul float %add138, %conv183
  %mul377 = fmul float %mul376, %tabscale
  %conv378 = fptosi float %mul377 to i32
  %conv379 = sitofp i32 %conv378 to float
  %sub380 = fsub float %mul377, %conv379
  %mul381 = fmul float %sub380, %sub380
  %mul382 = shl nsw i32 %conv378, 2
  %idxprom383 = sext i32 %mul382 to i64
  %arrayidx384 = getelementptr inbounds float* %VFtab, i64 %idxprom383
  %56 = load float* %arrayidx384, align 4, !tbaa !3
  %add3851422 = or i32 %mul382, 1
  %idxprom386 = sext i32 %add3851422 to i64
  %arrayidx387 = getelementptr inbounds float* %VFtab, i64 %idxprom386
  %57 = load float* %arrayidx387, align 4, !tbaa !3
  %add3881423 = or i32 %mul382, 2
  %idxprom389 = sext i32 %add3881423 to i64
  %arrayidx390 = getelementptr inbounds float* %VFtab, i64 %idxprom389
  %58 = load float* %arrayidx390, align 4, !tbaa !3
  %mul391 = fmul float %sub380, %58
  %add3921424 = or i32 %mul382, 3
  %idxprom393 = sext i32 %add3921424 to i64
  %arrayidx394 = getelementptr inbounds float* %VFtab, i64 %idxprom393
  %59 = load float* %arrayidx394, align 4, !tbaa !3
  %mul395 = fmul float %mul381, %59
  %add396 = fadd float %57, %mul391
  %add397 = fadd float %add396, %mul395
  %mul398 = fmul float %sub380, %add397
  %add399 = fadd float %56, %mul398
  %add400 = fadd float %mul391, %add397
  %mul401 = fmul float %mul395, 2.000000e+00
  %add402 = fadd float %mul401, %add400
  %mul403 = fmul float %mul6, %add399
  %mul404 = fmul float %mul6, %add402
  %mul405 = fmul float %mul404, %tabscale
  %60 = fmul float %conv183, %mul405
  %mul407 = fsub float -0.000000e+00, %60
  %add408 = fadd float %add357, %mul403
  %mul409 = fmul float %sub131, %mul407
  %mul410 = fmul float %sub132, %mul407
  %mul411 = fmul float %sub133, %mul407
  %add412 = fadd float %fix2.01446, %mul409
  %add413 = fadd float %fiy2.01445, %mul410
  %add414 = fadd float %fiz2.01444, %mul411
  %sub415 = fsub float %sub265, %mul409
  %sub416 = fsub float %sub269, %mul410
  %sub417 = fsub float %sub273, %mul411
  %mul418 = fmul float %add146, %conv195
  %mul419 = fmul float %mul418, %tabscale
  %conv420 = fptosi float %mul419 to i32
  %conv421 = sitofp i32 %conv420 to float
  %sub422 = fsub float %mul419, %conv421
  %mul423 = fmul float %sub422, %sub422
  %mul424 = shl nsw i32 %conv420, 2
  %idxprom425 = sext i32 %mul424 to i64
  %arrayidx426 = getelementptr inbounds float* %VFtab, i64 %idxprom425
  %61 = load float* %arrayidx426, align 4, !tbaa !3
  %add4271425 = or i32 %mul424, 1
  %idxprom428 = sext i32 %add4271425 to i64
  %arrayidx429 = getelementptr inbounds float* %VFtab, i64 %idxprom428
  %62 = load float* %arrayidx429, align 4, !tbaa !3
  %add4301426 = or i32 %mul424, 2
  %idxprom431 = sext i32 %add4301426 to i64
  %arrayidx432 = getelementptr inbounds float* %VFtab, i64 %idxprom431
  %63 = load float* %arrayidx432, align 4, !tbaa !3
  %mul433 = fmul float %sub422, %63
  %add4341427 = or i32 %mul424, 3
  %idxprom435 = sext i32 %add4341427 to i64
  %arrayidx436 = getelementptr inbounds float* %VFtab, i64 %idxprom435
  %64 = load float* %arrayidx436, align 4, !tbaa !3
  %mul437 = fmul float %mul423, %64
  %add438 = fadd float %62, %mul433
  %add439 = fadd float %add438, %mul437
  %mul440 = fmul float %sub422, %add439
  %add441 = fadd float %61, %mul440
  %add442 = fadd float %mul433, %add439
  %mul443 = fmul float %mul437, 2.000000e+00
  %add444 = fadd float %mul443, %add442
  %mul445 = fmul float %mul8, %add441
  %mul446 = fmul float %mul8, %add444
  %mul447 = fmul float %mul446, %tabscale
  %65 = fmul float %conv195, %mul447
  %mul449 = fsub float -0.000000e+00, %65
  %add450 = fadd float %add408, %mul445
  %mul451 = fmul float %sub139, %mul449
  %mul452 = fmul float %sub140, %mul449
  %mul453 = fmul float %sub141, %mul449
  %add454 = fadd float %add412, %mul451
  %add455 = fadd float %add413, %mul452
  %add456 = fadd float %add414, %mul453
  %sub457 = fsub float %sub316, %mul451
  %sub458 = fsub float %sub320, %mul452
  %sub459 = fsub float %sub324, %mul453
  %mul460 = fmul float %add154, %conv207
  %mul461 = fmul float %mul460, %tabscale
  %conv462 = fptosi float %mul461 to i32
  %conv463 = sitofp i32 %conv462 to float
  %sub464 = fsub float %mul461, %conv463
  %mul465 = fmul float %sub464, %sub464
  %mul466 = shl nsw i32 %conv462, 2
  %idxprom467 = sext i32 %mul466 to i64
  %arrayidx468 = getelementptr inbounds float* %VFtab, i64 %idxprom467
  %66 = load float* %arrayidx468, align 4, !tbaa !3
  %add4691428 = or i32 %mul466, 1
  %idxprom470 = sext i32 %add4691428 to i64
  %arrayidx471 = getelementptr inbounds float* %VFtab, i64 %idxprom470
  %67 = load float* %arrayidx471, align 4, !tbaa !3
  %add4721429 = or i32 %mul466, 2
  %idxprom473 = sext i32 %add4721429 to i64
  %arrayidx474 = getelementptr inbounds float* %VFtab, i64 %idxprom473
  %68 = load float* %arrayidx474, align 4, !tbaa !3
  %mul475 = fmul float %sub464, %68
  %add4761430 = or i32 %mul466, 3
  %idxprom477 = sext i32 %add4761430 to i64
  %arrayidx478 = getelementptr inbounds float* %VFtab, i64 %idxprom477
  %69 = load float* %arrayidx478, align 4, !tbaa !3
  %mul479 = fmul float %mul465, %69
  %add480 = fadd float %67, %mul475
  %add481 = fadd float %add480, %mul479
  %mul482 = fmul float %sub464, %add481
  %add483 = fadd float %66, %mul482
  %add484 = fadd float %mul475, %add481
  %mul485 = fmul float %mul479, 2.000000e+00
  %add486 = fadd float %mul485, %add484
  %mul487 = fmul float %mul8, %add483
  %mul488 = fmul float %mul8, %add486
  %mul489 = fmul float %mul488, %tabscale
  %70 = fmul float %conv207, %mul489
  %mul491 = fsub float -0.000000e+00, %70
  %add492 = fadd float %add450, %mul487
  %mul493 = fmul float %sub147, %mul491
  %mul494 = fmul float %sub148, %mul491
  %mul495 = fmul float %sub149, %mul491
  %add496 = fadd float %add454, %mul493
  %add497 = fadd float %add455, %mul494
  %add498 = fadd float %add456, %mul495
  %sub499 = fsub float %sub367, %mul493
  %sub500 = fsub float %sub371, %mul494
  %sub501 = fsub float %sub375, %mul495
  %mul502 = fmul float %add162, %conv187
  %mul503 = fmul float %mul502, %tabscale
  %conv504 = fptosi float %mul503 to i32
  %conv505 = sitofp i32 %conv504 to float
  %sub506 = fsub float %mul503, %conv505
  %mul507 = fmul float %sub506, %sub506
  %mul508 = shl nsw i32 %conv504, 2
  %idxprom509 = sext i32 %mul508 to i64
  %arrayidx510 = getelementptr inbounds float* %VFtab, i64 %idxprom509
  %71 = load float* %arrayidx510, align 4, !tbaa !3
  %add5111431 = or i32 %mul508, 1
  %idxprom512 = sext i32 %add5111431 to i64
  %arrayidx513 = getelementptr inbounds float* %VFtab, i64 %idxprom512
  %72 = load float* %arrayidx513, align 4, !tbaa !3
  %add5141432 = or i32 %mul508, 2
  %idxprom515 = sext i32 %add5141432 to i64
  %arrayidx516 = getelementptr inbounds float* %VFtab, i64 %idxprom515
  %73 = load float* %arrayidx516, align 4, !tbaa !3
  %mul517 = fmul float %sub506, %73
  %add5181433 = or i32 %mul508, 3
  %idxprom519 = sext i32 %add5181433 to i64
  %arrayidx520 = getelementptr inbounds float* %VFtab, i64 %idxprom519
  %74 = load float* %arrayidx520, align 4, !tbaa !3
  %mul521 = fmul float %mul507, %74
  %add522 = fadd float %72, %mul517
  %add523 = fadd float %add522, %mul521
  %mul524 = fmul float %sub506, %add523
  %add525 = fadd float %71, %mul524
  %add526 = fadd float %mul517, %add523
  %mul527 = fmul float %mul521, 2.000000e+00
  %add528 = fadd float %mul527, %add526
  %mul529 = fmul float %mul6, %add525
  %mul530 = fmul float %mul6, %add528
  %mul531 = fmul float %mul530, %tabscale
  %75 = fmul float %conv187, %mul531
  %mul533 = fsub float -0.000000e+00, %75
  %add534 = fadd float %add492, %mul529
  %mul535 = fmul float %sub155, %mul533
  %mul536 = fmul float %sub156, %mul533
  %mul537 = fmul float %sub157, %mul533
  %add538 = fadd float %fix3.01443, %mul535
  %add539 = fadd float %fiy3.01442, %mul536
  %add540 = fadd float %fiz3.01441, %mul537
  %sub541 = fsub float %sub415, %mul535
  store float %sub541, float* %arrayidx264, align 4, !tbaa !3
  %sub544 = fsub float %sub416, %mul536
  store float %sub544, float* %arrayidx268, align 4, !tbaa !3
  %sub548 = fsub float %sub417, %mul537
  store float %sub548, float* %arrayidx272, align 4, !tbaa !3
  %mul552 = fmul float %add170, %conv199
  %mul553 = fmul float %mul552, %tabscale
  %conv554 = fptosi float %mul553 to i32
  %conv555 = sitofp i32 %conv554 to float
  %sub556 = fsub float %mul553, %conv555
  %mul557 = fmul float %sub556, %sub556
  %mul558 = shl nsw i32 %conv554, 2
  %idxprom559 = sext i32 %mul558 to i64
  %arrayidx560 = getelementptr inbounds float* %VFtab, i64 %idxprom559
  %76 = load float* %arrayidx560, align 4, !tbaa !3
  %add5611434 = or i32 %mul558, 1
  %idxprom562 = sext i32 %add5611434 to i64
  %arrayidx563 = getelementptr inbounds float* %VFtab, i64 %idxprom562
  %77 = load float* %arrayidx563, align 4, !tbaa !3
  %add5641435 = or i32 %mul558, 2
  %idxprom565 = sext i32 %add5641435 to i64
  %arrayidx566 = getelementptr inbounds float* %VFtab, i64 %idxprom565
  %78 = load float* %arrayidx566, align 4, !tbaa !3
  %mul567 = fmul float %sub556, %78
  %add5681436 = or i32 %mul558, 3
  %idxprom569 = sext i32 %add5681436 to i64
  %arrayidx570 = getelementptr inbounds float* %VFtab, i64 %idxprom569
  %79 = load float* %arrayidx570, align 4, !tbaa !3
  %mul571 = fmul float %mul557, %79
  %add572 = fadd float %77, %mul567
  %add573 = fadd float %add572, %mul571
  %mul574 = fmul float %sub556, %add573
  %add575 = fadd float %76, %mul574
  %add576 = fadd float %mul567, %add573
  %mul577 = fmul float %mul571, 2.000000e+00
  %add578 = fadd float %mul577, %add576
  %mul579 = fmul float %mul8, %add575
  %mul580 = fmul float %mul8, %add578
  %mul581 = fmul float %mul580, %tabscale
  %80 = fmul float %conv199, %mul581
  %mul583 = fsub float -0.000000e+00, %80
  %add584 = fadd float %add534, %mul579
  %mul585 = fmul float %sub163, %mul583
  %mul586 = fmul float %sub164, %mul583
  %mul587 = fmul float %sub165, %mul583
  %add588 = fadd float %add538, %mul585
  %add589 = fadd float %add539, %mul586
  %add590 = fadd float %add540, %mul587
  %sub591 = fsub float %sub457, %mul585
  store float %sub591, float* %arrayidx315, align 4, !tbaa !3
  %sub595 = fsub float %sub458, %mul586
  store float %sub595, float* %arrayidx319, align 4, !tbaa !3
  %sub599 = fsub float %sub459, %mul587
  store float %sub599, float* %arrayidx323, align 4, !tbaa !3
  %mul603 = fmul float %add178, %conv211
  %mul604 = fmul float %mul603, %tabscale
  %conv605 = fptosi float %mul604 to i32
  %conv606 = sitofp i32 %conv605 to float
  %sub607 = fsub float %mul604, %conv606
  %mul608 = fmul float %sub607, %sub607
  %mul609 = shl nsw i32 %conv605, 2
  %idxprom610 = sext i32 %mul609 to i64
  %arrayidx611 = getelementptr inbounds float* %VFtab, i64 %idxprom610
  %81 = load float* %arrayidx611, align 4, !tbaa !3
  %add6121437 = or i32 %mul609, 1
  %idxprom613 = sext i32 %add6121437 to i64
  %arrayidx614 = getelementptr inbounds float* %VFtab, i64 %idxprom613
  %82 = load float* %arrayidx614, align 4, !tbaa !3
  %add6151438 = or i32 %mul609, 2
  %idxprom616 = sext i32 %add6151438 to i64
  %arrayidx617 = getelementptr inbounds float* %VFtab, i64 %idxprom616
  %83 = load float* %arrayidx617, align 4, !tbaa !3
  %mul618 = fmul float %sub607, %83
  %add6191439 = or i32 %mul609, 3
  %idxprom620 = sext i32 %add6191439 to i64
  %arrayidx621 = getelementptr inbounds float* %VFtab, i64 %idxprom620
  %84 = load float* %arrayidx621, align 4, !tbaa !3
  %mul622 = fmul float %mul608, %84
  %add623 = fadd float %82, %mul618
  %add624 = fadd float %add623, %mul622
  %mul625 = fmul float %sub607, %add624
  %add626 = fadd float %81, %mul625
  %add627 = fadd float %mul618, %add624
  %mul628 = fmul float %mul622, 2.000000e+00
  %add629 = fadd float %mul628, %add627
  %mul630 = fmul float %mul8, %add626
  %mul631 = fmul float %mul8, %add629
  %mul632 = fmul float %mul631, %tabscale
  %85 = fmul float %conv211, %mul632
  %mul634 = fsub float -0.000000e+00, %85
  %add635 = fadd float %add584, %mul630
  %mul636 = fmul float %sub171, %mul634
  %mul637 = fmul float %sub172, %mul634
  %mul638 = fmul float %sub173, %mul634
  %add639 = fadd float %add588, %mul636
  %add640 = fadd float %add589, %mul637
  %add641 = fadd float %add590, %mul638
  %sub642 = fsub float %sub499, %mul636
  store float %sub642, float* %arrayidx366, align 4, !tbaa !3
  %sub646 = fsub float %sub500, %mul637
  store float %sub646, float* %arrayidx370, align 4, !tbaa !3
  %sub650 = fsub float %sub501, %mul638
  store float %sub650, float* %arrayidx374, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %86 = trunc i64 %indvars.iv.next to i32
  %cmp77 = icmp slt i32 %86, %12
  br i1 %cmp77, label %for.body78, label %for.end

for.end:                                          ; preds = %for.body78, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add635, %for.body78 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %sub220, %for.body78 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add361, %for.body78 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add362, %for.body78 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add363, %for.body78 ]
  %fix2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add496, %for.body78 ]
  %fiy2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add497, %for.body78 ]
  %fiz2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add498, %for.body78 ]
  %fix3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add639, %for.body78 ]
  %fiy3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add640, %for.body78 ]
  %fiz3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add641, %for.body78 ]
  %arrayidx655 = getelementptr inbounds float* %faction, i64 %idxprom41
  %87 = load float* %arrayidx655, align 4, !tbaa !3
  %add656 = fadd float %fix1.0.lcssa, %87
  store float %add656, float* %arrayidx655, align 4, !tbaa !3
  %arrayidx661 = getelementptr inbounds float* %faction, i64 %idxprom45
  %88 = load float* %arrayidx661, align 4, !tbaa !3
  %add662 = fadd float %fiy1.0.lcssa, %88
  store float %add662, float* %arrayidx661, align 4, !tbaa !3
  %arrayidx668 = getelementptr inbounds float* %faction, i64 %idxprom49
  %89 = load float* %arrayidx668, align 4, !tbaa !3
  %add669 = fadd float %fiz1.0.lcssa, %89
  store float %add669, float* %arrayidx668, align 4, !tbaa !3
  %arrayidx675 = getelementptr inbounds float* %faction, i64 %idxprom53
  %90 = load float* %arrayidx675, align 4, !tbaa !3
  %add676 = fadd float %fix2.0.lcssa, %90
  store float %add676, float* %arrayidx675, align 4, !tbaa !3
  %arrayidx682 = getelementptr inbounds float* %faction, i64 %idxprom57
  %91 = load float* %arrayidx682, align 4, !tbaa !3
  %add683 = fadd float %fiy2.0.lcssa, %91
  store float %add683, float* %arrayidx682, align 4, !tbaa !3
  %arrayidx689 = getelementptr inbounds float* %faction, i64 %idxprom61
  %92 = load float* %arrayidx689, align 4, !tbaa !3
  %add690 = fadd float %fiz2.0.lcssa, %92
  store float %add690, float* %arrayidx689, align 4, !tbaa !3
  %arrayidx696 = getelementptr inbounds float* %faction, i64 %idxprom65
  %93 = load float* %arrayidx696, align 4, !tbaa !3
  %add697 = fadd float %fix3.0.lcssa, %93
  store float %add697, float* %arrayidx696, align 4, !tbaa !3
  %arrayidx703 = getelementptr inbounds float* %faction, i64 %idxprom69
  %94 = load float* %arrayidx703, align 4, !tbaa !3
  %add704 = fadd float %fiy3.0.lcssa, %94
  store float %add704, float* %arrayidx703, align 4, !tbaa !3
  %arrayidx710 = getelementptr inbounds float* %faction, i64 %idxprom73
  %95 = load float* %arrayidx710, align 4, !tbaa !3
  %add711 = fadd float %fiz3.0.lcssa, %95
  store float %add711, float* %arrayidx710, align 4, !tbaa !3
  %arrayidx716 = getelementptr inbounds float* %fshift, i64 %idxprom25
  %96 = load float* %arrayidx716, align 4, !tbaa !3
  %add717 = fadd float %fix1.0.lcssa, %96
  %add718 = fadd float %fix2.0.lcssa, %add717
  %add719 = fadd float %fix3.0.lcssa, %add718
  store float %add719, float* %arrayidx716, align 4, !tbaa !3
  %arrayidx724 = getelementptr inbounds float* %fshift, i64 %idxprom28
  %97 = load float* %arrayidx724, align 4, !tbaa !3
  %add725 = fadd float %fiy1.0.lcssa, %97
  %add726 = fadd float %fiy2.0.lcssa, %add725
  %add727 = fadd float %fiy3.0.lcssa, %add726
  store float %add727, float* %arrayidx724, align 4, !tbaa !3
  %arrayidx733 = getelementptr inbounds float* %fshift, i64 %idxprom31
  %98 = load float* %arrayidx733, align 4, !tbaa !3
  %add734 = fadd float %fiz1.0.lcssa, %98
  %add735 = fadd float %fiz2.0.lcssa, %add734
  %add736 = fadd float %fiz3.0.lcssa, %add735
  store float %add736, float* %arrayidx733, align 4, !tbaa !3
  %arrayidx741 = getelementptr inbounds i32* %gid, i64 %indvars.iv1465
  %99 = load i32* %arrayidx741, align 4, !tbaa !0
  %idxprom742 = sext i32 %99 to i64
  %arrayidx743 = getelementptr inbounds float* %Vc, i64 %idxprom742
  %100 = load float* %arrayidx743, align 4, !tbaa !3
  %add744 = fadd float %vctot.0.lcssa, %100
  store float %add744, float* %arrayidx743, align 4, !tbaa !3
  %arrayidx748 = getelementptr inbounds float* %Vnb, i64 %idxprom742
  %101 = load float* %arrayidx748, align 4, !tbaa !3
  %add749 = fadd float %vnbtot.0.lcssa, %101
  store float %add749, float* %arrayidx748, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next1466 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end754, label %for.end.for.body_crit_edge

for.end.for.body_crit_edge:                       ; preds = %for.end
  %arrayidx34.phi.trans.insert = getelementptr inbounds i32* %iinr, i64 %indvars.iv.next1466
  %.pre = load i32* %arrayidx34.phi.trans.insert, align 4, !tbaa !0
  br label %for.body

for.end754:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl3200(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab) #0 {
entry:
  %cmp331 = icmp sgt i32 %nri, 0
  br i1 %cmp331, label %for.body, label %for.end198

for.body:                                         ; preds = %for.end, %entry
  %indvars.iv333 = phi i64 [ 0, %entry ], [ %indvars.iv.next334, %for.end ]
  %arrayidx = getelementptr inbounds i32* %shift, i64 %indvars.iv333
  %0 = load i32* %arrayidx, align 4, !tbaa !0
  %mul = mul nsw i32 %0, 3
  %idxprom1 = sext i32 %mul to i64
  %arrayidx2 = getelementptr inbounds float* %shiftvec, i64 %idxprom1
  %1 = load float* %arrayidx2, align 4, !tbaa !3
  %add = add nsw i32 %mul, 1
  %idxprom3 = sext i32 %add to i64
  %arrayidx4 = getelementptr inbounds float* %shiftvec, i64 %idxprom3
  %2 = load float* %arrayidx4, align 4, !tbaa !3
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds float* %shiftvec, i64 %idxprom6
  %3 = load float* %arrayidx7, align 4, !tbaa !3
  %arrayidx9 = getelementptr inbounds i32* %iinr, i64 %indvars.iv333
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %arrayidx12 = getelementptr inbounds i32* %jindex, i64 %indvars.iv333
  %5 = load i32* %arrayidx12, align 4, !tbaa !0
  %indvars.iv.next334 = add i64 %indvars.iv333, 1
  %arrayidx15 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next334
  %6 = load i32* %arrayidx15, align 4, !tbaa !0
  %idxprom16 = sext i32 %mul10 to i64
  %arrayidx17 = getelementptr inbounds float* %pos, i64 %idxprom16
  %7 = load float* %arrayidx17, align 4, !tbaa !3
  %add18 = fadd float %1, %7
  %add19 = add nsw i32 %mul10, 1
  %idxprom20 = sext i32 %add19 to i64
  %arrayidx21 = getelementptr inbounds float* %pos, i64 %idxprom20
  %8 = load float* %arrayidx21, align 4, !tbaa !3
  %add22 = fadd float %2, %8
  %add23 = add nsw i32 %mul10, 2
  %idxprom24 = sext i32 %add23 to i64
  %arrayidx25 = getelementptr inbounds float* %pos, i64 %idxprom24
  %9 = load float* %arrayidx25, align 4, !tbaa !3
  %add26 = fadd float %3, %9
  %idxprom27 = sext i32 %4 to i64
  %arrayidx28 = getelementptr inbounds float* %charge, i64 %idxprom27
  %10 = load float* %arrayidx28, align 4, !tbaa !3
  %mul29 = fmul float %10, %facel
  %arrayidx32 = getelementptr inbounds i32* %type, i64 %idxprom27
  %11 = load i32* %arrayidx32, align 4, !tbaa !0
  %mul33 = mul i32 %11, %ntype
  %cmp35320 = icmp slt i32 %5, %6
  br i1 %cmp35320, label %for.body36.lr.ph, label %for.end

for.body36.lr.ph:                                 ; preds = %for.body
  %12 = sext i32 %5 to i64
  br label %for.body36

for.body36:                                       ; preds = %for.body36.lr.ph, %for.body36
  %indvars.iv = phi i64 [ %12, %for.body36.lr.ph ], [ %indvars.iv.next, %for.body36 ]
  %vctot.0325 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add120, %for.body36 ]
  %vnbtot.0324 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %sub81, %for.body36 ]
  %fix1.0323 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add124, %for.body36 ]
  %fiy1.0322 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add125, %for.body36 ]
  %fiz1.0321 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add126, %for.body36 ]
  %arrayidx38 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %13 = load i32* %arrayidx38, align 4, !tbaa !0
  %mul39 = mul nsw i32 %13, 3
  %idxprom40 = sext i32 %mul39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %14 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = add nsw i32 %mul39, 1
  %idxprom43 = sext i32 %add42 to i64
  %arrayidx44 = getelementptr inbounds float* %pos, i64 %idxprom43
  %15 = load float* %arrayidx44, align 4, !tbaa !3
  %add45 = add nsw i32 %mul39, 2
  %idxprom46 = sext i32 %add45 to i64
  %arrayidx47 = getelementptr inbounds float* %pos, i64 %idxprom46
  %16 = load float* %arrayidx47, align 4, !tbaa !3
  %sub = fsub float %add18, %14
  %sub48 = fsub float %add22, %15
  %sub49 = fsub float %add26, %16
  %mul50 = fmul float %sub, %sub
  %mul51 = fmul float %sub48, %sub48
  %add52 = fadd float %mul50, %mul51
  %mul53 = fmul float %sub49, %sub49
  %add54 = fadd float %add52, %mul53
  %conv = fpext float %add54 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv55 = fptrunc double %div to float
  %mul56 = fmul float %add54, %conv55
  %mul57 = fmul float %conv55, %conv55
  %mul58 = fmul float %mul57, %mul57
  %mul59 = fmul float %mul57, %mul58
  %idxprom60 = sext i32 %13 to i64
  %arrayidx61 = getelementptr inbounds i32* %type, i64 %idxprom60
  %17 = load i32* %arrayidx61, align 4, !tbaa !0
  %tmp = add i32 %17, %mul33
  %tmp319 = mul i32 %tmp, 3
  %idxprom64 = sext i32 %tmp319 to i64
  %arrayidx65 = getelementptr inbounds float* %nbfp, i64 %idxprom64
  %18 = load float* %arrayidx65, align 4, !tbaa !3
  %mul66 = fmul float %18, %mul59
  %add67 = add nsw i32 %tmp319, 2
  %idxprom68 = sext i32 %add67 to i64
  %arrayidx69 = getelementptr inbounds float* %nbfp, i64 %idxprom68
  %19 = load float* %arrayidx69, align 4, !tbaa !3
  %mul70 = fmul float %mul56, %19
  %sub71 = fsub float -0.000000e+00, %mul70
  %conv72 = fpext float %sub71 to double
  %call73 = tail call double @exp(double %conv72) #2
  %add74 = add nsw i32 %tmp319, 1
  %idxprom75 = sext i32 %add74 to i64
  %arrayidx76 = getelementptr inbounds float* %nbfp, i64 %idxprom75
  %20 = load float* %arrayidx76, align 4, !tbaa !3
  %conv77 = fpext float %20 to double
  %mul78 = fmul double %call73, %conv77
  %conv79 = fptrunc double %mul78 to float
  %add80 = fadd float %vnbtot.0324, %conv79
  %sub81 = fsub float %add80, %mul66
  %mul82 = fmul float %mul56, %tabscale
  %conv83 = fptosi float %mul82 to i32
  %conv84 = sitofp i32 %conv83 to float
  %sub85 = fsub float %mul82, %conv84
  %mul86 = fmul float %sub85, %sub85
  %mul87 = shl nsw i32 %conv83, 2
  %arrayidx89 = getelementptr inbounds float* %charge, i64 %idxprom60
  %21 = load float* %arrayidx89, align 4, !tbaa !3
  %mul90 = fmul float %mul29, %21
  %idxprom91 = sext i32 %mul87 to i64
  %arrayidx92 = getelementptr inbounds float* %VFtab, i64 %idxprom91
  %22 = load float* %arrayidx92, align 4, !tbaa !3
  %add93316 = or i32 %mul87, 1
  %idxprom94 = sext i32 %add93316 to i64
  %arrayidx95 = getelementptr inbounds float* %VFtab, i64 %idxprom94
  %23 = load float* %arrayidx95, align 4, !tbaa !3
  %add96317 = or i32 %mul87, 2
  %idxprom97 = sext i32 %add96317 to i64
  %arrayidx98 = getelementptr inbounds float* %VFtab, i64 %idxprom97
  %24 = load float* %arrayidx98, align 4, !tbaa !3
  %mul99 = fmul float %sub85, %24
  %add100318 = or i32 %mul87, 3
  %idxprom101 = sext i32 %add100318 to i64
  %arrayidx102 = getelementptr inbounds float* %VFtab, i64 %idxprom101
  %25 = load float* %arrayidx102, align 4, !tbaa !3
  %mul103 = fmul float %mul86, %25
  %add104 = fadd float %23, %mul99
  %add105 = fadd float %add104, %mul103
  %mul106 = fmul float %sub85, %add105
  %add107 = fadd float %22, %mul106
  %add108 = fadd float %mul99, %add105
  %mul109 = fmul float %mul103, 2.000000e+00
  %add110 = fadd float %mul109, %add108
  %mul111 = fmul float %mul90, %add107
  %mul112 = fmul float %mul90, %add110
  %mul113 = fmul float %mul70, %conv79
  %mul114 = fmul float %mul66, 6.000000e+00
  %sub115 = fsub float %mul113, %mul114
  %mul116 = fmul float %conv55, %sub115
  %mul117 = fmul float %mul112, %tabscale
  %sub118 = fsub float %mul116, %mul117
  %mul119 = fmul float %conv55, %sub118
  %add120 = fadd float %vctot.0325, %mul111
  %mul121 = fmul float %sub, %mul119
  %mul122 = fmul float %sub48, %mul119
  %mul123 = fmul float %sub49, %mul119
  %add124 = fadd float %fix1.0323, %mul121
  %add125 = fadd float %fiy1.0322, %mul122
  %add126 = fadd float %fiz1.0321, %mul123
  %arrayidx128 = getelementptr inbounds float* %faction, i64 %idxprom40
  %26 = load float* %arrayidx128, align 4, !tbaa !3
  %sub129 = fsub float %26, %mul121
  store float %sub129, float* %arrayidx128, align 4, !tbaa !3
  %arrayidx134 = getelementptr inbounds float* %faction, i64 %idxprom43
  %27 = load float* %arrayidx134, align 4, !tbaa !3
  %sub135 = fsub float %27, %mul122
  store float %sub135, float* %arrayidx134, align 4, !tbaa !3
  %arrayidx141 = getelementptr inbounds float* %faction, i64 %idxprom46
  %28 = load float* %arrayidx141, align 4, !tbaa !3
  %sub142 = fsub float %28, %mul123
  store float %sub142, float* %arrayidx141, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %29 = trunc i64 %indvars.iv.next to i32
  %cmp35 = icmp slt i32 %29, %6
  br i1 %cmp35, label %for.body36, label %for.end

for.end:                                          ; preds = %for.body36, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add120, %for.body36 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %sub81, %for.body36 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add124, %for.body36 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add125, %for.body36 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add126, %for.body36 ]
  %arrayidx147 = getelementptr inbounds float* %faction, i64 %idxprom16
  %30 = load float* %arrayidx147, align 4, !tbaa !3
  %add148 = fadd float %fix1.0.lcssa, %30
  store float %add148, float* %arrayidx147, align 4, !tbaa !3
  %arrayidx153 = getelementptr inbounds float* %faction, i64 %idxprom20
  %31 = load float* %arrayidx153, align 4, !tbaa !3
  %add154 = fadd float %fiy1.0.lcssa, %31
  store float %add154, float* %arrayidx153, align 4, !tbaa !3
  %arrayidx160 = getelementptr inbounds float* %faction, i64 %idxprom24
  %32 = load float* %arrayidx160, align 4, !tbaa !3
  %add161 = fadd float %fiz1.0.lcssa, %32
  store float %add161, float* %arrayidx160, align 4, !tbaa !3
  %arrayidx166 = getelementptr inbounds float* %fshift, i64 %idxprom1
  %33 = load float* %arrayidx166, align 4, !tbaa !3
  %add167 = fadd float %fix1.0.lcssa, %33
  store float %add167, float* %arrayidx166, align 4, !tbaa !3
  %arrayidx172 = getelementptr inbounds float* %fshift, i64 %idxprom3
  %34 = load float* %arrayidx172, align 4, !tbaa !3
  %add173 = fadd float %fiy1.0.lcssa, %34
  store float %add173, float* %arrayidx172, align 4, !tbaa !3
  %arrayidx179 = getelementptr inbounds float* %fshift, i64 %idxprom6
  %35 = load float* %arrayidx179, align 4, !tbaa !3
  %add180 = fadd float %fiz1.0.lcssa, %35
  store float %add180, float* %arrayidx179, align 4, !tbaa !3
  %arrayidx185 = getelementptr inbounds i32* %gid, i64 %indvars.iv333
  %36 = load i32* %arrayidx185, align 4, !tbaa !0
  %idxprom186 = sext i32 %36 to i64
  %arrayidx187 = getelementptr inbounds float* %Vc, i64 %idxprom186
  %37 = load float* %arrayidx187, align 4, !tbaa !3
  %add188 = fadd float %vctot.0.lcssa, %37
  store float %add188, float* %arrayidx187, align 4, !tbaa !3
  %arrayidx192 = getelementptr inbounds float* %Vnb, i64 %idxprom186
  %38 = load float* %arrayidx192, align 4, !tbaa !3
  %add193 = fadd float %vnbtot.0.lcssa, %38
  store float %add193, float* %arrayidx192, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next334 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end198, label %for.body

for.end198:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl3210(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab, i32* nocapture %nsatoms) #0 {
entry:
  %cmp974 = icmp sgt i32 %nri, 0
  br i1 %cmp974, label %for.body, label %for.end516

for.body:                                         ; preds = %for.end501, %entry
  %indvars.iv1000 = phi i64 [ 0, %entry ], [ %indvars.iv.next1001, %for.end501 ]
  %0 = trunc i64 %indvars.iv1000 to i32
  %mul = mul nsw i32 %0, 3
  %idxprom = sext i32 %mul to i64
  %arrayidx = getelementptr inbounds i32* %nsatoms, i64 %idxprom
  %1 = load i32* %arrayidx, align 4, !tbaa !0
  %add = add nsw i32 %mul, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds i32* %nsatoms, i64 %idxprom2
  %2 = load i32* %arrayidx3, align 4, !tbaa !0
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds i32* %nsatoms, i64 %idxprom6
  %3 = load i32* %arrayidx7, align 4, !tbaa !0
  %arrayidx9 = getelementptr inbounds i32* %shift, i64 %indvars.iv1000
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %idxprom11 = sext i32 %mul10 to i64
  %arrayidx12 = getelementptr inbounds float* %shiftvec, i64 %idxprom11
  %5 = load float* %arrayidx12, align 4, !tbaa !3
  %add13 = add nsw i32 %mul10, 1
  %idxprom14 = sext i32 %add13 to i64
  %arrayidx15 = getelementptr inbounds float* %shiftvec, i64 %idxprom14
  %6 = load float* %arrayidx15, align 4, !tbaa !3
  %add16 = add nsw i32 %mul10, 2
  %idxprom17 = sext i32 %add16 to i64
  %arrayidx18 = getelementptr inbounds float* %shiftvec, i64 %idxprom17
  %7 = load float* %arrayidx18, align 4, !tbaa !3
  %arrayidx20 = getelementptr inbounds i32* %iinr, i64 %indvars.iv1000
  %8 = load i32* %arrayidx20, align 4, !tbaa !0
  %mul21 = mul i32 %8, 3
  %arrayidx23 = getelementptr inbounds i32* %jindex, i64 %indvars.iv1000
  %9 = load i32* %arrayidx23, align 4, !tbaa !0
  %indvars.iv.next1001 = add i64 %indvars.iv1000, 1
  %arrayidx26 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next1001
  %10 = load i32* %arrayidx26, align 4, !tbaa !0
  %cmp28930 = icmp sgt i32 %2, 0
  br i1 %cmp28930, label %for.body29.lr.ph, label %for.cond203.loopexit

for.body29.lr.ph:                                 ; preds = %for.body
  %cmp49919 = icmp slt i32 %9, %10
  %arrayidx180 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx186 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx193 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %11 = sext i32 %9 to i64
  %12 = sext i32 %8 to i64
  %13 = sext i32 %mul21 to i64
  %14 = add i32 %2, %8
  %15 = mul i32 %14, 3
  br label %for.body29

for.body29:                                       ; preds = %for.end, %for.body29.lr.ph
  %indvars.iv978 = phi i64 [ %13, %for.body29.lr.ph ], [ %indvars.iv.next979, %for.end ]
  %indvars.iv976 = phi i64 [ %12, %for.body29.lr.ph ], [ %indvars.iv.next977, %for.end ]
  %s.0933 = phi i32 [ 0, %for.body29.lr.ph ], [ %inc201, %for.end ]
  %vnbtot.0932 = phi float [ 0.000000e+00, %for.body29.lr.ph ], [ %vnbtot.1.lcssa, %for.end ]
  %vctot.0931 = phi float [ 0.000000e+00, %for.body29.lr.ph ], [ %vctot.1.lcssa, %for.end ]
  %arrayidx31 = getelementptr inbounds float* %pos, i64 %indvars.iv978
  %16 = load float* %arrayidx31, align 4, !tbaa !3
  %add32 = fadd float %5, %16
  %17 = add nsw i64 %indvars.iv978, 1
  %arrayidx35 = getelementptr inbounds float* %pos, i64 %17
  %18 = load float* %arrayidx35, align 4, !tbaa !3
  %add36 = fadd float %6, %18
  %19 = add nsw i64 %indvars.iv978, 2
  %arrayidx39 = getelementptr inbounds float* %pos, i64 %19
  %20 = load float* %arrayidx39, align 4, !tbaa !3
  %add40 = fadd float %7, %20
  %arrayidx42 = getelementptr inbounds float* %charge, i64 %indvars.iv976
  %21 = load float* %arrayidx42, align 4, !tbaa !3
  %mul43 = fmul float %21, %facel
  %arrayidx46 = getelementptr inbounds i32* %type, i64 %indvars.iv976
  %22 = load i32* %arrayidx46, align 4, !tbaa !0
  %mul47 = mul i32 %22, %ntype
  br i1 %cmp49919, label %for.body50, label %for.end

for.body50:                                       ; preds = %for.body29, %for.body50
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body50 ], [ %11, %for.body29 ]
  %fiz1.0924 = phi float [ %add140, %for.body50 ], [ 0.000000e+00, %for.body29 ]
  %fiy1.0923 = phi float [ %add139, %for.body50 ], [ 0.000000e+00, %for.body29 ]
  %fix1.0922 = phi float [ %add138, %for.body50 ], [ 0.000000e+00, %for.body29 ]
  %vnbtot.1921 = phi float [ %sub95, %for.body50 ], [ %vnbtot.0932, %for.body29 ]
  %vctot.1920 = phi float [ %add134, %for.body50 ], [ %vctot.0931, %for.body29 ]
  %arrayidx52 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %23 = load i32* %arrayidx52, align 4, !tbaa !0
  %mul53 = mul nsw i32 %23, 3
  %idxprom54 = sext i32 %mul53 to i64
  %arrayidx55 = getelementptr inbounds float* %pos, i64 %idxprom54
  %24 = load float* %arrayidx55, align 4, !tbaa !3
  %add56 = add nsw i32 %mul53, 1
  %idxprom57 = sext i32 %add56 to i64
  %arrayidx58 = getelementptr inbounds float* %pos, i64 %idxprom57
  %25 = load float* %arrayidx58, align 4, !tbaa !3
  %add59 = add nsw i32 %mul53, 2
  %idxprom60 = sext i32 %add59 to i64
  %arrayidx61 = getelementptr inbounds float* %pos, i64 %idxprom60
  %26 = load float* %arrayidx61, align 4, !tbaa !3
  %sub = fsub float %add32, %24
  %sub62 = fsub float %add36, %25
  %sub63 = fsub float %add40, %26
  %mul64 = fmul float %sub, %sub
  %mul65 = fmul float %sub62, %sub62
  %add66 = fadd float %mul64, %mul65
  %mul67 = fmul float %sub63, %sub63
  %add68 = fadd float %add66, %mul67
  %conv = fpext float %add68 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv69 = fptrunc double %div to float
  %mul70 = fmul float %add68, %conv69
  %mul71 = fmul float %conv69, %conv69
  %mul72 = fmul float %mul71, %mul71
  %mul73 = fmul float %mul71, %mul72
  %idxprom74 = sext i32 %23 to i64
  %arrayidx75 = getelementptr inbounds i32* %type, i64 %idxprom74
  %27 = load i32* %arrayidx75, align 4, !tbaa !0
  %tmp = add i32 %27, %mul47
  %tmp916 = mul i32 %tmp, 3
  %idxprom78 = sext i32 %tmp916 to i64
  %arrayidx79 = getelementptr inbounds float* %nbfp, i64 %idxprom78
  %28 = load float* %arrayidx79, align 4, !tbaa !3
  %mul80 = fmul float %28, %mul73
  %add81 = add nsw i32 %tmp916, 2
  %idxprom82 = sext i32 %add81 to i64
  %arrayidx83 = getelementptr inbounds float* %nbfp, i64 %idxprom82
  %29 = load float* %arrayidx83, align 4, !tbaa !3
  %mul84 = fmul float %mul70, %29
  %sub85 = fsub float -0.000000e+00, %mul84
  %conv86 = fpext float %sub85 to double
  %call87 = tail call double @exp(double %conv86) #2
  %add88 = add nsw i32 %tmp916, 1
  %idxprom89 = sext i32 %add88 to i64
  %arrayidx90 = getelementptr inbounds float* %nbfp, i64 %idxprom89
  %30 = load float* %arrayidx90, align 4, !tbaa !3
  %conv91 = fpext float %30 to double
  %mul92 = fmul double %call87, %conv91
  %conv93 = fptrunc double %mul92 to float
  %add94 = fadd float %vnbtot.1921, %conv93
  %sub95 = fsub float %add94, %mul80
  %mul96 = fmul float %mul70, %tabscale
  %conv97 = fptosi float %mul96 to i32
  %conv98 = sitofp i32 %conv97 to float
  %sub99 = fsub float %mul96, %conv98
  %mul100 = fmul float %sub99, %sub99
  %mul101 = shl nsw i32 %conv97, 2
  %arrayidx103 = getelementptr inbounds float* %charge, i64 %idxprom74
  %31 = load float* %arrayidx103, align 4, !tbaa !3
  %mul104 = fmul float %mul43, %31
  %idxprom105 = sext i32 %mul101 to i64
  %arrayidx106 = getelementptr inbounds float* %VFtab, i64 %idxprom105
  %32 = load float* %arrayidx106, align 4, !tbaa !3
  %add107913 = or i32 %mul101, 1
  %idxprom108 = sext i32 %add107913 to i64
  %arrayidx109 = getelementptr inbounds float* %VFtab, i64 %idxprom108
  %33 = load float* %arrayidx109, align 4, !tbaa !3
  %add110914 = or i32 %mul101, 2
  %idxprom111 = sext i32 %add110914 to i64
  %arrayidx112 = getelementptr inbounds float* %VFtab, i64 %idxprom111
  %34 = load float* %arrayidx112, align 4, !tbaa !3
  %mul113 = fmul float %sub99, %34
  %add114915 = or i32 %mul101, 3
  %idxprom115 = sext i32 %add114915 to i64
  %arrayidx116 = getelementptr inbounds float* %VFtab, i64 %idxprom115
  %35 = load float* %arrayidx116, align 4, !tbaa !3
  %mul117 = fmul float %mul100, %35
  %add118 = fadd float %33, %mul113
  %add119 = fadd float %add118, %mul117
  %mul120 = fmul float %sub99, %add119
  %add121 = fadd float %32, %mul120
  %add122 = fadd float %mul113, %add119
  %mul123 = fmul float %mul117, 2.000000e+00
  %add124 = fadd float %mul123, %add122
  %mul125 = fmul float %mul104, %add121
  %mul126 = fmul float %mul104, %add124
  %mul127 = fmul float %mul84, %conv93
  %mul128 = fmul float %mul80, 6.000000e+00
  %sub129 = fsub float %mul127, %mul128
  %mul130 = fmul float %conv69, %sub129
  %mul131 = fmul float %mul126, %tabscale
  %sub132 = fsub float %mul130, %mul131
  %mul133 = fmul float %conv69, %sub132
  %add134 = fadd float %vctot.1920, %mul125
  %mul135 = fmul float %sub, %mul133
  %mul136 = fmul float %sub62, %mul133
  %mul137 = fmul float %sub63, %mul133
  %add138 = fadd float %fix1.0922, %mul135
  %add139 = fadd float %fiy1.0923, %mul136
  %add140 = fadd float %fiz1.0924, %mul137
  %arrayidx142 = getelementptr inbounds float* %faction, i64 %idxprom54
  %36 = load float* %arrayidx142, align 4, !tbaa !3
  %sub143 = fsub float %36, %mul135
  store float %sub143, float* %arrayidx142, align 4, !tbaa !3
  %arrayidx148 = getelementptr inbounds float* %faction, i64 %idxprom57
  %37 = load float* %arrayidx148, align 4, !tbaa !3
  %sub149 = fsub float %37, %mul136
  store float %sub149, float* %arrayidx148, align 4, !tbaa !3
  %arrayidx155 = getelementptr inbounds float* %faction, i64 %idxprom60
  %38 = load float* %arrayidx155, align 4, !tbaa !3
  %sub156 = fsub float %38, %mul137
  store float %sub156, float* %arrayidx155, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %39 = trunc i64 %indvars.iv.next to i32
  %cmp49 = icmp slt i32 %39, %10
  br i1 %cmp49, label %for.body50, label %for.end

for.end:                                          ; preds = %for.body50, %for.body29
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add140, %for.body50 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add139, %for.body50 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add138, %for.body50 ]
  %vnbtot.1.lcssa = phi float [ %vnbtot.0932, %for.body29 ], [ %sub95, %for.body50 ]
  %vctot.1.lcssa = phi float [ %vctot.0931, %for.body29 ], [ %add134, %for.body50 ]
  %arrayidx161 = getelementptr inbounds float* %faction, i64 %indvars.iv978
  %40 = load float* %arrayidx161, align 4, !tbaa !3
  %add162 = fadd float %fix1.0.lcssa, %40
  store float %add162, float* %arrayidx161, align 4, !tbaa !3
  %arrayidx167 = getelementptr inbounds float* %faction, i64 %17
  %41 = load float* %arrayidx167, align 4, !tbaa !3
  %add168 = fadd float %fiy1.0.lcssa, %41
  store float %add168, float* %arrayidx167, align 4, !tbaa !3
  %arrayidx174 = getelementptr inbounds float* %faction, i64 %19
  %42 = load float* %arrayidx174, align 4, !tbaa !3
  %add175 = fadd float %fiz1.0.lcssa, %42
  store float %add175, float* %arrayidx174, align 4, !tbaa !3
  %43 = load float* %arrayidx180, align 4, !tbaa !3
  %add181 = fadd float %fix1.0.lcssa, %43
  store float %add181, float* %arrayidx180, align 4, !tbaa !3
  %44 = load float* %arrayidx186, align 4, !tbaa !3
  %add187 = fadd float %fiy1.0.lcssa, %44
  store float %add187, float* %arrayidx186, align 4, !tbaa !3
  %45 = load float* %arrayidx193, align 4, !tbaa !3
  %add194 = fadd float %fiz1.0.lcssa, %45
  store float %add194, float* %arrayidx193, align 4, !tbaa !3
  %indvars.iv.next977 = add i64 %indvars.iv976, 1
  %indvars.iv.next979 = add i64 %indvars.iv978, 3
  %inc201 = add nsw i32 %s.0933, 1
  %exitcond = icmp eq i32 %inc201, %2
  br i1 %exitcond, label %for.cond27.for.cond203.loopexit_crit_edge, label %for.body29

for.cond27.for.cond203.loopexit_crit_edge:        ; preds = %for.end
  %46 = add i32 %2, %8
  br label %for.cond203.loopexit

for.cond203.loopexit:                             ; preds = %for.cond27.for.cond203.loopexit_crit_edge, %for.body
  %ii.0.lcssa = phi i32 [ %46, %for.cond27.for.cond203.loopexit_crit_edge ], [ %8, %for.body ]
  %ii3.0.lcssa = phi i32 [ %15, %for.cond27.for.cond203.loopexit_crit_edge ], [ %mul21, %for.body ]
  %vnbtot.0.lcssa = phi float [ %vnbtot.1.lcssa, %for.cond27.for.cond203.loopexit_crit_edge ], [ 0.000000e+00, %for.body ]
  %vctot.0.lcssa = phi float [ %vctot.1.lcssa, %for.cond27.for.cond203.loopexit_crit_edge ], [ 0.000000e+00, %for.body ]
  %cmp204950 = icmp slt i32 %2, %3
  br i1 %cmp204950, label %for.body206.lr.ph, label %for.cond355.loopexit

for.body206.lr.ph:                                ; preds = %for.cond203.loopexit
  %cmp222940 = icmp slt i32 %9, %10
  %arrayidx332 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx338 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx345 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %47 = sext i32 %9 to i64
  %48 = sext i32 %ii.0.lcssa to i64
  %49 = sext i32 %ii3.0.lcssa to i64
  %50 = mul i32 %3, 3
  %51 = add i32 %ii.0.lcssa, %3
  br label %for.body206

for.body206:                                      ; preds = %for.end311, %for.body206.lr.ph
  %indvars.iv986 = phi i64 [ %49, %for.body206.lr.ph ], [ %indvars.iv.next987, %for.end311 ]
  %indvars.iv984 = phi i64 [ %48, %for.body206.lr.ph ], [ %indvars.iv.next985, %for.end311 ]
  %s.1952 = phi i32 [ %2, %for.body206.lr.ph ], [ %inc353, %for.end311 ]
  %vctot.2951 = phi float [ %vctot.0.lcssa, %for.body206.lr.ph ], [ %vctot.3.lcssa, %for.end311 ]
  %arrayidx208 = getelementptr inbounds float* %pos, i64 %indvars.iv986
  %52 = load float* %arrayidx208, align 4, !tbaa !3
  %add209 = fadd float %5, %52
  %53 = add nsw i64 %indvars.iv986, 1
  %arrayidx212 = getelementptr inbounds float* %pos, i64 %53
  %54 = load float* %arrayidx212, align 4, !tbaa !3
  %add213 = fadd float %6, %54
  %55 = add nsw i64 %indvars.iv986, 2
  %arrayidx216 = getelementptr inbounds float* %pos, i64 %55
  %56 = load float* %arrayidx216, align 4, !tbaa !3
  %add217 = fadd float %7, %56
  %arrayidx219 = getelementptr inbounds float* %charge, i64 %indvars.iv984
  %57 = load float* %arrayidx219, align 4, !tbaa !3
  %mul220 = fmul float %57, %facel
  br i1 %cmp222940, label %for.body224, label %for.end311

for.body224:                                      ; preds = %for.body206, %for.body224
  %indvars.iv982 = phi i64 [ %indvars.iv.next983, %for.body224 ], [ %47, %for.body206 ]
  %fiz1.1944 = phi float [ %add289, %for.body224 ], [ 0.000000e+00, %for.body206 ]
  %fiy1.1943 = phi float [ %add288, %for.body224 ], [ 0.000000e+00, %for.body206 ]
  %fix1.1942 = phi float [ %add287, %for.body224 ], [ 0.000000e+00, %for.body206 ]
  %vctot.3941 = phi float [ %add283, %for.body224 ], [ %vctot.2951, %for.body206 ]
  %arrayidx226 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv982
  %58 = load i32* %arrayidx226, align 4, !tbaa !0
  %mul227 = mul nsw i32 %58, 3
  %idxprom228 = sext i32 %mul227 to i64
  %arrayidx229 = getelementptr inbounds float* %pos, i64 %idxprom228
  %59 = load float* %arrayidx229, align 4, !tbaa !3
  %add230 = add nsw i32 %mul227, 1
  %idxprom231 = sext i32 %add230 to i64
  %arrayidx232 = getelementptr inbounds float* %pos, i64 %idxprom231
  %60 = load float* %arrayidx232, align 4, !tbaa !3
  %add233 = add nsw i32 %mul227, 2
  %idxprom234 = sext i32 %add233 to i64
  %arrayidx235 = getelementptr inbounds float* %pos, i64 %idxprom234
  %61 = load float* %arrayidx235, align 4, !tbaa !3
  %sub236 = fsub float %add209, %59
  %sub237 = fsub float %add213, %60
  %sub238 = fsub float %add217, %61
  %mul239 = fmul float %sub236, %sub236
  %mul240 = fmul float %sub237, %sub237
  %add241 = fadd float %mul239, %mul240
  %mul242 = fmul float %sub238, %sub238
  %add243 = fadd float %add241, %mul242
  %conv244 = fpext float %add243 to double
  %call245 = tail call double @sqrt(double %conv244) #2
  %div246 = fdiv double 1.000000e+00, %call245
  %conv247 = fptrunc double %div246 to float
  %mul248 = fmul float %add243, %conv247
  %mul249 = fmul float %mul248, %tabscale
  %conv250 = fptosi float %mul249 to i32
  %conv251 = sitofp i32 %conv250 to float
  %sub252 = fsub float %mul249, %conv251
  %mul253 = fmul float %sub252, %sub252
  %mul254 = shl nsw i32 %conv250, 2
  %idxprom255 = sext i32 %58 to i64
  %arrayidx256 = getelementptr inbounds float* %charge, i64 %idxprom255
  %62 = load float* %arrayidx256, align 4, !tbaa !3
  %mul257 = fmul float %mul220, %62
  %idxprom258 = sext i32 %mul254 to i64
  %arrayidx259 = getelementptr inbounds float* %VFtab, i64 %idxprom258
  %63 = load float* %arrayidx259, align 4, !tbaa !3
  %add260910 = or i32 %mul254, 1
  %idxprom261 = sext i32 %add260910 to i64
  %arrayidx262 = getelementptr inbounds float* %VFtab, i64 %idxprom261
  %64 = load float* %arrayidx262, align 4, !tbaa !3
  %add263911 = or i32 %mul254, 2
  %idxprom264 = sext i32 %add263911 to i64
  %arrayidx265 = getelementptr inbounds float* %VFtab, i64 %idxprom264
  %65 = load float* %arrayidx265, align 4, !tbaa !3
  %mul266 = fmul float %65, %sub252
  %add267912 = or i32 %mul254, 3
  %idxprom268 = sext i32 %add267912 to i64
  %arrayidx269 = getelementptr inbounds float* %VFtab, i64 %idxprom268
  %66 = load float* %arrayidx269, align 4, !tbaa !3
  %mul270 = fmul float %66, %mul253
  %add271 = fadd float %64, %mul266
  %add272 = fadd float %add271, %mul270
  %mul273 = fmul float %sub252, %add272
  %add274 = fadd float %63, %mul273
  %add275 = fadd float %mul266, %add272
  %mul276 = fmul float %mul270, 2.000000e+00
  %add277 = fadd float %mul276, %add275
  %mul278 = fmul float %mul257, %add274
  %mul279 = fmul float %mul257, %add277
  %mul280 = fmul float %mul279, %tabscale
  %67 = fmul float %conv247, %mul280
  %mul282 = fsub float -0.000000e+00, %67
  %add283 = fadd float %vctot.3941, %mul278
  %mul284 = fmul float %sub236, %mul282
  %mul285 = fmul float %sub237, %mul282
  %mul286 = fmul float %sub238, %mul282
  %add287 = fadd float %fix1.1942, %mul284
  %add288 = fadd float %fiy1.1943, %mul285
  %add289 = fadd float %fiz1.1944, %mul286
  %arrayidx291 = getelementptr inbounds float* %faction, i64 %idxprom228
  %68 = load float* %arrayidx291, align 4, !tbaa !3
  %sub292 = fsub float %68, %mul284
  store float %sub292, float* %arrayidx291, align 4, !tbaa !3
  %arrayidx297 = getelementptr inbounds float* %faction, i64 %idxprom231
  %69 = load float* %arrayidx297, align 4, !tbaa !3
  %sub298 = fsub float %69, %mul285
  store float %sub298, float* %arrayidx297, align 4, !tbaa !3
  %arrayidx304 = getelementptr inbounds float* %faction, i64 %idxprom234
  %70 = load float* %arrayidx304, align 4, !tbaa !3
  %sub305 = fsub float %70, %mul286
  store float %sub305, float* %arrayidx304, align 4, !tbaa !3
  %indvars.iv.next983 = add i64 %indvars.iv982, 1
  %71 = trunc i64 %indvars.iv.next983 to i32
  %cmp222 = icmp slt i32 %71, %10
  br i1 %cmp222, label %for.body224, label %for.end311

for.end311:                                       ; preds = %for.body224, %for.body206
  %fiz1.1.lcssa = phi float [ 0.000000e+00, %for.body206 ], [ %add289, %for.body224 ]
  %fiy1.1.lcssa = phi float [ 0.000000e+00, %for.body206 ], [ %add288, %for.body224 ]
  %fix1.1.lcssa = phi float [ 0.000000e+00, %for.body206 ], [ %add287, %for.body224 ]
  %vctot.3.lcssa = phi float [ %vctot.2951, %for.body206 ], [ %add283, %for.body224 ]
  %arrayidx313 = getelementptr inbounds float* %faction, i64 %indvars.iv986
  %72 = load float* %arrayidx313, align 4, !tbaa !3
  %add314 = fadd float %fix1.1.lcssa, %72
  store float %add314, float* %arrayidx313, align 4, !tbaa !3
  %arrayidx319 = getelementptr inbounds float* %faction, i64 %53
  %73 = load float* %arrayidx319, align 4, !tbaa !3
  %add320 = fadd float %fiy1.1.lcssa, %73
  store float %add320, float* %arrayidx319, align 4, !tbaa !3
  %arrayidx326 = getelementptr inbounds float* %faction, i64 %55
  %74 = load float* %arrayidx326, align 4, !tbaa !3
  %add327 = fadd float %fiz1.1.lcssa, %74
  store float %add327, float* %arrayidx326, align 4, !tbaa !3
  %75 = load float* %arrayidx332, align 4, !tbaa !3
  %add333 = fadd float %fix1.1.lcssa, %75
  store float %add333, float* %arrayidx332, align 4, !tbaa !3
  %76 = load float* %arrayidx338, align 4, !tbaa !3
  %add339 = fadd float %fiy1.1.lcssa, %76
  store float %add339, float* %arrayidx338, align 4, !tbaa !3
  %77 = load float* %arrayidx345, align 4, !tbaa !3
  %add346 = fadd float %fiz1.1.lcssa, %77
  store float %add346, float* %arrayidx345, align 4, !tbaa !3
  %indvars.iv.next985 = add i64 %indvars.iv984, 1
  %indvars.iv.next987 = add i64 %indvars.iv986, 3
  %inc353 = add nsw i32 %s.1952, 1
  %exitcond990 = icmp eq i32 %inc353, %3
  br i1 %exitcond990, label %for.cond203.for.cond355.loopexit_crit_edge, label %for.body206

for.cond203.for.cond355.loopexit_crit_edge:       ; preds = %for.end311
  %78 = add i32 %ii3.0.lcssa, %50
  %79 = mul i32 %2, -3
  %80 = add i32 %78, %79
  %81 = sub i32 %51, %2
  br label %for.cond355.loopexit

for.cond355.loopexit:                             ; preds = %for.cond203.for.cond355.loopexit_crit_edge, %for.cond203.loopexit
  %ii.1.lcssa = phi i32 [ %81, %for.cond203.for.cond355.loopexit_crit_edge ], [ %ii.0.lcssa, %for.cond203.loopexit ]
  %ii3.1.lcssa = phi i32 [ %80, %for.cond203.for.cond355.loopexit_crit_edge ], [ %ii3.0.lcssa, %for.cond203.loopexit ]
  %vctot.2.lcssa = phi float [ %vctot.3.lcssa, %for.cond203.for.cond355.loopexit_crit_edge ], [ %vctot.0.lcssa, %for.cond203.loopexit ]
  %cmp356968 = icmp slt i32 %3, %1
  br i1 %cmp356968, label %for.body358.lr.ph, label %for.end501

for.body358.lr.ph:                                ; preds = %for.cond355.loopexit
  %cmp375958 = icmp slt i32 %9, %10
  %arrayidx479 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx485 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx492 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %82 = sext i32 %9 to i64
  %83 = sext i32 %ii.1.lcssa to i64
  %84 = sext i32 %ii3.1.lcssa to i64
  br label %for.body358

for.body358:                                      ; preds = %for.end458, %for.body358.lr.ph
  %indvars.iv995 = phi i64 [ %84, %for.body358.lr.ph ], [ %indvars.iv.next996, %for.end458 ]
  %indvars.iv993 = phi i64 [ %83, %for.body358.lr.ph ], [ %indvars.iv.next994, %for.end458 ]
  %s.2970 = phi i32 [ %3, %for.body358.lr.ph ], [ %inc500, %for.end458 ]
  %vnbtot.2969 = phi float [ %vnbtot.0.lcssa, %for.body358.lr.ph ], [ %vnbtot.3.lcssa, %for.end458 ]
  %arrayidx360 = getelementptr inbounds float* %pos, i64 %indvars.iv995
  %85 = load float* %arrayidx360, align 4, !tbaa !3
  %add361 = fadd float %5, %85
  %86 = add nsw i64 %indvars.iv995, 1
  %arrayidx364 = getelementptr inbounds float* %pos, i64 %86
  %87 = load float* %arrayidx364, align 4, !tbaa !3
  %add365 = fadd float %6, %87
  %88 = add nsw i64 %indvars.iv995, 2
  %arrayidx368 = getelementptr inbounds float* %pos, i64 %88
  %89 = load float* %arrayidx368, align 4, !tbaa !3
  %add369 = fadd float %7, %89
  %arrayidx372 = getelementptr inbounds i32* %type, i64 %indvars.iv993
  %90 = load i32* %arrayidx372, align 4, !tbaa !0
  %mul373 = mul i32 %90, %ntype
  br i1 %cmp375958, label %for.body377, label %for.end458

for.body377:                                      ; preds = %for.body358, %for.body377
  %indvars.iv991 = phi i64 [ %indvars.iv.next992, %for.body377 ], [ %82, %for.body358 ]
  %fiz1.2962 = phi float [ %add436, %for.body377 ], [ 0.000000e+00, %for.body358 ]
  %fiy1.2961 = phi float [ %add435, %for.body377 ], [ 0.000000e+00, %for.body358 ]
  %fix1.2960 = phi float [ %add434, %for.body377 ], [ 0.000000e+00, %for.body358 ]
  %vnbtot.3959 = phi float [ %sub426, %for.body377 ], [ %vnbtot.2969, %for.body358 ]
  %arrayidx379 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv991
  %91 = load i32* %arrayidx379, align 4, !tbaa !0
  %mul380 = mul nsw i32 %91, 3
  %idxprom381 = sext i32 %mul380 to i64
  %arrayidx382 = getelementptr inbounds float* %pos, i64 %idxprom381
  %92 = load float* %arrayidx382, align 4, !tbaa !3
  %add383 = add nsw i32 %mul380, 1
  %idxprom384 = sext i32 %add383 to i64
  %arrayidx385 = getelementptr inbounds float* %pos, i64 %idxprom384
  %93 = load float* %arrayidx385, align 4, !tbaa !3
  %add386 = add nsw i32 %mul380, 2
  %idxprom387 = sext i32 %add386 to i64
  %arrayidx388 = getelementptr inbounds float* %pos, i64 %idxprom387
  %94 = load float* %arrayidx388, align 4, !tbaa !3
  %sub389 = fsub float %add361, %92
  %sub390 = fsub float %add365, %93
  %sub391 = fsub float %add369, %94
  %mul392 = fmul float %sub389, %sub389
  %mul393 = fmul float %sub390, %sub390
  %add394 = fadd float %mul392, %mul393
  %mul395 = fmul float %sub391, %sub391
  %add396 = fadd float %add394, %mul395
  %conv397 = fpext float %add396 to double
  %call398 = tail call double @sqrt(double %conv397) #2
  %div399 = fdiv double 1.000000e+00, %call398
  %conv400 = fptrunc double %div399 to float
  %mul401 = fmul float %add396, %conv400
  %mul402 = fmul float %conv400, %conv400
  %mul403 = fmul float %mul402, %mul402
  %mul404 = fmul float %mul402, %mul403
  %idxprom405 = sext i32 %91 to i64
  %arrayidx406 = getelementptr inbounds i32* %type, i64 %idxprom405
  %95 = load i32* %arrayidx406, align 4, !tbaa !0
  %tmp917 = add i32 %95, %mul373
  %tmp918 = mul i32 %tmp917, 3
  %idxprom409 = sext i32 %tmp918 to i64
  %arrayidx410 = getelementptr inbounds float* %nbfp, i64 %idxprom409
  %96 = load float* %arrayidx410, align 4, !tbaa !3
  %mul411 = fmul float %96, %mul404
  %add412 = add nsw i32 %tmp918, 2
  %idxprom413 = sext i32 %add412 to i64
  %arrayidx414 = getelementptr inbounds float* %nbfp, i64 %idxprom413
  %97 = load float* %arrayidx414, align 4, !tbaa !3
  %mul415 = fmul float %mul401, %97
  %sub416 = fsub float -0.000000e+00, %mul415
  %conv417 = fpext float %sub416 to double
  %call418 = tail call double @exp(double %conv417) #2
  %add419 = add nsw i32 %tmp918, 1
  %idxprom420 = sext i32 %add419 to i64
  %arrayidx421 = getelementptr inbounds float* %nbfp, i64 %idxprom420
  %98 = load float* %arrayidx421, align 4, !tbaa !3
  %conv422 = fpext float %98 to double
  %mul423 = fmul double %call418, %conv422
  %conv424 = fptrunc double %mul423 to float
  %add425 = fadd float %vnbtot.3959, %conv424
  %sub426 = fsub float %add425, %mul411
  %mul427 = fmul float %mul415, %conv424
  %mul428 = fmul float %mul411, 6.000000e+00
  %sub429 = fsub float %mul427, %mul428
  %mul430 = fmul float %mul402, %sub429
  %mul431 = fmul float %sub389, %mul430
  %mul432 = fmul float %sub390, %mul430
  %mul433 = fmul float %sub391, %mul430
  %add434 = fadd float %fix1.2960, %mul431
  %add435 = fadd float %fiy1.2961, %mul432
  %add436 = fadd float %fiz1.2962, %mul433
  %arrayidx438 = getelementptr inbounds float* %faction, i64 %idxprom381
  %99 = load float* %arrayidx438, align 4, !tbaa !3
  %sub439 = fsub float %99, %mul431
  store float %sub439, float* %arrayidx438, align 4, !tbaa !3
  %arrayidx444 = getelementptr inbounds float* %faction, i64 %idxprom384
  %100 = load float* %arrayidx444, align 4, !tbaa !3
  %sub445 = fsub float %100, %mul432
  store float %sub445, float* %arrayidx444, align 4, !tbaa !3
  %arrayidx451 = getelementptr inbounds float* %faction, i64 %idxprom387
  %101 = load float* %arrayidx451, align 4, !tbaa !3
  %sub452 = fsub float %101, %mul433
  store float %sub452, float* %arrayidx451, align 4, !tbaa !3
  %indvars.iv.next992 = add i64 %indvars.iv991, 1
  %102 = trunc i64 %indvars.iv.next992 to i32
  %cmp375 = icmp slt i32 %102, %10
  br i1 %cmp375, label %for.body377, label %for.end458

for.end458:                                       ; preds = %for.body377, %for.body358
  %fiz1.2.lcssa = phi float [ 0.000000e+00, %for.body358 ], [ %add436, %for.body377 ]
  %fiy1.2.lcssa = phi float [ 0.000000e+00, %for.body358 ], [ %add435, %for.body377 ]
  %fix1.2.lcssa = phi float [ 0.000000e+00, %for.body358 ], [ %add434, %for.body377 ]
  %vnbtot.3.lcssa = phi float [ %vnbtot.2969, %for.body358 ], [ %sub426, %for.body377 ]
  %arrayidx460 = getelementptr inbounds float* %faction, i64 %indvars.iv995
  %103 = load float* %arrayidx460, align 4, !tbaa !3
  %add461 = fadd float %fix1.2.lcssa, %103
  store float %add461, float* %arrayidx460, align 4, !tbaa !3
  %arrayidx466 = getelementptr inbounds float* %faction, i64 %86
  %104 = load float* %arrayidx466, align 4, !tbaa !3
  %add467 = fadd float %fiy1.2.lcssa, %104
  store float %add467, float* %arrayidx466, align 4, !tbaa !3
  %arrayidx473 = getelementptr inbounds float* %faction, i64 %88
  %105 = load float* %arrayidx473, align 4, !tbaa !3
  %add474 = fadd float %fiz1.2.lcssa, %105
  store float %add474, float* %arrayidx473, align 4, !tbaa !3
  %106 = load float* %arrayidx479, align 4, !tbaa !3
  %add480 = fadd float %fix1.2.lcssa, %106
  store float %add480, float* %arrayidx479, align 4, !tbaa !3
  %107 = load float* %arrayidx485, align 4, !tbaa !3
  %add486 = fadd float %fiy1.2.lcssa, %107
  store float %add486, float* %arrayidx485, align 4, !tbaa !3
  %108 = load float* %arrayidx492, align 4, !tbaa !3
  %add493 = fadd float %fiz1.2.lcssa, %108
  store float %add493, float* %arrayidx492, align 4, !tbaa !3
  %indvars.iv.next994 = add i64 %indvars.iv993, 1
  %indvars.iv.next996 = add i64 %indvars.iv995, 3
  %inc500 = add nsw i32 %s.2970, 1
  %exitcond999 = icmp eq i32 %inc500, %1
  br i1 %exitcond999, label %for.end501, label %for.body358

for.end501:                                       ; preds = %for.end458, %for.cond355.loopexit
  %vnbtot.2.lcssa = phi float [ %vnbtot.0.lcssa, %for.cond355.loopexit ], [ %vnbtot.3.lcssa, %for.end458 ]
  %arrayidx503 = getelementptr inbounds i32* %gid, i64 %indvars.iv1000
  %109 = load i32* %arrayidx503, align 4, !tbaa !0
  %idxprom504 = sext i32 %109 to i64
  %arrayidx505 = getelementptr inbounds float* %Vc, i64 %idxprom504
  %110 = load float* %arrayidx505, align 4, !tbaa !3
  %add506 = fadd float %vctot.2.lcssa, %110
  store float %add506, float* %arrayidx505, align 4, !tbaa !3
  %arrayidx510 = getelementptr inbounds float* %Vnb, i64 %idxprom504
  %111 = load float* %arrayidx510, align 4, !tbaa !3
  %add511 = fadd float %vnbtot.2.lcssa, %111
  store float %add511, float* %arrayidx510, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next1001 to i32
  %exitcond1002 = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond1002, label %for.end516, label %for.body

for.end516:                                       ; preds = %for.end501, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl3220(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab) #0 {
entry:
  %0 = load i32* %iinr, align 4, !tbaa !0
  %idxprom = sext i32 %0 to i64
  %arrayidx1 = getelementptr inbounds float* %charge, i64 %idxprom
  %1 = load float* %arrayidx1, align 4, !tbaa !3
  %add = add nsw i32 %0, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds float* %charge, i64 %idxprom2
  %2 = load float* %arrayidx3, align 4, !tbaa !3
  %mul = fmul float %1, %facel
  %mul4 = fmul float %2, %facel
  %arrayidx7 = getelementptr inbounds i32* %type, i64 %idxprom
  %3 = load i32* %arrayidx7, align 4, !tbaa !0
  %mul8 = mul i32 %3, %ntype
  %cmp710 = icmp sgt i32 %nri, 0
  br i1 %cmp710, label %for.body, label %for.end389

for.body:                                         ; preds = %entry, %for.end.for.body_crit_edge
  %4 = phi i32 [ %.pre, %for.end.for.body_crit_edge ], [ %0, %entry ]
  %indvars.iv712 = phi i64 [ %indvars.iv.next713, %for.end.for.body_crit_edge ], [ 0, %entry ]
  %arrayidx10 = getelementptr inbounds i32* %shift, i64 %indvars.iv712
  %5 = load i32* %arrayidx10, align 4, !tbaa !0
  %mul11 = mul nsw i32 %5, 3
  %idxprom12 = sext i32 %mul11 to i64
  %arrayidx13 = getelementptr inbounds float* %shiftvec, i64 %idxprom12
  %6 = load float* %arrayidx13, align 4, !tbaa !3
  %add14 = add nsw i32 %mul11, 1
  %idxprom15 = sext i32 %add14 to i64
  %arrayidx16 = getelementptr inbounds float* %shiftvec, i64 %idxprom15
  %7 = load float* %arrayidx16, align 4, !tbaa !3
  %add17 = add nsw i32 %mul11, 2
  %idxprom18 = sext i32 %add17 to i64
  %arrayidx19 = getelementptr inbounds float* %shiftvec, i64 %idxprom18
  %8 = load float* %arrayidx19, align 4, !tbaa !3
  %mul22 = mul nsw i32 %4, 3
  %arrayidx24 = getelementptr inbounds i32* %jindex, i64 %indvars.iv712
  %9 = load i32* %arrayidx24, align 4, !tbaa !0
  %indvars.iv.next713 = add i64 %indvars.iv712, 1
  %arrayidx27 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next713
  %10 = load i32* %arrayidx27, align 4, !tbaa !0
  %idxprom28 = sext i32 %mul22 to i64
  %arrayidx29 = getelementptr inbounds float* %pos, i64 %idxprom28
  %11 = load float* %arrayidx29, align 4, !tbaa !3
  %add30 = fadd float %6, %11
  %add31 = add nsw i32 %mul22, 1
  %idxprom32 = sext i32 %add31 to i64
  %arrayidx33 = getelementptr inbounds float* %pos, i64 %idxprom32
  %12 = load float* %arrayidx33, align 4, !tbaa !3
  %add34 = fadd float %7, %12
  %add35 = add nsw i32 %mul22, 2
  %idxprom36 = sext i32 %add35 to i64
  %arrayidx37 = getelementptr inbounds float* %pos, i64 %idxprom36
  %13 = load float* %arrayidx37, align 4, !tbaa !3
  %add38 = fadd float %8, %13
  %add39 = add nsw i32 %mul22, 3
  %idxprom40 = sext i32 %add39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %14 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = fadd float %6, %14
  %add43 = add nsw i32 %mul22, 4
  %idxprom44 = sext i32 %add43 to i64
  %arrayidx45 = getelementptr inbounds float* %pos, i64 %idxprom44
  %15 = load float* %arrayidx45, align 4, !tbaa !3
  %add46 = fadd float %7, %15
  %add47 = add nsw i32 %mul22, 5
  %idxprom48 = sext i32 %add47 to i64
  %arrayidx49 = getelementptr inbounds float* %pos, i64 %idxprom48
  %16 = load float* %arrayidx49, align 4, !tbaa !3
  %add50 = fadd float %8, %16
  %add51 = add nsw i32 %mul22, 6
  %idxprom52 = sext i32 %add51 to i64
  %arrayidx53 = getelementptr inbounds float* %pos, i64 %idxprom52
  %17 = load float* %arrayidx53, align 4, !tbaa !3
  %add54 = fadd float %6, %17
  %add55 = add nsw i32 %mul22, 7
  %idxprom56 = sext i32 %add55 to i64
  %arrayidx57 = getelementptr inbounds float* %pos, i64 %idxprom56
  %18 = load float* %arrayidx57, align 4, !tbaa !3
  %add58 = fadd float %7, %18
  %add59 = add nsw i32 %mul22, 8
  %idxprom60 = sext i32 %add59 to i64
  %arrayidx61 = getelementptr inbounds float* %pos, i64 %idxprom60
  %19 = load float* %arrayidx61, align 4, !tbaa !3
  %add62 = fadd float %8, %19
  %cmp64687 = icmp slt i32 %9, %10
  br i1 %cmp64687, label %for.body65.lr.ph, label %for.end

for.body65.lr.ph:                                 ; preds = %for.body
  %20 = sext i32 %9 to i64
  br label %for.body65

for.body65:                                       ; preds = %for.body65.lr.ph, %for.body65
  %indvars.iv = phi i64 [ %20, %for.body65.lr.ph ], [ %indvars.iv.next, %for.body65 ]
  %vctot.0698 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add271, %for.body65 ]
  %vnbtot.0697 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %sub134, %for.body65 ]
  %fix1.0696 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add177, %for.body65 ]
  %fiy1.0695 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add178, %for.body65 ]
  %fiz1.0694 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add179, %for.body65 ]
  %fix2.0693 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add230, %for.body65 ]
  %fiy2.0692 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add231, %for.body65 ]
  %fiz2.0691 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add232, %for.body65 ]
  %fix3.0690 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add275, %for.body65 ]
  %fiy3.0689 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add276, %for.body65 ]
  %fiz3.0688 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add277, %for.body65 ]
  %arrayidx67 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %21 = load i32* %arrayidx67, align 4, !tbaa !0
  %mul68 = mul nsw i32 %21, 3
  %idxprom69 = sext i32 %mul68 to i64
  %arrayidx70 = getelementptr inbounds float* %pos, i64 %idxprom69
  %22 = load float* %arrayidx70, align 4, !tbaa !3
  %add71 = add nsw i32 %mul68, 1
  %idxprom72 = sext i32 %add71 to i64
  %arrayidx73 = getelementptr inbounds float* %pos, i64 %idxprom72
  %23 = load float* %arrayidx73, align 4, !tbaa !3
  %add74 = add nsw i32 %mul68, 2
  %idxprom75 = sext i32 %add74 to i64
  %arrayidx76 = getelementptr inbounds float* %pos, i64 %idxprom75
  %24 = load float* %arrayidx76, align 4, !tbaa !3
  %sub = fsub float %add30, %22
  %sub77 = fsub float %add34, %23
  %sub78 = fsub float %add38, %24
  %mul79 = fmul float %sub, %sub
  %mul80 = fmul float %sub77, %sub77
  %add81 = fadd float %mul79, %mul80
  %mul82 = fmul float %sub78, %sub78
  %add83 = fadd float %add81, %mul82
  %sub84 = fsub float %add42, %22
  %sub85 = fsub float %add46, %23
  %sub86 = fsub float %add50, %24
  %mul87 = fmul float %sub84, %sub84
  %mul88 = fmul float %sub85, %sub85
  %add89 = fadd float %mul87, %mul88
  %mul90 = fmul float %sub86, %sub86
  %add91 = fadd float %add89, %mul90
  %sub92 = fsub float %add54, %22
  %sub93 = fsub float %add58, %23
  %sub94 = fsub float %add62, %24
  %mul95 = fmul float %sub92, %sub92
  %mul96 = fmul float %sub93, %sub93
  %add97 = fadd float %mul95, %mul96
  %mul98 = fmul float %sub94, %sub94
  %add99 = fadd float %add97, %mul98
  %conv = fpext float %add83 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv100 = fptrunc double %div to float
  %conv101 = fpext float %add91 to double
  %call102 = tail call double @sqrt(double %conv101) #2
  %div103 = fdiv double 1.000000e+00, %call102
  %conv104 = fptrunc double %div103 to float
  %conv105 = fpext float %add99 to double
  %call106 = tail call double @sqrt(double %conv105) #2
  %div107 = fdiv double 1.000000e+00, %call106
  %conv108 = fptrunc double %div107 to float
  %mul109 = fmul float %add83, %conv100
  %mul110 = fmul float %conv100, %conv100
  %mul111 = fmul float %mul110, %mul110
  %mul112 = fmul float %mul110, %mul111
  %idxprom113 = sext i32 %21 to i64
  %arrayidx114 = getelementptr inbounds i32* %type, i64 %idxprom113
  %25 = load i32* %arrayidx114, align 4, !tbaa !0
  %tmp = add i32 %25, %mul8
  %tmp686 = mul i32 %tmp, 3
  %idxprom117 = sext i32 %tmp686 to i64
  %arrayidx118 = getelementptr inbounds float* %nbfp, i64 %idxprom117
  %26 = load float* %arrayidx118, align 4, !tbaa !3
  %mul119 = fmul float %mul112, %26
  %add120 = add nsw i32 %tmp686, 2
  %idxprom121 = sext i32 %add120 to i64
  %arrayidx122 = getelementptr inbounds float* %nbfp, i64 %idxprom121
  %27 = load float* %arrayidx122, align 4, !tbaa !3
  %mul123 = fmul float %mul109, %27
  %sub124 = fsub float -0.000000e+00, %mul123
  %conv125 = fpext float %sub124 to double
  %call126 = tail call double @exp(double %conv125) #2
  %add127 = add nsw i32 %tmp686, 1
  %idxprom128 = sext i32 %add127 to i64
  %arrayidx129 = getelementptr inbounds float* %nbfp, i64 %idxprom128
  %28 = load float* %arrayidx129, align 4, !tbaa !3
  %conv130 = fpext float %28 to double
  %mul131 = fmul double %call126, %conv130
  %conv132 = fptrunc double %mul131 to float
  %add133 = fadd float %vnbtot.0697, %conv132
  %sub134 = fsub float %add133, %mul119
  %mul135 = fmul float %mul109, %tabscale
  %conv136 = fptosi float %mul135 to i32
  %conv137 = sitofp i32 %conv136 to float
  %sub138 = fsub float %mul135, %conv137
  %mul139 = fmul float %sub138, %sub138
  %mul140 = shl nsw i32 %conv136, 2
  %arrayidx142 = getelementptr inbounds float* %charge, i64 %idxprom113
  %29 = load float* %arrayidx142, align 4, !tbaa !3
  %mul143 = fmul float %mul, %29
  %idxprom144 = sext i32 %mul140 to i64
  %arrayidx145 = getelementptr inbounds float* %VFtab, i64 %idxprom144
  %30 = load float* %arrayidx145, align 4, !tbaa !3
  %add146677 = or i32 %mul140, 1
  %idxprom147 = sext i32 %add146677 to i64
  %arrayidx148 = getelementptr inbounds float* %VFtab, i64 %idxprom147
  %31 = load float* %arrayidx148, align 4, !tbaa !3
  %add149678 = or i32 %mul140, 2
  %idxprom150 = sext i32 %add149678 to i64
  %arrayidx151 = getelementptr inbounds float* %VFtab, i64 %idxprom150
  %32 = load float* %arrayidx151, align 4, !tbaa !3
  %mul152 = fmul float %sub138, %32
  %add153679 = or i32 %mul140, 3
  %idxprom154 = sext i32 %add153679 to i64
  %arrayidx155 = getelementptr inbounds float* %VFtab, i64 %idxprom154
  %33 = load float* %arrayidx155, align 4, !tbaa !3
  %mul156 = fmul float %mul139, %33
  %add157 = fadd float %31, %mul152
  %add158 = fadd float %add157, %mul156
  %mul159 = fmul float %sub138, %add158
  %add160 = fadd float %30, %mul159
  %add161 = fadd float %mul152, %add158
  %mul162 = fmul float %mul156, 2.000000e+00
  %add163 = fadd float %mul162, %add161
  %mul164 = fmul float %mul143, %add160
  %mul165 = fmul float %mul143, %add163
  %mul166 = fmul float %mul123, %conv132
  %mul167 = fmul float %mul119, 6.000000e+00
  %sub168 = fsub float %mul166, %mul167
  %mul169 = fmul float %conv100, %sub168
  %mul170 = fmul float %mul165, %tabscale
  %sub171 = fsub float %mul169, %mul170
  %mul172 = fmul float %conv100, %sub171
  %add173 = fadd float %vctot.0698, %mul164
  %mul174 = fmul float %sub, %mul172
  %mul175 = fmul float %sub77, %mul172
  %mul176 = fmul float %sub78, %mul172
  %add177 = fadd float %fix1.0696, %mul174
  %add178 = fadd float %fiy1.0695, %mul175
  %add179 = fadd float %fiz1.0694, %mul176
  %arrayidx181 = getelementptr inbounds float* %faction, i64 %idxprom69
  %34 = load float* %arrayidx181, align 4, !tbaa !3
  %sub182 = fsub float %34, %mul174
  %arrayidx185 = getelementptr inbounds float* %faction, i64 %idxprom72
  %35 = load float* %arrayidx185, align 4, !tbaa !3
  %sub186 = fsub float %35, %mul175
  %arrayidx189 = getelementptr inbounds float* %faction, i64 %idxprom75
  %36 = load float* %arrayidx189, align 4, !tbaa !3
  %sub190 = fsub float %36, %mul176
  %mul191 = fmul float %add91, %conv104
  %mul192 = fmul float %mul191, %tabscale
  %conv193 = fptosi float %mul192 to i32
  %conv194 = sitofp i32 %conv193 to float
  %sub195 = fsub float %mul192, %conv194
  %mul196 = fmul float %sub195, %sub195
  %mul197 = shl nsw i32 %conv193, 2
  %mul200 = fmul float %mul4, %29
  %idxprom201 = sext i32 %mul197 to i64
  %arrayidx202 = getelementptr inbounds float* %VFtab, i64 %idxprom201
  %37 = load float* %arrayidx202, align 4, !tbaa !3
  %add203680 = or i32 %mul197, 1
  %idxprom204 = sext i32 %add203680 to i64
  %arrayidx205 = getelementptr inbounds float* %VFtab, i64 %idxprom204
  %38 = load float* %arrayidx205, align 4, !tbaa !3
  %add206681 = or i32 %mul197, 2
  %idxprom207 = sext i32 %add206681 to i64
  %arrayidx208 = getelementptr inbounds float* %VFtab, i64 %idxprom207
  %39 = load float* %arrayidx208, align 4, !tbaa !3
  %mul209 = fmul float %sub195, %39
  %add210682 = or i32 %mul197, 3
  %idxprom211 = sext i32 %add210682 to i64
  %arrayidx212 = getelementptr inbounds float* %VFtab, i64 %idxprom211
  %40 = load float* %arrayidx212, align 4, !tbaa !3
  %mul213 = fmul float %mul196, %40
  %add214 = fadd float %38, %mul209
  %add215 = fadd float %add214, %mul213
  %mul216 = fmul float %sub195, %add215
  %add217 = fadd float %37, %mul216
  %add218 = fadd float %mul209, %add215
  %mul219 = fmul float %mul213, 2.000000e+00
  %add220 = fadd float %mul219, %add218
  %mul221 = fmul float %mul200, %add217
  %mul222 = fmul float %mul200, %add220
  %mul223 = fmul float %mul222, %tabscale
  %41 = fmul float %conv104, %mul223
  %mul225 = fsub float -0.000000e+00, %41
  %add226 = fadd float %add173, %mul221
  %mul227 = fmul float %sub84, %mul225
  %mul228 = fmul float %sub85, %mul225
  %mul229 = fmul float %sub86, %mul225
  %add230 = fadd float %fix2.0693, %mul227
  %add231 = fadd float %fiy2.0692, %mul228
  %add232 = fadd float %fiz2.0691, %mul229
  %sub233 = fsub float %sub182, %mul227
  %sub234 = fsub float %sub186, %mul228
  %sub235 = fsub float %sub190, %mul229
  %mul236 = fmul float %add99, %conv108
  %mul237 = fmul float %mul236, %tabscale
  %conv238 = fptosi float %mul237 to i32
  %conv239 = sitofp i32 %conv238 to float
  %sub240 = fsub float %mul237, %conv239
  %mul241 = fmul float %sub240, %sub240
  %mul242 = shl nsw i32 %conv238, 2
  %idxprom246 = sext i32 %mul242 to i64
  %arrayidx247 = getelementptr inbounds float* %VFtab, i64 %idxprom246
  %42 = load float* %arrayidx247, align 4, !tbaa !3
  %add248683 = or i32 %mul242, 1
  %idxprom249 = sext i32 %add248683 to i64
  %arrayidx250 = getelementptr inbounds float* %VFtab, i64 %idxprom249
  %43 = load float* %arrayidx250, align 4, !tbaa !3
  %add251684 = or i32 %mul242, 2
  %idxprom252 = sext i32 %add251684 to i64
  %arrayidx253 = getelementptr inbounds float* %VFtab, i64 %idxprom252
  %44 = load float* %arrayidx253, align 4, !tbaa !3
  %mul254 = fmul float %sub240, %44
  %add255685 = or i32 %mul242, 3
  %idxprom256 = sext i32 %add255685 to i64
  %arrayidx257 = getelementptr inbounds float* %VFtab, i64 %idxprom256
  %45 = load float* %arrayidx257, align 4, !tbaa !3
  %mul258 = fmul float %mul241, %45
  %add259 = fadd float %43, %mul254
  %add260 = fadd float %add259, %mul258
  %mul261 = fmul float %sub240, %add260
  %add262 = fadd float %42, %mul261
  %add263 = fadd float %mul254, %add260
  %mul264 = fmul float %mul258, 2.000000e+00
  %add265 = fadd float %mul264, %add263
  %mul266 = fmul float %mul200, %add262
  %mul267 = fmul float %mul200, %add265
  %mul268 = fmul float %mul267, %tabscale
  %46 = fmul float %conv108, %mul268
  %mul270 = fsub float -0.000000e+00, %46
  %add271 = fadd float %add226, %mul266
  %mul272 = fmul float %sub92, %mul270
  %mul273 = fmul float %sub93, %mul270
  %mul274 = fmul float %sub94, %mul270
  %add275 = fadd float %fix3.0690, %mul272
  %add276 = fadd float %fiy3.0689, %mul273
  %add277 = fadd float %fiz3.0688, %mul274
  %sub278 = fsub float %sub233, %mul272
  store float %sub278, float* %arrayidx181, align 4, !tbaa !3
  %sub281 = fsub float %sub234, %mul273
  store float %sub281, float* %arrayidx185, align 4, !tbaa !3
  %sub285 = fsub float %sub235, %mul274
  store float %sub285, float* %arrayidx189, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %47 = trunc i64 %indvars.iv.next to i32
  %cmp64 = icmp slt i32 %47, %10
  br i1 %cmp64, label %for.body65, label %for.end

for.end:                                          ; preds = %for.body65, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add271, %for.body65 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %sub134, %for.body65 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add177, %for.body65 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add178, %for.body65 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add179, %for.body65 ]
  %fix2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add230, %for.body65 ]
  %fiy2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add231, %for.body65 ]
  %fiz2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add232, %for.body65 ]
  %fix3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add275, %for.body65 ]
  %fiy3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add276, %for.body65 ]
  %fiz3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add277, %for.body65 ]
  %arrayidx290 = getelementptr inbounds float* %faction, i64 %idxprom28
  %48 = load float* %arrayidx290, align 4, !tbaa !3
  %add291 = fadd float %fix1.0.lcssa, %48
  store float %add291, float* %arrayidx290, align 4, !tbaa !3
  %arrayidx296 = getelementptr inbounds float* %faction, i64 %idxprom32
  %49 = load float* %arrayidx296, align 4, !tbaa !3
  %add297 = fadd float %fiy1.0.lcssa, %49
  store float %add297, float* %arrayidx296, align 4, !tbaa !3
  %arrayidx303 = getelementptr inbounds float* %faction, i64 %idxprom36
  %50 = load float* %arrayidx303, align 4, !tbaa !3
  %add304 = fadd float %fiz1.0.lcssa, %50
  store float %add304, float* %arrayidx303, align 4, !tbaa !3
  %arrayidx310 = getelementptr inbounds float* %faction, i64 %idxprom40
  %51 = load float* %arrayidx310, align 4, !tbaa !3
  %add311 = fadd float %fix2.0.lcssa, %51
  store float %add311, float* %arrayidx310, align 4, !tbaa !3
  %arrayidx317 = getelementptr inbounds float* %faction, i64 %idxprom44
  %52 = load float* %arrayidx317, align 4, !tbaa !3
  %add318 = fadd float %fiy2.0.lcssa, %52
  store float %add318, float* %arrayidx317, align 4, !tbaa !3
  %arrayidx324 = getelementptr inbounds float* %faction, i64 %idxprom48
  %53 = load float* %arrayidx324, align 4, !tbaa !3
  %add325 = fadd float %fiz2.0.lcssa, %53
  store float %add325, float* %arrayidx324, align 4, !tbaa !3
  %arrayidx331 = getelementptr inbounds float* %faction, i64 %idxprom52
  %54 = load float* %arrayidx331, align 4, !tbaa !3
  %add332 = fadd float %fix3.0.lcssa, %54
  store float %add332, float* %arrayidx331, align 4, !tbaa !3
  %arrayidx338 = getelementptr inbounds float* %faction, i64 %idxprom56
  %55 = load float* %arrayidx338, align 4, !tbaa !3
  %add339 = fadd float %fiy3.0.lcssa, %55
  store float %add339, float* %arrayidx338, align 4, !tbaa !3
  %arrayidx345 = getelementptr inbounds float* %faction, i64 %idxprom60
  %56 = load float* %arrayidx345, align 4, !tbaa !3
  %add346 = fadd float %fiz3.0.lcssa, %56
  store float %add346, float* %arrayidx345, align 4, !tbaa !3
  %arrayidx351 = getelementptr inbounds float* %fshift, i64 %idxprom12
  %57 = load float* %arrayidx351, align 4, !tbaa !3
  %add352 = fadd float %fix1.0.lcssa, %57
  %add353 = fadd float %fix2.0.lcssa, %add352
  %add354 = fadd float %fix3.0.lcssa, %add353
  store float %add354, float* %arrayidx351, align 4, !tbaa !3
  %arrayidx359 = getelementptr inbounds float* %fshift, i64 %idxprom15
  %58 = load float* %arrayidx359, align 4, !tbaa !3
  %add360 = fadd float %fiy1.0.lcssa, %58
  %add361 = fadd float %fiy2.0.lcssa, %add360
  %add362 = fadd float %fiy3.0.lcssa, %add361
  store float %add362, float* %arrayidx359, align 4, !tbaa !3
  %arrayidx368 = getelementptr inbounds float* %fshift, i64 %idxprom18
  %59 = load float* %arrayidx368, align 4, !tbaa !3
  %add369 = fadd float %fiz1.0.lcssa, %59
  %add370 = fadd float %fiz2.0.lcssa, %add369
  %add371 = fadd float %fiz3.0.lcssa, %add370
  store float %add371, float* %arrayidx368, align 4, !tbaa !3
  %arrayidx376 = getelementptr inbounds i32* %gid, i64 %indvars.iv712
  %60 = load i32* %arrayidx376, align 4, !tbaa !0
  %idxprom377 = sext i32 %60 to i64
  %arrayidx378 = getelementptr inbounds float* %Vc, i64 %idxprom377
  %61 = load float* %arrayidx378, align 4, !tbaa !3
  %add379 = fadd float %vctot.0.lcssa, %61
  store float %add379, float* %arrayidx378, align 4, !tbaa !3
  %arrayidx383 = getelementptr inbounds float* %Vnb, i64 %idxprom377
  %62 = load float* %arrayidx383, align 4, !tbaa !3
  %add384 = fadd float %vnbtot.0.lcssa, %62
  store float %add384, float* %arrayidx383, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next713 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end389, label %for.end.for.body_crit_edge

for.end.for.body_crit_edge:                       ; preds = %for.end
  %arrayidx21.phi.trans.insert = getelementptr inbounds i32* %iinr, i64 %indvars.iv.next713
  %.pre = load i32* %arrayidx21.phi.trans.insert, align 4, !tbaa !0
  br label %for.body

for.end389:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl3230(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* %VFtab) #0 {
entry:
  %0 = load i32* %iinr, align 4, !tbaa !0
  %idxprom = sext i32 %0 to i64
  %arrayidx1 = getelementptr inbounds float* %charge, i64 %idxprom
  %1 = load float* %arrayidx1, align 4, !tbaa !3
  %add = add nsw i32 %0, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds float* %charge, i64 %idxprom2
  %2 = load float* %arrayidx3, align 4, !tbaa !3
  %mul = fmul float %1, %facel
  %mul4 = fmul float %1, %mul
  %mul6 = fmul float %mul, %2
  %mul7 = fmul float %2, %facel
  %mul8 = fmul float %2, %mul7
  %mul9 = mul nsw i32 %ntype, 3
  %arrayidx11 = getelementptr inbounds i32* %type, i64 %idxprom
  %3 = load i32* %arrayidx11, align 4, !tbaa !0
  %mul121422 = add i32 %mul9, 3
  %add16 = mul i32 %3, %mul121422
  %idxprom17 = sext i32 %add16 to i64
  %arrayidx18 = getelementptr inbounds float* %nbfp, i64 %idxprom17
  %4 = load float* %arrayidx18, align 4, !tbaa !3
  %add22 = add nsw i32 %add16, 2
  %idxprom23 = sext i32 %add22 to i64
  %arrayidx24 = getelementptr inbounds float* %nbfp, i64 %idxprom23
  %5 = load float* %arrayidx24, align 4, !tbaa !3
  %cmp1473 = icmp sgt i32 %nri, 0
  br i1 %cmp1473, label %for.body.lr.ph, label %for.end762

for.body.lr.ph:                                   ; preds = %entry
  %add19 = add nsw i32 %add16, 1
  %idxprom20 = sext i32 %add19 to i64
  %arrayidx21 = getelementptr inbounds float* %nbfp, i64 %idxprom20
  %6 = load float* %arrayidx21, align 4, !tbaa !3
  %conv221 = fpext float %6 to double
  br label %for.body

for.body:                                         ; preds = %for.end.for.body_crit_edge, %for.body.lr.ph
  %7 = phi i32 [ %0, %for.body.lr.ph ], [ %.pre, %for.end.for.body_crit_edge ]
  %indvars.iv1475 = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next1476, %for.end.for.body_crit_edge ]
  %arrayidx26 = getelementptr inbounds i32* %shift, i64 %indvars.iv1475
  %8 = load i32* %arrayidx26, align 4, !tbaa !0
  %mul27 = mul nsw i32 %8, 3
  %idxprom28 = sext i32 %mul27 to i64
  %arrayidx29 = getelementptr inbounds float* %shiftvec, i64 %idxprom28
  %9 = load float* %arrayidx29, align 4, !tbaa !3
  %add30 = add nsw i32 %mul27, 1
  %idxprom31 = sext i32 %add30 to i64
  %arrayidx32 = getelementptr inbounds float* %shiftvec, i64 %idxprom31
  %10 = load float* %arrayidx32, align 4, !tbaa !3
  %add33 = add nsw i32 %mul27, 2
  %idxprom34 = sext i32 %add33 to i64
  %arrayidx35 = getelementptr inbounds float* %shiftvec, i64 %idxprom34
  %11 = load float* %arrayidx35, align 4, !tbaa !3
  %mul38 = mul nsw i32 %7, 3
  %arrayidx40 = getelementptr inbounds i32* %jindex, i64 %indvars.iv1475
  %12 = load i32* %arrayidx40, align 4, !tbaa !0
  %indvars.iv.next1476 = add i64 %indvars.iv1475, 1
  %arrayidx43 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next1476
  %13 = load i32* %arrayidx43, align 4, !tbaa !0
  %idxprom44 = sext i32 %mul38 to i64
  %arrayidx45 = getelementptr inbounds float* %pos, i64 %idxprom44
  %14 = load float* %arrayidx45, align 4, !tbaa !3
  %add46 = fadd float %9, %14
  %add47 = add nsw i32 %mul38, 1
  %idxprom48 = sext i32 %add47 to i64
  %arrayidx49 = getelementptr inbounds float* %pos, i64 %idxprom48
  %15 = load float* %arrayidx49, align 4, !tbaa !3
  %add50 = fadd float %10, %15
  %add51 = add nsw i32 %mul38, 2
  %idxprom52 = sext i32 %add51 to i64
  %arrayidx53 = getelementptr inbounds float* %pos, i64 %idxprom52
  %16 = load float* %arrayidx53, align 4, !tbaa !3
  %add54 = fadd float %11, %16
  %add55 = add nsw i32 %mul38, 3
  %idxprom56 = sext i32 %add55 to i64
  %arrayidx57 = getelementptr inbounds float* %pos, i64 %idxprom56
  %17 = load float* %arrayidx57, align 4, !tbaa !3
  %add58 = fadd float %9, %17
  %add59 = add nsw i32 %mul38, 4
  %idxprom60 = sext i32 %add59 to i64
  %arrayidx61 = getelementptr inbounds float* %pos, i64 %idxprom60
  %18 = load float* %arrayidx61, align 4, !tbaa !3
  %add62 = fadd float %10, %18
  %add63 = add nsw i32 %mul38, 5
  %idxprom64 = sext i32 %add63 to i64
  %arrayidx65 = getelementptr inbounds float* %pos, i64 %idxprom64
  %19 = load float* %arrayidx65, align 4, !tbaa !3
  %add66 = fadd float %11, %19
  %add67 = add nsw i32 %mul38, 6
  %idxprom68 = sext i32 %add67 to i64
  %arrayidx69 = getelementptr inbounds float* %pos, i64 %idxprom68
  %20 = load float* %arrayidx69, align 4, !tbaa !3
  %add70 = fadd float %9, %20
  %add71 = add nsw i32 %mul38, 7
  %idxprom72 = sext i32 %add71 to i64
  %arrayidx73 = getelementptr inbounds float* %pos, i64 %idxprom72
  %21 = load float* %arrayidx73, align 4, !tbaa !3
  %add74 = fadd float %10, %21
  %add75 = add nsw i32 %mul38, 8
  %idxprom76 = sext i32 %add75 to i64
  %arrayidx77 = getelementptr inbounds float* %pos, i64 %idxprom76
  %22 = load float* %arrayidx77, align 4, !tbaa !3
  %add78 = fadd float %11, %22
  %cmp801450 = icmp slt i32 %12, %13
  br i1 %cmp801450, label %for.body81.lr.ph, label %for.end

for.body81.lr.ph:                                 ; preds = %for.body
  %23 = sext i32 %12 to i64
  br label %for.body81

for.body81:                                       ; preds = %for.body81.lr.ph, %for.body81
  %indvars.iv = phi i64 [ %23, %for.body81.lr.ph ], [ %indvars.iv.next, %for.body81 ]
  %vctot.01461 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add643, %for.body81 ]
  %vnbtot.01460 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %sub228, %for.body81 ]
  %fix1.01459 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add369, %for.body81 ]
  %fiy1.01458 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add370, %for.body81 ]
  %fiz1.01457 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add371, %for.body81 ]
  %fix2.01456 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add504, %for.body81 ]
  %fiy2.01455 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add505, %for.body81 ]
  %fiz2.01454 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add506, %for.body81 ]
  %fix3.01453 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add647, %for.body81 ]
  %fiy3.01452 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add648, %for.body81 ]
  %fiz3.01451 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add649, %for.body81 ]
  %arrayidx83 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %24 = load i32* %arrayidx83, align 4, !tbaa !0
  %mul84 = mul nsw i32 %24, 3
  %idxprom85 = sext i32 %mul84 to i64
  %arrayidx86 = getelementptr inbounds float* %pos, i64 %idxprom85
  %25 = load float* %arrayidx86, align 4, !tbaa !3
  %add87 = add nsw i32 %mul84, 1
  %idxprom88 = sext i32 %add87 to i64
  %arrayidx89 = getelementptr inbounds float* %pos, i64 %idxprom88
  %26 = load float* %arrayidx89, align 4, !tbaa !3
  %add90 = add nsw i32 %mul84, 2
  %idxprom91 = sext i32 %add90 to i64
  %arrayidx92 = getelementptr inbounds float* %pos, i64 %idxprom91
  %27 = load float* %arrayidx92, align 4, !tbaa !3
  %add93 = add nsw i32 %mul84, 3
  %idxprom94 = sext i32 %add93 to i64
  %arrayidx95 = getelementptr inbounds float* %pos, i64 %idxprom94
  %28 = load float* %arrayidx95, align 4, !tbaa !3
  %add96 = add nsw i32 %mul84, 4
  %idxprom97 = sext i32 %add96 to i64
  %arrayidx98 = getelementptr inbounds float* %pos, i64 %idxprom97
  %29 = load float* %arrayidx98, align 4, !tbaa !3
  %add99 = add nsw i32 %mul84, 5
  %idxprom100 = sext i32 %add99 to i64
  %arrayidx101 = getelementptr inbounds float* %pos, i64 %idxprom100
  %30 = load float* %arrayidx101, align 4, !tbaa !3
  %add102 = add nsw i32 %mul84, 6
  %idxprom103 = sext i32 %add102 to i64
  %arrayidx104 = getelementptr inbounds float* %pos, i64 %idxprom103
  %31 = load float* %arrayidx104, align 4, !tbaa !3
  %add105 = add nsw i32 %mul84, 7
  %idxprom106 = sext i32 %add105 to i64
  %arrayidx107 = getelementptr inbounds float* %pos, i64 %idxprom106
  %32 = load float* %arrayidx107, align 4, !tbaa !3
  %add108 = add nsw i32 %mul84, 8
  %idxprom109 = sext i32 %add108 to i64
  %arrayidx110 = getelementptr inbounds float* %pos, i64 %idxprom109
  %33 = load float* %arrayidx110, align 4, !tbaa !3
  %sub = fsub float %add46, %25
  %sub111 = fsub float %add50, %26
  %sub112 = fsub float %add54, %27
  %mul113 = fmul float %sub, %sub
  %mul114 = fmul float %sub111, %sub111
  %add115 = fadd float %mul113, %mul114
  %mul116 = fmul float %sub112, %sub112
  %add117 = fadd float %add115, %mul116
  %sub118 = fsub float %add46, %28
  %sub119 = fsub float %add50, %29
  %sub120 = fsub float %add54, %30
  %mul121 = fmul float %sub118, %sub118
  %mul122 = fmul float %sub119, %sub119
  %add123 = fadd float %mul121, %mul122
  %mul124 = fmul float %sub120, %sub120
  %add125 = fadd float %add123, %mul124
  %sub126 = fsub float %add46, %31
  %sub127 = fsub float %add50, %32
  %sub128 = fsub float %add54, %33
  %mul129 = fmul float %sub126, %sub126
  %mul130 = fmul float %sub127, %sub127
  %add131 = fadd float %mul129, %mul130
  %mul132 = fmul float %sub128, %sub128
  %add133 = fadd float %add131, %mul132
  %sub134 = fsub float %add58, %25
  %sub135 = fsub float %add62, %26
  %sub136 = fsub float %add66, %27
  %mul137 = fmul float %sub134, %sub134
  %mul138 = fmul float %sub135, %sub135
  %add139 = fadd float %mul137, %mul138
  %mul140 = fmul float %sub136, %sub136
  %add141 = fadd float %add139, %mul140
  %sub142 = fsub float %add58, %28
  %sub143 = fsub float %add62, %29
  %sub144 = fsub float %add66, %30
  %mul145 = fmul float %sub142, %sub142
  %mul146 = fmul float %sub143, %sub143
  %add147 = fadd float %mul145, %mul146
  %mul148 = fmul float %sub144, %sub144
  %add149 = fadd float %add147, %mul148
  %sub150 = fsub float %add58, %31
  %sub151 = fsub float %add62, %32
  %sub152 = fsub float %add66, %33
  %mul153 = fmul float %sub150, %sub150
  %mul154 = fmul float %sub151, %sub151
  %add155 = fadd float %mul153, %mul154
  %mul156 = fmul float %sub152, %sub152
  %add157 = fadd float %add155, %mul156
  %sub158 = fsub float %add70, %25
  %sub159 = fsub float %add74, %26
  %sub160 = fsub float %add78, %27
  %mul161 = fmul float %sub158, %sub158
  %mul162 = fmul float %sub159, %sub159
  %add163 = fadd float %mul161, %mul162
  %mul164 = fmul float %sub160, %sub160
  %add165 = fadd float %add163, %mul164
  %sub166 = fsub float %add70, %28
  %sub167 = fsub float %add74, %29
  %sub168 = fsub float %add78, %30
  %mul169 = fmul float %sub166, %sub166
  %mul170 = fmul float %sub167, %sub167
  %add171 = fadd float %mul169, %mul170
  %mul172 = fmul float %sub168, %sub168
  %add173 = fadd float %add171, %mul172
  %sub174 = fsub float %add70, %31
  %sub175 = fsub float %add74, %32
  %sub176 = fsub float %add78, %33
  %mul177 = fmul float %sub174, %sub174
  %mul178 = fmul float %sub175, %sub175
  %add179 = fadd float %mul177, %mul178
  %mul180 = fmul float %sub176, %sub176
  %add181 = fadd float %add179, %mul180
  %conv = fpext float %add117 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv182 = fptrunc double %div to float
  %conv183 = fpext float %add141 to double
  %call184 = tail call double @sqrt(double %conv183) #2
  %div185 = fdiv double 1.000000e+00, %call184
  %conv186 = fptrunc double %div185 to float
  %conv187 = fpext float %add165 to double
  %call188 = tail call double @sqrt(double %conv187) #2
  %div189 = fdiv double 1.000000e+00, %call188
  %conv190 = fptrunc double %div189 to float
  %conv191 = fpext float %add125 to double
  %call192 = tail call double @sqrt(double %conv191) #2
  %div193 = fdiv double 1.000000e+00, %call192
  %conv194 = fptrunc double %div193 to float
  %conv195 = fpext float %add149 to double
  %call196 = tail call double @sqrt(double %conv195) #2
  %div197 = fdiv double 1.000000e+00, %call196
  %conv198 = fptrunc double %div197 to float
  %conv199 = fpext float %add173 to double
  %call200 = tail call double @sqrt(double %conv199) #2
  %div201 = fdiv double 1.000000e+00, %call200
  %conv202 = fptrunc double %div201 to float
  %conv203 = fpext float %add133 to double
  %call204 = tail call double @sqrt(double %conv203) #2
  %div205 = fdiv double 1.000000e+00, %call204
  %conv206 = fptrunc double %div205 to float
  %conv207 = fpext float %add157 to double
  %call208 = tail call double @sqrt(double %conv207) #2
  %div209 = fdiv double 1.000000e+00, %call208
  %conv210 = fptrunc double %div209 to float
  %conv211 = fpext float %add181 to double
  %call212 = tail call double @sqrt(double %conv211) #2
  %div213 = fdiv double 1.000000e+00, %call212
  %conv214 = fptrunc double %div213 to float
  %mul215 = fmul float %add117, %conv182
  %mul216 = fmul float %conv182, %conv182
  %mul217 = fmul float %mul216, %mul216
  %mul218 = fmul float %mul216, %mul217
  %mul219 = fmul float %4, %mul218
  %mul220 = fmul float %5, %mul215
  %sub222 = fsub float -0.000000e+00, %mul220
  %conv223 = fpext float %sub222 to double
  %call224 = tail call double @exp(double %conv223) #2
  %mul225 = fmul double %conv221, %call224
  %conv226 = fptrunc double %mul225 to float
  %add227 = fadd float %vnbtot.01460, %conv226
  %sub228 = fsub float %add227, %mul219
  %mul229 = fmul float %mul215, %tabscale
  %conv230 = fptosi float %mul229 to i32
  %conv231 = sitofp i32 %conv230 to float
  %sub232 = fsub float %mul229, %conv231
  %mul233 = fmul float %sub232, %sub232
  %mul234 = shl nsw i32 %conv230, 2
  %idxprom235 = sext i32 %mul234 to i64
  %arrayidx236 = getelementptr inbounds float* %VFtab, i64 %idxprom235
  %34 = load float* %arrayidx236, align 4, !tbaa !3
  %add2371423 = or i32 %mul234, 1
  %idxprom238 = sext i32 %add2371423 to i64
  %arrayidx239 = getelementptr inbounds float* %VFtab, i64 %idxprom238
  %35 = load float* %arrayidx239, align 4, !tbaa !3
  %add2401424 = or i32 %mul234, 2
  %idxprom241 = sext i32 %add2401424 to i64
  %arrayidx242 = getelementptr inbounds float* %VFtab, i64 %idxprom241
  %36 = load float* %arrayidx242, align 4, !tbaa !3
  %mul243 = fmul float %sub232, %36
  %add2441425 = or i32 %mul234, 3
  %idxprom245 = sext i32 %add2441425 to i64
  %arrayidx246 = getelementptr inbounds float* %VFtab, i64 %idxprom245
  %37 = load float* %arrayidx246, align 4, !tbaa !3
  %mul247 = fmul float %mul233, %37
  %add248 = fadd float %35, %mul243
  %add249 = fadd float %add248, %mul247
  %mul250 = fmul float %sub232, %add249
  %add251 = fadd float %34, %mul250
  %add252 = fadd float %mul243, %add249
  %mul253 = fmul float %mul247, 2.000000e+00
  %add254 = fadd float %mul253, %add252
  %mul255 = fmul float %mul4, %add251
  %mul256 = fmul float %mul4, %add254
  %mul257 = fmul float %mul220, %conv226
  %mul258 = fmul float %mul219, 6.000000e+00
  %sub259 = fsub float %mul257, %mul258
  %mul260 = fmul float %conv182, %sub259
  %mul261 = fmul float %mul256, %tabscale
  %sub262 = fsub float %mul260, %mul261
  %mul263 = fmul float %conv182, %sub262
  %add264 = fadd float %vctot.01461, %mul255
  %mul265 = fmul float %sub, %mul263
  %mul266 = fmul float %sub111, %mul263
  %mul267 = fmul float %sub112, %mul263
  %add268 = fadd float %fix1.01459, %mul265
  %add269 = fadd float %fiy1.01458, %mul266
  %add270 = fadd float %fiz1.01457, %mul267
  %arrayidx272 = getelementptr inbounds float* %faction, i64 %idxprom85
  %38 = load float* %arrayidx272, align 4, !tbaa !3
  %sub273 = fsub float %38, %mul265
  %arrayidx276 = getelementptr inbounds float* %faction, i64 %idxprom88
  %39 = load float* %arrayidx276, align 4, !tbaa !3
  %sub277 = fsub float %39, %mul266
  %arrayidx280 = getelementptr inbounds float* %faction, i64 %idxprom91
  %40 = load float* %arrayidx280, align 4, !tbaa !3
  %sub281 = fsub float %40, %mul267
  %mul282 = fmul float %add125, %conv194
  %mul283 = fmul float %mul282, %tabscale
  %conv284 = fptosi float %mul283 to i32
  %conv285 = sitofp i32 %conv284 to float
  %sub286 = fsub float %mul283, %conv285
  %mul287 = fmul float %sub286, %sub286
  %mul288 = shl nsw i32 %conv284, 2
  %idxprom289 = sext i32 %mul288 to i64
  %arrayidx290 = getelementptr inbounds float* %VFtab, i64 %idxprom289
  %41 = load float* %arrayidx290, align 4, !tbaa !3
  %add2911426 = or i32 %mul288, 1
  %idxprom292 = sext i32 %add2911426 to i64
  %arrayidx293 = getelementptr inbounds float* %VFtab, i64 %idxprom292
  %42 = load float* %arrayidx293, align 4, !tbaa !3
  %add2941427 = or i32 %mul288, 2
  %idxprom295 = sext i32 %add2941427 to i64
  %arrayidx296 = getelementptr inbounds float* %VFtab, i64 %idxprom295
  %43 = load float* %arrayidx296, align 4, !tbaa !3
  %mul297 = fmul float %sub286, %43
  %add2981428 = or i32 %mul288, 3
  %idxprom299 = sext i32 %add2981428 to i64
  %arrayidx300 = getelementptr inbounds float* %VFtab, i64 %idxprom299
  %44 = load float* %arrayidx300, align 4, !tbaa !3
  %mul301 = fmul float %mul287, %44
  %add302 = fadd float %42, %mul297
  %add303 = fadd float %add302, %mul301
  %mul304 = fmul float %sub286, %add303
  %add305 = fadd float %41, %mul304
  %add306 = fadd float %mul297, %add303
  %mul307 = fmul float %mul301, 2.000000e+00
  %add308 = fadd float %mul307, %add306
  %mul309 = fmul float %mul6, %add305
  %mul310 = fmul float %mul6, %add308
  %mul311 = fmul float %mul310, %tabscale
  %45 = fmul float %conv194, %mul311
  %mul313 = fsub float -0.000000e+00, %45
  %add314 = fadd float %add264, %mul309
  %mul315 = fmul float %sub118, %mul313
  %mul316 = fmul float %sub119, %mul313
  %mul317 = fmul float %sub120, %mul313
  %add318 = fadd float %add268, %mul315
  %add319 = fadd float %add269, %mul316
  %add320 = fadd float %add270, %mul317
  %arrayidx323 = getelementptr inbounds float* %faction, i64 %idxprom94
  %46 = load float* %arrayidx323, align 4, !tbaa !3
  %sub324 = fsub float %46, %mul315
  %arrayidx327 = getelementptr inbounds float* %faction, i64 %idxprom97
  %47 = load float* %arrayidx327, align 4, !tbaa !3
  %sub328 = fsub float %47, %mul316
  %arrayidx331 = getelementptr inbounds float* %faction, i64 %idxprom100
  %48 = load float* %arrayidx331, align 4, !tbaa !3
  %sub332 = fsub float %48, %mul317
  %mul333 = fmul float %add133, %conv206
  %mul334 = fmul float %mul333, %tabscale
  %conv335 = fptosi float %mul334 to i32
  %conv336 = sitofp i32 %conv335 to float
  %sub337 = fsub float %mul334, %conv336
  %mul338 = fmul float %sub337, %sub337
  %mul339 = shl nsw i32 %conv335, 2
  %idxprom340 = sext i32 %mul339 to i64
  %arrayidx341 = getelementptr inbounds float* %VFtab, i64 %idxprom340
  %49 = load float* %arrayidx341, align 4, !tbaa !3
  %add3421429 = or i32 %mul339, 1
  %idxprom343 = sext i32 %add3421429 to i64
  %arrayidx344 = getelementptr inbounds float* %VFtab, i64 %idxprom343
  %50 = load float* %arrayidx344, align 4, !tbaa !3
  %add3451430 = or i32 %mul339, 2
  %idxprom346 = sext i32 %add3451430 to i64
  %arrayidx347 = getelementptr inbounds float* %VFtab, i64 %idxprom346
  %51 = load float* %arrayidx347, align 4, !tbaa !3
  %mul348 = fmul float %sub337, %51
  %add3491431 = or i32 %mul339, 3
  %idxprom350 = sext i32 %add3491431 to i64
  %arrayidx351 = getelementptr inbounds float* %VFtab, i64 %idxprom350
  %52 = load float* %arrayidx351, align 4, !tbaa !3
  %mul352 = fmul float %mul338, %52
  %add353 = fadd float %50, %mul348
  %add354 = fadd float %add353, %mul352
  %mul355 = fmul float %sub337, %add354
  %add356 = fadd float %49, %mul355
  %add357 = fadd float %mul348, %add354
  %mul358 = fmul float %mul352, 2.000000e+00
  %add359 = fadd float %mul358, %add357
  %mul360 = fmul float %mul6, %add356
  %mul361 = fmul float %mul6, %add359
  %mul362 = fmul float %mul361, %tabscale
  %53 = fmul float %conv206, %mul362
  %mul364 = fsub float -0.000000e+00, %53
  %add365 = fadd float %add314, %mul360
  %mul366 = fmul float %sub126, %mul364
  %mul367 = fmul float %sub127, %mul364
  %mul368 = fmul float %sub128, %mul364
  %add369 = fadd float %add318, %mul366
  %add370 = fadd float %add319, %mul367
  %add371 = fadd float %add320, %mul368
  %arrayidx374 = getelementptr inbounds float* %faction, i64 %idxprom103
  %54 = load float* %arrayidx374, align 4, !tbaa !3
  %sub375 = fsub float %54, %mul366
  %arrayidx378 = getelementptr inbounds float* %faction, i64 %idxprom106
  %55 = load float* %arrayidx378, align 4, !tbaa !3
  %sub379 = fsub float %55, %mul367
  %arrayidx382 = getelementptr inbounds float* %faction, i64 %idxprom109
  %56 = load float* %arrayidx382, align 4, !tbaa !3
  %sub383 = fsub float %56, %mul368
  %mul384 = fmul float %add141, %conv186
  %mul385 = fmul float %mul384, %tabscale
  %conv386 = fptosi float %mul385 to i32
  %conv387 = sitofp i32 %conv386 to float
  %sub388 = fsub float %mul385, %conv387
  %mul389 = fmul float %sub388, %sub388
  %mul390 = shl nsw i32 %conv386, 2
  %idxprom391 = sext i32 %mul390 to i64
  %arrayidx392 = getelementptr inbounds float* %VFtab, i64 %idxprom391
  %57 = load float* %arrayidx392, align 4, !tbaa !3
  %add3931432 = or i32 %mul390, 1
  %idxprom394 = sext i32 %add3931432 to i64
  %arrayidx395 = getelementptr inbounds float* %VFtab, i64 %idxprom394
  %58 = load float* %arrayidx395, align 4, !tbaa !3
  %add3961433 = or i32 %mul390, 2
  %idxprom397 = sext i32 %add3961433 to i64
  %arrayidx398 = getelementptr inbounds float* %VFtab, i64 %idxprom397
  %59 = load float* %arrayidx398, align 4, !tbaa !3
  %mul399 = fmul float %sub388, %59
  %add4001434 = or i32 %mul390, 3
  %idxprom401 = sext i32 %add4001434 to i64
  %arrayidx402 = getelementptr inbounds float* %VFtab, i64 %idxprom401
  %60 = load float* %arrayidx402, align 4, !tbaa !3
  %mul403 = fmul float %mul389, %60
  %add404 = fadd float %58, %mul399
  %add405 = fadd float %add404, %mul403
  %mul406 = fmul float %sub388, %add405
  %add407 = fadd float %57, %mul406
  %add408 = fadd float %mul399, %add405
  %mul409 = fmul float %mul403, 2.000000e+00
  %add410 = fadd float %mul409, %add408
  %mul411 = fmul float %mul6, %add407
  %mul412 = fmul float %mul6, %add410
  %mul413 = fmul float %mul412, %tabscale
  %61 = fmul float %conv186, %mul413
  %mul415 = fsub float -0.000000e+00, %61
  %add416 = fadd float %add365, %mul411
  %mul417 = fmul float %sub134, %mul415
  %mul418 = fmul float %sub135, %mul415
  %mul419 = fmul float %sub136, %mul415
  %add420 = fadd float %fix2.01456, %mul417
  %add421 = fadd float %fiy2.01455, %mul418
  %add422 = fadd float %fiz2.01454, %mul419
  %sub423 = fsub float %sub273, %mul417
  %sub424 = fsub float %sub277, %mul418
  %sub425 = fsub float %sub281, %mul419
  %mul426 = fmul float %add149, %conv198
  %mul427 = fmul float %mul426, %tabscale
  %conv428 = fptosi float %mul427 to i32
  %conv429 = sitofp i32 %conv428 to float
  %sub430 = fsub float %mul427, %conv429
  %mul431 = fmul float %sub430, %sub430
  %mul432 = shl nsw i32 %conv428, 2
  %idxprom433 = sext i32 %mul432 to i64
  %arrayidx434 = getelementptr inbounds float* %VFtab, i64 %idxprom433
  %62 = load float* %arrayidx434, align 4, !tbaa !3
  %add4351435 = or i32 %mul432, 1
  %idxprom436 = sext i32 %add4351435 to i64
  %arrayidx437 = getelementptr inbounds float* %VFtab, i64 %idxprom436
  %63 = load float* %arrayidx437, align 4, !tbaa !3
  %add4381436 = or i32 %mul432, 2
  %idxprom439 = sext i32 %add4381436 to i64
  %arrayidx440 = getelementptr inbounds float* %VFtab, i64 %idxprom439
  %64 = load float* %arrayidx440, align 4, !tbaa !3
  %mul441 = fmul float %sub430, %64
  %add4421437 = or i32 %mul432, 3
  %idxprom443 = sext i32 %add4421437 to i64
  %arrayidx444 = getelementptr inbounds float* %VFtab, i64 %idxprom443
  %65 = load float* %arrayidx444, align 4, !tbaa !3
  %mul445 = fmul float %mul431, %65
  %add446 = fadd float %63, %mul441
  %add447 = fadd float %add446, %mul445
  %mul448 = fmul float %sub430, %add447
  %add449 = fadd float %62, %mul448
  %add450 = fadd float %mul441, %add447
  %mul451 = fmul float %mul445, 2.000000e+00
  %add452 = fadd float %mul451, %add450
  %mul453 = fmul float %mul8, %add449
  %mul454 = fmul float %mul8, %add452
  %mul455 = fmul float %mul454, %tabscale
  %66 = fmul float %conv198, %mul455
  %mul457 = fsub float -0.000000e+00, %66
  %add458 = fadd float %add416, %mul453
  %mul459 = fmul float %sub142, %mul457
  %mul460 = fmul float %sub143, %mul457
  %mul461 = fmul float %sub144, %mul457
  %add462 = fadd float %add420, %mul459
  %add463 = fadd float %add421, %mul460
  %add464 = fadd float %add422, %mul461
  %sub465 = fsub float %sub324, %mul459
  %sub466 = fsub float %sub328, %mul460
  %sub467 = fsub float %sub332, %mul461
  %mul468 = fmul float %add157, %conv210
  %mul469 = fmul float %mul468, %tabscale
  %conv470 = fptosi float %mul469 to i32
  %conv471 = sitofp i32 %conv470 to float
  %sub472 = fsub float %mul469, %conv471
  %mul473 = fmul float %sub472, %sub472
  %mul474 = shl nsw i32 %conv470, 2
  %idxprom475 = sext i32 %mul474 to i64
  %arrayidx476 = getelementptr inbounds float* %VFtab, i64 %idxprom475
  %67 = load float* %arrayidx476, align 4, !tbaa !3
  %add4771438 = or i32 %mul474, 1
  %idxprom478 = sext i32 %add4771438 to i64
  %arrayidx479 = getelementptr inbounds float* %VFtab, i64 %idxprom478
  %68 = load float* %arrayidx479, align 4, !tbaa !3
  %add4801439 = or i32 %mul474, 2
  %idxprom481 = sext i32 %add4801439 to i64
  %arrayidx482 = getelementptr inbounds float* %VFtab, i64 %idxprom481
  %69 = load float* %arrayidx482, align 4, !tbaa !3
  %mul483 = fmul float %sub472, %69
  %add4841440 = or i32 %mul474, 3
  %idxprom485 = sext i32 %add4841440 to i64
  %arrayidx486 = getelementptr inbounds float* %VFtab, i64 %idxprom485
  %70 = load float* %arrayidx486, align 4, !tbaa !3
  %mul487 = fmul float %mul473, %70
  %add488 = fadd float %68, %mul483
  %add489 = fadd float %add488, %mul487
  %mul490 = fmul float %sub472, %add489
  %add491 = fadd float %67, %mul490
  %add492 = fadd float %mul483, %add489
  %mul493 = fmul float %mul487, 2.000000e+00
  %add494 = fadd float %mul493, %add492
  %mul495 = fmul float %mul8, %add491
  %mul496 = fmul float %mul8, %add494
  %mul497 = fmul float %mul496, %tabscale
  %71 = fmul float %conv210, %mul497
  %mul499 = fsub float -0.000000e+00, %71
  %add500 = fadd float %add458, %mul495
  %mul501 = fmul float %sub150, %mul499
  %mul502 = fmul float %sub151, %mul499
  %mul503 = fmul float %sub152, %mul499
  %add504 = fadd float %add462, %mul501
  %add505 = fadd float %add463, %mul502
  %add506 = fadd float %add464, %mul503
  %sub507 = fsub float %sub375, %mul501
  %sub508 = fsub float %sub379, %mul502
  %sub509 = fsub float %sub383, %mul503
  %mul510 = fmul float %add165, %conv190
  %mul511 = fmul float %mul510, %tabscale
  %conv512 = fptosi float %mul511 to i32
  %conv513 = sitofp i32 %conv512 to float
  %sub514 = fsub float %mul511, %conv513
  %mul515 = fmul float %sub514, %sub514
  %mul516 = shl nsw i32 %conv512, 2
  %idxprom517 = sext i32 %mul516 to i64
  %arrayidx518 = getelementptr inbounds float* %VFtab, i64 %idxprom517
  %72 = load float* %arrayidx518, align 4, !tbaa !3
  %add5191441 = or i32 %mul516, 1
  %idxprom520 = sext i32 %add5191441 to i64
  %arrayidx521 = getelementptr inbounds float* %VFtab, i64 %idxprom520
  %73 = load float* %arrayidx521, align 4, !tbaa !3
  %add5221442 = or i32 %mul516, 2
  %idxprom523 = sext i32 %add5221442 to i64
  %arrayidx524 = getelementptr inbounds float* %VFtab, i64 %idxprom523
  %74 = load float* %arrayidx524, align 4, !tbaa !3
  %mul525 = fmul float %sub514, %74
  %add5261443 = or i32 %mul516, 3
  %idxprom527 = sext i32 %add5261443 to i64
  %arrayidx528 = getelementptr inbounds float* %VFtab, i64 %idxprom527
  %75 = load float* %arrayidx528, align 4, !tbaa !3
  %mul529 = fmul float %mul515, %75
  %add530 = fadd float %73, %mul525
  %add531 = fadd float %add530, %mul529
  %mul532 = fmul float %sub514, %add531
  %add533 = fadd float %72, %mul532
  %add534 = fadd float %mul525, %add531
  %mul535 = fmul float %mul529, 2.000000e+00
  %add536 = fadd float %mul535, %add534
  %mul537 = fmul float %mul6, %add533
  %mul538 = fmul float %mul6, %add536
  %mul539 = fmul float %mul538, %tabscale
  %76 = fmul float %conv190, %mul539
  %mul541 = fsub float -0.000000e+00, %76
  %add542 = fadd float %add500, %mul537
  %mul543 = fmul float %sub158, %mul541
  %mul544 = fmul float %sub159, %mul541
  %mul545 = fmul float %sub160, %mul541
  %add546 = fadd float %fix3.01453, %mul543
  %add547 = fadd float %fiy3.01452, %mul544
  %add548 = fadd float %fiz3.01451, %mul545
  %sub549 = fsub float %sub423, %mul543
  store float %sub549, float* %arrayidx272, align 4, !tbaa !3
  %sub552 = fsub float %sub424, %mul544
  store float %sub552, float* %arrayidx276, align 4, !tbaa !3
  %sub556 = fsub float %sub425, %mul545
  store float %sub556, float* %arrayidx280, align 4, !tbaa !3
  %mul560 = fmul float %add173, %conv202
  %mul561 = fmul float %mul560, %tabscale
  %conv562 = fptosi float %mul561 to i32
  %conv563 = sitofp i32 %conv562 to float
  %sub564 = fsub float %mul561, %conv563
  %mul565 = fmul float %sub564, %sub564
  %mul566 = shl nsw i32 %conv562, 2
  %idxprom567 = sext i32 %mul566 to i64
  %arrayidx568 = getelementptr inbounds float* %VFtab, i64 %idxprom567
  %77 = load float* %arrayidx568, align 4, !tbaa !3
  %add5691444 = or i32 %mul566, 1
  %idxprom570 = sext i32 %add5691444 to i64
  %arrayidx571 = getelementptr inbounds float* %VFtab, i64 %idxprom570
  %78 = load float* %arrayidx571, align 4, !tbaa !3
  %add5721445 = or i32 %mul566, 2
  %idxprom573 = sext i32 %add5721445 to i64
  %arrayidx574 = getelementptr inbounds float* %VFtab, i64 %idxprom573
  %79 = load float* %arrayidx574, align 4, !tbaa !3
  %mul575 = fmul float %sub564, %79
  %add5761446 = or i32 %mul566, 3
  %idxprom577 = sext i32 %add5761446 to i64
  %arrayidx578 = getelementptr inbounds float* %VFtab, i64 %idxprom577
  %80 = load float* %arrayidx578, align 4, !tbaa !3
  %mul579 = fmul float %mul565, %80
  %add580 = fadd float %78, %mul575
  %add581 = fadd float %add580, %mul579
  %mul582 = fmul float %sub564, %add581
  %add583 = fadd float %77, %mul582
  %add584 = fadd float %mul575, %add581
  %mul585 = fmul float %mul579, 2.000000e+00
  %add586 = fadd float %mul585, %add584
  %mul587 = fmul float %mul8, %add583
  %mul588 = fmul float %mul8, %add586
  %mul589 = fmul float %mul588, %tabscale
  %81 = fmul float %conv202, %mul589
  %mul591 = fsub float -0.000000e+00, %81
  %add592 = fadd float %add542, %mul587
  %mul593 = fmul float %sub166, %mul591
  %mul594 = fmul float %sub167, %mul591
  %mul595 = fmul float %sub168, %mul591
  %add596 = fadd float %add546, %mul593
  %add597 = fadd float %add547, %mul594
  %add598 = fadd float %add548, %mul595
  %sub599 = fsub float %sub465, %mul593
  store float %sub599, float* %arrayidx323, align 4, !tbaa !3
  %sub603 = fsub float %sub466, %mul594
  store float %sub603, float* %arrayidx327, align 4, !tbaa !3
  %sub607 = fsub float %sub467, %mul595
  store float %sub607, float* %arrayidx331, align 4, !tbaa !3
  %mul611 = fmul float %add181, %conv214
  %mul612 = fmul float %mul611, %tabscale
  %conv613 = fptosi float %mul612 to i32
  %conv614 = sitofp i32 %conv613 to float
  %sub615 = fsub float %mul612, %conv614
  %mul616 = fmul float %sub615, %sub615
  %mul617 = shl nsw i32 %conv613, 2
  %idxprom618 = sext i32 %mul617 to i64
  %arrayidx619 = getelementptr inbounds float* %VFtab, i64 %idxprom618
  %82 = load float* %arrayidx619, align 4, !tbaa !3
  %add6201447 = or i32 %mul617, 1
  %idxprom621 = sext i32 %add6201447 to i64
  %arrayidx622 = getelementptr inbounds float* %VFtab, i64 %idxprom621
  %83 = load float* %arrayidx622, align 4, !tbaa !3
  %add6231448 = or i32 %mul617, 2
  %idxprom624 = sext i32 %add6231448 to i64
  %arrayidx625 = getelementptr inbounds float* %VFtab, i64 %idxprom624
  %84 = load float* %arrayidx625, align 4, !tbaa !3
  %mul626 = fmul float %sub615, %84
  %add6271449 = or i32 %mul617, 3
  %idxprom628 = sext i32 %add6271449 to i64
  %arrayidx629 = getelementptr inbounds float* %VFtab, i64 %idxprom628
  %85 = load float* %arrayidx629, align 4, !tbaa !3
  %mul630 = fmul float %mul616, %85
  %add631 = fadd float %83, %mul626
  %add632 = fadd float %add631, %mul630
  %mul633 = fmul float %sub615, %add632
  %add634 = fadd float %82, %mul633
  %add635 = fadd float %mul626, %add632
  %mul636 = fmul float %mul630, 2.000000e+00
  %add637 = fadd float %mul636, %add635
  %mul638 = fmul float %mul8, %add634
  %mul639 = fmul float %mul8, %add637
  %mul640 = fmul float %mul639, %tabscale
  %86 = fmul float %conv214, %mul640
  %mul642 = fsub float -0.000000e+00, %86
  %add643 = fadd float %add592, %mul638
  %mul644 = fmul float %sub174, %mul642
  %mul645 = fmul float %sub175, %mul642
  %mul646 = fmul float %sub176, %mul642
  %add647 = fadd float %add596, %mul644
  %add648 = fadd float %add597, %mul645
  %add649 = fadd float %add598, %mul646
  %sub650 = fsub float %sub507, %mul644
  store float %sub650, float* %arrayidx374, align 4, !tbaa !3
  %sub654 = fsub float %sub508, %mul645
  store float %sub654, float* %arrayidx378, align 4, !tbaa !3
  %sub658 = fsub float %sub509, %mul646
  store float %sub658, float* %arrayidx382, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %87 = trunc i64 %indvars.iv.next to i32
  %cmp80 = icmp slt i32 %87, %13
  br i1 %cmp80, label %for.body81, label %for.end

for.end:                                          ; preds = %for.body81, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add643, %for.body81 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %sub228, %for.body81 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add369, %for.body81 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add370, %for.body81 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add371, %for.body81 ]
  %fix2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add504, %for.body81 ]
  %fiy2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add505, %for.body81 ]
  %fiz2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add506, %for.body81 ]
  %fix3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add647, %for.body81 ]
  %fiy3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add648, %for.body81 ]
  %fiz3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add649, %for.body81 ]
  %arrayidx663 = getelementptr inbounds float* %faction, i64 %idxprom44
  %88 = load float* %arrayidx663, align 4, !tbaa !3
  %add664 = fadd float %fix1.0.lcssa, %88
  store float %add664, float* %arrayidx663, align 4, !tbaa !3
  %arrayidx669 = getelementptr inbounds float* %faction, i64 %idxprom48
  %89 = load float* %arrayidx669, align 4, !tbaa !3
  %add670 = fadd float %fiy1.0.lcssa, %89
  store float %add670, float* %arrayidx669, align 4, !tbaa !3
  %arrayidx676 = getelementptr inbounds float* %faction, i64 %idxprom52
  %90 = load float* %arrayidx676, align 4, !tbaa !3
  %add677 = fadd float %fiz1.0.lcssa, %90
  store float %add677, float* %arrayidx676, align 4, !tbaa !3
  %arrayidx683 = getelementptr inbounds float* %faction, i64 %idxprom56
  %91 = load float* %arrayidx683, align 4, !tbaa !3
  %add684 = fadd float %fix2.0.lcssa, %91
  store float %add684, float* %arrayidx683, align 4, !tbaa !3
  %arrayidx690 = getelementptr inbounds float* %faction, i64 %idxprom60
  %92 = load float* %arrayidx690, align 4, !tbaa !3
  %add691 = fadd float %fiy2.0.lcssa, %92
  store float %add691, float* %arrayidx690, align 4, !tbaa !3
  %arrayidx697 = getelementptr inbounds float* %faction, i64 %idxprom64
  %93 = load float* %arrayidx697, align 4, !tbaa !3
  %add698 = fadd float %fiz2.0.lcssa, %93
  store float %add698, float* %arrayidx697, align 4, !tbaa !3
  %arrayidx704 = getelementptr inbounds float* %faction, i64 %idxprom68
  %94 = load float* %arrayidx704, align 4, !tbaa !3
  %add705 = fadd float %fix3.0.lcssa, %94
  store float %add705, float* %arrayidx704, align 4, !tbaa !3
  %arrayidx711 = getelementptr inbounds float* %faction, i64 %idxprom72
  %95 = load float* %arrayidx711, align 4, !tbaa !3
  %add712 = fadd float %fiy3.0.lcssa, %95
  store float %add712, float* %arrayidx711, align 4, !tbaa !3
  %arrayidx718 = getelementptr inbounds float* %faction, i64 %idxprom76
  %96 = load float* %arrayidx718, align 4, !tbaa !3
  %add719 = fadd float %fiz3.0.lcssa, %96
  store float %add719, float* %arrayidx718, align 4, !tbaa !3
  %arrayidx724 = getelementptr inbounds float* %fshift, i64 %idxprom28
  %97 = load float* %arrayidx724, align 4, !tbaa !3
  %add725 = fadd float %fix1.0.lcssa, %97
  %add726 = fadd float %fix2.0.lcssa, %add725
  %add727 = fadd float %fix3.0.lcssa, %add726
  store float %add727, float* %arrayidx724, align 4, !tbaa !3
  %arrayidx732 = getelementptr inbounds float* %fshift, i64 %idxprom31
  %98 = load float* %arrayidx732, align 4, !tbaa !3
  %add733 = fadd float %fiy1.0.lcssa, %98
  %add734 = fadd float %fiy2.0.lcssa, %add733
  %add735 = fadd float %fiy3.0.lcssa, %add734
  store float %add735, float* %arrayidx732, align 4, !tbaa !3
  %arrayidx741 = getelementptr inbounds float* %fshift, i64 %idxprom34
  %99 = load float* %arrayidx741, align 4, !tbaa !3
  %add742 = fadd float %fiz1.0.lcssa, %99
  %add743 = fadd float %fiz2.0.lcssa, %add742
  %add744 = fadd float %fiz3.0.lcssa, %add743
  store float %add744, float* %arrayidx741, align 4, !tbaa !3
  %arrayidx749 = getelementptr inbounds i32* %gid, i64 %indvars.iv1475
  %100 = load i32* %arrayidx749, align 4, !tbaa !0
  %idxprom750 = sext i32 %100 to i64
  %arrayidx751 = getelementptr inbounds float* %Vc, i64 %idxprom750
  %101 = load float* %arrayidx751, align 4, !tbaa !3
  %add752 = fadd float %vctot.0.lcssa, %101
  store float %add752, float* %arrayidx751, align 4, !tbaa !3
  %arrayidx756 = getelementptr inbounds float* %Vnb, i64 %idxprom750
  %102 = load float* %arrayidx756, align 4, !tbaa !3
  %add757 = fadd float %vnbtot.0.lcssa, %102
  store float %add757, float* %arrayidx756, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next1476 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end762, label %for.end.for.body_crit_edge

for.end.for.body_crit_edge:                       ; preds = %for.end
  %arrayidx37.phi.trans.insert = getelementptr inbounds i32* %iinr, i64 %indvars.iv.next1476
  %.pre = load i32* %arrayidx37.phi.trans.insert, align 4, !tbaa !0
  br label %for.body

for.end762:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl3300(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab) #0 {
entry:
  %cmp396 = icmp sgt i32 %nri, 0
  br i1 %cmp396, label %for.body.lr.ph, label %for.end228

for.body.lr.ph:                                   ; preds = %entry
  %mul30 = shl i32 %ntype, 1
  br label %for.body

for.body:                                         ; preds = %for.end, %for.body.lr.ph
  %indvars.iv398 = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next399, %for.end ]
  %arrayidx = getelementptr inbounds i32* %shift, i64 %indvars.iv398
  %0 = load i32* %arrayidx, align 4, !tbaa !0
  %mul = mul nsw i32 %0, 3
  %idxprom1 = sext i32 %mul to i64
  %arrayidx2 = getelementptr inbounds float* %shiftvec, i64 %idxprom1
  %1 = load float* %arrayidx2, align 4, !tbaa !3
  %add = add nsw i32 %mul, 1
  %idxprom3 = sext i32 %add to i64
  %arrayidx4 = getelementptr inbounds float* %shiftvec, i64 %idxprom3
  %2 = load float* %arrayidx4, align 4, !tbaa !3
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds float* %shiftvec, i64 %idxprom6
  %3 = load float* %arrayidx7, align 4, !tbaa !3
  %arrayidx9 = getelementptr inbounds i32* %iinr, i64 %indvars.iv398
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %arrayidx12 = getelementptr inbounds i32* %jindex, i64 %indvars.iv398
  %5 = load i32* %arrayidx12, align 4, !tbaa !0
  %indvars.iv.next399 = add i64 %indvars.iv398, 1
  %arrayidx15 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next399
  %6 = load i32* %arrayidx15, align 4, !tbaa !0
  %idxprom16 = sext i32 %mul10 to i64
  %arrayidx17 = getelementptr inbounds float* %pos, i64 %idxprom16
  %7 = load float* %arrayidx17, align 4, !tbaa !3
  %add18 = fadd float %1, %7
  %add19 = add nsw i32 %mul10, 1
  %idxprom20 = sext i32 %add19 to i64
  %arrayidx21 = getelementptr inbounds float* %pos, i64 %idxprom20
  %8 = load float* %arrayidx21, align 4, !tbaa !3
  %add22 = fadd float %2, %8
  %add23 = add nsw i32 %mul10, 2
  %idxprom24 = sext i32 %add23 to i64
  %arrayidx25 = getelementptr inbounds float* %pos, i64 %idxprom24
  %9 = load float* %arrayidx25, align 4, !tbaa !3
  %add26 = fadd float %3, %9
  %idxprom27 = sext i32 %4 to i64
  %arrayidx28 = getelementptr inbounds float* %charge, i64 %idxprom27
  %10 = load float* %arrayidx28, align 4, !tbaa !3
  %mul29 = fmul float %10, %facel
  %arrayidx32 = getelementptr inbounds i32* %type, i64 %idxprom27
  %11 = load i32* %arrayidx32, align 4, !tbaa !0
  %mul33 = mul nsw i32 %mul30, %11
  %cmp35385 = icmp slt i32 %5, %6
  br i1 %cmp35385, label %for.body36.lr.ph, label %for.end

for.body36.lr.ph:                                 ; preds = %for.body
  %12 = sext i32 %5 to i64
  br label %for.body36

for.body36:                                       ; preds = %for.body36.lr.ph, %for.body36
  %indvars.iv = phi i64 [ %12, %for.body36.lr.ph ], [ %indvars.iv.next, %for.body36 ]
  %vctot.0390 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add150, %for.body36 ]
  %vnbtot.0389 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add144, %for.body36 ]
  %fix1.0388 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add154, %for.body36 ]
  %fiy1.0387 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add155, %for.body36 ]
  %fiz1.0386 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add156, %for.body36 ]
  %arrayidx38 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %13 = load i32* %arrayidx38, align 4, !tbaa !0
  %mul39 = mul nsw i32 %13, 3
  %idxprom40 = sext i32 %mul39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %14 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = add nsw i32 %mul39, 1
  %idxprom43 = sext i32 %add42 to i64
  %arrayidx44 = getelementptr inbounds float* %pos, i64 %idxprom43
  %15 = load float* %arrayidx44, align 4, !tbaa !3
  %add45 = add nsw i32 %mul39, 2
  %idxprom46 = sext i32 %add45 to i64
  %arrayidx47 = getelementptr inbounds float* %pos, i64 %idxprom46
  %16 = load float* %arrayidx47, align 4, !tbaa !3
  %sub = fsub float %add18, %14
  %sub48 = fsub float %add22, %15
  %sub49 = fsub float %add26, %16
  %mul50 = fmul float %sub, %sub
  %mul51 = fmul float %sub48, %sub48
  %add52 = fadd float %mul50, %mul51
  %mul53 = fmul float %sub49, %sub49
  %add54 = fadd float %add52, %mul53
  %conv = fpext float %add54 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv55 = fptrunc double %div to float
  %mul56 = fmul float %add54, %conv55
  %mul57 = fmul float %mul56, %tabscale
  %conv58 = fptosi float %mul57 to i32
  %conv59 = sitofp i32 %conv58 to float
  %sub60 = fsub float %mul57, %conv59
  %mul61 = fmul float %sub60, %sub60
  %mul62 = mul nsw i32 %conv58, 12
  %idxprom63 = sext i32 %13 to i64
  %arrayidx64 = getelementptr inbounds float* %charge, i64 %idxprom63
  %17 = load float* %arrayidx64, align 4, !tbaa !3
  %mul65 = fmul float %mul29, %17
  %idxprom66 = sext i32 %mul62 to i64
  %arrayidx67 = getelementptr inbounds float* %VFtab, i64 %idxprom66
  %18 = load float* %arrayidx67, align 4, !tbaa !3
  %add68381 = or i32 %mul62, 1
  %idxprom69 = sext i32 %add68381 to i64
  %arrayidx70 = getelementptr inbounds float* %VFtab, i64 %idxprom69
  %19 = load float* %arrayidx70, align 4, !tbaa !3
  %add71382 = or i32 %mul62, 2
  %idxprom72 = sext i32 %add71382 to i64
  %arrayidx73 = getelementptr inbounds float* %VFtab, i64 %idxprom72
  %20 = load float* %arrayidx73, align 4, !tbaa !3
  %mul74 = fmul float %20, %sub60
  %add75383 = or i32 %mul62, 3
  %idxprom76 = sext i32 %add75383 to i64
  %arrayidx77 = getelementptr inbounds float* %VFtab, i64 %idxprom76
  %21 = load float* %arrayidx77, align 4, !tbaa !3
  %mul78 = fmul float %21, %mul61
  %add79 = fadd float %19, %mul74
  %add80 = fadd float %add79, %mul78
  %mul81 = fmul float %sub60, %add80
  %add82 = fadd float %18, %mul81
  %add83 = fadd float %mul74, %add80
  %mul84 = fmul float %mul78, 2.000000e+00
  %add85 = fadd float %mul84, %add83
  %mul86 = fmul float %mul65, %add82
  %mul87 = fmul float %mul65, %add85
  %arrayidx89 = getelementptr inbounds i32* %type, i64 %idxprom63
  %22 = load i32* %arrayidx89, align 4, !tbaa !0
  %mul90 = shl nsw i32 %22, 1
  %add91 = add nsw i32 %mul90, %mul33
  %idxprom92 = sext i32 %add91 to i64
  %arrayidx93 = getelementptr inbounds float* %nbfp, i64 %idxprom92
  %23 = load float* %arrayidx93, align 4, !tbaa !3
  %add94384 = or i32 %add91, 1
  %idxprom95 = sext i32 %add94384 to i64
  %arrayidx96 = getelementptr inbounds float* %nbfp, i64 %idxprom95
  %24 = load float* %arrayidx96, align 4, !tbaa !3
  %add97 = add nsw i32 %mul62, 4
  %idxprom98 = sext i32 %add97 to i64
  %arrayidx99 = getelementptr inbounds float* %VFtab, i64 %idxprom98
  %25 = load float* %arrayidx99, align 4, !tbaa !3
  %add100 = add nsw i32 %mul62, 5
  %idxprom101 = sext i32 %add100 to i64
  %arrayidx102 = getelementptr inbounds float* %VFtab, i64 %idxprom101
  %26 = load float* %arrayidx102, align 4, !tbaa !3
  %add103 = add nsw i32 %mul62, 6
  %idxprom104 = sext i32 %add103 to i64
  %arrayidx105 = getelementptr inbounds float* %VFtab, i64 %idxprom104
  %27 = load float* %arrayidx105, align 4, !tbaa !3
  %mul106 = fmul float %sub60, %27
  %add107 = add nsw i32 %mul62, 7
  %idxprom108 = sext i32 %add107 to i64
  %arrayidx109 = getelementptr inbounds float* %VFtab, i64 %idxprom108
  %28 = load float* %arrayidx109, align 4, !tbaa !3
  %mul110 = fmul float %mul61, %28
  %add111 = fadd float %26, %mul106
  %add112 = fadd float %add111, %mul110
  %mul113 = fmul float %sub60, %add112
  %add114 = fadd float %25, %mul113
  %add115 = fadd float %mul106, %add112
  %mul116 = fmul float %mul110, 2.000000e+00
  %add117 = fadd float %mul116, %add115
  %mul118 = fmul float %23, %add114
  %mul119 = fmul float %23, %add117
  %add120 = add nsw i32 %mul62, 8
  %idxprom121 = sext i32 %add120 to i64
  %arrayidx122 = getelementptr inbounds float* %VFtab, i64 %idxprom121
  %29 = load float* %arrayidx122, align 4, !tbaa !3
  %add123 = add nsw i32 %mul62, 9
  %idxprom124 = sext i32 %add123 to i64
  %arrayidx125 = getelementptr inbounds float* %VFtab, i64 %idxprom124
  %30 = load float* %arrayidx125, align 4, !tbaa !3
  %add126 = add nsw i32 %mul62, 10
  %idxprom127 = sext i32 %add126 to i64
  %arrayidx128 = getelementptr inbounds float* %VFtab, i64 %idxprom127
  %31 = load float* %arrayidx128, align 4, !tbaa !3
  %mul129 = fmul float %sub60, %31
  %add130 = add nsw i32 %mul62, 11
  %idxprom131 = sext i32 %add130 to i64
  %arrayidx132 = getelementptr inbounds float* %VFtab, i64 %idxprom131
  %32 = load float* %arrayidx132, align 4, !tbaa !3
  %mul133 = fmul float %mul61, %32
  %add134 = fadd float %30, %mul129
  %add135 = fadd float %add134, %mul133
  %mul136 = fmul float %sub60, %add135
  %add137 = fadd float %29, %mul136
  %add138 = fadd float %mul129, %add135
  %mul139 = fmul float %mul133, 2.000000e+00
  %add140 = fadd float %mul139, %add138
  %mul141 = fmul float %24, %add137
  %mul142 = fmul float %24, %add140
  %add143 = fadd float %vnbtot.0389, %mul118
  %add144 = fadd float %add143, %mul141
  %add145 = fadd float %mul87, %mul119
  %add146 = fadd float %add145, %mul142
  %mul147 = fmul float %add146, %tabscale
  %33 = fmul float %conv55, %mul147
  %mul149 = fsub float -0.000000e+00, %33
  %add150 = fadd float %vctot.0390, %mul86
  %mul151 = fmul float %sub, %mul149
  %mul152 = fmul float %sub48, %mul149
  %mul153 = fmul float %sub49, %mul149
  %add154 = fadd float %fix1.0388, %mul151
  %add155 = fadd float %fiy1.0387, %mul152
  %add156 = fadd float %fiz1.0386, %mul153
  %arrayidx158 = getelementptr inbounds float* %faction, i64 %idxprom40
  %34 = load float* %arrayidx158, align 4, !tbaa !3
  %sub159 = fsub float %34, %mul151
  store float %sub159, float* %arrayidx158, align 4, !tbaa !3
  %arrayidx164 = getelementptr inbounds float* %faction, i64 %idxprom43
  %35 = load float* %arrayidx164, align 4, !tbaa !3
  %sub165 = fsub float %35, %mul152
  store float %sub165, float* %arrayidx164, align 4, !tbaa !3
  %arrayidx171 = getelementptr inbounds float* %faction, i64 %idxprom46
  %36 = load float* %arrayidx171, align 4, !tbaa !3
  %sub172 = fsub float %36, %mul153
  store float %sub172, float* %arrayidx171, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %37 = trunc i64 %indvars.iv.next to i32
  %cmp35 = icmp slt i32 %37, %6
  br i1 %cmp35, label %for.body36, label %for.end

for.end:                                          ; preds = %for.body36, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add150, %for.body36 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add144, %for.body36 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add154, %for.body36 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add155, %for.body36 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add156, %for.body36 ]
  %arrayidx177 = getelementptr inbounds float* %faction, i64 %idxprom16
  %38 = load float* %arrayidx177, align 4, !tbaa !3
  %add178 = fadd float %fix1.0.lcssa, %38
  store float %add178, float* %arrayidx177, align 4, !tbaa !3
  %arrayidx183 = getelementptr inbounds float* %faction, i64 %idxprom20
  %39 = load float* %arrayidx183, align 4, !tbaa !3
  %add184 = fadd float %fiy1.0.lcssa, %39
  store float %add184, float* %arrayidx183, align 4, !tbaa !3
  %arrayidx190 = getelementptr inbounds float* %faction, i64 %idxprom24
  %40 = load float* %arrayidx190, align 4, !tbaa !3
  %add191 = fadd float %fiz1.0.lcssa, %40
  store float %add191, float* %arrayidx190, align 4, !tbaa !3
  %arrayidx196 = getelementptr inbounds float* %fshift, i64 %idxprom1
  %41 = load float* %arrayidx196, align 4, !tbaa !3
  %add197 = fadd float %fix1.0.lcssa, %41
  store float %add197, float* %arrayidx196, align 4, !tbaa !3
  %arrayidx202 = getelementptr inbounds float* %fshift, i64 %idxprom3
  %42 = load float* %arrayidx202, align 4, !tbaa !3
  %add203 = fadd float %fiy1.0.lcssa, %42
  store float %add203, float* %arrayidx202, align 4, !tbaa !3
  %arrayidx209 = getelementptr inbounds float* %fshift, i64 %idxprom6
  %43 = load float* %arrayidx209, align 4, !tbaa !3
  %add210 = fadd float %fiz1.0.lcssa, %43
  store float %add210, float* %arrayidx209, align 4, !tbaa !3
  %arrayidx215 = getelementptr inbounds i32* %gid, i64 %indvars.iv398
  %44 = load i32* %arrayidx215, align 4, !tbaa !0
  %idxprom216 = sext i32 %44 to i64
  %arrayidx217 = getelementptr inbounds float* %Vc, i64 %idxprom216
  %45 = load float* %arrayidx217, align 4, !tbaa !3
  %add218 = fadd float %vctot.0.lcssa, %45
  store float %add218, float* %arrayidx217, align 4, !tbaa !3
  %arrayidx222 = getelementptr inbounds float* %Vnb, i64 %idxprom216
  %46 = load float* %arrayidx222, align 4, !tbaa !3
  %add223 = fadd float %vnbtot.0.lcssa, %46
  store float %add223, float* %arrayidx222, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next399 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end228, label %for.body

for.end228:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl3301(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab, float %lambda, float* nocapture %dvdlambda, float* nocapture %chargeB, i32* nocapture %typeB) #0 {
entry:
  %sub = fsub float 1.000000e+00, %lambda
  %cmp467 = icmp sgt i32 %nri, 0
  br i1 %cmp467, label %for.body.lr.ph, label %for.end266

for.body.lr.ph:                                   ; preds = %entry
  %mul33 = shl nsw i32 %ntype, 1
  br label %for.body

for.body:                                         ; preds = %for.end, %for.body.lr.ph
  %indvars.iv471 = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next472, %for.end ]
  %dvdl.0468 = phi float [ 0.000000e+00, %for.body.lr.ph ], [ %dvdl.1.lcssa, %for.end ]
  %arrayidx = getelementptr inbounds i32* %shift, i64 %indvars.iv471
  %0 = load i32* %arrayidx, align 4, !tbaa !0
  %mul = mul nsw i32 %0, 3
  %idxprom1 = sext i32 %mul to i64
  %arrayidx2 = getelementptr inbounds float* %shiftvec, i64 %idxprom1
  %1 = load float* %arrayidx2, align 4, !tbaa !3
  %add = add nsw i32 %mul, 1
  %idxprom3 = sext i32 %add to i64
  %arrayidx4 = getelementptr inbounds float* %shiftvec, i64 %idxprom3
  %2 = load float* %arrayidx4, align 4, !tbaa !3
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds float* %shiftvec, i64 %idxprom6
  %3 = load float* %arrayidx7, align 4, !tbaa !3
  %arrayidx9 = getelementptr inbounds i32* %iinr, i64 %indvars.iv471
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %arrayidx12 = getelementptr inbounds i32* %jindex, i64 %indvars.iv471
  %5 = load i32* %arrayidx12, align 4, !tbaa !0
  %indvars.iv.next472 = add i64 %indvars.iv471, 1
  %arrayidx15 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next472
  %6 = load i32* %arrayidx15, align 4, !tbaa !0
  %idxprom16 = sext i32 %mul10 to i64
  %arrayidx17 = getelementptr inbounds float* %pos, i64 %idxprom16
  %7 = load float* %arrayidx17, align 4, !tbaa !3
  %add18 = fadd float %1, %7
  %add19 = add nsw i32 %mul10, 1
  %idxprom20 = sext i32 %add19 to i64
  %arrayidx21 = getelementptr inbounds float* %pos, i64 %idxprom20
  %8 = load float* %arrayidx21, align 4, !tbaa !3
  %add22 = fadd float %2, %8
  %add23 = add nsw i32 %mul10, 2
  %idxprom24 = sext i32 %add23 to i64
  %arrayidx25 = getelementptr inbounds float* %pos, i64 %idxprom24
  %9 = load float* %arrayidx25, align 4, !tbaa !3
  %add26 = fadd float %3, %9
  %idxprom27 = sext i32 %4 to i64
  %arrayidx28 = getelementptr inbounds float* %charge, i64 %idxprom27
  %10 = load float* %arrayidx28, align 4, !tbaa !3
  %mul29 = fmul float %10, %facel
  %arrayidx31 = getelementptr inbounds float* %chargeB, i64 %idxprom27
  %11 = load float* %arrayidx31, align 4, !tbaa !3
  %mul32 = fmul float %11, %facel
  %arrayidx35 = getelementptr inbounds i32* %type, i64 %idxprom27
  %12 = load i32* %arrayidx35, align 4, !tbaa !0
  %mul36 = mul nsw i32 %12, %mul33
  %arrayidx39 = getelementptr inbounds i32* %typeB, i64 %idxprom27
  %13 = load i32* %arrayidx39, align 4, !tbaa !0
  %mul40 = mul nsw i32 %13, %mul33
  %cmp42454 = icmp slt i32 %5, %6
  br i1 %cmp42454, label %for.body43.lr.ph, label %for.end

for.body43.lr.ph:                                 ; preds = %for.body
  %14 = sext i32 %5 to i64
  br label %for.body43

for.body43:                                       ; preds = %for.body43.lr.ph, %for.body43
  %indvars.iv = phi i64 [ %14, %for.body43.lr.ph ], [ %indvars.iv.next, %for.body43 ]
  %vctot.0460 = phi float [ 0.000000e+00, %for.body43.lr.ph ], [ %add188, %for.body43 ]
  %dvdl.1459 = phi float [ %dvdl.0468, %for.body43.lr.ph ], [ %add182, %for.body43 ]
  %vnbtot.0458 = phi float [ 0.000000e+00, %for.body43.lr.ph ], [ %add179, %for.body43 ]
  %fix1.0457 = phi float [ 0.000000e+00, %for.body43.lr.ph ], [ %add192, %for.body43 ]
  %fiy1.0456 = phi float [ 0.000000e+00, %for.body43.lr.ph ], [ %add193, %for.body43 ]
  %fiz1.0455 = phi float [ 0.000000e+00, %for.body43.lr.ph ], [ %add194, %for.body43 ]
  %arrayidx45 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %15 = load i32* %arrayidx45, align 4, !tbaa !0
  %mul46 = mul nsw i32 %15, 3
  %idxprom47 = sext i32 %mul46 to i64
  %arrayidx48 = getelementptr inbounds float* %pos, i64 %idxprom47
  %16 = load float* %arrayidx48, align 4, !tbaa !3
  %add49 = add nsw i32 %mul46, 1
  %idxprom50 = sext i32 %add49 to i64
  %arrayidx51 = getelementptr inbounds float* %pos, i64 %idxprom50
  %17 = load float* %arrayidx51, align 4, !tbaa !3
  %add52 = add nsw i32 %mul46, 2
  %idxprom53 = sext i32 %add52 to i64
  %arrayidx54 = getelementptr inbounds float* %pos, i64 %idxprom53
  %18 = load float* %arrayidx54, align 4, !tbaa !3
  %sub55 = fsub float %add18, %16
  %sub56 = fsub float %add22, %17
  %sub57 = fsub float %add26, %18
  %mul58 = fmul float %sub55, %sub55
  %mul59 = fmul float %sub56, %sub56
  %add60 = fadd float %mul58, %mul59
  %mul61 = fmul float %sub57, %sub57
  %add62 = fadd float %add60, %mul61
  %conv = fpext float %add62 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv63 = fptrunc double %div to float
  %mul64 = fmul float %add62, %conv63
  %mul65 = fmul float %mul64, %tabscale
  %conv66 = fptosi float %mul65 to i32
  %conv67 = sitofp i32 %conv66 to float
  %sub68 = fsub float %mul65, %conv67
  %mul69 = fmul float %sub68, %sub68
  %mul70 = mul nsw i32 %conv66, 12
  %idxprom71 = sext i32 %15 to i64
  %arrayidx72 = getelementptr inbounds float* %charge, i64 %idxprom71
  %19 = load float* %arrayidx72, align 4, !tbaa !3
  %mul73 = fmul float %mul29, %19
  %arrayidx75 = getelementptr inbounds float* %chargeB, i64 %idxprom71
  %20 = load float* %arrayidx75, align 4, !tbaa !3
  %mul76 = fmul float %mul32, %20
  %mul77 = fmul float %sub, %mul73
  %mul78 = fmul float %mul76, %lambda
  %add79 = fadd float %mul77, %mul78
  %idxprom80 = sext i32 %mul70 to i64
  %arrayidx81 = getelementptr inbounds float* %VFtab, i64 %idxprom80
  %21 = load float* %arrayidx81, align 4, !tbaa !3
  %add82449 = or i32 %mul70, 1
  %idxprom83 = sext i32 %add82449 to i64
  %arrayidx84 = getelementptr inbounds float* %VFtab, i64 %idxprom83
  %22 = load float* %arrayidx84, align 4, !tbaa !3
  %add85450 = or i32 %mul70, 2
  %idxprom86 = sext i32 %add85450 to i64
  %arrayidx87 = getelementptr inbounds float* %VFtab, i64 %idxprom86
  %23 = load float* %arrayidx87, align 4, !tbaa !3
  %mul88 = fmul float %23, %sub68
  %add89451 = or i32 %mul70, 3
  %idxprom90 = sext i32 %add89451 to i64
  %arrayidx91 = getelementptr inbounds float* %VFtab, i64 %idxprom90
  %24 = load float* %arrayidx91, align 4, !tbaa !3
  %mul92 = fmul float %24, %mul69
  %add93 = fadd float %22, %mul88
  %add94 = fadd float %add93, %mul92
  %mul95 = fmul float %sub68, %add94
  %add96 = fadd float %21, %mul95
  %add97 = fadd float %mul88, %add94
  %mul98 = fmul float %mul92, 2.000000e+00
  %add99 = fadd float %mul98, %add97
  %mul100 = fmul float %add79, %add96
  %mul101 = fmul float %add79, %add99
  %sub102 = fsub float %mul76, %mul73
  %mul103 = fmul float %sub102, %add96
  %add104 = fadd float %dvdl.1459, %mul103
  %arrayidx106 = getelementptr inbounds i32* %type, i64 %idxprom71
  %25 = load i32* %arrayidx106, align 4, !tbaa !0
  %mul107 = shl nsw i32 %25, 1
  %add108 = add nsw i32 %mul107, %mul36
  %arrayidx110 = getelementptr inbounds i32* %typeB, i64 %idxprom71
  %26 = load i32* %arrayidx110, align 4, !tbaa !0
  %mul111 = shl nsw i32 %26, 1
  %add112 = add nsw i32 %mul111, %mul40
  %idxprom113 = sext i32 %add108 to i64
  %arrayidx114 = getelementptr inbounds float* %nbfp, i64 %idxprom113
  %27 = load float* %arrayidx114, align 4, !tbaa !3
  %idxprom115 = sext i32 %add112 to i64
  %arrayidx116 = getelementptr inbounds float* %nbfp, i64 %idxprom115
  %28 = load float* %arrayidx116, align 4, !tbaa !3
  %mul117 = fmul float %sub, %27
  %mul118 = fmul float %28, %lambda
  %add119 = fadd float %mul117, %mul118
  %add120452 = or i32 %add108, 1
  %idxprom121 = sext i32 %add120452 to i64
  %arrayidx122 = getelementptr inbounds float* %nbfp, i64 %idxprom121
  %29 = load float* %arrayidx122, align 4, !tbaa !3
  %add123453 = or i32 %add112, 1
  %idxprom124 = sext i32 %add123453 to i64
  %arrayidx125 = getelementptr inbounds float* %nbfp, i64 %idxprom124
  %30 = load float* %arrayidx125, align 4, !tbaa !3
  %mul126 = fmul float %sub, %29
  %mul127 = fmul float %30, %lambda
  %add128 = fadd float %mul126, %mul127
  %add129 = add nsw i32 %mul70, 4
  %idxprom130 = sext i32 %add129 to i64
  %arrayidx131 = getelementptr inbounds float* %VFtab, i64 %idxprom130
  %31 = load float* %arrayidx131, align 4, !tbaa !3
  %add132 = add nsw i32 %mul70, 5
  %idxprom133 = sext i32 %add132 to i64
  %arrayidx134 = getelementptr inbounds float* %VFtab, i64 %idxprom133
  %32 = load float* %arrayidx134, align 4, !tbaa !3
  %add135 = add nsw i32 %mul70, 6
  %idxprom136 = sext i32 %add135 to i64
  %arrayidx137 = getelementptr inbounds float* %VFtab, i64 %idxprom136
  %33 = load float* %arrayidx137, align 4, !tbaa !3
  %mul138 = fmul float %sub68, %33
  %add139 = add nsw i32 %mul70, 7
  %idxprom140 = sext i32 %add139 to i64
  %arrayidx141 = getelementptr inbounds float* %VFtab, i64 %idxprom140
  %34 = load float* %arrayidx141, align 4, !tbaa !3
  %mul142 = fmul float %mul69, %34
  %add143 = fadd float %32, %mul138
  %add144 = fadd float %add143, %mul142
  %mul145 = fmul float %sub68, %add144
  %add146 = fadd float %31, %mul145
  %add147 = fadd float %mul138, %add144
  %mul148 = fmul float %mul142, 2.000000e+00
  %add149 = fadd float %mul148, %add147
  %mul150 = fmul float %add119, %add146
  %mul151 = fmul float %add119, %add149
  %sub152 = fsub float %28, %27
  %mul153 = fmul float %sub152, %add146
  %add154 = fadd float %add104, %mul153
  %add155 = add nsw i32 %mul70, 8
  %idxprom156 = sext i32 %add155 to i64
  %arrayidx157 = getelementptr inbounds float* %VFtab, i64 %idxprom156
  %35 = load float* %arrayidx157, align 4, !tbaa !3
  %add158 = add nsw i32 %mul70, 9
  %idxprom159 = sext i32 %add158 to i64
  %arrayidx160 = getelementptr inbounds float* %VFtab, i64 %idxprom159
  %36 = load float* %arrayidx160, align 4, !tbaa !3
  %add161 = add nsw i32 %mul70, 10
  %idxprom162 = sext i32 %add161 to i64
  %arrayidx163 = getelementptr inbounds float* %VFtab, i64 %idxprom162
  %37 = load float* %arrayidx163, align 4, !tbaa !3
  %mul164 = fmul float %sub68, %37
  %add165 = add nsw i32 %mul70, 11
  %idxprom166 = sext i32 %add165 to i64
  %arrayidx167 = getelementptr inbounds float* %VFtab, i64 %idxprom166
  %38 = load float* %arrayidx167, align 4, !tbaa !3
  %mul168 = fmul float %mul69, %38
  %add169 = fadd float %36, %mul164
  %add170 = fadd float %add169, %mul168
  %mul171 = fmul float %sub68, %add170
  %add172 = fadd float %35, %mul171
  %add173 = fadd float %mul164, %add170
  %mul174 = fmul float %mul168, 2.000000e+00
  %add175 = fadd float %mul174, %add173
  %mul176 = fmul float %add128, %add172
  %mul177 = fmul float %add128, %add175
  %add178 = fadd float %vnbtot.0458, %mul150
  %add179 = fadd float %add178, %mul176
  %sub180 = fsub float %30, %29
  %mul181 = fmul float %sub180, %add172
  %add182 = fadd float %add154, %mul181
  %add183 = fadd float %mul101, %mul151
  %add184 = fadd float %add183, %mul177
  %mul185 = fmul float %add184, %tabscale
  %39 = fmul float %conv63, %mul185
  %mul187 = fsub float -0.000000e+00, %39
  %add188 = fadd float %vctot.0460, %mul100
  %mul189 = fmul float %sub55, %mul187
  %mul190 = fmul float %sub56, %mul187
  %mul191 = fmul float %sub57, %mul187
  %add192 = fadd float %fix1.0457, %mul189
  %add193 = fadd float %fiy1.0456, %mul190
  %add194 = fadd float %fiz1.0455, %mul191
  %arrayidx196 = getelementptr inbounds float* %faction, i64 %idxprom47
  %40 = load float* %arrayidx196, align 4, !tbaa !3
  %sub197 = fsub float %40, %mul189
  store float %sub197, float* %arrayidx196, align 4, !tbaa !3
  %arrayidx202 = getelementptr inbounds float* %faction, i64 %idxprom50
  %41 = load float* %arrayidx202, align 4, !tbaa !3
  %sub203 = fsub float %41, %mul190
  store float %sub203, float* %arrayidx202, align 4, !tbaa !3
  %arrayidx209 = getelementptr inbounds float* %faction, i64 %idxprom53
  %42 = load float* %arrayidx209, align 4, !tbaa !3
  %sub210 = fsub float %42, %mul191
  store float %sub210, float* %arrayidx209, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %43 = trunc i64 %indvars.iv.next to i32
  %cmp42 = icmp slt i32 %43, %6
  br i1 %cmp42, label %for.body43, label %for.end

for.end:                                          ; preds = %for.body43, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add188, %for.body43 ]
  %dvdl.1.lcssa = phi float [ %dvdl.0468, %for.body ], [ %add182, %for.body43 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add179, %for.body43 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add192, %for.body43 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add193, %for.body43 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add194, %for.body43 ]
  %arrayidx215 = getelementptr inbounds float* %faction, i64 %idxprom16
  %44 = load float* %arrayidx215, align 4, !tbaa !3
  %add216 = fadd float %fix1.0.lcssa, %44
  store float %add216, float* %arrayidx215, align 4, !tbaa !3
  %arrayidx221 = getelementptr inbounds float* %faction, i64 %idxprom20
  %45 = load float* %arrayidx221, align 4, !tbaa !3
  %add222 = fadd float %fiy1.0.lcssa, %45
  store float %add222, float* %arrayidx221, align 4, !tbaa !3
  %arrayidx228 = getelementptr inbounds float* %faction, i64 %idxprom24
  %46 = load float* %arrayidx228, align 4, !tbaa !3
  %add229 = fadd float %fiz1.0.lcssa, %46
  store float %add229, float* %arrayidx228, align 4, !tbaa !3
  %arrayidx234 = getelementptr inbounds float* %fshift, i64 %idxprom1
  %47 = load float* %arrayidx234, align 4, !tbaa !3
  %add235 = fadd float %fix1.0.lcssa, %47
  store float %add235, float* %arrayidx234, align 4, !tbaa !3
  %arrayidx240 = getelementptr inbounds float* %fshift, i64 %idxprom3
  %48 = load float* %arrayidx240, align 4, !tbaa !3
  %add241 = fadd float %fiy1.0.lcssa, %48
  store float %add241, float* %arrayidx240, align 4, !tbaa !3
  %arrayidx247 = getelementptr inbounds float* %fshift, i64 %idxprom6
  %49 = load float* %arrayidx247, align 4, !tbaa !3
  %add248 = fadd float %fiz1.0.lcssa, %49
  store float %add248, float* %arrayidx247, align 4, !tbaa !3
  %arrayidx253 = getelementptr inbounds i32* %gid, i64 %indvars.iv471
  %50 = load i32* %arrayidx253, align 4, !tbaa !0
  %idxprom254 = sext i32 %50 to i64
  %arrayidx255 = getelementptr inbounds float* %Vc, i64 %idxprom254
  %51 = load float* %arrayidx255, align 4, !tbaa !3
  %add256 = fadd float %vctot.0.lcssa, %51
  store float %add256, float* %arrayidx255, align 4, !tbaa !3
  %arrayidx260 = getelementptr inbounds float* %Vnb, i64 %idxprom254
  %52 = load float* %arrayidx260, align 4, !tbaa !3
  %add261 = fadd float %vnbtot.0.lcssa, %52
  store float %add261, float* %arrayidx260, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next472 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end266, label %for.body

for.end266:                                       ; preds = %for.end, %entry
  %dvdl.0.lcssa = phi float [ 0.000000e+00, %entry ], [ %dvdl.1.lcssa, %for.end ]
  %53 = load float* %dvdlambda, align 4, !tbaa !3
  %add267 = fadd float %dvdl.0.lcssa, %53
  store float %add267, float* %dvdlambda, align 4, !tbaa !3
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl3302(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* %VFtab, float %lambda, float* nocapture %dvdlambda, float* nocapture %chargeB, i32* nocapture %typeB, float %Alpha, float %defsigma6) #0 {
entry:
  %sub = fsub float 1.000000e+00, %lambda
  %mul = fmul float %lambda, %lambda
  %mul1 = fmul float %sub, %sub
  %cmp748 = icmp sgt i32 %nri, 0
  br i1 %cmp748, label %for.body.lr.ph, label %for.end421

for.body.lr.ph:                                   ; preds = %entry
  %mul35 = shl nsw i32 %ntype, 1
  %mul333 = fmul float %Alpha, 0x3FD5555560000000
  %mul334 = fmul float %mul333, %lambda
  %mul335 = fmul float %sub, %mul334
  br label %for.body

for.body:                                         ; preds = %for.end, %for.body.lr.ph
  %indvars.iv752 = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next753, %for.end ]
  %dvdl.0749 = phi float [ 0.000000e+00, %for.body.lr.ph ], [ %dvdl.1.lcssa, %for.end ]
  %arrayidx = getelementptr inbounds i32* %shift, i64 %indvars.iv752
  %0 = load i32* %arrayidx, align 4, !tbaa !0
  %mul2 = mul nsw i32 %0, 3
  %idxprom3 = sext i32 %mul2 to i64
  %arrayidx4 = getelementptr inbounds float* %shiftvec, i64 %idxprom3
  %1 = load float* %arrayidx4, align 4, !tbaa !3
  %add = add nsw i32 %mul2, 1
  %idxprom5 = sext i32 %add to i64
  %arrayidx6 = getelementptr inbounds float* %shiftvec, i64 %idxprom5
  %2 = load float* %arrayidx6, align 4, !tbaa !3
  %add7 = add nsw i32 %mul2, 2
  %idxprom8 = sext i32 %add7 to i64
  %arrayidx9 = getelementptr inbounds float* %shiftvec, i64 %idxprom8
  %3 = load float* %arrayidx9, align 4, !tbaa !3
  %arrayidx11 = getelementptr inbounds i32* %iinr, i64 %indvars.iv752
  %4 = load i32* %arrayidx11, align 4, !tbaa !0
  %mul12 = mul nsw i32 %4, 3
  %arrayidx14 = getelementptr inbounds i32* %jindex, i64 %indvars.iv752
  %5 = load i32* %arrayidx14, align 4, !tbaa !0
  %indvars.iv.next753 = add i64 %indvars.iv752, 1
  %arrayidx17 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next753
  %6 = load i32* %arrayidx17, align 4, !tbaa !0
  %idxprom18 = sext i32 %mul12 to i64
  %arrayidx19 = getelementptr inbounds float* %pos, i64 %idxprom18
  %7 = load float* %arrayidx19, align 4, !tbaa !3
  %add20 = fadd float %1, %7
  %add21 = add nsw i32 %mul12, 1
  %idxprom22 = sext i32 %add21 to i64
  %arrayidx23 = getelementptr inbounds float* %pos, i64 %idxprom22
  %8 = load float* %arrayidx23, align 4, !tbaa !3
  %add24 = fadd float %2, %8
  %add25 = add nsw i32 %mul12, 2
  %idxprom26 = sext i32 %add25 to i64
  %arrayidx27 = getelementptr inbounds float* %pos, i64 %idxprom26
  %9 = load float* %arrayidx27, align 4, !tbaa !3
  %add28 = fadd float %3, %9
  %idxprom29 = sext i32 %4 to i64
  %arrayidx30 = getelementptr inbounds float* %charge, i64 %idxprom29
  %10 = load float* %arrayidx30, align 4, !tbaa !3
  %mul31 = fmul float %10, %facel
  %arrayidx33 = getelementptr inbounds float* %chargeB, i64 %idxprom29
  %11 = load float* %arrayidx33, align 4, !tbaa !3
  %mul34 = fmul float %11, %facel
  %arrayidx37 = getelementptr inbounds i32* %type, i64 %idxprom29
  %12 = load i32* %arrayidx37, align 4, !tbaa !0
  %mul38 = mul nsw i32 %12, %mul35
  %arrayidx41 = getelementptr inbounds i32* %typeB, i64 %idxprom29
  %13 = load i32* %arrayidx41, align 4, !tbaa !0
  %mul42 = mul nsw i32 %13, %mul35
  %cmp44735 = icmp slt i32 %5, %6
  br i1 %cmp44735, label %for.body45.lr.ph, label %for.end

for.body45.lr.ph:                                 ; preds = %for.body
  %14 = sext i32 %5 to i64
  br label %for.body45

for.body45:                                       ; preds = %for.body45.lr.ph, %if.end305
  %indvars.iv = phi i64 [ %14, %for.body45.lr.ph ], [ %indvars.iv.next, %if.end305 ]
  %vctot.0741 = phi float [ 0.000000e+00, %for.body45.lr.ph ], [ %add343, %if.end305 ]
  %fiz1.0740 = phi float [ 0.000000e+00, %for.body45.lr.ph ], [ %add349, %if.end305 ]
  %fiy1.0739 = phi float [ 0.000000e+00, %for.body45.lr.ph ], [ %add348, %if.end305 ]
  %fix1.0738 = phi float [ 0.000000e+00, %for.body45.lr.ph ], [ %add347, %if.end305 ]
  %dvdl.1737 = phi float [ %dvdl.0749, %for.body45.lr.ph ], [ %add342, %if.end305 ]
  %vnbtot.0736 = phi float [ 0.000000e+00, %for.body45.lr.ph ], [ %add314, %if.end305 ]
  %arrayidx47 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %15 = load i32* %arrayidx47, align 4, !tbaa !0
  %mul48 = mul nsw i32 %15, 3
  %idxprom49 = sext i32 %mul48 to i64
  %arrayidx50 = getelementptr inbounds float* %pos, i64 %idxprom49
  %16 = load float* %arrayidx50, align 4, !tbaa !3
  %add51 = add nsw i32 %mul48, 1
  %idxprom52 = sext i32 %add51 to i64
  %arrayidx53 = getelementptr inbounds float* %pos, i64 %idxprom52
  %17 = load float* %arrayidx53, align 4, !tbaa !3
  %add54 = add nsw i32 %mul48, 2
  %idxprom55 = sext i32 %add54 to i64
  %arrayidx56 = getelementptr inbounds float* %pos, i64 %idxprom55
  %18 = load float* %arrayidx56, align 4, !tbaa !3
  %sub57 = fsub float %add20, %16
  %sub58 = fsub float %add24, %17
  %sub59 = fsub float %add28, %18
  %mul60 = fmul float %sub57, %sub57
  %mul61 = fmul float %sub58, %sub58
  %add62 = fadd float %mul60, %mul61
  %mul63 = fmul float %sub59, %sub59
  %add64 = fadd float %add62, %mul63
  %conv = fpext float %add64 to double
  %call = tail call double @sqrt(double %conv) #2
  %idxprom67 = sext i32 %15 to i64
  %arrayidx68 = getelementptr inbounds i32* %type, i64 %idxprom67
  %19 = load i32* %arrayidx68, align 4, !tbaa !0
  %mul69 = shl nsw i32 %19, 1
  %add70 = add nsw i32 %mul69, %mul38
  %arrayidx72 = getelementptr inbounds i32* %typeB, i64 %idxprom67
  %20 = load i32* %arrayidx72, align 4, !tbaa !0
  %mul73 = shl nsw i32 %20, 1
  %add74 = add nsw i32 %mul73, %mul42
  %idxprom75 = sext i32 %add70 to i64
  %arrayidx76 = getelementptr inbounds float* %nbfp, i64 %idxprom75
  %21 = load float* %arrayidx76, align 4, !tbaa !3
  %idxprom77 = sext i32 %add74 to i64
  %arrayidx78 = getelementptr inbounds float* %nbfp, i64 %idxprom77
  %22 = load float* %arrayidx78, align 4, !tbaa !3
  %add79723 = or i32 %add70, 1
  %idxprom80 = sext i32 %add79723 to i64
  %arrayidx81 = getelementptr inbounds float* %nbfp, i64 %idxprom80
  %23 = load float* %arrayidx81, align 4, !tbaa !3
  %add82724 = or i32 %add74, 1
  %idxprom83 = sext i32 %add82724 to i64
  %arrayidx84 = getelementptr inbounds float* %nbfp, i64 %idxprom83
  %24 = load float* %arrayidx84, align 4, !tbaa !3
  %cmp85 = fcmp ogt float %21, 0.000000e+00
  %cmp87 = fcmp ogt float %23, 0.000000e+00
  %or.cond = and i1 %cmp85, %cmp87
  br i1 %or.cond, label %if.then, label %if.end

if.then:                                          ; preds = %for.body45
  %div89 = fdiv float %23, %21
  br label %if.end

if.end:                                           ; preds = %for.body45, %if.then
  %sigma6a.0 = phi float [ %div89, %if.then ], [ %defsigma6, %for.body45 ]
  %cmp90 = fcmp ogt float %22, 0.000000e+00
  %cmp93 = fcmp ogt float %24, 0.000000e+00
  %or.cond731 = and i1 %cmp90, %cmp93
  br i1 %or.cond731, label %if.then95, label %if.end98

if.then95:                                        ; preds = %if.end
  %div96 = fdiv float %24, %22
  br label %if.end98

if.end98:                                         ; preds = %if.end, %if.then95
  %sigma6b.0 = phi float [ %div96, %if.then95 ], [ %defsigma6, %if.end ]
  %mul99 = fmul float %add64, %add64
  %mul100 = fmul float %add64, %mul99
  %arrayidx102 = getelementptr inbounds float* %charge, i64 %idxprom67
  %25 = load float* %arrayidx102, align 4, !tbaa !3
  %mul103 = fmul float %mul31, %25
  %cmp104 = fcmp une float %mul103, 0.000000e+00
  %brmerge = or i1 %cmp104, %cmp85
  %or.cond732 = or i1 %brmerge, %cmp87
  br i1 %or.cond732, label %if.then111, label %if.end202

if.then111:                                       ; preds = %if.end98
  %mul112 = fmul float %sigma6a.0, %Alpha
  %mul113 = fmul float %mul, %mul112
  %add114 = fadd float %mul100, %mul113
  %conv115 = fpext float %add114 to double
  %call116 = tail call double @pow(double %conv115, double 0x3FC5555560000000) #2
  %conv117 = fptrunc double %call116 to float
  %conv120 = fdiv float 1.000000e+00, %conv117
  %mul121 = fmul float %conv120, %conv120
  %mul122 = fmul float %mul121, %mul121
  %mul123 = fmul float %conv120, %mul122
  %mul124 = fmul float %conv117, %tabscale
  %conv125 = fptosi float %mul124 to i32
  %conv126 = sitofp i32 %conv125 to float
  %sub127 = fsub float %mul124, %conv126
  %mul128 = fmul float %sub127, %sub127
  %mul129 = mul nsw i32 %conv125, 12
  %idxprom130 = sext i32 %mul129 to i64
  %arrayidx131 = getelementptr inbounds float* %VFtab, i64 %idxprom130
  %26 = load float* %arrayidx131, align 4, !tbaa !3
  %add132728 = or i32 %mul129, 1
  %idxprom133 = sext i32 %add132728 to i64
  %arrayidx134 = getelementptr inbounds float* %VFtab, i64 %idxprom133
  %27 = load float* %arrayidx134, align 4, !tbaa !3
  %add135729 = or i32 %mul129, 2
  %idxprom136 = sext i32 %add135729 to i64
  %arrayidx137 = getelementptr inbounds float* %VFtab, i64 %idxprom136
  %28 = load float* %arrayidx137, align 4, !tbaa !3
  %mul138 = fmul float %28, %sub127
  %add139730 = or i32 %mul129, 3
  %idxprom140 = sext i32 %add139730 to i64
  %arrayidx141 = getelementptr inbounds float* %VFtab, i64 %idxprom140
  %29 = load float* %arrayidx141, align 4, !tbaa !3
  %mul142 = fmul float %29, %mul128
  %add143 = fadd float %27, %mul138
  %add144 = fadd float %add143, %mul142
  %mul145 = fmul float %sub127, %add144
  %add146 = fadd float %26, %mul145
  %add147 = fadd float %mul138, %add144
  %mul148 = fmul float %mul142, 2.000000e+00
  %add149 = fadd float %mul148, %add147
  %mul150 = fmul float %mul103, %add146
  %mul151 = fmul float %mul103, %tabscale
  %mul152 = fmul float %mul151, %add149
  %add153 = add nsw i32 %mul129, 4
  %idxprom154 = sext i32 %add153 to i64
  %arrayidx155 = getelementptr inbounds float* %VFtab, i64 %idxprom154
  %30 = load float* %arrayidx155, align 4, !tbaa !3
  %add156 = add nsw i32 %mul129, 5
  %idxprom157 = sext i32 %add156 to i64
  %arrayidx158 = getelementptr inbounds float* %VFtab, i64 %idxprom157
  %31 = load float* %arrayidx158, align 4, !tbaa !3
  %add159 = add nsw i32 %mul129, 6
  %idxprom160 = sext i32 %add159 to i64
  %arrayidx161 = getelementptr inbounds float* %VFtab, i64 %idxprom160
  %32 = load float* %arrayidx161, align 4, !tbaa !3
  %mul162 = fmul float %sub127, %32
  %add163 = add nsw i32 %mul129, 7
  %idxprom164 = sext i32 %add163 to i64
  %arrayidx165 = getelementptr inbounds float* %VFtab, i64 %idxprom164
  %33 = load float* %arrayidx165, align 4, !tbaa !3
  %mul166 = fmul float %mul128, %33
  %add167 = fadd float %31, %mul162
  %add168 = fadd float %add167, %mul166
  %mul169 = fmul float %sub127, %add168
  %add170 = fadd float %30, %mul169
  %add171 = fadd float %mul162, %add168
  %mul172 = fmul float %mul166, 2.000000e+00
  %add173 = fadd float %mul172, %add171
  %mul174 = fmul float %21, %add170
  %mul175 = fmul float %21, %tabscale
  %mul176 = fmul float %mul175, %add173
  %add177 = add nsw i32 %mul129, 8
  %idxprom178 = sext i32 %add177 to i64
  %arrayidx179 = getelementptr inbounds float* %VFtab, i64 %idxprom178
  %34 = load float* %arrayidx179, align 4, !tbaa !3
  %add180 = add nsw i32 %mul129, 9
  %idxprom181 = sext i32 %add180 to i64
  %arrayidx182 = getelementptr inbounds float* %VFtab, i64 %idxprom181
  %35 = load float* %arrayidx182, align 4, !tbaa !3
  %add183 = add nsw i32 %mul129, 10
  %idxprom184 = sext i32 %add183 to i64
  %arrayidx185 = getelementptr inbounds float* %VFtab, i64 %idxprom184
  %36 = load float* %arrayidx185, align 4, !tbaa !3
  %mul186 = fmul float %sub127, %36
  %add187 = add nsw i32 %mul129, 11
  %idxprom188 = sext i32 %add187 to i64
  %arrayidx189 = getelementptr inbounds float* %VFtab, i64 %idxprom188
  %37 = load float* %arrayidx189, align 4, !tbaa !3
  %mul190 = fmul float %mul128, %37
  %add191 = fadd float %35, %mul186
  %add192 = fadd float %add191, %mul190
  %mul193 = fmul float %sub127, %add192
  %add194 = fadd float %34, %mul193
  %add195 = fadd float %mul186, %add192
  %mul196 = fmul float %mul190, 2.000000e+00
  %add197 = fadd float %mul196, %add195
  %mul198 = fmul float %23, %add194
  %mul199 = fmul float %23, %tabscale
  %mul200 = fmul float %mul199, %add197
  br label %if.end202

if.end202:                                        ; preds = %if.end98, %if.then111
  %FFRa.0 = phi float [ %mul200, %if.then111 ], [ 0.000000e+00, %if.end98 ]
  %VVRa.0 = phi float [ %mul198, %if.then111 ], [ 0.000000e+00, %if.end98 ]
  %FFDa.0 = phi float [ %mul176, %if.then111 ], [ 0.000000e+00, %if.end98 ]
  %VVDa.0 = phi float [ %mul174, %if.then111 ], [ 0.000000e+00, %if.end98 ]
  %FFCa.0 = phi float [ %mul152, %if.then111 ], [ 0.000000e+00, %if.end98 ]
  %VVCa.0 = phi float [ %mul150, %if.then111 ], [ 0.000000e+00, %if.end98 ]
  %rinv5a.0 = phi float [ %mul123, %if.then111 ], [ 0.000000e+00, %if.end98 ]
  %arrayidx204 = getelementptr inbounds float* %chargeB, i64 %idxprom67
  %38 = load float* %arrayidx204, align 4, !tbaa !3
  %mul205 = fmul float %mul34, %38
  %cmp206 = fcmp une float %mul205, 0.000000e+00
  %brmerge733 = or i1 %cmp206, %cmp90
  %or.cond734 = or i1 %brmerge733, %cmp93
  br i1 %or.cond734, label %if.then214, label %if.end305

if.then214:                                       ; preds = %if.end202
  %mul215 = fmul float %sigma6b.0, %Alpha
  %mul216 = fmul float %mul1, %mul215
  %add217 = fadd float %mul100, %mul216
  %conv218 = fpext float %add217 to double
  %call219 = tail call double @pow(double %conv218, double 0x3FC5555560000000) #2
  %conv220 = fptrunc double %call219 to float
  %conv223 = fdiv float 1.000000e+00, %conv220
  %mul224 = fmul float %conv223, %conv223
  %mul225 = fmul float %mul224, %mul224
  %mul226 = fmul float %conv223, %mul225
  %mul227 = fmul float %conv220, %tabscale
  %conv228 = fptosi float %mul227 to i32
  %conv229 = sitofp i32 %conv228 to float
  %sub230 = fsub float %mul227, %conv229
  %mul231 = fmul float %sub230, %sub230
  %mul232 = mul nsw i32 %conv228, 12
  %idxprom233 = sext i32 %mul232 to i64
  %arrayidx234 = getelementptr inbounds float* %VFtab, i64 %idxprom233
  %39 = load float* %arrayidx234, align 4, !tbaa !3
  %add235725 = or i32 %mul232, 1
  %idxprom236 = sext i32 %add235725 to i64
  %arrayidx237 = getelementptr inbounds float* %VFtab, i64 %idxprom236
  %40 = load float* %arrayidx237, align 4, !tbaa !3
  %add238726 = or i32 %mul232, 2
  %idxprom239 = sext i32 %add238726 to i64
  %arrayidx240 = getelementptr inbounds float* %VFtab, i64 %idxprom239
  %41 = load float* %arrayidx240, align 4, !tbaa !3
  %mul241 = fmul float %41, %sub230
  %add242727 = or i32 %mul232, 3
  %idxprom243 = sext i32 %add242727 to i64
  %arrayidx244 = getelementptr inbounds float* %VFtab, i64 %idxprom243
  %42 = load float* %arrayidx244, align 4, !tbaa !3
  %mul245 = fmul float %42, %mul231
  %add246 = fadd float %40, %mul241
  %add247 = fadd float %add246, %mul245
  %mul248 = fmul float %sub230, %add247
  %add249 = fadd float %39, %mul248
  %add250 = fadd float %mul241, %add247
  %mul251 = fmul float %mul245, 2.000000e+00
  %add252 = fadd float %mul251, %add250
  %mul253 = fmul float %mul205, %add249
  %mul254 = fmul float %mul205, %tabscale
  %mul255 = fmul float %mul254, %add252
  %add256 = add nsw i32 %mul232, 4
  %idxprom257 = sext i32 %add256 to i64
  %arrayidx258 = getelementptr inbounds float* %VFtab, i64 %idxprom257
  %43 = load float* %arrayidx258, align 4, !tbaa !3
  %add259 = add nsw i32 %mul232, 5
  %idxprom260 = sext i32 %add259 to i64
  %arrayidx261 = getelementptr inbounds float* %VFtab, i64 %idxprom260
  %44 = load float* %arrayidx261, align 4, !tbaa !3
  %add262 = add nsw i32 %mul232, 6
  %idxprom263 = sext i32 %add262 to i64
  %arrayidx264 = getelementptr inbounds float* %VFtab, i64 %idxprom263
  %45 = load float* %arrayidx264, align 4, !tbaa !3
  %mul265 = fmul float %sub230, %45
  %add266 = add nsw i32 %mul232, 7
  %idxprom267 = sext i32 %add266 to i64
  %arrayidx268 = getelementptr inbounds float* %VFtab, i64 %idxprom267
  %46 = load float* %arrayidx268, align 4, !tbaa !3
  %mul269 = fmul float %mul231, %46
  %add270 = fadd float %44, %mul265
  %add271 = fadd float %add270, %mul269
  %mul272 = fmul float %sub230, %add271
  %add273 = fadd float %43, %mul272
  %add274 = fadd float %mul265, %add271
  %mul275 = fmul float %mul269, 2.000000e+00
  %add276 = fadd float %mul275, %add274
  %mul277 = fmul float %22, %add273
  %mul278 = fmul float %22, %tabscale
  %mul279 = fmul float %mul278, %add276
  %add280 = add nsw i32 %mul232, 8
  %idxprom281 = sext i32 %add280 to i64
  %arrayidx282 = getelementptr inbounds float* %VFtab, i64 %idxprom281
  %47 = load float* %arrayidx282, align 4, !tbaa !3
  %add283 = add nsw i32 %mul232, 9
  %idxprom284 = sext i32 %add283 to i64
  %arrayidx285 = getelementptr inbounds float* %VFtab, i64 %idxprom284
  %48 = load float* %arrayidx285, align 4, !tbaa !3
  %add286 = add nsw i32 %mul232, 10
  %idxprom287 = sext i32 %add286 to i64
  %arrayidx288 = getelementptr inbounds float* %VFtab, i64 %idxprom287
  %49 = load float* %arrayidx288, align 4, !tbaa !3
  %mul289 = fmul float %sub230, %49
  %add290 = add nsw i32 %mul232, 11
  %idxprom291 = sext i32 %add290 to i64
  %arrayidx292 = getelementptr inbounds float* %VFtab, i64 %idxprom291
  %50 = load float* %arrayidx292, align 4, !tbaa !3
  %mul293 = fmul float %mul231, %50
  %add294 = fadd float %48, %mul289
  %add295 = fadd float %add294, %mul293
  %mul296 = fmul float %sub230, %add295
  %add297 = fadd float %47, %mul296
  %add298 = fadd float %mul289, %add295
  %mul299 = fmul float %mul293, 2.000000e+00
  %add300 = fadd float %mul299, %add298
  %mul301 = fmul float %24, %add297
  %mul302 = fmul float %24, %tabscale
  %mul303 = fmul float %mul302, %add300
  br label %if.end305

if.end305:                                        ; preds = %if.end202, %if.then214
  %FFRb.0 = phi float [ %mul303, %if.then214 ], [ 0.000000e+00, %if.end202 ]
  %VVRb.0 = phi float [ %mul301, %if.then214 ], [ 0.000000e+00, %if.end202 ]
  %FFDb.0 = phi float [ %mul279, %if.then214 ], [ 0.000000e+00, %if.end202 ]
  %VVDb.0 = phi float [ %mul277, %if.then214 ], [ 0.000000e+00, %if.end202 ]
  %FFCb.0 = phi float [ %mul255, %if.then214 ], [ 0.000000e+00, %if.end202 ]
  %VVCb.0 = phi float [ %mul253, %if.then214 ], [ 0.000000e+00, %if.end202 ]
  %rinv5b.0 = phi float [ %mul226, %if.then214 ], [ 0.000000e+00, %if.end202 ]
  %mul306 = fmul float %VVCb.0, %lambda
  %mul307 = fmul float %sub, %VVCa.0
  %add308 = fadd float %mul307, %mul306
  %add309 = fadd float %VVRb.0, %VVDb.0
  %mul310 = fmul float %add309, %lambda
  %add311 = fadd float %vnbtot.0736, %mul310
  %add312 = fadd float %VVRa.0, %VVDa.0
  %mul313 = fmul float %sub, %add312
  %add314 = fadd float %mul313, %add311
  %add315 = fadd float %FFDa.0, %FFCa.0
  %add316 = fadd float %FFRa.0, %add315
  %sub317 = fsub float -0.000000e+00, %add316
  %add318 = fadd float %FFDb.0, %FFCb.0
  %add319 = fadd float %FFRb.0, %add318
  %sub320 = fsub float -0.000000e+00, %add319
  %mul321 = fmul float %sub, %sub317
  %mul322 = fmul float %rinv5a.0, %mul321
  %mul323 = fmul float %lambda, %sub320
  %mul324 = fmul float %rinv5b.0, %mul323
  %add325 = fadd float %mul322, %mul324
  %mul326 = fmul float %mul99, %add325
  %add327 = fadd float %dvdl.1737, %VVCb.0
  %sub328 = fsub float %add327, %VVCa.0
  %add329 = fadd float %VVDb.0, %sub328
  %add330 = fadd float %VVRb.0, %add329
  %sub331 = fsub float %add330, %VVDa.0
  %sub332 = fsub float %sub331, %VVRa.0
  %mul336 = fmul float %sigma6b.0, %sub320
  %mul337 = fmul float %rinv5b.0, %mul336
  %mul338 = fmul float %sigma6a.0, %sub317
  %mul339 = fmul float %rinv5a.0, %mul338
  %sub340 = fsub float %mul337, %mul339
  %mul341 = fmul float %mul335, %sub340
  %add342 = fadd float %sub332, %mul341
  %add343 = fadd float %vctot.0741, %add308
  %mul344 = fmul float %sub57, %mul326
  %mul345 = fmul float %sub58, %mul326
  %mul346 = fmul float %sub59, %mul326
  %add347 = fadd float %fix1.0738, %mul344
  %add348 = fadd float %fiy1.0739, %mul345
  %add349 = fadd float %fiz1.0740, %mul346
  %arrayidx351 = getelementptr inbounds float* %faction, i64 %idxprom49
  %51 = load float* %arrayidx351, align 4, !tbaa !3
  %sub352 = fsub float %51, %mul344
  store float %sub352, float* %arrayidx351, align 4, !tbaa !3
  %arrayidx357 = getelementptr inbounds float* %faction, i64 %idxprom52
  %52 = load float* %arrayidx357, align 4, !tbaa !3
  %sub358 = fsub float %52, %mul345
  store float %sub358, float* %arrayidx357, align 4, !tbaa !3
  %arrayidx364 = getelementptr inbounds float* %faction, i64 %idxprom55
  %53 = load float* %arrayidx364, align 4, !tbaa !3
  %sub365 = fsub float %53, %mul346
  store float %sub365, float* %arrayidx364, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %54 = trunc i64 %indvars.iv.next to i32
  %cmp44 = icmp slt i32 %54, %6
  br i1 %cmp44, label %for.body45, label %for.end

for.end:                                          ; preds = %if.end305, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add343, %if.end305 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add349, %if.end305 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add348, %if.end305 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add347, %if.end305 ]
  %dvdl.1.lcssa = phi float [ %dvdl.0749, %for.body ], [ %add342, %if.end305 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add314, %if.end305 ]
  %arrayidx370 = getelementptr inbounds float* %faction, i64 %idxprom18
  %55 = load float* %arrayidx370, align 4, !tbaa !3
  %add371 = fadd float %fix1.0.lcssa, %55
  store float %add371, float* %arrayidx370, align 4, !tbaa !3
  %arrayidx376 = getelementptr inbounds float* %faction, i64 %idxprom22
  %56 = load float* %arrayidx376, align 4, !tbaa !3
  %add377 = fadd float %fiy1.0.lcssa, %56
  store float %add377, float* %arrayidx376, align 4, !tbaa !3
  %arrayidx383 = getelementptr inbounds float* %faction, i64 %idxprom26
  %57 = load float* %arrayidx383, align 4, !tbaa !3
  %add384 = fadd float %fiz1.0.lcssa, %57
  store float %add384, float* %arrayidx383, align 4, !tbaa !3
  %arrayidx389 = getelementptr inbounds float* %fshift, i64 %idxprom3
  %58 = load float* %arrayidx389, align 4, !tbaa !3
  %add390 = fadd float %fix1.0.lcssa, %58
  store float %add390, float* %arrayidx389, align 4, !tbaa !3
  %arrayidx395 = getelementptr inbounds float* %fshift, i64 %idxprom5
  %59 = load float* %arrayidx395, align 4, !tbaa !3
  %add396 = fadd float %fiy1.0.lcssa, %59
  store float %add396, float* %arrayidx395, align 4, !tbaa !3
  %arrayidx402 = getelementptr inbounds float* %fshift, i64 %idxprom8
  %60 = load float* %arrayidx402, align 4, !tbaa !3
  %add403 = fadd float %fiz1.0.lcssa, %60
  store float %add403, float* %arrayidx402, align 4, !tbaa !3
  %arrayidx408 = getelementptr inbounds i32* %gid, i64 %indvars.iv752
  %61 = load i32* %arrayidx408, align 4, !tbaa !0
  %idxprom409 = sext i32 %61 to i64
  %arrayidx410 = getelementptr inbounds float* %Vc, i64 %idxprom409
  %62 = load float* %arrayidx410, align 4, !tbaa !3
  %add411 = fadd float %vctot.0.lcssa, %62
  store float %add411, float* %arrayidx410, align 4, !tbaa !3
  %arrayidx415 = getelementptr inbounds float* %Vnb, i64 %idxprom409
  %63 = load float* %arrayidx415, align 4, !tbaa !3
  %add416 = fadd float %vnbtot.0.lcssa, %63
  store float %add416, float* %arrayidx415, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next753 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end421, label %for.body

for.end421:                                       ; preds = %for.end, %entry
  %dvdl.0.lcssa = phi float [ 0.000000e+00, %entry ], [ %dvdl.1.lcssa, %for.end ]
  %64 = load float* %dvdlambda, align 4, !tbaa !3
  %add422 = fadd float %dvdl.0.lcssa, %64
  store float %add422, float* %dvdlambda, align 4, !tbaa !3
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl3310(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* %VFtab, i32* nocapture %nsatoms) #0 {
entry:
  %cmp1124 = icmp sgt i32 %nri, 0
  br i1 %cmp1124, label %for.body.lr.ph, label %for.end583

for.body.lr.ph:                                   ; preds = %entry
  %mul400 = shl i32 %ntype, 1
  br label %for.body

for.body:                                         ; preds = %for.end568, %for.body.lr.ph
  %indvars.iv1150 = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next1151, %for.end568 ]
  %0 = trunc i64 %indvars.iv1150 to i32
  %mul = mul nsw i32 %0, 3
  %idxprom = sext i32 %mul to i64
  %arrayidx = getelementptr inbounds i32* %nsatoms, i64 %idxprom
  %1 = load i32* %arrayidx, align 4, !tbaa !0
  %add = add nsw i32 %mul, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds i32* %nsatoms, i64 %idxprom2
  %2 = load i32* %arrayidx3, align 4, !tbaa !0
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds i32* %nsatoms, i64 %idxprom6
  %3 = load i32* %arrayidx7, align 4, !tbaa !0
  %arrayidx9 = getelementptr inbounds i32* %shift, i64 %indvars.iv1150
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %idxprom11 = sext i32 %mul10 to i64
  %arrayidx12 = getelementptr inbounds float* %shiftvec, i64 %idxprom11
  %5 = load float* %arrayidx12, align 4, !tbaa !3
  %add13 = add nsw i32 %mul10, 1
  %idxprom14 = sext i32 %add13 to i64
  %arrayidx15 = getelementptr inbounds float* %shiftvec, i64 %idxprom14
  %6 = load float* %arrayidx15, align 4, !tbaa !3
  %add16 = add nsw i32 %mul10, 2
  %idxprom17 = sext i32 %add16 to i64
  %arrayidx18 = getelementptr inbounds float* %shiftvec, i64 %idxprom17
  %7 = load float* %arrayidx18, align 4, !tbaa !3
  %arrayidx20 = getelementptr inbounds i32* %iinr, i64 %indvars.iv1150
  %8 = load i32* %arrayidx20, align 4, !tbaa !0
  %mul21 = mul i32 %8, 3
  %arrayidx23 = getelementptr inbounds i32* %jindex, i64 %indvars.iv1150
  %9 = load i32* %arrayidx23, align 4, !tbaa !0
  %indvars.iv.next1151 = add i64 %indvars.iv1150, 1
  %arrayidx26 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next1151
  %10 = load i32* %arrayidx26, align 4, !tbaa !0
  %cmp281080 = icmp sgt i32 %2, 0
  br i1 %cmp281080, label %for.body29.lr.ph, label %for.cond233.loopexit

for.body29.lr.ph:                                 ; preds = %for.body
  %cmp491069 = icmp slt i32 %9, %10
  %arrayidx210 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx216 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx223 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %11 = sext i32 %9 to i64
  %12 = sext i32 %8 to i64
  %13 = sext i32 %mul21 to i64
  %14 = add i32 %2, %8
  %15 = mul i32 %14, 3
  br label %for.body29

for.body29:                                       ; preds = %for.end, %for.body29.lr.ph
  %indvars.iv1128 = phi i64 [ %13, %for.body29.lr.ph ], [ %indvars.iv.next1129, %for.end ]
  %indvars.iv1126 = phi i64 [ %12, %for.body29.lr.ph ], [ %indvars.iv.next1127, %for.end ]
  %s.01083 = phi i32 [ 0, %for.body29.lr.ph ], [ %inc231, %for.end ]
  %vnbtot.01082 = phi float [ 0.000000e+00, %for.body29.lr.ph ], [ %vnbtot.1.lcssa, %for.end ]
  %vctot.01081 = phi float [ 0.000000e+00, %for.body29.lr.ph ], [ %vctot.1.lcssa, %for.end ]
  %arrayidx31 = getelementptr inbounds float* %pos, i64 %indvars.iv1128
  %16 = load float* %arrayidx31, align 4, !tbaa !3
  %add32 = fadd float %5, %16
  %17 = add nsw i64 %indvars.iv1128, 1
  %arrayidx35 = getelementptr inbounds float* %pos, i64 %17
  %18 = load float* %arrayidx35, align 4, !tbaa !3
  %add36 = fadd float %6, %18
  %19 = add nsw i64 %indvars.iv1128, 2
  %arrayidx39 = getelementptr inbounds float* %pos, i64 %19
  %20 = load float* %arrayidx39, align 4, !tbaa !3
  %add40 = fadd float %7, %20
  %arrayidx42 = getelementptr inbounds float* %charge, i64 %indvars.iv1126
  %21 = load float* %arrayidx42, align 4, !tbaa !3
  %mul43 = fmul float %21, %facel
  %arrayidx46 = getelementptr inbounds i32* %type, i64 %indvars.iv1126
  %22 = load i32* %arrayidx46, align 4, !tbaa !0
  %mul47 = mul nsw i32 %mul400, %22
  br i1 %cmp491069, label %for.body50, label %for.end

for.body50:                                       ; preds = %for.body29, %for.body50
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body50 ], [ %11, %for.body29 ]
  %fiz1.01074 = phi float [ %add170, %for.body50 ], [ 0.000000e+00, %for.body29 ]
  %fiy1.01073 = phi float [ %add169, %for.body50 ], [ 0.000000e+00, %for.body29 ]
  %fix1.01072 = phi float [ %add168, %for.body50 ], [ 0.000000e+00, %for.body29 ]
  %vnbtot.11071 = phi float [ %add158, %for.body50 ], [ %vnbtot.01082, %for.body29 ]
  %vctot.11070 = phi float [ %add164, %for.body50 ], [ %vctot.01081, %for.body29 ]
  %arrayidx52 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %23 = load i32* %arrayidx52, align 4, !tbaa !0
  %mul53 = mul nsw i32 %23, 3
  %idxprom54 = sext i32 %mul53 to i64
  %arrayidx55 = getelementptr inbounds float* %pos, i64 %idxprom54
  %24 = load float* %arrayidx55, align 4, !tbaa !3
  %add56 = add nsw i32 %mul53, 1
  %idxprom57 = sext i32 %add56 to i64
  %arrayidx58 = getelementptr inbounds float* %pos, i64 %idxprom57
  %25 = load float* %arrayidx58, align 4, !tbaa !3
  %add59 = add nsw i32 %mul53, 2
  %idxprom60 = sext i32 %add59 to i64
  %arrayidx61 = getelementptr inbounds float* %pos, i64 %idxprom60
  %26 = load float* %arrayidx61, align 4, !tbaa !3
  %sub = fsub float %add32, %24
  %sub62 = fsub float %add36, %25
  %sub63 = fsub float %add40, %26
  %mul64 = fmul float %sub, %sub
  %mul65 = fmul float %sub62, %sub62
  %add66 = fadd float %mul64, %mul65
  %mul67 = fmul float %sub63, %sub63
  %add68 = fadd float %add66, %mul67
  %conv = fpext float %add68 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv69 = fptrunc double %div to float
  %mul70 = fmul float %add68, %conv69
  %mul71 = fmul float %mul70, %tabscale
  %conv72 = fptosi float %mul71 to i32
  %conv73 = sitofp i32 %conv72 to float
  %sub74 = fsub float %mul71, %conv73
  %mul75 = fmul float %sub74, %sub74
  %mul76 = mul nsw i32 %conv72, 12
  %idxprom77 = sext i32 %23 to i64
  %arrayidx78 = getelementptr inbounds float* %charge, i64 %idxprom77
  %27 = load float* %arrayidx78, align 4, !tbaa !3
  %mul79 = fmul float %mul43, %27
  %idxprom80 = sext i32 %mul76 to i64
  %arrayidx81 = getelementptr inbounds float* %VFtab, i64 %idxprom80
  %28 = load float* %arrayidx81, align 4, !tbaa !3
  %add821065 = or i32 %mul76, 1
  %idxprom83 = sext i32 %add821065 to i64
  %arrayidx84 = getelementptr inbounds float* %VFtab, i64 %idxprom83
  %29 = load float* %arrayidx84, align 4, !tbaa !3
  %add851066 = or i32 %mul76, 2
  %idxprom86 = sext i32 %add851066 to i64
  %arrayidx87 = getelementptr inbounds float* %VFtab, i64 %idxprom86
  %30 = load float* %arrayidx87, align 4, !tbaa !3
  %mul88 = fmul float %30, %sub74
  %add891067 = or i32 %mul76, 3
  %idxprom90 = sext i32 %add891067 to i64
  %arrayidx91 = getelementptr inbounds float* %VFtab, i64 %idxprom90
  %31 = load float* %arrayidx91, align 4, !tbaa !3
  %mul92 = fmul float %31, %mul75
  %add93 = fadd float %29, %mul88
  %add94 = fadd float %add93, %mul92
  %mul95 = fmul float %sub74, %add94
  %add96 = fadd float %28, %mul95
  %add97 = fadd float %mul88, %add94
  %mul98 = fmul float %mul92, 2.000000e+00
  %add99 = fadd float %mul98, %add97
  %mul100 = fmul float %mul79, %add96
  %mul101 = fmul float %mul79, %add99
  %arrayidx103 = getelementptr inbounds i32* %type, i64 %idxprom77
  %32 = load i32* %arrayidx103, align 4, !tbaa !0
  %mul104 = shl nsw i32 %32, 1
  %add105 = add nsw i32 %mul104, %mul47
  %idxprom106 = sext i32 %add105 to i64
  %arrayidx107 = getelementptr inbounds float* %nbfp, i64 %idxprom106
  %33 = load float* %arrayidx107, align 4, !tbaa !3
  %add1081068 = or i32 %add105, 1
  %idxprom109 = sext i32 %add1081068 to i64
  %arrayidx110 = getelementptr inbounds float* %nbfp, i64 %idxprom109
  %34 = load float* %arrayidx110, align 4, !tbaa !3
  %add111 = add nsw i32 %mul76, 4
  %idxprom112 = sext i32 %add111 to i64
  %arrayidx113 = getelementptr inbounds float* %VFtab, i64 %idxprom112
  %35 = load float* %arrayidx113, align 4, !tbaa !3
  %add114 = add nsw i32 %mul76, 5
  %idxprom115 = sext i32 %add114 to i64
  %arrayidx116 = getelementptr inbounds float* %VFtab, i64 %idxprom115
  %36 = load float* %arrayidx116, align 4, !tbaa !3
  %add117 = add nsw i32 %mul76, 6
  %idxprom118 = sext i32 %add117 to i64
  %arrayidx119 = getelementptr inbounds float* %VFtab, i64 %idxprom118
  %37 = load float* %arrayidx119, align 4, !tbaa !3
  %mul120 = fmul float %sub74, %37
  %add121 = add nsw i32 %mul76, 7
  %idxprom122 = sext i32 %add121 to i64
  %arrayidx123 = getelementptr inbounds float* %VFtab, i64 %idxprom122
  %38 = load float* %arrayidx123, align 4, !tbaa !3
  %mul124 = fmul float %mul75, %38
  %add125 = fadd float %36, %mul120
  %add126 = fadd float %add125, %mul124
  %mul127 = fmul float %sub74, %add126
  %add128 = fadd float %35, %mul127
  %add129 = fadd float %mul120, %add126
  %mul130 = fmul float %mul124, 2.000000e+00
  %add131 = fadd float %mul130, %add129
  %mul132 = fmul float %33, %add128
  %mul133 = fmul float %33, %add131
  %add134 = add nsw i32 %mul76, 8
  %idxprom135 = sext i32 %add134 to i64
  %arrayidx136 = getelementptr inbounds float* %VFtab, i64 %idxprom135
  %39 = load float* %arrayidx136, align 4, !tbaa !3
  %add137 = add nsw i32 %mul76, 9
  %idxprom138 = sext i32 %add137 to i64
  %arrayidx139 = getelementptr inbounds float* %VFtab, i64 %idxprom138
  %40 = load float* %arrayidx139, align 4, !tbaa !3
  %add140 = add nsw i32 %mul76, 10
  %idxprom141 = sext i32 %add140 to i64
  %arrayidx142 = getelementptr inbounds float* %VFtab, i64 %idxprom141
  %41 = load float* %arrayidx142, align 4, !tbaa !3
  %mul143 = fmul float %sub74, %41
  %add144 = add nsw i32 %mul76, 11
  %idxprom145 = sext i32 %add144 to i64
  %arrayidx146 = getelementptr inbounds float* %VFtab, i64 %idxprom145
  %42 = load float* %arrayidx146, align 4, !tbaa !3
  %mul147 = fmul float %mul75, %42
  %add148 = fadd float %40, %mul143
  %add149 = fadd float %add148, %mul147
  %mul150 = fmul float %sub74, %add149
  %add151 = fadd float %39, %mul150
  %add152 = fadd float %mul143, %add149
  %mul153 = fmul float %mul147, 2.000000e+00
  %add154 = fadd float %mul153, %add152
  %mul155 = fmul float %34, %add151
  %mul156 = fmul float %34, %add154
  %add157 = fadd float %vnbtot.11071, %mul132
  %add158 = fadd float %add157, %mul155
  %add159 = fadd float %mul101, %mul133
  %add160 = fadd float %add159, %mul156
  %mul161 = fmul float %add160, %tabscale
  %43 = fmul float %conv69, %mul161
  %mul163 = fsub float -0.000000e+00, %43
  %add164 = fadd float %vctot.11070, %mul100
  %mul165 = fmul float %sub, %mul163
  %mul166 = fmul float %sub62, %mul163
  %mul167 = fmul float %sub63, %mul163
  %add168 = fadd float %fix1.01072, %mul165
  %add169 = fadd float %fiy1.01073, %mul166
  %add170 = fadd float %fiz1.01074, %mul167
  %arrayidx172 = getelementptr inbounds float* %faction, i64 %idxprom54
  %44 = load float* %arrayidx172, align 4, !tbaa !3
  %sub173 = fsub float %44, %mul165
  store float %sub173, float* %arrayidx172, align 4, !tbaa !3
  %arrayidx178 = getelementptr inbounds float* %faction, i64 %idxprom57
  %45 = load float* %arrayidx178, align 4, !tbaa !3
  %sub179 = fsub float %45, %mul166
  store float %sub179, float* %arrayidx178, align 4, !tbaa !3
  %arrayidx185 = getelementptr inbounds float* %faction, i64 %idxprom60
  %46 = load float* %arrayidx185, align 4, !tbaa !3
  %sub186 = fsub float %46, %mul167
  store float %sub186, float* %arrayidx185, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %47 = trunc i64 %indvars.iv.next to i32
  %cmp49 = icmp slt i32 %47, %10
  br i1 %cmp49, label %for.body50, label %for.end

for.end:                                          ; preds = %for.body50, %for.body29
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add170, %for.body50 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add169, %for.body50 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add168, %for.body50 ]
  %vnbtot.1.lcssa = phi float [ %vnbtot.01082, %for.body29 ], [ %add158, %for.body50 ]
  %vctot.1.lcssa = phi float [ %vctot.01081, %for.body29 ], [ %add164, %for.body50 ]
  %arrayidx191 = getelementptr inbounds float* %faction, i64 %indvars.iv1128
  %48 = load float* %arrayidx191, align 4, !tbaa !3
  %add192 = fadd float %fix1.0.lcssa, %48
  store float %add192, float* %arrayidx191, align 4, !tbaa !3
  %arrayidx197 = getelementptr inbounds float* %faction, i64 %17
  %49 = load float* %arrayidx197, align 4, !tbaa !3
  %add198 = fadd float %fiy1.0.lcssa, %49
  store float %add198, float* %arrayidx197, align 4, !tbaa !3
  %arrayidx204 = getelementptr inbounds float* %faction, i64 %19
  %50 = load float* %arrayidx204, align 4, !tbaa !3
  %add205 = fadd float %fiz1.0.lcssa, %50
  store float %add205, float* %arrayidx204, align 4, !tbaa !3
  %51 = load float* %arrayidx210, align 4, !tbaa !3
  %add211 = fadd float %fix1.0.lcssa, %51
  store float %add211, float* %arrayidx210, align 4, !tbaa !3
  %52 = load float* %arrayidx216, align 4, !tbaa !3
  %add217 = fadd float %fiy1.0.lcssa, %52
  store float %add217, float* %arrayidx216, align 4, !tbaa !3
  %53 = load float* %arrayidx223, align 4, !tbaa !3
  %add224 = fadd float %fiz1.0.lcssa, %53
  store float %add224, float* %arrayidx223, align 4, !tbaa !3
  %indvars.iv.next1127 = add i64 %indvars.iv1126, 1
  %indvars.iv.next1129 = add i64 %indvars.iv1128, 3
  %inc231 = add nsw i32 %s.01083, 1
  %exitcond = icmp eq i32 %inc231, %2
  br i1 %exitcond, label %for.cond27.for.cond233.loopexit_crit_edge, label %for.body29

for.cond27.for.cond233.loopexit_crit_edge:        ; preds = %for.end
  %54 = add i32 %2, %8
  br label %for.cond233.loopexit

for.cond233.loopexit:                             ; preds = %for.cond27.for.cond233.loopexit_crit_edge, %for.body
  %ii.0.lcssa = phi i32 [ %54, %for.cond27.for.cond233.loopexit_crit_edge ], [ %8, %for.body ]
  %ii3.0.lcssa = phi i32 [ %15, %for.cond27.for.cond233.loopexit_crit_edge ], [ %mul21, %for.body ]
  %vnbtot.0.lcssa = phi float [ %vnbtot.1.lcssa, %for.cond27.for.cond233.loopexit_crit_edge ], [ 0.000000e+00, %for.body ]
  %vctot.0.lcssa = phi float [ %vctot.1.lcssa, %for.cond27.for.cond233.loopexit_crit_edge ], [ 0.000000e+00, %for.body ]
  %cmp2341100 = icmp slt i32 %2, %3
  br i1 %cmp2341100, label %for.body236.lr.ph, label %for.cond385.loopexit

for.body236.lr.ph:                                ; preds = %for.cond233.loopexit
  %cmp2521090 = icmp slt i32 %9, %10
  %arrayidx362 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx368 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx375 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %55 = sext i32 %9 to i64
  %56 = sext i32 %ii.0.lcssa to i64
  %57 = sext i32 %ii3.0.lcssa to i64
  %58 = mul i32 %3, 3
  %59 = add i32 %ii.0.lcssa, %3
  br label %for.body236

for.body236:                                      ; preds = %for.end341, %for.body236.lr.ph
  %indvars.iv1136 = phi i64 [ %57, %for.body236.lr.ph ], [ %indvars.iv.next1137, %for.end341 ]
  %indvars.iv1134 = phi i64 [ %56, %for.body236.lr.ph ], [ %indvars.iv.next1135, %for.end341 ]
  %s.11102 = phi i32 [ %2, %for.body236.lr.ph ], [ %inc383, %for.end341 ]
  %vctot.21101 = phi float [ %vctot.0.lcssa, %for.body236.lr.ph ], [ %vctot.3.lcssa, %for.end341 ]
  %arrayidx238 = getelementptr inbounds float* %pos, i64 %indvars.iv1136
  %60 = load float* %arrayidx238, align 4, !tbaa !3
  %add239 = fadd float %5, %60
  %61 = add nsw i64 %indvars.iv1136, 1
  %arrayidx242 = getelementptr inbounds float* %pos, i64 %61
  %62 = load float* %arrayidx242, align 4, !tbaa !3
  %add243 = fadd float %6, %62
  %63 = add nsw i64 %indvars.iv1136, 2
  %arrayidx246 = getelementptr inbounds float* %pos, i64 %63
  %64 = load float* %arrayidx246, align 4, !tbaa !3
  %add247 = fadd float %7, %64
  %arrayidx249 = getelementptr inbounds float* %charge, i64 %indvars.iv1134
  %65 = load float* %arrayidx249, align 4, !tbaa !3
  %mul250 = fmul float %65, %facel
  br i1 %cmp2521090, label %for.body254, label %for.end341

for.body254:                                      ; preds = %for.body236, %for.body254
  %indvars.iv1132 = phi i64 [ %indvars.iv.next1133, %for.body254 ], [ %55, %for.body236 ]
  %fiz1.11094 = phi float [ %add319, %for.body254 ], [ 0.000000e+00, %for.body236 ]
  %fiy1.11093 = phi float [ %add318, %for.body254 ], [ 0.000000e+00, %for.body236 ]
  %fix1.11092 = phi float [ %add317, %for.body254 ], [ 0.000000e+00, %for.body236 ]
  %vctot.31091 = phi float [ %add313, %for.body254 ], [ %vctot.21101, %for.body236 ]
  %arrayidx256 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv1132
  %66 = load i32* %arrayidx256, align 4, !tbaa !0
  %mul257 = mul nsw i32 %66, 3
  %idxprom258 = sext i32 %mul257 to i64
  %arrayidx259 = getelementptr inbounds float* %pos, i64 %idxprom258
  %67 = load float* %arrayidx259, align 4, !tbaa !3
  %add260 = add nsw i32 %mul257, 1
  %idxprom261 = sext i32 %add260 to i64
  %arrayidx262 = getelementptr inbounds float* %pos, i64 %idxprom261
  %68 = load float* %arrayidx262, align 4, !tbaa !3
  %add263 = add nsw i32 %mul257, 2
  %idxprom264 = sext i32 %add263 to i64
  %arrayidx265 = getelementptr inbounds float* %pos, i64 %idxprom264
  %69 = load float* %arrayidx265, align 4, !tbaa !3
  %sub266 = fsub float %add239, %67
  %sub267 = fsub float %add243, %68
  %sub268 = fsub float %add247, %69
  %mul269 = fmul float %sub266, %sub266
  %mul270 = fmul float %sub267, %sub267
  %add271 = fadd float %mul269, %mul270
  %mul272 = fmul float %sub268, %sub268
  %add273 = fadd float %add271, %mul272
  %conv274 = fpext float %add273 to double
  %call275 = tail call double @sqrt(double %conv274) #2
  %div276 = fdiv double 1.000000e+00, %call275
  %conv277 = fptrunc double %div276 to float
  %mul278 = fmul float %add273, %conv277
  %mul279 = fmul float %mul278, %tabscale
  %conv280 = fptosi float %mul279 to i32
  %conv281 = sitofp i32 %conv280 to float
  %sub282 = fsub float %mul279, %conv281
  %mul283 = fmul float %sub282, %sub282
  %mul284 = mul nsw i32 %conv280, 12
  %idxprom285 = sext i32 %66 to i64
  %arrayidx286 = getelementptr inbounds float* %charge, i64 %idxprom285
  %70 = load float* %arrayidx286, align 4, !tbaa !3
  %mul287 = fmul float %mul250, %70
  %idxprom288 = sext i32 %mul284 to i64
  %arrayidx289 = getelementptr inbounds float* %VFtab, i64 %idxprom288
  %71 = load float* %arrayidx289, align 4, !tbaa !3
  %add2901062 = or i32 %mul284, 1
  %idxprom291 = sext i32 %add2901062 to i64
  %arrayidx292 = getelementptr inbounds float* %VFtab, i64 %idxprom291
  %72 = load float* %arrayidx292, align 4, !tbaa !3
  %add2931063 = or i32 %mul284, 2
  %idxprom294 = sext i32 %add2931063 to i64
  %arrayidx295 = getelementptr inbounds float* %VFtab, i64 %idxprom294
  %73 = load float* %arrayidx295, align 4, !tbaa !3
  %mul296 = fmul float %73, %sub282
  %add2971064 = or i32 %mul284, 3
  %idxprom298 = sext i32 %add2971064 to i64
  %arrayidx299 = getelementptr inbounds float* %VFtab, i64 %idxprom298
  %74 = load float* %arrayidx299, align 4, !tbaa !3
  %mul300 = fmul float %74, %mul283
  %add301 = fadd float %72, %mul296
  %add302 = fadd float %add301, %mul300
  %mul303 = fmul float %sub282, %add302
  %add304 = fadd float %71, %mul303
  %add305 = fadd float %mul296, %add302
  %mul306 = fmul float %mul300, 2.000000e+00
  %add307 = fadd float %mul306, %add305
  %mul308 = fmul float %mul287, %add304
  %mul309 = fmul float %mul287, %add307
  %mul310 = fmul float %mul309, %tabscale
  %75 = fmul float %conv277, %mul310
  %mul312 = fsub float -0.000000e+00, %75
  %add313 = fadd float %vctot.31091, %mul308
  %mul314 = fmul float %sub266, %mul312
  %mul315 = fmul float %sub267, %mul312
  %mul316 = fmul float %sub268, %mul312
  %add317 = fadd float %fix1.11092, %mul314
  %add318 = fadd float %fiy1.11093, %mul315
  %add319 = fadd float %fiz1.11094, %mul316
  %arrayidx321 = getelementptr inbounds float* %faction, i64 %idxprom258
  %76 = load float* %arrayidx321, align 4, !tbaa !3
  %sub322 = fsub float %76, %mul314
  store float %sub322, float* %arrayidx321, align 4, !tbaa !3
  %arrayidx327 = getelementptr inbounds float* %faction, i64 %idxprom261
  %77 = load float* %arrayidx327, align 4, !tbaa !3
  %sub328 = fsub float %77, %mul315
  store float %sub328, float* %arrayidx327, align 4, !tbaa !3
  %arrayidx334 = getelementptr inbounds float* %faction, i64 %idxprom264
  %78 = load float* %arrayidx334, align 4, !tbaa !3
  %sub335 = fsub float %78, %mul316
  store float %sub335, float* %arrayidx334, align 4, !tbaa !3
  %indvars.iv.next1133 = add i64 %indvars.iv1132, 1
  %79 = trunc i64 %indvars.iv.next1133 to i32
  %cmp252 = icmp slt i32 %79, %10
  br i1 %cmp252, label %for.body254, label %for.end341

for.end341:                                       ; preds = %for.body254, %for.body236
  %fiz1.1.lcssa = phi float [ 0.000000e+00, %for.body236 ], [ %add319, %for.body254 ]
  %fiy1.1.lcssa = phi float [ 0.000000e+00, %for.body236 ], [ %add318, %for.body254 ]
  %fix1.1.lcssa = phi float [ 0.000000e+00, %for.body236 ], [ %add317, %for.body254 ]
  %vctot.3.lcssa = phi float [ %vctot.21101, %for.body236 ], [ %add313, %for.body254 ]
  %arrayidx343 = getelementptr inbounds float* %faction, i64 %indvars.iv1136
  %80 = load float* %arrayidx343, align 4, !tbaa !3
  %add344 = fadd float %fix1.1.lcssa, %80
  store float %add344, float* %arrayidx343, align 4, !tbaa !3
  %arrayidx349 = getelementptr inbounds float* %faction, i64 %61
  %81 = load float* %arrayidx349, align 4, !tbaa !3
  %add350 = fadd float %fiy1.1.lcssa, %81
  store float %add350, float* %arrayidx349, align 4, !tbaa !3
  %arrayidx356 = getelementptr inbounds float* %faction, i64 %63
  %82 = load float* %arrayidx356, align 4, !tbaa !3
  %add357 = fadd float %fiz1.1.lcssa, %82
  store float %add357, float* %arrayidx356, align 4, !tbaa !3
  %83 = load float* %arrayidx362, align 4, !tbaa !3
  %add363 = fadd float %fix1.1.lcssa, %83
  store float %add363, float* %arrayidx362, align 4, !tbaa !3
  %84 = load float* %arrayidx368, align 4, !tbaa !3
  %add369 = fadd float %fiy1.1.lcssa, %84
  store float %add369, float* %arrayidx368, align 4, !tbaa !3
  %85 = load float* %arrayidx375, align 4, !tbaa !3
  %add376 = fadd float %fiz1.1.lcssa, %85
  store float %add376, float* %arrayidx375, align 4, !tbaa !3
  %indvars.iv.next1135 = add i64 %indvars.iv1134, 1
  %indvars.iv.next1137 = add i64 %indvars.iv1136, 3
  %inc383 = add nsw i32 %s.11102, 1
  %exitcond1140 = icmp eq i32 %inc383, %3
  br i1 %exitcond1140, label %for.cond233.for.cond385.loopexit_crit_edge, label %for.body236

for.cond233.for.cond385.loopexit_crit_edge:       ; preds = %for.end341
  %86 = add i32 %ii3.0.lcssa, %58
  %87 = mul i32 %2, -3
  %88 = add i32 %86, %87
  %89 = sub i32 %59, %2
  br label %for.cond385.loopexit

for.cond385.loopexit:                             ; preds = %for.cond233.for.cond385.loopexit_crit_edge, %for.cond233.loopexit
  %ii.1.lcssa = phi i32 [ %89, %for.cond233.for.cond385.loopexit_crit_edge ], [ %ii.0.lcssa, %for.cond233.loopexit ]
  %ii3.1.lcssa = phi i32 [ %88, %for.cond233.for.cond385.loopexit_crit_edge ], [ %ii3.0.lcssa, %for.cond233.loopexit ]
  %vctot.2.lcssa = phi float [ %vctot.3.lcssa, %for.cond233.for.cond385.loopexit_crit_edge ], [ %vctot.0.lcssa, %for.cond233.loopexit ]
  %cmp3861118 = icmp slt i32 %3, %1
  br i1 %cmp3861118, label %for.body388.lr.ph, label %for.end568

for.body388.lr.ph:                                ; preds = %for.cond385.loopexit
  %cmp4051108 = icmp slt i32 %9, %10
  %arrayidx546 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx552 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx559 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %90 = sext i32 %9 to i64
  %91 = sext i32 %ii.1.lcssa to i64
  %92 = sext i32 %ii3.1.lcssa to i64
  br label %for.body388

for.body388:                                      ; preds = %for.end525, %for.body388.lr.ph
  %indvars.iv1145 = phi i64 [ %92, %for.body388.lr.ph ], [ %indvars.iv.next1146, %for.end525 ]
  %indvars.iv1143 = phi i64 [ %91, %for.body388.lr.ph ], [ %indvars.iv.next1144, %for.end525 ]
  %s.21120 = phi i32 [ %3, %for.body388.lr.ph ], [ %inc567, %for.end525 ]
  %vnbtot.21119 = phi float [ %vnbtot.0.lcssa, %for.body388.lr.ph ], [ %vnbtot.3.lcssa, %for.end525 ]
  %arrayidx390 = getelementptr inbounds float* %pos, i64 %indvars.iv1145
  %93 = load float* %arrayidx390, align 4, !tbaa !3
  %add391 = fadd float %5, %93
  %94 = add nsw i64 %indvars.iv1145, 1
  %arrayidx394 = getelementptr inbounds float* %pos, i64 %94
  %95 = load float* %arrayidx394, align 4, !tbaa !3
  %add395 = fadd float %6, %95
  %96 = add nsw i64 %indvars.iv1145, 2
  %arrayidx398 = getelementptr inbounds float* %pos, i64 %96
  %97 = load float* %arrayidx398, align 4, !tbaa !3
  %add399 = fadd float %7, %97
  %arrayidx402 = getelementptr inbounds i32* %type, i64 %indvars.iv1143
  %98 = load i32* %arrayidx402, align 4, !tbaa !0
  %mul403 = mul nsw i32 %mul400, %98
  br i1 %cmp4051108, label %for.body407, label %for.end525

for.body407:                                      ; preds = %for.body388, %for.body407
  %indvars.iv1141 = phi i64 [ %indvars.iv.next1142, %for.body407 ], [ %90, %for.body388 ]
  %fiz1.21112 = phi float [ %add503, %for.body407 ], [ 0.000000e+00, %for.body388 ]
  %fiy1.21111 = phi float [ %add502, %for.body407 ], [ 0.000000e+00, %for.body388 ]
  %fix1.21110 = phi float [ %add501, %for.body407 ], [ 0.000000e+00, %for.body388 ]
  %vnbtot.31109 = phi float [ %add493, %for.body407 ], [ %vnbtot.21119, %for.body388 ]
  %arrayidx409 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv1141
  %99 = load i32* %arrayidx409, align 4, !tbaa !0
  %mul410 = mul nsw i32 %99, 3
  %idxprom411 = sext i32 %mul410 to i64
  %arrayidx412 = getelementptr inbounds float* %pos, i64 %idxprom411
  %100 = load float* %arrayidx412, align 4, !tbaa !3
  %add413 = add nsw i32 %mul410, 1
  %idxprom414 = sext i32 %add413 to i64
  %arrayidx415 = getelementptr inbounds float* %pos, i64 %idxprom414
  %101 = load float* %arrayidx415, align 4, !tbaa !3
  %add416 = add nsw i32 %mul410, 2
  %idxprom417 = sext i32 %add416 to i64
  %arrayidx418 = getelementptr inbounds float* %pos, i64 %idxprom417
  %102 = load float* %arrayidx418, align 4, !tbaa !3
  %sub419 = fsub float %add391, %100
  %sub420 = fsub float %add395, %101
  %sub421 = fsub float %add399, %102
  %mul422 = fmul float %sub419, %sub419
  %mul423 = fmul float %sub420, %sub420
  %add424 = fadd float %mul422, %mul423
  %mul425 = fmul float %sub421, %sub421
  %add426 = fadd float %add424, %mul425
  %conv427 = fpext float %add426 to double
  %call428 = tail call double @sqrt(double %conv427) #2
  %div429 = fdiv double 1.000000e+00, %call428
  %conv430 = fptrunc double %div429 to float
  %mul431 = fmul float %add426, %conv430
  %mul432 = fmul float %mul431, %tabscale
  %conv433 = fptosi float %mul432 to i32
  %conv434 = sitofp i32 %conv433 to float
  %sub435 = fsub float %mul432, %conv434
  %mul436 = fmul float %sub435, %sub435
  %mul437 = mul nsw i32 %conv433, 12
  %idxprom438 = sext i32 %99 to i64
  %arrayidx439 = getelementptr inbounds i32* %type, i64 %idxprom438
  %103 = load i32* %arrayidx439, align 4, !tbaa !0
  %mul440 = shl nsw i32 %103, 1
  %add441 = add nsw i32 %mul440, %mul403
  %idxprom442 = sext i32 %add441 to i64
  %arrayidx443 = getelementptr inbounds float* %nbfp, i64 %idxprom442
  %104 = load float* %arrayidx443, align 4, !tbaa !3
  %add4441058 = or i32 %add441, 1
  %idxprom445 = sext i32 %add4441058 to i64
  %arrayidx446 = getelementptr inbounds float* %nbfp, i64 %idxprom445
  %105 = load float* %arrayidx446, align 4, !tbaa !3
  %idxprom447 = sext i32 %mul437 to i64
  %arrayidx448 = getelementptr inbounds float* %VFtab, i64 %idxprom447
  %106 = load float* %arrayidx448, align 4, !tbaa !3
  %add4491059 = or i32 %mul437, 1
  %idxprom450 = sext i32 %add4491059 to i64
  %arrayidx451 = getelementptr inbounds float* %VFtab, i64 %idxprom450
  %107 = load float* %arrayidx451, align 4, !tbaa !3
  %add4521060 = or i32 %mul437, 2
  %idxprom453 = sext i32 %add4521060 to i64
  %arrayidx454 = getelementptr inbounds float* %VFtab, i64 %idxprom453
  %108 = load float* %arrayidx454, align 4, !tbaa !3
  %mul455 = fmul float %sub435, %108
  %add4561061 = or i32 %mul437, 3
  %idxprom457 = sext i32 %add4561061 to i64
  %arrayidx458 = getelementptr inbounds float* %VFtab, i64 %idxprom457
  %109 = load float* %arrayidx458, align 4, !tbaa !3
  %mul459 = fmul float %mul436, %109
  %add460 = fadd float %107, %mul455
  %add461 = fadd float %add460, %mul459
  %mul462 = fmul float %sub435, %add461
  %add463 = fadd float %106, %mul462
  %add464 = fadd float %mul455, %add461
  %mul465 = fmul float %mul459, 2.000000e+00
  %add466 = fadd float %mul465, %add464
  %mul467 = fmul float %104, %add463
  %mul468 = fmul float %104, %add466
  %add469 = add nsw i32 %mul437, 4
  %idxprom470 = sext i32 %add469 to i64
  %arrayidx471 = getelementptr inbounds float* %VFtab, i64 %idxprom470
  %110 = load float* %arrayidx471, align 4, !tbaa !3
  %add472 = add nsw i32 %mul437, 5
  %idxprom473 = sext i32 %add472 to i64
  %arrayidx474 = getelementptr inbounds float* %VFtab, i64 %idxprom473
  %111 = load float* %arrayidx474, align 4, !tbaa !3
  %add475 = add nsw i32 %mul437, 6
  %idxprom476 = sext i32 %add475 to i64
  %arrayidx477 = getelementptr inbounds float* %VFtab, i64 %idxprom476
  %112 = load float* %arrayidx477, align 4, !tbaa !3
  %mul478 = fmul float %sub435, %112
  %add479 = add nsw i32 %mul437, 7
  %idxprom480 = sext i32 %add479 to i64
  %arrayidx481 = getelementptr inbounds float* %VFtab, i64 %idxprom480
  %113 = load float* %arrayidx481, align 4, !tbaa !3
  %mul482 = fmul float %mul436, %113
  %add483 = fadd float %111, %mul478
  %add484 = fadd float %add483, %mul482
  %mul485 = fmul float %sub435, %add484
  %add486 = fadd float %110, %mul485
  %add487 = fadd float %mul478, %add484
  %mul488 = fmul float %mul482, 2.000000e+00
  %add489 = fadd float %mul488, %add487
  %mul490 = fmul float %105, %add486
  %mul491 = fmul float %105, %add489
  %add492 = fadd float %vnbtot.31109, %mul467
  %add493 = fadd float %add492, %mul490
  %add494 = fadd float %mul468, %mul491
  %mul495 = fmul float %add494, %tabscale
  %114 = fmul float %conv430, %mul495
  %mul497 = fsub float -0.000000e+00, %114
  %mul498 = fmul float %sub419, %mul497
  %mul499 = fmul float %sub420, %mul497
  %mul500 = fmul float %sub421, %mul497
  %add501 = fadd float %fix1.21110, %mul498
  %add502 = fadd float %fiy1.21111, %mul499
  %add503 = fadd float %fiz1.21112, %mul500
  %arrayidx505 = getelementptr inbounds float* %faction, i64 %idxprom411
  %115 = load float* %arrayidx505, align 4, !tbaa !3
  %sub506 = fsub float %115, %mul498
  store float %sub506, float* %arrayidx505, align 4, !tbaa !3
  %arrayidx511 = getelementptr inbounds float* %faction, i64 %idxprom414
  %116 = load float* %arrayidx511, align 4, !tbaa !3
  %sub512 = fsub float %116, %mul499
  store float %sub512, float* %arrayidx511, align 4, !tbaa !3
  %arrayidx518 = getelementptr inbounds float* %faction, i64 %idxprom417
  %117 = load float* %arrayidx518, align 4, !tbaa !3
  %sub519 = fsub float %117, %mul500
  store float %sub519, float* %arrayidx518, align 4, !tbaa !3
  %indvars.iv.next1142 = add i64 %indvars.iv1141, 1
  %118 = trunc i64 %indvars.iv.next1142 to i32
  %cmp405 = icmp slt i32 %118, %10
  br i1 %cmp405, label %for.body407, label %for.end525

for.end525:                                       ; preds = %for.body407, %for.body388
  %fiz1.2.lcssa = phi float [ 0.000000e+00, %for.body388 ], [ %add503, %for.body407 ]
  %fiy1.2.lcssa = phi float [ 0.000000e+00, %for.body388 ], [ %add502, %for.body407 ]
  %fix1.2.lcssa = phi float [ 0.000000e+00, %for.body388 ], [ %add501, %for.body407 ]
  %vnbtot.3.lcssa = phi float [ %vnbtot.21119, %for.body388 ], [ %add493, %for.body407 ]
  %arrayidx527 = getelementptr inbounds float* %faction, i64 %indvars.iv1145
  %119 = load float* %arrayidx527, align 4, !tbaa !3
  %add528 = fadd float %fix1.2.lcssa, %119
  store float %add528, float* %arrayidx527, align 4, !tbaa !3
  %arrayidx533 = getelementptr inbounds float* %faction, i64 %94
  %120 = load float* %arrayidx533, align 4, !tbaa !3
  %add534 = fadd float %fiy1.2.lcssa, %120
  store float %add534, float* %arrayidx533, align 4, !tbaa !3
  %arrayidx540 = getelementptr inbounds float* %faction, i64 %96
  %121 = load float* %arrayidx540, align 4, !tbaa !3
  %add541 = fadd float %fiz1.2.lcssa, %121
  store float %add541, float* %arrayidx540, align 4, !tbaa !3
  %122 = load float* %arrayidx546, align 4, !tbaa !3
  %add547 = fadd float %fix1.2.lcssa, %122
  store float %add547, float* %arrayidx546, align 4, !tbaa !3
  %123 = load float* %arrayidx552, align 4, !tbaa !3
  %add553 = fadd float %fiy1.2.lcssa, %123
  store float %add553, float* %arrayidx552, align 4, !tbaa !3
  %124 = load float* %arrayidx559, align 4, !tbaa !3
  %add560 = fadd float %fiz1.2.lcssa, %124
  store float %add560, float* %arrayidx559, align 4, !tbaa !3
  %indvars.iv.next1144 = add i64 %indvars.iv1143, 1
  %indvars.iv.next1146 = add i64 %indvars.iv1145, 3
  %inc567 = add nsw i32 %s.21120, 1
  %exitcond1149 = icmp eq i32 %inc567, %1
  br i1 %exitcond1149, label %for.end568, label %for.body388

for.end568:                                       ; preds = %for.end525, %for.cond385.loopexit
  %vnbtot.2.lcssa = phi float [ %vnbtot.0.lcssa, %for.cond385.loopexit ], [ %vnbtot.3.lcssa, %for.end525 ]
  %arrayidx570 = getelementptr inbounds i32* %gid, i64 %indvars.iv1150
  %125 = load i32* %arrayidx570, align 4, !tbaa !0
  %idxprom571 = sext i32 %125 to i64
  %arrayidx572 = getelementptr inbounds float* %Vc, i64 %idxprom571
  %126 = load float* %arrayidx572, align 4, !tbaa !3
  %add573 = fadd float %vctot.2.lcssa, %126
  store float %add573, float* %arrayidx572, align 4, !tbaa !3
  %arrayidx577 = getelementptr inbounds float* %Vnb, i64 %idxprom571
  %127 = load float* %arrayidx577, align 4, !tbaa !3
  %add578 = fadd float %vnbtot.2.lcssa, %127
  store float %add578, float* %arrayidx577, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next1151 to i32
  %exitcond1152 = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond1152, label %for.end583, label %for.body

for.end583:                                       ; preds = %for.end568, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl3320(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab) #0 {
entry:
  %0 = load i32* %iinr, align 4, !tbaa !0
  %idxprom = sext i32 %0 to i64
  %arrayidx1 = getelementptr inbounds float* %charge, i64 %idxprom
  %1 = load float* %arrayidx1, align 4, !tbaa !3
  %add = add nsw i32 %0, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds float* %charge, i64 %idxprom2
  %2 = load float* %arrayidx3, align 4, !tbaa !3
  %mul = fmul float %1, %facel
  %mul4 = fmul float %2, %facel
  %mul5 = shl i32 %ntype, 1
  %arrayidx7 = getelementptr inbounds i32* %type, i64 %idxprom
  %3 = load i32* %arrayidx7, align 4, !tbaa !0
  %mul8 = mul nsw i32 %mul5, %3
  %cmp775 = icmp sgt i32 %nri, 0
  br i1 %cmp775, label %for.body, label %for.end419

for.body:                                         ; preds = %entry, %for.end.for.body_crit_edge
  %4 = phi i32 [ %.pre, %for.end.for.body_crit_edge ], [ %0, %entry ]
  %indvars.iv777 = phi i64 [ %indvars.iv.next778, %for.end.for.body_crit_edge ], [ 0, %entry ]
  %arrayidx10 = getelementptr inbounds i32* %shift, i64 %indvars.iv777
  %5 = load i32* %arrayidx10, align 4, !tbaa !0
  %mul11 = mul nsw i32 %5, 3
  %idxprom12 = sext i32 %mul11 to i64
  %arrayidx13 = getelementptr inbounds float* %shiftvec, i64 %idxprom12
  %6 = load float* %arrayidx13, align 4, !tbaa !3
  %add14 = add nsw i32 %mul11, 1
  %idxprom15 = sext i32 %add14 to i64
  %arrayidx16 = getelementptr inbounds float* %shiftvec, i64 %idxprom15
  %7 = load float* %arrayidx16, align 4, !tbaa !3
  %add17 = add nsw i32 %mul11, 2
  %idxprom18 = sext i32 %add17 to i64
  %arrayidx19 = getelementptr inbounds float* %shiftvec, i64 %idxprom18
  %8 = load float* %arrayidx19, align 4, !tbaa !3
  %mul22 = mul nsw i32 %4, 3
  %arrayidx24 = getelementptr inbounds i32* %jindex, i64 %indvars.iv777
  %9 = load i32* %arrayidx24, align 4, !tbaa !0
  %indvars.iv.next778 = add i64 %indvars.iv777, 1
  %arrayidx27 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next778
  %10 = load i32* %arrayidx27, align 4, !tbaa !0
  %idxprom28 = sext i32 %mul22 to i64
  %arrayidx29 = getelementptr inbounds float* %pos, i64 %idxprom28
  %11 = load float* %arrayidx29, align 4, !tbaa !3
  %add30 = fadd float %6, %11
  %add31 = add nsw i32 %mul22, 1
  %idxprom32 = sext i32 %add31 to i64
  %arrayidx33 = getelementptr inbounds float* %pos, i64 %idxprom32
  %12 = load float* %arrayidx33, align 4, !tbaa !3
  %add34 = fadd float %7, %12
  %add35 = add nsw i32 %mul22, 2
  %idxprom36 = sext i32 %add35 to i64
  %arrayidx37 = getelementptr inbounds float* %pos, i64 %idxprom36
  %13 = load float* %arrayidx37, align 4, !tbaa !3
  %add38 = fadd float %8, %13
  %add39 = add nsw i32 %mul22, 3
  %idxprom40 = sext i32 %add39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %14 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = fadd float %6, %14
  %add43 = add nsw i32 %mul22, 4
  %idxprom44 = sext i32 %add43 to i64
  %arrayidx45 = getelementptr inbounds float* %pos, i64 %idxprom44
  %15 = load float* %arrayidx45, align 4, !tbaa !3
  %add46 = fadd float %7, %15
  %add47 = add nsw i32 %mul22, 5
  %idxprom48 = sext i32 %add47 to i64
  %arrayidx49 = getelementptr inbounds float* %pos, i64 %idxprom48
  %16 = load float* %arrayidx49, align 4, !tbaa !3
  %add50 = fadd float %8, %16
  %add51 = add nsw i32 %mul22, 6
  %idxprom52 = sext i32 %add51 to i64
  %arrayidx53 = getelementptr inbounds float* %pos, i64 %idxprom52
  %17 = load float* %arrayidx53, align 4, !tbaa !3
  %add54 = fadd float %6, %17
  %add55 = add nsw i32 %mul22, 7
  %idxprom56 = sext i32 %add55 to i64
  %arrayidx57 = getelementptr inbounds float* %pos, i64 %idxprom56
  %18 = load float* %arrayidx57, align 4, !tbaa !3
  %add58 = fadd float %7, %18
  %add59 = add nsw i32 %mul22, 8
  %idxprom60 = sext i32 %add59 to i64
  %arrayidx61 = getelementptr inbounds float* %pos, i64 %idxprom60
  %19 = load float* %arrayidx61, align 4, !tbaa !3
  %add62 = fadd float %8, %19
  %cmp64752 = icmp slt i32 %9, %10
  br i1 %cmp64752, label %for.body65.lr.ph, label %for.end

for.body65.lr.ph:                                 ; preds = %for.body
  %20 = sext i32 %9 to i64
  br label %for.body65

for.body65:                                       ; preds = %for.body65.lr.ph, %for.body65
  %indvars.iv = phi i64 [ %20, %for.body65.lr.ph ], [ %indvars.iv.next, %for.body65 ]
  %vctot.0763 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add301, %for.body65 ]
  %vnbtot.0762 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add197, %for.body65 ]
  %fix1.0761 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add207, %for.body65 ]
  %fiy1.0760 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add208, %for.body65 ]
  %fiz1.0759 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add209, %for.body65 ]
  %fix2.0758 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add260, %for.body65 ]
  %fiy2.0757 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add261, %for.body65 ]
  %fiz2.0756 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add262, %for.body65 ]
  %fix3.0755 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add305, %for.body65 ]
  %fiy3.0754 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add306, %for.body65 ]
  %fiz3.0753 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add307, %for.body65 ]
  %arrayidx67 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %21 = load i32* %arrayidx67, align 4, !tbaa !0
  %mul68 = mul nsw i32 %21, 3
  %idxprom69 = sext i32 %mul68 to i64
  %arrayidx70 = getelementptr inbounds float* %pos, i64 %idxprom69
  %22 = load float* %arrayidx70, align 4, !tbaa !3
  %add71 = add nsw i32 %mul68, 1
  %idxprom72 = sext i32 %add71 to i64
  %arrayidx73 = getelementptr inbounds float* %pos, i64 %idxprom72
  %23 = load float* %arrayidx73, align 4, !tbaa !3
  %add74 = add nsw i32 %mul68, 2
  %idxprom75 = sext i32 %add74 to i64
  %arrayidx76 = getelementptr inbounds float* %pos, i64 %idxprom75
  %24 = load float* %arrayidx76, align 4, !tbaa !3
  %sub = fsub float %add30, %22
  %sub77 = fsub float %add34, %23
  %sub78 = fsub float %add38, %24
  %mul79 = fmul float %sub, %sub
  %mul80 = fmul float %sub77, %sub77
  %add81 = fadd float %mul79, %mul80
  %mul82 = fmul float %sub78, %sub78
  %add83 = fadd float %add81, %mul82
  %sub84 = fsub float %add42, %22
  %sub85 = fsub float %add46, %23
  %sub86 = fsub float %add50, %24
  %mul87 = fmul float %sub84, %sub84
  %mul88 = fmul float %sub85, %sub85
  %add89 = fadd float %mul87, %mul88
  %mul90 = fmul float %sub86, %sub86
  %add91 = fadd float %add89, %mul90
  %sub92 = fsub float %add54, %22
  %sub93 = fsub float %add58, %23
  %sub94 = fsub float %add62, %24
  %mul95 = fmul float %sub92, %sub92
  %mul96 = fmul float %sub93, %sub93
  %add97 = fadd float %mul95, %mul96
  %mul98 = fmul float %sub94, %sub94
  %add99 = fadd float %add97, %mul98
  %conv = fpext float %add83 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv100 = fptrunc double %div to float
  %conv101 = fpext float %add91 to double
  %call102 = tail call double @sqrt(double %conv101) #2
  %div103 = fdiv double 1.000000e+00, %call102
  %conv104 = fptrunc double %div103 to float
  %conv105 = fpext float %add99 to double
  %call106 = tail call double @sqrt(double %conv105) #2
  %div107 = fdiv double 1.000000e+00, %call106
  %conv108 = fptrunc double %div107 to float
  %mul109 = fmul float %add83, %conv100
  %mul110 = fmul float %mul109, %tabscale
  %conv111 = fptosi float %mul110 to i32
  %conv112 = sitofp i32 %conv111 to float
  %sub113 = fsub float %mul110, %conv112
  %mul114 = fmul float %sub113, %sub113
  %mul115 = mul nsw i32 %conv111, 12
  %idxprom116 = sext i32 %21 to i64
  %arrayidx117 = getelementptr inbounds float* %charge, i64 %idxprom116
  %25 = load float* %arrayidx117, align 4, !tbaa !3
  %mul118 = fmul float %mul, %25
  %idxprom119 = sext i32 %mul115 to i64
  %arrayidx120 = getelementptr inbounds float* %VFtab, i64 %idxprom119
  %26 = load float* %arrayidx120, align 4, !tbaa !3
  %add121742 = or i32 %mul115, 1
  %idxprom122 = sext i32 %add121742 to i64
  %arrayidx123 = getelementptr inbounds float* %VFtab, i64 %idxprom122
  %27 = load float* %arrayidx123, align 4, !tbaa !3
  %add124743 = or i32 %mul115, 2
  %idxprom125 = sext i32 %add124743 to i64
  %arrayidx126 = getelementptr inbounds float* %VFtab, i64 %idxprom125
  %28 = load float* %arrayidx126, align 4, !tbaa !3
  %mul127 = fmul float %sub113, %28
  %add128744 = or i32 %mul115, 3
  %idxprom129 = sext i32 %add128744 to i64
  %arrayidx130 = getelementptr inbounds float* %VFtab, i64 %idxprom129
  %29 = load float* %arrayidx130, align 4, !tbaa !3
  %mul131 = fmul float %mul114, %29
  %add132 = fadd float %27, %mul127
  %add133 = fadd float %add132, %mul131
  %mul134 = fmul float %sub113, %add133
  %add135 = fadd float %26, %mul134
  %add136 = fadd float %mul127, %add133
  %mul137 = fmul float %mul131, 2.000000e+00
  %add138 = fadd float %mul137, %add136
  %mul139 = fmul float %mul118, %add135
  %mul140 = fmul float %mul118, %add138
  %arrayidx142 = getelementptr inbounds i32* %type, i64 %idxprom116
  %30 = load i32* %arrayidx142, align 4, !tbaa !0
  %mul143 = shl nsw i32 %30, 1
  %add144 = add nsw i32 %mul143, %mul8
  %idxprom145 = sext i32 %add144 to i64
  %arrayidx146 = getelementptr inbounds float* %nbfp, i64 %idxprom145
  %31 = load float* %arrayidx146, align 4, !tbaa !3
  %add147745 = or i32 %add144, 1
  %idxprom148 = sext i32 %add147745 to i64
  %arrayidx149 = getelementptr inbounds float* %nbfp, i64 %idxprom148
  %32 = load float* %arrayidx149, align 4, !tbaa !3
  %add150 = add nsw i32 %mul115, 4
  %idxprom151 = sext i32 %add150 to i64
  %arrayidx152 = getelementptr inbounds float* %VFtab, i64 %idxprom151
  %33 = load float* %arrayidx152, align 4, !tbaa !3
  %add153 = add nsw i32 %mul115, 5
  %idxprom154 = sext i32 %add153 to i64
  %arrayidx155 = getelementptr inbounds float* %VFtab, i64 %idxprom154
  %34 = load float* %arrayidx155, align 4, !tbaa !3
  %add156 = add nsw i32 %mul115, 6
  %idxprom157 = sext i32 %add156 to i64
  %arrayidx158 = getelementptr inbounds float* %VFtab, i64 %idxprom157
  %35 = load float* %arrayidx158, align 4, !tbaa !3
  %mul159 = fmul float %sub113, %35
  %add160 = add nsw i32 %mul115, 7
  %idxprom161 = sext i32 %add160 to i64
  %arrayidx162 = getelementptr inbounds float* %VFtab, i64 %idxprom161
  %36 = load float* %arrayidx162, align 4, !tbaa !3
  %mul163 = fmul float %mul114, %36
  %add164 = fadd float %34, %mul159
  %add165 = fadd float %add164, %mul163
  %mul166 = fmul float %sub113, %add165
  %add167 = fadd float %33, %mul166
  %add168 = fadd float %mul159, %add165
  %mul169 = fmul float %mul163, 2.000000e+00
  %add170 = fadd float %mul169, %add168
  %mul171 = fmul float %31, %add167
  %mul172 = fmul float %31, %add170
  %add173 = add nsw i32 %mul115, 8
  %idxprom174 = sext i32 %add173 to i64
  %arrayidx175 = getelementptr inbounds float* %VFtab, i64 %idxprom174
  %37 = load float* %arrayidx175, align 4, !tbaa !3
  %add176 = add nsw i32 %mul115, 9
  %idxprom177 = sext i32 %add176 to i64
  %arrayidx178 = getelementptr inbounds float* %VFtab, i64 %idxprom177
  %38 = load float* %arrayidx178, align 4, !tbaa !3
  %add179 = add nsw i32 %mul115, 10
  %idxprom180 = sext i32 %add179 to i64
  %arrayidx181 = getelementptr inbounds float* %VFtab, i64 %idxprom180
  %39 = load float* %arrayidx181, align 4, !tbaa !3
  %mul182 = fmul float %sub113, %39
  %add183 = add nsw i32 %mul115, 11
  %idxprom184 = sext i32 %add183 to i64
  %arrayidx185 = getelementptr inbounds float* %VFtab, i64 %idxprom184
  %40 = load float* %arrayidx185, align 4, !tbaa !3
  %mul186 = fmul float %mul114, %40
  %add187 = fadd float %38, %mul182
  %add188 = fadd float %add187, %mul186
  %mul189 = fmul float %sub113, %add188
  %add190 = fadd float %37, %mul189
  %add191 = fadd float %mul182, %add188
  %mul192 = fmul float %mul186, 2.000000e+00
  %add193 = fadd float %mul192, %add191
  %mul194 = fmul float %32, %add190
  %mul195 = fmul float %32, %add193
  %add196 = fadd float %vnbtot.0762, %mul171
  %add197 = fadd float %add196, %mul194
  %add198 = fadd float %mul140, %mul172
  %add199 = fadd float %add198, %mul195
  %mul200 = fmul float %add199, %tabscale
  %41 = fmul float %conv100, %mul200
  %mul202 = fsub float -0.000000e+00, %41
  %add203 = fadd float %vctot.0763, %mul139
  %mul204 = fmul float %sub, %mul202
  %mul205 = fmul float %sub77, %mul202
  %mul206 = fmul float %sub78, %mul202
  %add207 = fadd float %fix1.0761, %mul204
  %add208 = fadd float %fiy1.0760, %mul205
  %add209 = fadd float %fiz1.0759, %mul206
  %arrayidx211 = getelementptr inbounds float* %faction, i64 %idxprom69
  %42 = load float* %arrayidx211, align 4, !tbaa !3
  %sub212 = fsub float %42, %mul204
  %arrayidx215 = getelementptr inbounds float* %faction, i64 %idxprom72
  %43 = load float* %arrayidx215, align 4, !tbaa !3
  %sub216 = fsub float %43, %mul205
  %arrayidx219 = getelementptr inbounds float* %faction, i64 %idxprom75
  %44 = load float* %arrayidx219, align 4, !tbaa !3
  %sub220 = fsub float %44, %mul206
  %mul221 = fmul float %add91, %conv104
  %mul222 = fmul float %mul221, %tabscale
  %conv223 = fptosi float %mul222 to i32
  %conv224 = sitofp i32 %conv223 to float
  %sub225 = fsub float %mul222, %conv224
  %mul226 = fmul float %sub225, %sub225
  %mul227 = mul nsw i32 %conv223, 12
  %mul230 = fmul float %mul4, %25
  %idxprom231 = sext i32 %mul227 to i64
  %arrayidx232 = getelementptr inbounds float* %VFtab, i64 %idxprom231
  %45 = load float* %arrayidx232, align 4, !tbaa !3
  %add233746 = or i32 %mul227, 1
  %idxprom234 = sext i32 %add233746 to i64
  %arrayidx235 = getelementptr inbounds float* %VFtab, i64 %idxprom234
  %46 = load float* %arrayidx235, align 4, !tbaa !3
  %add236747 = or i32 %mul227, 2
  %idxprom237 = sext i32 %add236747 to i64
  %arrayidx238 = getelementptr inbounds float* %VFtab, i64 %idxprom237
  %47 = load float* %arrayidx238, align 4, !tbaa !3
  %mul239 = fmul float %sub225, %47
  %add240748 = or i32 %mul227, 3
  %idxprom241 = sext i32 %add240748 to i64
  %arrayidx242 = getelementptr inbounds float* %VFtab, i64 %idxprom241
  %48 = load float* %arrayidx242, align 4, !tbaa !3
  %mul243 = fmul float %mul226, %48
  %add244 = fadd float %46, %mul239
  %add245 = fadd float %add244, %mul243
  %mul246 = fmul float %sub225, %add245
  %add247 = fadd float %45, %mul246
  %add248 = fadd float %mul239, %add245
  %mul249 = fmul float %mul243, 2.000000e+00
  %add250 = fadd float %mul249, %add248
  %mul251 = fmul float %mul230, %add247
  %mul252 = fmul float %mul230, %add250
  %mul253 = fmul float %mul252, %tabscale
  %49 = fmul float %conv104, %mul253
  %mul255 = fsub float -0.000000e+00, %49
  %add256 = fadd float %add203, %mul251
  %mul257 = fmul float %sub84, %mul255
  %mul258 = fmul float %sub85, %mul255
  %mul259 = fmul float %sub86, %mul255
  %add260 = fadd float %fix2.0758, %mul257
  %add261 = fadd float %fiy2.0757, %mul258
  %add262 = fadd float %fiz2.0756, %mul259
  %sub263 = fsub float %sub212, %mul257
  %sub264 = fsub float %sub216, %mul258
  %sub265 = fsub float %sub220, %mul259
  %mul266 = fmul float %add99, %conv108
  %mul267 = fmul float %mul266, %tabscale
  %conv268 = fptosi float %mul267 to i32
  %conv269 = sitofp i32 %conv268 to float
  %sub270 = fsub float %mul267, %conv269
  %mul271 = fmul float %sub270, %sub270
  %mul272 = mul nsw i32 %conv268, 12
  %idxprom276 = sext i32 %mul272 to i64
  %arrayidx277 = getelementptr inbounds float* %VFtab, i64 %idxprom276
  %50 = load float* %arrayidx277, align 4, !tbaa !3
  %add278749 = or i32 %mul272, 1
  %idxprom279 = sext i32 %add278749 to i64
  %arrayidx280 = getelementptr inbounds float* %VFtab, i64 %idxprom279
  %51 = load float* %arrayidx280, align 4, !tbaa !3
  %add281750 = or i32 %mul272, 2
  %idxprom282 = sext i32 %add281750 to i64
  %arrayidx283 = getelementptr inbounds float* %VFtab, i64 %idxprom282
  %52 = load float* %arrayidx283, align 4, !tbaa !3
  %mul284 = fmul float %sub270, %52
  %add285751 = or i32 %mul272, 3
  %idxprom286 = sext i32 %add285751 to i64
  %arrayidx287 = getelementptr inbounds float* %VFtab, i64 %idxprom286
  %53 = load float* %arrayidx287, align 4, !tbaa !3
  %mul288 = fmul float %mul271, %53
  %add289 = fadd float %51, %mul284
  %add290 = fadd float %add289, %mul288
  %mul291 = fmul float %sub270, %add290
  %add292 = fadd float %50, %mul291
  %add293 = fadd float %mul284, %add290
  %mul294 = fmul float %mul288, 2.000000e+00
  %add295 = fadd float %mul294, %add293
  %mul296 = fmul float %mul230, %add292
  %mul297 = fmul float %mul230, %add295
  %mul298 = fmul float %mul297, %tabscale
  %54 = fmul float %conv108, %mul298
  %mul300 = fsub float -0.000000e+00, %54
  %add301 = fadd float %add256, %mul296
  %mul302 = fmul float %sub92, %mul300
  %mul303 = fmul float %sub93, %mul300
  %mul304 = fmul float %sub94, %mul300
  %add305 = fadd float %fix3.0755, %mul302
  %add306 = fadd float %fiy3.0754, %mul303
  %add307 = fadd float %fiz3.0753, %mul304
  %sub308 = fsub float %sub263, %mul302
  store float %sub308, float* %arrayidx211, align 4, !tbaa !3
  %sub311 = fsub float %sub264, %mul303
  store float %sub311, float* %arrayidx215, align 4, !tbaa !3
  %sub315 = fsub float %sub265, %mul304
  store float %sub315, float* %arrayidx219, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %55 = trunc i64 %indvars.iv.next to i32
  %cmp64 = icmp slt i32 %55, %10
  br i1 %cmp64, label %for.body65, label %for.end

for.end:                                          ; preds = %for.body65, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add301, %for.body65 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add197, %for.body65 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add207, %for.body65 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add208, %for.body65 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add209, %for.body65 ]
  %fix2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add260, %for.body65 ]
  %fiy2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add261, %for.body65 ]
  %fiz2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add262, %for.body65 ]
  %fix3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add305, %for.body65 ]
  %fiy3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add306, %for.body65 ]
  %fiz3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add307, %for.body65 ]
  %arrayidx320 = getelementptr inbounds float* %faction, i64 %idxprom28
  %56 = load float* %arrayidx320, align 4, !tbaa !3
  %add321 = fadd float %fix1.0.lcssa, %56
  store float %add321, float* %arrayidx320, align 4, !tbaa !3
  %arrayidx326 = getelementptr inbounds float* %faction, i64 %idxprom32
  %57 = load float* %arrayidx326, align 4, !tbaa !3
  %add327 = fadd float %fiy1.0.lcssa, %57
  store float %add327, float* %arrayidx326, align 4, !tbaa !3
  %arrayidx333 = getelementptr inbounds float* %faction, i64 %idxprom36
  %58 = load float* %arrayidx333, align 4, !tbaa !3
  %add334 = fadd float %fiz1.0.lcssa, %58
  store float %add334, float* %arrayidx333, align 4, !tbaa !3
  %arrayidx340 = getelementptr inbounds float* %faction, i64 %idxprom40
  %59 = load float* %arrayidx340, align 4, !tbaa !3
  %add341 = fadd float %fix2.0.lcssa, %59
  store float %add341, float* %arrayidx340, align 4, !tbaa !3
  %arrayidx347 = getelementptr inbounds float* %faction, i64 %idxprom44
  %60 = load float* %arrayidx347, align 4, !tbaa !3
  %add348 = fadd float %fiy2.0.lcssa, %60
  store float %add348, float* %arrayidx347, align 4, !tbaa !3
  %arrayidx354 = getelementptr inbounds float* %faction, i64 %idxprom48
  %61 = load float* %arrayidx354, align 4, !tbaa !3
  %add355 = fadd float %fiz2.0.lcssa, %61
  store float %add355, float* %arrayidx354, align 4, !tbaa !3
  %arrayidx361 = getelementptr inbounds float* %faction, i64 %idxprom52
  %62 = load float* %arrayidx361, align 4, !tbaa !3
  %add362 = fadd float %fix3.0.lcssa, %62
  store float %add362, float* %arrayidx361, align 4, !tbaa !3
  %arrayidx368 = getelementptr inbounds float* %faction, i64 %idxprom56
  %63 = load float* %arrayidx368, align 4, !tbaa !3
  %add369 = fadd float %fiy3.0.lcssa, %63
  store float %add369, float* %arrayidx368, align 4, !tbaa !3
  %arrayidx375 = getelementptr inbounds float* %faction, i64 %idxprom60
  %64 = load float* %arrayidx375, align 4, !tbaa !3
  %add376 = fadd float %fiz3.0.lcssa, %64
  store float %add376, float* %arrayidx375, align 4, !tbaa !3
  %arrayidx381 = getelementptr inbounds float* %fshift, i64 %idxprom12
  %65 = load float* %arrayidx381, align 4, !tbaa !3
  %add382 = fadd float %fix1.0.lcssa, %65
  %add383 = fadd float %fix2.0.lcssa, %add382
  %add384 = fadd float %fix3.0.lcssa, %add383
  store float %add384, float* %arrayidx381, align 4, !tbaa !3
  %arrayidx389 = getelementptr inbounds float* %fshift, i64 %idxprom15
  %66 = load float* %arrayidx389, align 4, !tbaa !3
  %add390 = fadd float %fiy1.0.lcssa, %66
  %add391 = fadd float %fiy2.0.lcssa, %add390
  %add392 = fadd float %fiy3.0.lcssa, %add391
  store float %add392, float* %arrayidx389, align 4, !tbaa !3
  %arrayidx398 = getelementptr inbounds float* %fshift, i64 %idxprom18
  %67 = load float* %arrayidx398, align 4, !tbaa !3
  %add399 = fadd float %fiz1.0.lcssa, %67
  %add400 = fadd float %fiz2.0.lcssa, %add399
  %add401 = fadd float %fiz3.0.lcssa, %add400
  store float %add401, float* %arrayidx398, align 4, !tbaa !3
  %arrayidx406 = getelementptr inbounds i32* %gid, i64 %indvars.iv777
  %68 = load i32* %arrayidx406, align 4, !tbaa !0
  %idxprom407 = sext i32 %68 to i64
  %arrayidx408 = getelementptr inbounds float* %Vc, i64 %idxprom407
  %69 = load float* %arrayidx408, align 4, !tbaa !3
  %add409 = fadd float %vctot.0.lcssa, %69
  store float %add409, float* %arrayidx408, align 4, !tbaa !3
  %arrayidx413 = getelementptr inbounds float* %Vnb, i64 %idxprom407
  %70 = load float* %arrayidx413, align 4, !tbaa !3
  %add414 = fadd float %vnbtot.0.lcssa, %70
  store float %add414, float* %arrayidx413, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next778 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end419, label %for.end.for.body_crit_edge

for.end.for.body_crit_edge:                       ; preds = %for.end
  %arrayidx21.phi.trans.insert = getelementptr inbounds i32* %iinr, i64 %indvars.iv.next778
  %.pre = load i32* %arrayidx21.phi.trans.insert, align 4, !tbaa !0
  br label %for.body

for.end419:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl3330(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* %VFtab) #0 {
entry:
  %0 = load i32* %iinr, align 4, !tbaa !0
  %idxprom = sext i32 %0 to i64
  %arrayidx1 = getelementptr inbounds float* %charge, i64 %idxprom
  %1 = load float* %arrayidx1, align 4, !tbaa !3
  %add = add nsw i32 %0, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds float* %charge, i64 %idxprom2
  %2 = load float* %arrayidx3, align 4, !tbaa !3
  %mul = fmul float %1, %facel
  %mul4 = fmul float %1, %mul
  %mul6 = fmul float %mul, %2
  %mul7 = fmul float %2, %facel
  %mul8 = fmul float %2, %mul7
  %mul9 = shl i32 %ntype, 1
  %arrayidx11 = getelementptr inbounds i32* %type, i64 %idxprom
  %3 = load i32* %arrayidx11, align 4, !tbaa !0
  %mul12 = mul nsw i32 %mul9, %3
  %mul15 = shl nsw i32 %3, 1
  %add16 = add nsw i32 %mul12, %mul15
  %idxprom17 = sext i32 %add16 to i64
  %arrayidx18 = getelementptr inbounds float* %nbfp, i64 %idxprom17
  %4 = load float* %arrayidx18, align 4, !tbaa !3
  %add191487 = or i32 %add16, 1
  %idxprom20 = sext i32 %add191487 to i64
  %arrayidx21 = getelementptr inbounds float* %nbfp, i64 %idxprom20
  %5 = load float* %arrayidx21, align 4, !tbaa !3
  %cmp1538 = icmp sgt i32 %nri, 0
  br i1 %cmp1538, label %for.body, label %for.end792

for.body:                                         ; preds = %entry, %for.end.for.body_crit_edge
  %6 = phi i32 [ %.pre, %for.end.for.body_crit_edge ], [ %0, %entry ]
  %indvars.iv1540 = phi i64 [ %indvars.iv.next1541, %for.end.for.body_crit_edge ], [ 0, %entry ]
  %arrayidx23 = getelementptr inbounds i32* %shift, i64 %indvars.iv1540
  %7 = load i32* %arrayidx23, align 4, !tbaa !0
  %mul24 = mul nsw i32 %7, 3
  %idxprom25 = sext i32 %mul24 to i64
  %arrayidx26 = getelementptr inbounds float* %shiftvec, i64 %idxprom25
  %8 = load float* %arrayidx26, align 4, !tbaa !3
  %add27 = add nsw i32 %mul24, 1
  %idxprom28 = sext i32 %add27 to i64
  %arrayidx29 = getelementptr inbounds float* %shiftvec, i64 %idxprom28
  %9 = load float* %arrayidx29, align 4, !tbaa !3
  %add30 = add nsw i32 %mul24, 2
  %idxprom31 = sext i32 %add30 to i64
  %arrayidx32 = getelementptr inbounds float* %shiftvec, i64 %idxprom31
  %10 = load float* %arrayidx32, align 4, !tbaa !3
  %mul35 = mul nsw i32 %6, 3
  %arrayidx37 = getelementptr inbounds i32* %jindex, i64 %indvars.iv1540
  %11 = load i32* %arrayidx37, align 4, !tbaa !0
  %indvars.iv.next1541 = add i64 %indvars.iv1540, 1
  %arrayidx40 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next1541
  %12 = load i32* %arrayidx40, align 4, !tbaa !0
  %idxprom41 = sext i32 %mul35 to i64
  %arrayidx42 = getelementptr inbounds float* %pos, i64 %idxprom41
  %13 = load float* %arrayidx42, align 4, !tbaa !3
  %add43 = fadd float %8, %13
  %add44 = add nsw i32 %mul35, 1
  %idxprom45 = sext i32 %add44 to i64
  %arrayidx46 = getelementptr inbounds float* %pos, i64 %idxprom45
  %14 = load float* %arrayidx46, align 4, !tbaa !3
  %add47 = fadd float %9, %14
  %add48 = add nsw i32 %mul35, 2
  %idxprom49 = sext i32 %add48 to i64
  %arrayidx50 = getelementptr inbounds float* %pos, i64 %idxprom49
  %15 = load float* %arrayidx50, align 4, !tbaa !3
  %add51 = fadd float %10, %15
  %add52 = add nsw i32 %mul35, 3
  %idxprom53 = sext i32 %add52 to i64
  %arrayidx54 = getelementptr inbounds float* %pos, i64 %idxprom53
  %16 = load float* %arrayidx54, align 4, !tbaa !3
  %add55 = fadd float %8, %16
  %add56 = add nsw i32 %mul35, 4
  %idxprom57 = sext i32 %add56 to i64
  %arrayidx58 = getelementptr inbounds float* %pos, i64 %idxprom57
  %17 = load float* %arrayidx58, align 4, !tbaa !3
  %add59 = fadd float %9, %17
  %add60 = add nsw i32 %mul35, 5
  %idxprom61 = sext i32 %add60 to i64
  %arrayidx62 = getelementptr inbounds float* %pos, i64 %idxprom61
  %18 = load float* %arrayidx62, align 4, !tbaa !3
  %add63 = fadd float %10, %18
  %add64 = add nsw i32 %mul35, 6
  %idxprom65 = sext i32 %add64 to i64
  %arrayidx66 = getelementptr inbounds float* %pos, i64 %idxprom65
  %19 = load float* %arrayidx66, align 4, !tbaa !3
  %add67 = fadd float %8, %19
  %add68 = add nsw i32 %mul35, 7
  %idxprom69 = sext i32 %add68 to i64
  %arrayidx70 = getelementptr inbounds float* %pos, i64 %idxprom69
  %20 = load float* %arrayidx70, align 4, !tbaa !3
  %add71 = fadd float %9, %20
  %add72 = add nsw i32 %mul35, 8
  %idxprom73 = sext i32 %add72 to i64
  %arrayidx74 = getelementptr inbounds float* %pos, i64 %idxprom73
  %21 = load float* %arrayidx74, align 4, !tbaa !3
  %add75 = fadd float %10, %21
  %cmp771515 = icmp slt i32 %11, %12
  br i1 %cmp771515, label %for.body78.lr.ph, label %for.end

for.body78.lr.ph:                                 ; preds = %for.body
  %22 = sext i32 %11 to i64
  br label %for.body78

for.body78:                                       ; preds = %for.body78.lr.ph, %for.body78
  %indvars.iv = phi i64 [ %22, %for.body78.lr.ph ], [ %indvars.iv.next, %for.body78 ]
  %vctot.01526 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add673, %for.body78 ]
  %vnbtot.01525 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add288, %for.body78 ]
  %fix1.01524 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add399, %for.body78 ]
  %fiy1.01523 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add400, %for.body78 ]
  %fiz1.01522 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add401, %for.body78 ]
  %fix2.01521 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add534, %for.body78 ]
  %fiy2.01520 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add535, %for.body78 ]
  %fiz2.01519 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add536, %for.body78 ]
  %fix3.01518 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add677, %for.body78 ]
  %fiy3.01517 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add678, %for.body78 ]
  %fiz3.01516 = phi float [ 0.000000e+00, %for.body78.lr.ph ], [ %add679, %for.body78 ]
  %arrayidx80 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %23 = load i32* %arrayidx80, align 4, !tbaa !0
  %mul81 = mul nsw i32 %23, 3
  %idxprom82 = sext i32 %mul81 to i64
  %arrayidx83 = getelementptr inbounds float* %pos, i64 %idxprom82
  %24 = load float* %arrayidx83, align 4, !tbaa !3
  %add84 = add nsw i32 %mul81, 1
  %idxprom85 = sext i32 %add84 to i64
  %arrayidx86 = getelementptr inbounds float* %pos, i64 %idxprom85
  %25 = load float* %arrayidx86, align 4, !tbaa !3
  %add87 = add nsw i32 %mul81, 2
  %idxprom88 = sext i32 %add87 to i64
  %arrayidx89 = getelementptr inbounds float* %pos, i64 %idxprom88
  %26 = load float* %arrayidx89, align 4, !tbaa !3
  %add90 = add nsw i32 %mul81, 3
  %idxprom91 = sext i32 %add90 to i64
  %arrayidx92 = getelementptr inbounds float* %pos, i64 %idxprom91
  %27 = load float* %arrayidx92, align 4, !tbaa !3
  %add93 = add nsw i32 %mul81, 4
  %idxprom94 = sext i32 %add93 to i64
  %arrayidx95 = getelementptr inbounds float* %pos, i64 %idxprom94
  %28 = load float* %arrayidx95, align 4, !tbaa !3
  %add96 = add nsw i32 %mul81, 5
  %idxprom97 = sext i32 %add96 to i64
  %arrayidx98 = getelementptr inbounds float* %pos, i64 %idxprom97
  %29 = load float* %arrayidx98, align 4, !tbaa !3
  %add99 = add nsw i32 %mul81, 6
  %idxprom100 = sext i32 %add99 to i64
  %arrayidx101 = getelementptr inbounds float* %pos, i64 %idxprom100
  %30 = load float* %arrayidx101, align 4, !tbaa !3
  %add102 = add nsw i32 %mul81, 7
  %idxprom103 = sext i32 %add102 to i64
  %arrayidx104 = getelementptr inbounds float* %pos, i64 %idxprom103
  %31 = load float* %arrayidx104, align 4, !tbaa !3
  %add105 = add nsw i32 %mul81, 8
  %idxprom106 = sext i32 %add105 to i64
  %arrayidx107 = getelementptr inbounds float* %pos, i64 %idxprom106
  %32 = load float* %arrayidx107, align 4, !tbaa !3
  %sub = fsub float %add43, %24
  %sub108 = fsub float %add47, %25
  %sub109 = fsub float %add51, %26
  %mul110 = fmul float %sub, %sub
  %mul111 = fmul float %sub108, %sub108
  %add112 = fadd float %mul110, %mul111
  %mul113 = fmul float %sub109, %sub109
  %add114 = fadd float %add112, %mul113
  %sub115 = fsub float %add43, %27
  %sub116 = fsub float %add47, %28
  %sub117 = fsub float %add51, %29
  %mul118 = fmul float %sub115, %sub115
  %mul119 = fmul float %sub116, %sub116
  %add120 = fadd float %mul118, %mul119
  %mul121 = fmul float %sub117, %sub117
  %add122 = fadd float %add120, %mul121
  %sub123 = fsub float %add43, %30
  %sub124 = fsub float %add47, %31
  %sub125 = fsub float %add51, %32
  %mul126 = fmul float %sub123, %sub123
  %mul127 = fmul float %sub124, %sub124
  %add128 = fadd float %mul126, %mul127
  %mul129 = fmul float %sub125, %sub125
  %add130 = fadd float %add128, %mul129
  %sub131 = fsub float %add55, %24
  %sub132 = fsub float %add59, %25
  %sub133 = fsub float %add63, %26
  %mul134 = fmul float %sub131, %sub131
  %mul135 = fmul float %sub132, %sub132
  %add136 = fadd float %mul134, %mul135
  %mul137 = fmul float %sub133, %sub133
  %add138 = fadd float %add136, %mul137
  %sub139 = fsub float %add55, %27
  %sub140 = fsub float %add59, %28
  %sub141 = fsub float %add63, %29
  %mul142 = fmul float %sub139, %sub139
  %mul143 = fmul float %sub140, %sub140
  %add144 = fadd float %mul142, %mul143
  %mul145 = fmul float %sub141, %sub141
  %add146 = fadd float %add144, %mul145
  %sub147 = fsub float %add55, %30
  %sub148 = fsub float %add59, %31
  %sub149 = fsub float %add63, %32
  %mul150 = fmul float %sub147, %sub147
  %mul151 = fmul float %sub148, %sub148
  %add152 = fadd float %mul150, %mul151
  %mul153 = fmul float %sub149, %sub149
  %add154 = fadd float %add152, %mul153
  %sub155 = fsub float %add67, %24
  %sub156 = fsub float %add71, %25
  %sub157 = fsub float %add75, %26
  %mul158 = fmul float %sub155, %sub155
  %mul159 = fmul float %sub156, %sub156
  %add160 = fadd float %mul158, %mul159
  %mul161 = fmul float %sub157, %sub157
  %add162 = fadd float %add160, %mul161
  %sub163 = fsub float %add67, %27
  %sub164 = fsub float %add71, %28
  %sub165 = fsub float %add75, %29
  %mul166 = fmul float %sub163, %sub163
  %mul167 = fmul float %sub164, %sub164
  %add168 = fadd float %mul166, %mul167
  %mul169 = fmul float %sub165, %sub165
  %add170 = fadd float %add168, %mul169
  %sub171 = fsub float %add67, %30
  %sub172 = fsub float %add71, %31
  %sub173 = fsub float %add75, %32
  %mul174 = fmul float %sub171, %sub171
  %mul175 = fmul float %sub172, %sub172
  %add176 = fadd float %mul174, %mul175
  %mul177 = fmul float %sub173, %sub173
  %add178 = fadd float %add176, %mul177
  %conv = fpext float %add114 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv179 = fptrunc double %div to float
  %conv180 = fpext float %add138 to double
  %call181 = tail call double @sqrt(double %conv180) #2
  %div182 = fdiv double 1.000000e+00, %call181
  %conv183 = fptrunc double %div182 to float
  %conv184 = fpext float %add162 to double
  %call185 = tail call double @sqrt(double %conv184) #2
  %div186 = fdiv double 1.000000e+00, %call185
  %conv187 = fptrunc double %div186 to float
  %conv188 = fpext float %add122 to double
  %call189 = tail call double @sqrt(double %conv188) #2
  %div190 = fdiv double 1.000000e+00, %call189
  %conv191 = fptrunc double %div190 to float
  %conv192 = fpext float %add146 to double
  %call193 = tail call double @sqrt(double %conv192) #2
  %div194 = fdiv double 1.000000e+00, %call193
  %conv195 = fptrunc double %div194 to float
  %conv196 = fpext float %add170 to double
  %call197 = tail call double @sqrt(double %conv196) #2
  %div198 = fdiv double 1.000000e+00, %call197
  %conv199 = fptrunc double %div198 to float
  %conv200 = fpext float %add130 to double
  %call201 = tail call double @sqrt(double %conv200) #2
  %div202 = fdiv double 1.000000e+00, %call201
  %conv203 = fptrunc double %div202 to float
  %conv204 = fpext float %add154 to double
  %call205 = tail call double @sqrt(double %conv204) #2
  %div206 = fdiv double 1.000000e+00, %call205
  %conv207 = fptrunc double %div206 to float
  %conv208 = fpext float %add178 to double
  %call209 = tail call double @sqrt(double %conv208) #2
  %div210 = fdiv double 1.000000e+00, %call209
  %conv211 = fptrunc double %div210 to float
  %mul212 = fmul float %add114, %conv179
  %mul213 = fmul float %mul212, %tabscale
  %conv214 = fptosi float %mul213 to i32
  %conv215 = sitofp i32 %conv214 to float
  %sub216 = fsub float %mul213, %conv215
  %mul217 = fmul float %sub216, %sub216
  %mul218 = mul nsw i32 %conv214, 12
  %idxprom219 = sext i32 %mul218 to i64
  %arrayidx220 = getelementptr inbounds float* %VFtab, i64 %idxprom219
  %33 = load float* %arrayidx220, align 4, !tbaa !3
  %add2211488 = or i32 %mul218, 1
  %idxprom222 = sext i32 %add2211488 to i64
  %arrayidx223 = getelementptr inbounds float* %VFtab, i64 %idxprom222
  %34 = load float* %arrayidx223, align 4, !tbaa !3
  %add2241489 = or i32 %mul218, 2
  %idxprom225 = sext i32 %add2241489 to i64
  %arrayidx226 = getelementptr inbounds float* %VFtab, i64 %idxprom225
  %35 = load float* %arrayidx226, align 4, !tbaa !3
  %mul227 = fmul float %sub216, %35
  %add2281490 = or i32 %mul218, 3
  %idxprom229 = sext i32 %add2281490 to i64
  %arrayidx230 = getelementptr inbounds float* %VFtab, i64 %idxprom229
  %36 = load float* %arrayidx230, align 4, !tbaa !3
  %mul231 = fmul float %mul217, %36
  %add232 = fadd float %34, %mul227
  %add233 = fadd float %add232, %mul231
  %mul234 = fmul float %sub216, %add233
  %add235 = fadd float %33, %mul234
  %add236 = fadd float %mul227, %add233
  %mul237 = fmul float %mul231, 2.000000e+00
  %add238 = fadd float %mul237, %add236
  %mul239 = fmul float %mul4, %add235
  %mul240 = fmul float %mul4, %add238
  %add241 = add nsw i32 %mul218, 4
  %idxprom242 = sext i32 %add241 to i64
  %arrayidx243 = getelementptr inbounds float* %VFtab, i64 %idxprom242
  %37 = load float* %arrayidx243, align 4, !tbaa !3
  %add244 = add nsw i32 %mul218, 5
  %idxprom245 = sext i32 %add244 to i64
  %arrayidx246 = getelementptr inbounds float* %VFtab, i64 %idxprom245
  %38 = load float* %arrayidx246, align 4, !tbaa !3
  %add247 = add nsw i32 %mul218, 6
  %idxprom248 = sext i32 %add247 to i64
  %arrayidx249 = getelementptr inbounds float* %VFtab, i64 %idxprom248
  %39 = load float* %arrayidx249, align 4, !tbaa !3
  %mul250 = fmul float %sub216, %39
  %add251 = add nsw i32 %mul218, 7
  %idxprom252 = sext i32 %add251 to i64
  %arrayidx253 = getelementptr inbounds float* %VFtab, i64 %idxprom252
  %40 = load float* %arrayidx253, align 4, !tbaa !3
  %mul254 = fmul float %mul217, %40
  %add255 = fadd float %38, %mul250
  %add256 = fadd float %add255, %mul254
  %mul257 = fmul float %sub216, %add256
  %add258 = fadd float %37, %mul257
  %add259 = fadd float %mul250, %add256
  %mul260 = fmul float %mul254, 2.000000e+00
  %add261 = fadd float %mul260, %add259
  %mul262 = fmul float %4, %add258
  %mul263 = fmul float %4, %add261
  %add264 = add nsw i32 %mul218, 8
  %idxprom265 = sext i32 %add264 to i64
  %arrayidx266 = getelementptr inbounds float* %VFtab, i64 %idxprom265
  %41 = load float* %arrayidx266, align 4, !tbaa !3
  %add267 = add nsw i32 %mul218, 9
  %idxprom268 = sext i32 %add267 to i64
  %arrayidx269 = getelementptr inbounds float* %VFtab, i64 %idxprom268
  %42 = load float* %arrayidx269, align 4, !tbaa !3
  %add270 = add nsw i32 %mul218, 10
  %idxprom271 = sext i32 %add270 to i64
  %arrayidx272 = getelementptr inbounds float* %VFtab, i64 %idxprom271
  %43 = load float* %arrayidx272, align 4, !tbaa !3
  %mul273 = fmul float %sub216, %43
  %add274 = add nsw i32 %mul218, 11
  %idxprom275 = sext i32 %add274 to i64
  %arrayidx276 = getelementptr inbounds float* %VFtab, i64 %idxprom275
  %44 = load float* %arrayidx276, align 4, !tbaa !3
  %mul277 = fmul float %mul217, %44
  %add278 = fadd float %42, %mul273
  %add279 = fadd float %add278, %mul277
  %mul280 = fmul float %sub216, %add279
  %add281 = fadd float %41, %mul280
  %add282 = fadd float %mul273, %add279
  %mul283 = fmul float %mul277, 2.000000e+00
  %add284 = fadd float %mul283, %add282
  %mul285 = fmul float %5, %add281
  %mul286 = fmul float %5, %add284
  %add287 = fadd float %vnbtot.01525, %mul262
  %add288 = fadd float %add287, %mul285
  %add289 = fadd float %mul240, %mul263
  %add290 = fadd float %add289, %mul286
  %mul291 = fmul float %add290, %tabscale
  %45 = fmul float %conv179, %mul291
  %mul293 = fsub float -0.000000e+00, %45
  %add294 = fadd float %vctot.01526, %mul239
  %mul295 = fmul float %sub, %mul293
  %mul296 = fmul float %sub108, %mul293
  %mul297 = fmul float %sub109, %mul293
  %add298 = fadd float %fix1.01524, %mul295
  %add299 = fadd float %fiy1.01523, %mul296
  %add300 = fadd float %fiz1.01522, %mul297
  %arrayidx302 = getelementptr inbounds float* %faction, i64 %idxprom82
  %46 = load float* %arrayidx302, align 4, !tbaa !3
  %sub303 = fsub float %46, %mul295
  %arrayidx306 = getelementptr inbounds float* %faction, i64 %idxprom85
  %47 = load float* %arrayidx306, align 4, !tbaa !3
  %sub307 = fsub float %47, %mul296
  %arrayidx310 = getelementptr inbounds float* %faction, i64 %idxprom88
  %48 = load float* %arrayidx310, align 4, !tbaa !3
  %sub311 = fsub float %48, %mul297
  %mul312 = fmul float %add122, %conv191
  %mul313 = fmul float %mul312, %tabscale
  %conv314 = fptosi float %mul313 to i32
  %conv315 = sitofp i32 %conv314 to float
  %sub316 = fsub float %mul313, %conv315
  %mul317 = fmul float %sub316, %sub316
  %mul318 = mul nsw i32 %conv314, 12
  %idxprom319 = sext i32 %mul318 to i64
  %arrayidx320 = getelementptr inbounds float* %VFtab, i64 %idxprom319
  %49 = load float* %arrayidx320, align 4, !tbaa !3
  %add3211491 = or i32 %mul318, 1
  %idxprom322 = sext i32 %add3211491 to i64
  %arrayidx323 = getelementptr inbounds float* %VFtab, i64 %idxprom322
  %50 = load float* %arrayidx323, align 4, !tbaa !3
  %add3241492 = or i32 %mul318, 2
  %idxprom325 = sext i32 %add3241492 to i64
  %arrayidx326 = getelementptr inbounds float* %VFtab, i64 %idxprom325
  %51 = load float* %arrayidx326, align 4, !tbaa !3
  %mul327 = fmul float %sub316, %51
  %add3281493 = or i32 %mul318, 3
  %idxprom329 = sext i32 %add3281493 to i64
  %arrayidx330 = getelementptr inbounds float* %VFtab, i64 %idxprom329
  %52 = load float* %arrayidx330, align 4, !tbaa !3
  %mul331 = fmul float %mul317, %52
  %add332 = fadd float %50, %mul327
  %add333 = fadd float %add332, %mul331
  %mul334 = fmul float %sub316, %add333
  %add335 = fadd float %49, %mul334
  %add336 = fadd float %mul327, %add333
  %mul337 = fmul float %mul331, 2.000000e+00
  %add338 = fadd float %mul337, %add336
  %mul339 = fmul float %mul6, %add335
  %mul340 = fmul float %mul6, %add338
  %mul341 = fmul float %mul340, %tabscale
  %53 = fmul float %conv191, %mul341
  %mul343 = fsub float -0.000000e+00, %53
  %add344 = fadd float %add294, %mul339
  %mul345 = fmul float %sub115, %mul343
  %mul346 = fmul float %sub116, %mul343
  %mul347 = fmul float %sub117, %mul343
  %add348 = fadd float %add298, %mul345
  %add349 = fadd float %add299, %mul346
  %add350 = fadd float %add300, %mul347
  %arrayidx353 = getelementptr inbounds float* %faction, i64 %idxprom91
  %54 = load float* %arrayidx353, align 4, !tbaa !3
  %sub354 = fsub float %54, %mul345
  %arrayidx357 = getelementptr inbounds float* %faction, i64 %idxprom94
  %55 = load float* %arrayidx357, align 4, !tbaa !3
  %sub358 = fsub float %55, %mul346
  %arrayidx361 = getelementptr inbounds float* %faction, i64 %idxprom97
  %56 = load float* %arrayidx361, align 4, !tbaa !3
  %sub362 = fsub float %56, %mul347
  %mul363 = fmul float %add130, %conv203
  %mul364 = fmul float %mul363, %tabscale
  %conv365 = fptosi float %mul364 to i32
  %conv366 = sitofp i32 %conv365 to float
  %sub367 = fsub float %mul364, %conv366
  %mul368 = fmul float %sub367, %sub367
  %mul369 = mul nsw i32 %conv365, 12
  %idxprom370 = sext i32 %mul369 to i64
  %arrayidx371 = getelementptr inbounds float* %VFtab, i64 %idxprom370
  %57 = load float* %arrayidx371, align 4, !tbaa !3
  %add3721494 = or i32 %mul369, 1
  %idxprom373 = sext i32 %add3721494 to i64
  %arrayidx374 = getelementptr inbounds float* %VFtab, i64 %idxprom373
  %58 = load float* %arrayidx374, align 4, !tbaa !3
  %add3751495 = or i32 %mul369, 2
  %idxprom376 = sext i32 %add3751495 to i64
  %arrayidx377 = getelementptr inbounds float* %VFtab, i64 %idxprom376
  %59 = load float* %arrayidx377, align 4, !tbaa !3
  %mul378 = fmul float %sub367, %59
  %add3791496 = or i32 %mul369, 3
  %idxprom380 = sext i32 %add3791496 to i64
  %arrayidx381 = getelementptr inbounds float* %VFtab, i64 %idxprom380
  %60 = load float* %arrayidx381, align 4, !tbaa !3
  %mul382 = fmul float %mul368, %60
  %add383 = fadd float %58, %mul378
  %add384 = fadd float %add383, %mul382
  %mul385 = fmul float %sub367, %add384
  %add386 = fadd float %57, %mul385
  %add387 = fadd float %mul378, %add384
  %mul388 = fmul float %mul382, 2.000000e+00
  %add389 = fadd float %mul388, %add387
  %mul390 = fmul float %mul6, %add386
  %mul391 = fmul float %mul6, %add389
  %mul392 = fmul float %mul391, %tabscale
  %61 = fmul float %conv203, %mul392
  %mul394 = fsub float -0.000000e+00, %61
  %add395 = fadd float %add344, %mul390
  %mul396 = fmul float %sub123, %mul394
  %mul397 = fmul float %sub124, %mul394
  %mul398 = fmul float %sub125, %mul394
  %add399 = fadd float %add348, %mul396
  %add400 = fadd float %add349, %mul397
  %add401 = fadd float %add350, %mul398
  %arrayidx404 = getelementptr inbounds float* %faction, i64 %idxprom100
  %62 = load float* %arrayidx404, align 4, !tbaa !3
  %sub405 = fsub float %62, %mul396
  %arrayidx408 = getelementptr inbounds float* %faction, i64 %idxprom103
  %63 = load float* %arrayidx408, align 4, !tbaa !3
  %sub409 = fsub float %63, %mul397
  %arrayidx412 = getelementptr inbounds float* %faction, i64 %idxprom106
  %64 = load float* %arrayidx412, align 4, !tbaa !3
  %sub413 = fsub float %64, %mul398
  %mul414 = fmul float %add138, %conv183
  %mul415 = fmul float %mul414, %tabscale
  %conv416 = fptosi float %mul415 to i32
  %conv417 = sitofp i32 %conv416 to float
  %sub418 = fsub float %mul415, %conv417
  %mul419 = fmul float %sub418, %sub418
  %mul420 = mul nsw i32 %conv416, 12
  %idxprom421 = sext i32 %mul420 to i64
  %arrayidx422 = getelementptr inbounds float* %VFtab, i64 %idxprom421
  %65 = load float* %arrayidx422, align 4, !tbaa !3
  %add4231497 = or i32 %mul420, 1
  %idxprom424 = sext i32 %add4231497 to i64
  %arrayidx425 = getelementptr inbounds float* %VFtab, i64 %idxprom424
  %66 = load float* %arrayidx425, align 4, !tbaa !3
  %add4261498 = or i32 %mul420, 2
  %idxprom427 = sext i32 %add4261498 to i64
  %arrayidx428 = getelementptr inbounds float* %VFtab, i64 %idxprom427
  %67 = load float* %arrayidx428, align 4, !tbaa !3
  %mul429 = fmul float %sub418, %67
  %add4301499 = or i32 %mul420, 3
  %idxprom431 = sext i32 %add4301499 to i64
  %arrayidx432 = getelementptr inbounds float* %VFtab, i64 %idxprom431
  %68 = load float* %arrayidx432, align 4, !tbaa !3
  %mul433 = fmul float %mul419, %68
  %add434 = fadd float %66, %mul429
  %add435 = fadd float %add434, %mul433
  %mul436 = fmul float %sub418, %add435
  %add437 = fadd float %65, %mul436
  %add438 = fadd float %mul429, %add435
  %mul439 = fmul float %mul433, 2.000000e+00
  %add440 = fadd float %mul439, %add438
  %mul441 = fmul float %mul6, %add437
  %mul442 = fmul float %mul6, %add440
  %mul443 = fmul float %mul442, %tabscale
  %69 = fmul float %conv183, %mul443
  %mul445 = fsub float -0.000000e+00, %69
  %add446 = fadd float %add395, %mul441
  %mul447 = fmul float %sub131, %mul445
  %mul448 = fmul float %sub132, %mul445
  %mul449 = fmul float %sub133, %mul445
  %add450 = fadd float %fix2.01521, %mul447
  %add451 = fadd float %fiy2.01520, %mul448
  %add452 = fadd float %fiz2.01519, %mul449
  %sub453 = fsub float %sub303, %mul447
  %sub454 = fsub float %sub307, %mul448
  %sub455 = fsub float %sub311, %mul449
  %mul456 = fmul float %add146, %conv195
  %mul457 = fmul float %mul456, %tabscale
  %conv458 = fptosi float %mul457 to i32
  %conv459 = sitofp i32 %conv458 to float
  %sub460 = fsub float %mul457, %conv459
  %mul461 = fmul float %sub460, %sub460
  %mul462 = mul nsw i32 %conv458, 12
  %idxprom463 = sext i32 %mul462 to i64
  %arrayidx464 = getelementptr inbounds float* %VFtab, i64 %idxprom463
  %70 = load float* %arrayidx464, align 4, !tbaa !3
  %add4651500 = or i32 %mul462, 1
  %idxprom466 = sext i32 %add4651500 to i64
  %arrayidx467 = getelementptr inbounds float* %VFtab, i64 %idxprom466
  %71 = load float* %arrayidx467, align 4, !tbaa !3
  %add4681501 = or i32 %mul462, 2
  %idxprom469 = sext i32 %add4681501 to i64
  %arrayidx470 = getelementptr inbounds float* %VFtab, i64 %idxprom469
  %72 = load float* %arrayidx470, align 4, !tbaa !3
  %mul471 = fmul float %sub460, %72
  %add4721502 = or i32 %mul462, 3
  %idxprom473 = sext i32 %add4721502 to i64
  %arrayidx474 = getelementptr inbounds float* %VFtab, i64 %idxprom473
  %73 = load float* %arrayidx474, align 4, !tbaa !3
  %mul475 = fmul float %mul461, %73
  %add476 = fadd float %71, %mul471
  %add477 = fadd float %add476, %mul475
  %mul478 = fmul float %sub460, %add477
  %add479 = fadd float %70, %mul478
  %add480 = fadd float %mul471, %add477
  %mul481 = fmul float %mul475, 2.000000e+00
  %add482 = fadd float %mul481, %add480
  %mul483 = fmul float %mul8, %add479
  %mul484 = fmul float %mul8, %add482
  %mul485 = fmul float %mul484, %tabscale
  %74 = fmul float %conv195, %mul485
  %mul487 = fsub float -0.000000e+00, %74
  %add488 = fadd float %add446, %mul483
  %mul489 = fmul float %sub139, %mul487
  %mul490 = fmul float %sub140, %mul487
  %mul491 = fmul float %sub141, %mul487
  %add492 = fadd float %add450, %mul489
  %add493 = fadd float %add451, %mul490
  %add494 = fadd float %add452, %mul491
  %sub495 = fsub float %sub354, %mul489
  %sub496 = fsub float %sub358, %mul490
  %sub497 = fsub float %sub362, %mul491
  %mul498 = fmul float %add154, %conv207
  %mul499 = fmul float %mul498, %tabscale
  %conv500 = fptosi float %mul499 to i32
  %conv501 = sitofp i32 %conv500 to float
  %sub502 = fsub float %mul499, %conv501
  %mul503 = fmul float %sub502, %sub502
  %mul504 = mul nsw i32 %conv500, 12
  %idxprom505 = sext i32 %mul504 to i64
  %arrayidx506 = getelementptr inbounds float* %VFtab, i64 %idxprom505
  %75 = load float* %arrayidx506, align 4, !tbaa !3
  %add5071503 = or i32 %mul504, 1
  %idxprom508 = sext i32 %add5071503 to i64
  %arrayidx509 = getelementptr inbounds float* %VFtab, i64 %idxprom508
  %76 = load float* %arrayidx509, align 4, !tbaa !3
  %add5101504 = or i32 %mul504, 2
  %idxprom511 = sext i32 %add5101504 to i64
  %arrayidx512 = getelementptr inbounds float* %VFtab, i64 %idxprom511
  %77 = load float* %arrayidx512, align 4, !tbaa !3
  %mul513 = fmul float %sub502, %77
  %add5141505 = or i32 %mul504, 3
  %idxprom515 = sext i32 %add5141505 to i64
  %arrayidx516 = getelementptr inbounds float* %VFtab, i64 %idxprom515
  %78 = load float* %arrayidx516, align 4, !tbaa !3
  %mul517 = fmul float %mul503, %78
  %add518 = fadd float %76, %mul513
  %add519 = fadd float %add518, %mul517
  %mul520 = fmul float %sub502, %add519
  %add521 = fadd float %75, %mul520
  %add522 = fadd float %mul513, %add519
  %mul523 = fmul float %mul517, 2.000000e+00
  %add524 = fadd float %mul523, %add522
  %mul525 = fmul float %mul8, %add521
  %mul526 = fmul float %mul8, %add524
  %mul527 = fmul float %mul526, %tabscale
  %79 = fmul float %conv207, %mul527
  %mul529 = fsub float -0.000000e+00, %79
  %add530 = fadd float %add488, %mul525
  %mul531 = fmul float %sub147, %mul529
  %mul532 = fmul float %sub148, %mul529
  %mul533 = fmul float %sub149, %mul529
  %add534 = fadd float %add492, %mul531
  %add535 = fadd float %add493, %mul532
  %add536 = fadd float %add494, %mul533
  %sub537 = fsub float %sub405, %mul531
  %sub538 = fsub float %sub409, %mul532
  %sub539 = fsub float %sub413, %mul533
  %mul540 = fmul float %add162, %conv187
  %mul541 = fmul float %mul540, %tabscale
  %conv542 = fptosi float %mul541 to i32
  %conv543 = sitofp i32 %conv542 to float
  %sub544 = fsub float %mul541, %conv543
  %mul545 = fmul float %sub544, %sub544
  %mul546 = mul nsw i32 %conv542, 12
  %idxprom547 = sext i32 %mul546 to i64
  %arrayidx548 = getelementptr inbounds float* %VFtab, i64 %idxprom547
  %80 = load float* %arrayidx548, align 4, !tbaa !3
  %add5491506 = or i32 %mul546, 1
  %idxprom550 = sext i32 %add5491506 to i64
  %arrayidx551 = getelementptr inbounds float* %VFtab, i64 %idxprom550
  %81 = load float* %arrayidx551, align 4, !tbaa !3
  %add5521507 = or i32 %mul546, 2
  %idxprom553 = sext i32 %add5521507 to i64
  %arrayidx554 = getelementptr inbounds float* %VFtab, i64 %idxprom553
  %82 = load float* %arrayidx554, align 4, !tbaa !3
  %mul555 = fmul float %sub544, %82
  %add5561508 = or i32 %mul546, 3
  %idxprom557 = sext i32 %add5561508 to i64
  %arrayidx558 = getelementptr inbounds float* %VFtab, i64 %idxprom557
  %83 = load float* %arrayidx558, align 4, !tbaa !3
  %mul559 = fmul float %mul545, %83
  %add560 = fadd float %81, %mul555
  %add561 = fadd float %add560, %mul559
  %mul562 = fmul float %sub544, %add561
  %add563 = fadd float %80, %mul562
  %add564 = fadd float %mul555, %add561
  %mul565 = fmul float %mul559, 2.000000e+00
  %add566 = fadd float %mul565, %add564
  %mul567 = fmul float %mul6, %add563
  %mul568 = fmul float %mul6, %add566
  %mul569 = fmul float %mul568, %tabscale
  %84 = fmul float %conv187, %mul569
  %mul571 = fsub float -0.000000e+00, %84
  %add572 = fadd float %add530, %mul567
  %mul573 = fmul float %sub155, %mul571
  %mul574 = fmul float %sub156, %mul571
  %mul575 = fmul float %sub157, %mul571
  %add576 = fadd float %fix3.01518, %mul573
  %add577 = fadd float %fiy3.01517, %mul574
  %add578 = fadd float %fiz3.01516, %mul575
  %sub579 = fsub float %sub453, %mul573
  store float %sub579, float* %arrayidx302, align 4, !tbaa !3
  %sub582 = fsub float %sub454, %mul574
  store float %sub582, float* %arrayidx306, align 4, !tbaa !3
  %sub586 = fsub float %sub455, %mul575
  store float %sub586, float* %arrayidx310, align 4, !tbaa !3
  %mul590 = fmul float %add170, %conv199
  %mul591 = fmul float %mul590, %tabscale
  %conv592 = fptosi float %mul591 to i32
  %conv593 = sitofp i32 %conv592 to float
  %sub594 = fsub float %mul591, %conv593
  %mul595 = fmul float %sub594, %sub594
  %mul596 = mul nsw i32 %conv592, 12
  %idxprom597 = sext i32 %mul596 to i64
  %arrayidx598 = getelementptr inbounds float* %VFtab, i64 %idxprom597
  %85 = load float* %arrayidx598, align 4, !tbaa !3
  %add5991509 = or i32 %mul596, 1
  %idxprom600 = sext i32 %add5991509 to i64
  %arrayidx601 = getelementptr inbounds float* %VFtab, i64 %idxprom600
  %86 = load float* %arrayidx601, align 4, !tbaa !3
  %add6021510 = or i32 %mul596, 2
  %idxprom603 = sext i32 %add6021510 to i64
  %arrayidx604 = getelementptr inbounds float* %VFtab, i64 %idxprom603
  %87 = load float* %arrayidx604, align 4, !tbaa !3
  %mul605 = fmul float %sub594, %87
  %add6061511 = or i32 %mul596, 3
  %idxprom607 = sext i32 %add6061511 to i64
  %arrayidx608 = getelementptr inbounds float* %VFtab, i64 %idxprom607
  %88 = load float* %arrayidx608, align 4, !tbaa !3
  %mul609 = fmul float %mul595, %88
  %add610 = fadd float %86, %mul605
  %add611 = fadd float %add610, %mul609
  %mul612 = fmul float %sub594, %add611
  %add613 = fadd float %85, %mul612
  %add614 = fadd float %mul605, %add611
  %mul615 = fmul float %mul609, 2.000000e+00
  %add616 = fadd float %mul615, %add614
  %mul617 = fmul float %mul8, %add613
  %mul618 = fmul float %mul8, %add616
  %mul619 = fmul float %mul618, %tabscale
  %89 = fmul float %conv199, %mul619
  %mul621 = fsub float -0.000000e+00, %89
  %add622 = fadd float %add572, %mul617
  %mul623 = fmul float %sub163, %mul621
  %mul624 = fmul float %sub164, %mul621
  %mul625 = fmul float %sub165, %mul621
  %add626 = fadd float %add576, %mul623
  %add627 = fadd float %add577, %mul624
  %add628 = fadd float %add578, %mul625
  %sub629 = fsub float %sub495, %mul623
  store float %sub629, float* %arrayidx353, align 4, !tbaa !3
  %sub633 = fsub float %sub496, %mul624
  store float %sub633, float* %arrayidx357, align 4, !tbaa !3
  %sub637 = fsub float %sub497, %mul625
  store float %sub637, float* %arrayidx361, align 4, !tbaa !3
  %mul641 = fmul float %add178, %conv211
  %mul642 = fmul float %mul641, %tabscale
  %conv643 = fptosi float %mul642 to i32
  %conv644 = sitofp i32 %conv643 to float
  %sub645 = fsub float %mul642, %conv644
  %mul646 = fmul float %sub645, %sub645
  %mul647 = mul nsw i32 %conv643, 12
  %idxprom648 = sext i32 %mul647 to i64
  %arrayidx649 = getelementptr inbounds float* %VFtab, i64 %idxprom648
  %90 = load float* %arrayidx649, align 4, !tbaa !3
  %add6501512 = or i32 %mul647, 1
  %idxprom651 = sext i32 %add6501512 to i64
  %arrayidx652 = getelementptr inbounds float* %VFtab, i64 %idxprom651
  %91 = load float* %arrayidx652, align 4, !tbaa !3
  %add6531513 = or i32 %mul647, 2
  %idxprom654 = sext i32 %add6531513 to i64
  %arrayidx655 = getelementptr inbounds float* %VFtab, i64 %idxprom654
  %92 = load float* %arrayidx655, align 4, !tbaa !3
  %mul656 = fmul float %sub645, %92
  %add6571514 = or i32 %mul647, 3
  %idxprom658 = sext i32 %add6571514 to i64
  %arrayidx659 = getelementptr inbounds float* %VFtab, i64 %idxprom658
  %93 = load float* %arrayidx659, align 4, !tbaa !3
  %mul660 = fmul float %mul646, %93
  %add661 = fadd float %91, %mul656
  %add662 = fadd float %add661, %mul660
  %mul663 = fmul float %sub645, %add662
  %add664 = fadd float %90, %mul663
  %add665 = fadd float %mul656, %add662
  %mul666 = fmul float %mul660, 2.000000e+00
  %add667 = fadd float %mul666, %add665
  %mul668 = fmul float %mul8, %add664
  %mul669 = fmul float %mul8, %add667
  %mul670 = fmul float %mul669, %tabscale
  %94 = fmul float %conv211, %mul670
  %mul672 = fsub float -0.000000e+00, %94
  %add673 = fadd float %add622, %mul668
  %mul674 = fmul float %sub171, %mul672
  %mul675 = fmul float %sub172, %mul672
  %mul676 = fmul float %sub173, %mul672
  %add677 = fadd float %add626, %mul674
  %add678 = fadd float %add627, %mul675
  %add679 = fadd float %add628, %mul676
  %sub680 = fsub float %sub537, %mul674
  store float %sub680, float* %arrayidx404, align 4, !tbaa !3
  %sub684 = fsub float %sub538, %mul675
  store float %sub684, float* %arrayidx408, align 4, !tbaa !3
  %sub688 = fsub float %sub539, %mul676
  store float %sub688, float* %arrayidx412, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %95 = trunc i64 %indvars.iv.next to i32
  %cmp77 = icmp slt i32 %95, %12
  br i1 %cmp77, label %for.body78, label %for.end

for.end:                                          ; preds = %for.body78, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add673, %for.body78 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add288, %for.body78 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add399, %for.body78 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add400, %for.body78 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add401, %for.body78 ]
  %fix2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add534, %for.body78 ]
  %fiy2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add535, %for.body78 ]
  %fiz2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add536, %for.body78 ]
  %fix3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add677, %for.body78 ]
  %fiy3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add678, %for.body78 ]
  %fiz3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add679, %for.body78 ]
  %arrayidx693 = getelementptr inbounds float* %faction, i64 %idxprom41
  %96 = load float* %arrayidx693, align 4, !tbaa !3
  %add694 = fadd float %fix1.0.lcssa, %96
  store float %add694, float* %arrayidx693, align 4, !tbaa !3
  %arrayidx699 = getelementptr inbounds float* %faction, i64 %idxprom45
  %97 = load float* %arrayidx699, align 4, !tbaa !3
  %add700 = fadd float %fiy1.0.lcssa, %97
  store float %add700, float* %arrayidx699, align 4, !tbaa !3
  %arrayidx706 = getelementptr inbounds float* %faction, i64 %idxprom49
  %98 = load float* %arrayidx706, align 4, !tbaa !3
  %add707 = fadd float %fiz1.0.lcssa, %98
  store float %add707, float* %arrayidx706, align 4, !tbaa !3
  %arrayidx713 = getelementptr inbounds float* %faction, i64 %idxprom53
  %99 = load float* %arrayidx713, align 4, !tbaa !3
  %add714 = fadd float %fix2.0.lcssa, %99
  store float %add714, float* %arrayidx713, align 4, !tbaa !3
  %arrayidx720 = getelementptr inbounds float* %faction, i64 %idxprom57
  %100 = load float* %arrayidx720, align 4, !tbaa !3
  %add721 = fadd float %fiy2.0.lcssa, %100
  store float %add721, float* %arrayidx720, align 4, !tbaa !3
  %arrayidx727 = getelementptr inbounds float* %faction, i64 %idxprom61
  %101 = load float* %arrayidx727, align 4, !tbaa !3
  %add728 = fadd float %fiz2.0.lcssa, %101
  store float %add728, float* %arrayidx727, align 4, !tbaa !3
  %arrayidx734 = getelementptr inbounds float* %faction, i64 %idxprom65
  %102 = load float* %arrayidx734, align 4, !tbaa !3
  %add735 = fadd float %fix3.0.lcssa, %102
  store float %add735, float* %arrayidx734, align 4, !tbaa !3
  %arrayidx741 = getelementptr inbounds float* %faction, i64 %idxprom69
  %103 = load float* %arrayidx741, align 4, !tbaa !3
  %add742 = fadd float %fiy3.0.lcssa, %103
  store float %add742, float* %arrayidx741, align 4, !tbaa !3
  %arrayidx748 = getelementptr inbounds float* %faction, i64 %idxprom73
  %104 = load float* %arrayidx748, align 4, !tbaa !3
  %add749 = fadd float %fiz3.0.lcssa, %104
  store float %add749, float* %arrayidx748, align 4, !tbaa !3
  %arrayidx754 = getelementptr inbounds float* %fshift, i64 %idxprom25
  %105 = load float* %arrayidx754, align 4, !tbaa !3
  %add755 = fadd float %fix1.0.lcssa, %105
  %add756 = fadd float %fix2.0.lcssa, %add755
  %add757 = fadd float %fix3.0.lcssa, %add756
  store float %add757, float* %arrayidx754, align 4, !tbaa !3
  %arrayidx762 = getelementptr inbounds float* %fshift, i64 %idxprom28
  %106 = load float* %arrayidx762, align 4, !tbaa !3
  %add763 = fadd float %fiy1.0.lcssa, %106
  %add764 = fadd float %fiy2.0.lcssa, %add763
  %add765 = fadd float %fiy3.0.lcssa, %add764
  store float %add765, float* %arrayidx762, align 4, !tbaa !3
  %arrayidx771 = getelementptr inbounds float* %fshift, i64 %idxprom31
  %107 = load float* %arrayidx771, align 4, !tbaa !3
  %add772 = fadd float %fiz1.0.lcssa, %107
  %add773 = fadd float %fiz2.0.lcssa, %add772
  %add774 = fadd float %fiz3.0.lcssa, %add773
  store float %add774, float* %arrayidx771, align 4, !tbaa !3
  %arrayidx779 = getelementptr inbounds i32* %gid, i64 %indvars.iv1540
  %108 = load i32* %arrayidx779, align 4, !tbaa !0
  %idxprom780 = sext i32 %108 to i64
  %arrayidx781 = getelementptr inbounds float* %Vc, i64 %idxprom780
  %109 = load float* %arrayidx781, align 4, !tbaa !3
  %add782 = fadd float %vctot.0.lcssa, %109
  store float %add782, float* %arrayidx781, align 4, !tbaa !3
  %arrayidx786 = getelementptr inbounds float* %Vnb, i64 %idxprom780
  %110 = load float* %arrayidx786, align 4, !tbaa !3
  %add787 = fadd float %vnbtot.0.lcssa, %110
  store float %add787, float* %arrayidx786, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next1541 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end792, label %for.end.for.body_crit_edge

for.end.for.body_crit_edge:                       ; preds = %for.end
  %arrayidx34.phi.trans.insert = getelementptr inbounds i32* %iinr, i64 %indvars.iv.next1541
  %.pre = load i32* %arrayidx34.phi.trans.insert, align 4, !tbaa !0
  br label %for.body

for.end792:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl3400(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab, float %exptabscale) #0 {
entry:
  %cmp419 = icmp sgt i32 %nri, 0
  br i1 %cmp419, label %for.body, label %for.end240

for.body:                                         ; preds = %for.end, %entry
  %indvars.iv421 = phi i64 [ 0, %entry ], [ %indvars.iv.next422, %for.end ]
  %arrayidx = getelementptr inbounds i32* %shift, i64 %indvars.iv421
  %0 = load i32* %arrayidx, align 4, !tbaa !0
  %mul = mul nsw i32 %0, 3
  %idxprom1 = sext i32 %mul to i64
  %arrayidx2 = getelementptr inbounds float* %shiftvec, i64 %idxprom1
  %1 = load float* %arrayidx2, align 4, !tbaa !3
  %add = add nsw i32 %mul, 1
  %idxprom3 = sext i32 %add to i64
  %arrayidx4 = getelementptr inbounds float* %shiftvec, i64 %idxprom3
  %2 = load float* %arrayidx4, align 4, !tbaa !3
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds float* %shiftvec, i64 %idxprom6
  %3 = load float* %arrayidx7, align 4, !tbaa !3
  %arrayidx9 = getelementptr inbounds i32* %iinr, i64 %indvars.iv421
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %arrayidx12 = getelementptr inbounds i32* %jindex, i64 %indvars.iv421
  %5 = load i32* %arrayidx12, align 4, !tbaa !0
  %indvars.iv.next422 = add i64 %indvars.iv421, 1
  %arrayidx15 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next422
  %6 = load i32* %arrayidx15, align 4, !tbaa !0
  %idxprom16 = sext i32 %mul10 to i64
  %arrayidx17 = getelementptr inbounds float* %pos, i64 %idxprom16
  %7 = load float* %arrayidx17, align 4, !tbaa !3
  %add18 = fadd float %1, %7
  %add19 = add nsw i32 %mul10, 1
  %idxprom20 = sext i32 %add19 to i64
  %arrayidx21 = getelementptr inbounds float* %pos, i64 %idxprom20
  %8 = load float* %arrayidx21, align 4, !tbaa !3
  %add22 = fadd float %2, %8
  %add23 = add nsw i32 %mul10, 2
  %idxprom24 = sext i32 %add23 to i64
  %arrayidx25 = getelementptr inbounds float* %pos, i64 %idxprom24
  %9 = load float* %arrayidx25, align 4, !tbaa !3
  %add26 = fadd float %3, %9
  %idxprom27 = sext i32 %4 to i64
  %arrayidx28 = getelementptr inbounds float* %charge, i64 %idxprom27
  %10 = load float* %arrayidx28, align 4, !tbaa !3
  %mul29 = fmul float %10, %facel
  %arrayidx32 = getelementptr inbounds i32* %type, i64 %idxprom27
  %11 = load i32* %arrayidx32, align 4, !tbaa !0
  %mul33 = mul i32 %11, %ntype
  %cmp35408 = icmp slt i32 %5, %6
  br i1 %cmp35408, label %for.body36.lr.ph, label %for.end

for.body36.lr.ph:                                 ; preds = %for.body
  %12 = sext i32 %5 to i64
  br label %for.body36

for.body36:                                       ; preds = %for.body36.lr.ph, %for.body36
  %indvars.iv = phi i64 [ %12, %for.body36.lr.ph ], [ %indvars.iv.next, %for.body36 ]
  %vctot.0413 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add162, %for.body36 ]
  %vnbtot.0412 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add155, %for.body36 ]
  %fix1.0411 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add166, %for.body36 ]
  %fiy1.0410 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add167, %for.body36 ]
  %fiz1.0409 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add168, %for.body36 ]
  %arrayidx38 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %13 = load i32* %arrayidx38, align 4, !tbaa !0
  %mul39 = mul nsw i32 %13, 3
  %idxprom40 = sext i32 %mul39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %14 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = add nsw i32 %mul39, 1
  %idxprom43 = sext i32 %add42 to i64
  %arrayidx44 = getelementptr inbounds float* %pos, i64 %idxprom43
  %15 = load float* %arrayidx44, align 4, !tbaa !3
  %add45 = add nsw i32 %mul39, 2
  %idxprom46 = sext i32 %add45 to i64
  %arrayidx47 = getelementptr inbounds float* %pos, i64 %idxprom46
  %16 = load float* %arrayidx47, align 4, !tbaa !3
  %sub = fsub float %add18, %14
  %sub48 = fsub float %add22, %15
  %sub49 = fsub float %add26, %16
  %mul50 = fmul float %sub, %sub
  %mul51 = fmul float %sub48, %sub48
  %add52 = fadd float %mul50, %mul51
  %mul53 = fmul float %sub49, %sub49
  %add54 = fadd float %add52, %mul53
  %conv = fpext float %add54 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv55 = fptrunc double %div to float
  %mul56 = fmul float %add54, %conv55
  %mul57 = fmul float %mul56, %tabscale
  %conv58 = fptosi float %mul57 to i32
  %conv59 = sitofp i32 %conv58 to float
  %sub60 = fsub float %mul57, %conv59
  %mul61 = fmul float %sub60, %sub60
  %mul62 = mul nsw i32 %conv58, 12
  %idxprom63 = sext i32 %13 to i64
  %arrayidx64 = getelementptr inbounds float* %charge, i64 %idxprom63
  %17 = load float* %arrayidx64, align 4, !tbaa !3
  %mul65 = fmul float %mul29, %17
  %idxprom66 = sext i32 %mul62 to i64
  %arrayidx67 = getelementptr inbounds float* %VFtab, i64 %idxprom66
  %18 = load float* %arrayidx67, align 4, !tbaa !3
  %add68404 = or i32 %mul62, 1
  %idxprom69 = sext i32 %add68404 to i64
  %arrayidx70 = getelementptr inbounds float* %VFtab, i64 %idxprom69
  %19 = load float* %arrayidx70, align 4, !tbaa !3
  %add71405 = or i32 %mul62, 2
  %idxprom72 = sext i32 %add71405 to i64
  %arrayidx73 = getelementptr inbounds float* %VFtab, i64 %idxprom72
  %20 = load float* %arrayidx73, align 4, !tbaa !3
  %mul74 = fmul float %20, %sub60
  %add75406 = or i32 %mul62, 3
  %idxprom76 = sext i32 %add75406 to i64
  %arrayidx77 = getelementptr inbounds float* %VFtab, i64 %idxprom76
  %21 = load float* %arrayidx77, align 4, !tbaa !3
  %mul78 = fmul float %21, %mul61
  %add79 = fadd float %19, %mul74
  %add80 = fadd float %add79, %mul78
  %mul81 = fmul float %sub60, %add80
  %add82 = fadd float %18, %mul81
  %add83 = fadd float %mul74, %add80
  %mul84 = fmul float %mul78, 2.000000e+00
  %add85 = fadd float %mul84, %add83
  %mul86 = fmul float %mul65, %add82
  %mul87 = fmul float %mul65, %add85
  %arrayidx89 = getelementptr inbounds i32* %type, i64 %idxprom63
  %22 = load i32* %arrayidx89, align 4, !tbaa !0
  %tmp = add i32 %22, %mul33
  %tmp407 = mul i32 %tmp, 3
  %idxprom92 = sext i32 %tmp407 to i64
  %arrayidx93 = getelementptr inbounds float* %nbfp, i64 %idxprom92
  %23 = load float* %arrayidx93, align 4, !tbaa !3
  %add94 = add nsw i32 %tmp407, 1
  %idxprom95 = sext i32 %add94 to i64
  %arrayidx96 = getelementptr inbounds float* %nbfp, i64 %idxprom95
  %24 = load float* %arrayidx96, align 4, !tbaa !3
  %add97 = add nsw i32 %tmp407, 2
  %idxprom98 = sext i32 %add97 to i64
  %arrayidx99 = getelementptr inbounds float* %nbfp, i64 %idxprom98
  %25 = load float* %arrayidx99, align 4, !tbaa !3
  %add100 = add nsw i32 %mul62, 4
  %idxprom101 = sext i32 %add100 to i64
  %arrayidx102 = getelementptr inbounds float* %VFtab, i64 %idxprom101
  %26 = load float* %arrayidx102, align 4, !tbaa !3
  %add103 = add nsw i32 %mul62, 5
  %idxprom104 = sext i32 %add103 to i64
  %arrayidx105 = getelementptr inbounds float* %VFtab, i64 %idxprom104
  %27 = load float* %arrayidx105, align 4, !tbaa !3
  %add106 = add nsw i32 %mul62, 6
  %idxprom107 = sext i32 %add106 to i64
  %arrayidx108 = getelementptr inbounds float* %VFtab, i64 %idxprom107
  %28 = load float* %arrayidx108, align 4, !tbaa !3
  %mul109 = fmul float %sub60, %28
  %add110 = add nsw i32 %mul62, 7
  %idxprom111 = sext i32 %add110 to i64
  %arrayidx112 = getelementptr inbounds float* %VFtab, i64 %idxprom111
  %29 = load float* %arrayidx112, align 4, !tbaa !3
  %mul113 = fmul float %mul61, %29
  %add114 = fadd float %27, %mul109
  %add115 = fadd float %add114, %mul113
  %mul116 = fmul float %sub60, %add115
  %add117 = fadd float %26, %mul116
  %add118 = fadd float %mul109, %add115
  %mul119 = fmul float %mul113, 2.000000e+00
  %add120 = fadd float %mul119, %add118
  %mul121 = fmul float %23, %add117
  %mul122 = fmul float %23, %add120
  %mul123 = fmul float %mul56, %25
  %mul124 = fmul float %mul123, %exptabscale
  %conv125 = fptosi float %mul124 to i32
  %conv126 = sitofp i32 %conv125 to float
  %sub127 = fsub float %mul124, %conv126
  %mul128 = fmul float %sub127, %sub127
  %mul129 = mul nsw i32 %conv125, 12
  %add130 = add nsw i32 %mul129, 8
  %idxprom131 = sext i32 %add130 to i64
  %arrayidx132 = getelementptr inbounds float* %VFtab, i64 %idxprom131
  %30 = load float* %arrayidx132, align 4, !tbaa !3
  %add133 = add nsw i32 %mul129, 9
  %idxprom134 = sext i32 %add133 to i64
  %arrayidx135 = getelementptr inbounds float* %VFtab, i64 %idxprom134
  %31 = load float* %arrayidx135, align 4, !tbaa !3
  %add136 = add nsw i32 %mul129, 10
  %idxprom137 = sext i32 %add136 to i64
  %arrayidx138 = getelementptr inbounds float* %VFtab, i64 %idxprom137
  %32 = load float* %arrayidx138, align 4, !tbaa !3
  %mul139 = fmul float %sub127, %32
  %add140 = add nsw i32 %mul129, 11
  %idxprom141 = sext i32 %add140 to i64
  %arrayidx142 = getelementptr inbounds float* %VFtab, i64 %idxprom141
  %33 = load float* %arrayidx142, align 4, !tbaa !3
  %mul143 = fmul float %mul128, %33
  %add144 = fadd float %31, %mul139
  %add145 = fadd float %add144, %mul143
  %mul146 = fmul float %sub127, %add145
  %add147 = fadd float %30, %mul146
  %add148 = fadd float %mul139, %add145
  %mul149 = fmul float %mul143, 2.000000e+00
  %add150 = fadd float %mul149, %add148
  %mul151 = fmul float %24, %add147
  %mul152 = fmul float %24, %25
  %mul153 = fmul float %mul152, %add150
  %add154 = fadd float %vnbtot.0412, %mul121
  %add155 = fadd float %add154, %mul151
  %add156 = fadd float %mul87, %mul122
  %mul157 = fmul float %add156, %tabscale
  %mul158 = fmul float %mul153, %exptabscale
  %add159 = fadd float %mul157, %mul158
  %34 = fmul float %conv55, %add159
  %mul161 = fsub float -0.000000e+00, %34
  %add162 = fadd float %vctot.0413, %mul86
  %mul163 = fmul float %sub, %mul161
  %mul164 = fmul float %sub48, %mul161
  %mul165 = fmul float %sub49, %mul161
  %add166 = fadd float %fix1.0411, %mul163
  %add167 = fadd float %fiy1.0410, %mul164
  %add168 = fadd float %fiz1.0409, %mul165
  %arrayidx170 = getelementptr inbounds float* %faction, i64 %idxprom40
  %35 = load float* %arrayidx170, align 4, !tbaa !3
  %sub171 = fsub float %35, %mul163
  store float %sub171, float* %arrayidx170, align 4, !tbaa !3
  %arrayidx176 = getelementptr inbounds float* %faction, i64 %idxprom43
  %36 = load float* %arrayidx176, align 4, !tbaa !3
  %sub177 = fsub float %36, %mul164
  store float %sub177, float* %arrayidx176, align 4, !tbaa !3
  %arrayidx183 = getelementptr inbounds float* %faction, i64 %idxprom46
  %37 = load float* %arrayidx183, align 4, !tbaa !3
  %sub184 = fsub float %37, %mul165
  store float %sub184, float* %arrayidx183, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %38 = trunc i64 %indvars.iv.next to i32
  %cmp35 = icmp slt i32 %38, %6
  br i1 %cmp35, label %for.body36, label %for.end

for.end:                                          ; preds = %for.body36, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add162, %for.body36 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add155, %for.body36 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add166, %for.body36 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add167, %for.body36 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add168, %for.body36 ]
  %arrayidx189 = getelementptr inbounds float* %faction, i64 %idxprom16
  %39 = load float* %arrayidx189, align 4, !tbaa !3
  %add190 = fadd float %fix1.0.lcssa, %39
  store float %add190, float* %arrayidx189, align 4, !tbaa !3
  %arrayidx195 = getelementptr inbounds float* %faction, i64 %idxprom20
  %40 = load float* %arrayidx195, align 4, !tbaa !3
  %add196 = fadd float %fiy1.0.lcssa, %40
  store float %add196, float* %arrayidx195, align 4, !tbaa !3
  %arrayidx202 = getelementptr inbounds float* %faction, i64 %idxprom24
  %41 = load float* %arrayidx202, align 4, !tbaa !3
  %add203 = fadd float %fiz1.0.lcssa, %41
  store float %add203, float* %arrayidx202, align 4, !tbaa !3
  %arrayidx208 = getelementptr inbounds float* %fshift, i64 %idxprom1
  %42 = load float* %arrayidx208, align 4, !tbaa !3
  %add209 = fadd float %fix1.0.lcssa, %42
  store float %add209, float* %arrayidx208, align 4, !tbaa !3
  %arrayidx214 = getelementptr inbounds float* %fshift, i64 %idxprom3
  %43 = load float* %arrayidx214, align 4, !tbaa !3
  %add215 = fadd float %fiy1.0.lcssa, %43
  store float %add215, float* %arrayidx214, align 4, !tbaa !3
  %arrayidx221 = getelementptr inbounds float* %fshift, i64 %idxprom6
  %44 = load float* %arrayidx221, align 4, !tbaa !3
  %add222 = fadd float %fiz1.0.lcssa, %44
  store float %add222, float* %arrayidx221, align 4, !tbaa !3
  %arrayidx227 = getelementptr inbounds i32* %gid, i64 %indvars.iv421
  %45 = load i32* %arrayidx227, align 4, !tbaa !0
  %idxprom228 = sext i32 %45 to i64
  %arrayidx229 = getelementptr inbounds float* %Vc, i64 %idxprom228
  %46 = load float* %arrayidx229, align 4, !tbaa !3
  %add230 = fadd float %vctot.0.lcssa, %46
  store float %add230, float* %arrayidx229, align 4, !tbaa !3
  %arrayidx234 = getelementptr inbounds float* %Vnb, i64 %idxprom228
  %47 = load float* %arrayidx234, align 4, !tbaa !3
  %add235 = fadd float %vnbtot.0.lcssa, %47
  store float %add235, float* %arrayidx234, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next422 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end240, label %for.body

for.end240:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl3401(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab, float %exptabscale, float %lambda, float* nocapture %dvdlambda, float* nocapture %chargeB, i32* nocapture %typeB) #0 {
entry:
  %sub = fsub float 1.000000e+00, %lambda
  %cmp559 = icmp sgt i32 %nri, 0
  br i1 %cmp559, label %for.body.lr.ph, label %for.end314

for.body.lr.ph:                                   ; preds = %entry
  %mul33 = mul nsw i32 %ntype, 3
  br label %for.body

for.body:                                         ; preds = %for.end, %for.body.lr.ph
  %indvars.iv563 = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next564, %for.end ]
  %dvdl.0560 = phi float [ 0.000000e+00, %for.body.lr.ph ], [ %dvdl.1.lcssa, %for.end ]
  %arrayidx = getelementptr inbounds i32* %shift, i64 %indvars.iv563
  %0 = load i32* %arrayidx, align 4, !tbaa !0
  %mul = mul nsw i32 %0, 3
  %idxprom1 = sext i32 %mul to i64
  %arrayidx2 = getelementptr inbounds float* %shiftvec, i64 %idxprom1
  %1 = load float* %arrayidx2, align 4, !tbaa !3
  %add = add nsw i32 %mul, 1
  %idxprom3 = sext i32 %add to i64
  %arrayidx4 = getelementptr inbounds float* %shiftvec, i64 %idxprom3
  %2 = load float* %arrayidx4, align 4, !tbaa !3
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds float* %shiftvec, i64 %idxprom6
  %3 = load float* %arrayidx7, align 4, !tbaa !3
  %arrayidx9 = getelementptr inbounds i32* %iinr, i64 %indvars.iv563
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %arrayidx12 = getelementptr inbounds i32* %jindex, i64 %indvars.iv563
  %5 = load i32* %arrayidx12, align 4, !tbaa !0
  %indvars.iv.next564 = add i64 %indvars.iv563, 1
  %arrayidx15 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next564
  %6 = load i32* %arrayidx15, align 4, !tbaa !0
  %idxprom16 = sext i32 %mul10 to i64
  %arrayidx17 = getelementptr inbounds float* %pos, i64 %idxprom16
  %7 = load float* %arrayidx17, align 4, !tbaa !3
  %add18 = fadd float %1, %7
  %add19 = add nsw i32 %mul10, 1
  %idxprom20 = sext i32 %add19 to i64
  %arrayidx21 = getelementptr inbounds float* %pos, i64 %idxprom20
  %8 = load float* %arrayidx21, align 4, !tbaa !3
  %add22 = fadd float %2, %8
  %add23 = add nsw i32 %mul10, 2
  %idxprom24 = sext i32 %add23 to i64
  %arrayidx25 = getelementptr inbounds float* %pos, i64 %idxprom24
  %9 = load float* %arrayidx25, align 4, !tbaa !3
  %add26 = fadd float %3, %9
  %idxprom27 = sext i32 %4 to i64
  %arrayidx28 = getelementptr inbounds float* %charge, i64 %idxprom27
  %10 = load float* %arrayidx28, align 4, !tbaa !3
  %mul29 = fmul float %10, %facel
  %arrayidx31 = getelementptr inbounds float* %chargeB, i64 %idxprom27
  %11 = load float* %arrayidx31, align 4, !tbaa !3
  %mul32 = fmul float %11, %facel
  %arrayidx35 = getelementptr inbounds i32* %type, i64 %idxprom27
  %12 = load i32* %arrayidx35, align 4, !tbaa !0
  %mul36 = mul nsw i32 %12, %mul33
  %arrayidx39 = getelementptr inbounds i32* %typeB, i64 %idxprom27
  %13 = load i32* %arrayidx39, align 4, !tbaa !0
  %mul40 = mul nsw i32 %13, %mul33
  %cmp42546 = icmp slt i32 %5, %6
  br i1 %cmp42546, label %for.body43.lr.ph, label %for.end

for.body43.lr.ph:                                 ; preds = %for.body
  %14 = sext i32 %5 to i64
  br label %for.body43

for.body43:                                       ; preds = %for.body43.lr.ph, %for.body43
  %indvars.iv = phi i64 [ %14, %for.body43.lr.ph ], [ %indvars.iv.next, %for.body43 ]
  %vctot.0552 = phi float [ 0.000000e+00, %for.body43.lr.ph ], [ %add236, %for.body43 ]
  %dvdl.1551 = phi float [ %dvdl.0560, %for.body43.lr.ph ], [ %sub229, %for.body43 ]
  %vnbtot.0550 = phi float [ 0.000000e+00, %for.body43.lr.ph ], [ %add227, %for.body43 ]
  %fix1.0549 = phi float [ 0.000000e+00, %for.body43.lr.ph ], [ %add240, %for.body43 ]
  %fiy1.0548 = phi float [ 0.000000e+00, %for.body43.lr.ph ], [ %add241, %for.body43 ]
  %fiz1.0547 = phi float [ 0.000000e+00, %for.body43.lr.ph ], [ %add242, %for.body43 ]
  %arrayidx45 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %15 = load i32* %arrayidx45, align 4, !tbaa !0
  %mul46 = mul nsw i32 %15, 3
  %idxprom47 = sext i32 %mul46 to i64
  %arrayidx48 = getelementptr inbounds float* %pos, i64 %idxprom47
  %16 = load float* %arrayidx48, align 4, !tbaa !3
  %add49 = add nsw i32 %mul46, 1
  %idxprom50 = sext i32 %add49 to i64
  %arrayidx51 = getelementptr inbounds float* %pos, i64 %idxprom50
  %17 = load float* %arrayidx51, align 4, !tbaa !3
  %add52 = add nsw i32 %mul46, 2
  %idxprom53 = sext i32 %add52 to i64
  %arrayidx54 = getelementptr inbounds float* %pos, i64 %idxprom53
  %18 = load float* %arrayidx54, align 4, !tbaa !3
  %sub55 = fsub float %add18, %16
  %sub56 = fsub float %add22, %17
  %sub57 = fsub float %add26, %18
  %mul58 = fmul float %sub55, %sub55
  %mul59 = fmul float %sub56, %sub56
  %add60 = fadd float %mul58, %mul59
  %mul61 = fmul float %sub57, %sub57
  %add62 = fadd float %add60, %mul61
  %conv = fpext float %add62 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv63 = fptrunc double %div to float
  %mul64 = fmul float %add62, %conv63
  %mul65 = fmul float %mul64, %tabscale
  %conv66 = fptosi float %mul65 to i32
  %conv67 = sitofp i32 %conv66 to float
  %sub68 = fsub float %mul65, %conv67
  %mul69 = fmul float %sub68, %sub68
  %mul70 = mul nsw i32 %conv66, 12
  %idxprom71 = sext i32 %15 to i64
  %arrayidx72 = getelementptr inbounds float* %charge, i64 %idxprom71
  %19 = load float* %arrayidx72, align 4, !tbaa !3
  %mul73 = fmul float %mul29, %19
  %arrayidx75 = getelementptr inbounds float* %chargeB, i64 %idxprom71
  %20 = load float* %arrayidx75, align 4, !tbaa !3
  %mul76 = fmul float %mul32, %20
  %mul77 = fmul float %sub, %mul73
  %mul78 = fmul float %mul76, %lambda
  %add79 = fadd float %mul77, %mul78
  %idxprom80 = sext i32 %mul70 to i64
  %arrayidx81 = getelementptr inbounds float* %VFtab, i64 %idxprom80
  %21 = load float* %arrayidx81, align 4, !tbaa !3
  %add82543 = or i32 %mul70, 1
  %idxprom83 = sext i32 %add82543 to i64
  %arrayidx84 = getelementptr inbounds float* %VFtab, i64 %idxprom83
  %22 = load float* %arrayidx84, align 4, !tbaa !3
  %add85544 = or i32 %mul70, 2
  %idxprom86 = sext i32 %add85544 to i64
  %arrayidx87 = getelementptr inbounds float* %VFtab, i64 %idxprom86
  %23 = load float* %arrayidx87, align 4, !tbaa !3
  %mul88 = fmul float %23, %sub68
  %add89545 = or i32 %mul70, 3
  %idxprom90 = sext i32 %add89545 to i64
  %arrayidx91 = getelementptr inbounds float* %VFtab, i64 %idxprom90
  %24 = load float* %arrayidx91, align 4, !tbaa !3
  %mul92 = fmul float %24, %mul69
  %add93 = fadd float %22, %mul88
  %add94 = fadd float %add93, %mul92
  %mul95 = fmul float %sub68, %add94
  %add96 = fadd float %21, %mul95
  %add97 = fadd float %mul88, %add94
  %mul98 = fmul float %mul92, 2.000000e+00
  %add99 = fadd float %mul98, %add97
  %mul100 = fmul float %add79, %add96
  %mul101 = fmul float %add79, %add99
  %sub102 = fsub float %mul76, %mul73
  %mul103 = fmul float %sub102, %add96
  %add104 = fadd float %dvdl.1551, %mul103
  %arrayidx106 = getelementptr inbounds i32* %type, i64 %idxprom71
  %25 = load i32* %arrayidx106, align 4, !tbaa !0
  %mul107 = mul nsw i32 %25, 3
  %add108 = add nsw i32 %mul107, %mul36
  %arrayidx110 = getelementptr inbounds i32* %typeB, i64 %idxprom71
  %26 = load i32* %arrayidx110, align 4, !tbaa !0
  %mul111 = mul nsw i32 %26, 3
  %add112 = add nsw i32 %mul111, %mul40
  %idxprom113 = sext i32 %add108 to i64
  %arrayidx114 = getelementptr inbounds float* %nbfp, i64 %idxprom113
  %27 = load float* %arrayidx114, align 4, !tbaa !3
  %idxprom115 = sext i32 %add112 to i64
  %arrayidx116 = getelementptr inbounds float* %nbfp, i64 %idxprom115
  %28 = load float* %arrayidx116, align 4, !tbaa !3
  %mul117 = fmul float %sub, %27
  %mul118 = fmul float %28, %lambda
  %add119 = fadd float %mul117, %mul118
  %add120 = add nsw i32 %add108, 1
  %idxprom121 = sext i32 %add120 to i64
  %arrayidx122 = getelementptr inbounds float* %nbfp, i64 %idxprom121
  %29 = load float* %arrayidx122, align 4, !tbaa !3
  %add123 = add nsw i32 %add112, 1
  %idxprom124 = sext i32 %add123 to i64
  %arrayidx125 = getelementptr inbounds float* %nbfp, i64 %idxprom124
  %30 = load float* %arrayidx125, align 4, !tbaa !3
  %add126 = add nsw i32 %add108, 2
  %idxprom127 = sext i32 %add126 to i64
  %arrayidx128 = getelementptr inbounds float* %nbfp, i64 %idxprom127
  %31 = load float* %arrayidx128, align 4, !tbaa !3
  %add129 = add nsw i32 %add112, 2
  %idxprom130 = sext i32 %add129 to i64
  %arrayidx131 = getelementptr inbounds float* %nbfp, i64 %idxprom130
  %32 = load float* %arrayidx131, align 4, !tbaa !3
  %add132 = add nsw i32 %mul70, 4
  %idxprom133 = sext i32 %add132 to i64
  %arrayidx134 = getelementptr inbounds float* %VFtab, i64 %idxprom133
  %33 = load float* %arrayidx134, align 4, !tbaa !3
  %add135 = add nsw i32 %mul70, 5
  %idxprom136 = sext i32 %add135 to i64
  %arrayidx137 = getelementptr inbounds float* %VFtab, i64 %idxprom136
  %34 = load float* %arrayidx137, align 4, !tbaa !3
  %add138 = add nsw i32 %mul70, 6
  %idxprom139 = sext i32 %add138 to i64
  %arrayidx140 = getelementptr inbounds float* %VFtab, i64 %idxprom139
  %35 = load float* %arrayidx140, align 4, !tbaa !3
  %mul141 = fmul float %sub68, %35
  %add142 = add nsw i32 %mul70, 7
  %idxprom143 = sext i32 %add142 to i64
  %arrayidx144 = getelementptr inbounds float* %VFtab, i64 %idxprom143
  %36 = load float* %arrayidx144, align 4, !tbaa !3
  %mul145 = fmul float %mul69, %36
  %add146 = fadd float %34, %mul141
  %add147 = fadd float %add146, %mul145
  %mul148 = fmul float %sub68, %add147
  %add149 = fadd float %33, %mul148
  %add150 = fadd float %mul141, %add147
  %mul151 = fmul float %mul145, 2.000000e+00
  %add152 = fadd float %mul151, %add150
  %mul153 = fmul float %add119, %add149
  %mul154 = fmul float %add119, %add152
  %sub155 = fsub float %28, %27
  %mul156 = fmul float %sub155, %add149
  %add157 = fadd float %add104, %mul156
  %mul158 = fmul float %mul64, %31
  %mul159 = fmul float %mul158, %exptabscale
  %conv160 = fptosi float %mul159 to i32
  %conv161 = sitofp i32 %conv160 to float
  %sub162 = fsub float %mul159, %conv161
  %mul163 = fmul float %sub162, %sub162
  %mul164 = mul nsw i32 %conv160, 12
  %add165 = add nsw i32 %mul164, 8
  %idxprom166 = sext i32 %add165 to i64
  %arrayidx167 = getelementptr inbounds float* %VFtab, i64 %idxprom166
  %37 = load float* %arrayidx167, align 4, !tbaa !3
  %add168 = add nsw i32 %mul164, 9
  %idxprom169 = sext i32 %add168 to i64
  %arrayidx170 = getelementptr inbounds float* %VFtab, i64 %idxprom169
  %38 = load float* %arrayidx170, align 4, !tbaa !3
  %add171 = add nsw i32 %mul164, 10
  %idxprom172 = sext i32 %add171 to i64
  %arrayidx173 = getelementptr inbounds float* %VFtab, i64 %idxprom172
  %39 = load float* %arrayidx173, align 4, !tbaa !3
  %mul174 = fmul float %sub162, %39
  %add175 = add nsw i32 %mul164, 11
  %idxprom176 = sext i32 %add175 to i64
  %arrayidx177 = getelementptr inbounds float* %VFtab, i64 %idxprom176
  %40 = load float* %arrayidx177, align 4, !tbaa !3
  %mul178 = fmul float %mul163, %40
  %add179 = fadd float %38, %mul174
  %add180 = fadd float %add179, %mul178
  %mul181 = fmul float %sub162, %add180
  %add182 = fadd float %37, %mul181
  %add183 = fadd float %mul174, %add180
  %mul184 = fmul float %mul178, 2.000000e+00
  %add185 = fadd float %mul184, %add183
  %mul186 = fmul float %29, %add182
  %mul187 = fmul float %29, %31
  %mul188 = fmul float %mul187, %add185
  %mul189 = fmul float %mul64, %32
  %mul190 = fmul float %mul189, %exptabscale
  %conv191 = fptosi float %mul190 to i32
  %conv192 = sitofp i32 %conv191 to float
  %sub193 = fsub float %mul190, %conv192
  %mul194 = fmul float %sub193, %sub193
  %mul195 = mul nsw i32 %conv191, 12
  %add196 = add nsw i32 %mul195, 8
  %idxprom197 = sext i32 %add196 to i64
  %arrayidx198 = getelementptr inbounds float* %VFtab, i64 %idxprom197
  %41 = load float* %arrayidx198, align 4, !tbaa !3
  %add199 = add nsw i32 %mul195, 9
  %idxprom200 = sext i32 %add199 to i64
  %arrayidx201 = getelementptr inbounds float* %VFtab, i64 %idxprom200
  %42 = load float* %arrayidx201, align 4, !tbaa !3
  %add202 = add nsw i32 %mul195, 10
  %idxprom203 = sext i32 %add202 to i64
  %arrayidx204 = getelementptr inbounds float* %VFtab, i64 %idxprom203
  %43 = load float* %arrayidx204, align 4, !tbaa !3
  %mul205 = fmul float %sub193, %43
  %add206 = add nsw i32 %mul195, 11
  %idxprom207 = sext i32 %add206 to i64
  %arrayidx208 = getelementptr inbounds float* %VFtab, i64 %idxprom207
  %44 = load float* %arrayidx208, align 4, !tbaa !3
  %mul209 = fmul float %mul194, %44
  %add210 = fadd float %42, %mul205
  %add211 = fadd float %add210, %mul209
  %mul212 = fmul float %sub193, %add211
  %add213 = fadd float %41, %mul212
  %add214 = fadd float %mul205, %add211
  %mul215 = fmul float %mul209, 2.000000e+00
  %add216 = fadd float %mul215, %add214
  %mul217 = fmul float %30, %add213
  %mul218 = fmul float %30, %32
  %mul219 = fmul float %mul218, %add216
  %mul220 = fmul float %sub, %mul188
  %mul221 = fmul float %mul219, %lambda
  %add222 = fadd float %mul220, %mul221
  %add223 = fadd float %vnbtot.0550, %mul153
  %mul224 = fmul float %sub, %mul186
  %add225 = fadd float %add223, %mul224
  %mul226 = fmul float %mul217, %lambda
  %add227 = fadd float %add225, %mul226
  %add228 = fadd float %add157, %mul217
  %sub229 = fsub float %add228, %mul186
  %add230 = fadd float %mul101, %mul154
  %mul231 = fmul float %add230, %tabscale
  %mul232 = fmul float %add222, %exptabscale
  %add233 = fadd float %mul231, %mul232
  %45 = fmul float %conv63, %add233
  %mul235 = fsub float -0.000000e+00, %45
  %add236 = fadd float %vctot.0552, %mul100
  %mul237 = fmul float %sub55, %mul235
  %mul238 = fmul float %sub56, %mul235
  %mul239 = fmul float %sub57, %mul235
  %add240 = fadd float %fix1.0549, %mul237
  %add241 = fadd float %fiy1.0548, %mul238
  %add242 = fadd float %fiz1.0547, %mul239
  %arrayidx244 = getelementptr inbounds float* %faction, i64 %idxprom47
  %46 = load float* %arrayidx244, align 4, !tbaa !3
  %sub245 = fsub float %46, %mul237
  store float %sub245, float* %arrayidx244, align 4, !tbaa !3
  %arrayidx250 = getelementptr inbounds float* %faction, i64 %idxprom50
  %47 = load float* %arrayidx250, align 4, !tbaa !3
  %sub251 = fsub float %47, %mul238
  store float %sub251, float* %arrayidx250, align 4, !tbaa !3
  %arrayidx257 = getelementptr inbounds float* %faction, i64 %idxprom53
  %48 = load float* %arrayidx257, align 4, !tbaa !3
  %sub258 = fsub float %48, %mul239
  store float %sub258, float* %arrayidx257, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %49 = trunc i64 %indvars.iv.next to i32
  %cmp42 = icmp slt i32 %49, %6
  br i1 %cmp42, label %for.body43, label %for.end

for.end:                                          ; preds = %for.body43, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add236, %for.body43 ]
  %dvdl.1.lcssa = phi float [ %dvdl.0560, %for.body ], [ %sub229, %for.body43 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add227, %for.body43 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add240, %for.body43 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add241, %for.body43 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add242, %for.body43 ]
  %arrayidx263 = getelementptr inbounds float* %faction, i64 %idxprom16
  %50 = load float* %arrayidx263, align 4, !tbaa !3
  %add264 = fadd float %fix1.0.lcssa, %50
  store float %add264, float* %arrayidx263, align 4, !tbaa !3
  %arrayidx269 = getelementptr inbounds float* %faction, i64 %idxprom20
  %51 = load float* %arrayidx269, align 4, !tbaa !3
  %add270 = fadd float %fiy1.0.lcssa, %51
  store float %add270, float* %arrayidx269, align 4, !tbaa !3
  %arrayidx276 = getelementptr inbounds float* %faction, i64 %idxprom24
  %52 = load float* %arrayidx276, align 4, !tbaa !3
  %add277 = fadd float %fiz1.0.lcssa, %52
  store float %add277, float* %arrayidx276, align 4, !tbaa !3
  %arrayidx282 = getelementptr inbounds float* %fshift, i64 %idxprom1
  %53 = load float* %arrayidx282, align 4, !tbaa !3
  %add283 = fadd float %fix1.0.lcssa, %53
  store float %add283, float* %arrayidx282, align 4, !tbaa !3
  %arrayidx288 = getelementptr inbounds float* %fshift, i64 %idxprom3
  %54 = load float* %arrayidx288, align 4, !tbaa !3
  %add289 = fadd float %fiy1.0.lcssa, %54
  store float %add289, float* %arrayidx288, align 4, !tbaa !3
  %arrayidx295 = getelementptr inbounds float* %fshift, i64 %idxprom6
  %55 = load float* %arrayidx295, align 4, !tbaa !3
  %add296 = fadd float %fiz1.0.lcssa, %55
  store float %add296, float* %arrayidx295, align 4, !tbaa !3
  %arrayidx301 = getelementptr inbounds i32* %gid, i64 %indvars.iv563
  %56 = load i32* %arrayidx301, align 4, !tbaa !0
  %idxprom302 = sext i32 %56 to i64
  %arrayidx303 = getelementptr inbounds float* %Vc, i64 %idxprom302
  %57 = load float* %arrayidx303, align 4, !tbaa !3
  %add304 = fadd float %vctot.0.lcssa, %57
  store float %add304, float* %arrayidx303, align 4, !tbaa !3
  %arrayidx308 = getelementptr inbounds float* %Vnb, i64 %idxprom302
  %58 = load float* %arrayidx308, align 4, !tbaa !3
  %add309 = fadd float %vnbtot.0.lcssa, %58
  store float %add309, float* %arrayidx308, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next564 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end314, label %for.body

for.end314:                                       ; preds = %for.end, %entry
  %dvdl.0.lcssa = phi float [ 0.000000e+00, %entry ], [ %dvdl.1.lcssa, %for.end ]
  %59 = load float* %dvdlambda, align 4, !tbaa !3
  %add315 = fadd float %dvdl.0.lcssa, %59
  store float %add315, float* %dvdlambda, align 4, !tbaa !3
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl3402(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* %VFtab, float %exptabscale, float %lambda, float* nocapture %dvdlambda, float* nocapture %chargeB, i32* nocapture %typeB, float %Alpha, float %defsigma6) #0 {
entry:
  %sub = fsub float 1.000000e+00, %lambda
  %cmp765 = icmp sgt i32 %nri, 0
  br i1 %cmp765, label %for.body.lr.ph, label %for.end426

for.body.lr.ph:                                   ; preds = %entry
  %mul1 = fmul float %sub, %sub
  %mul = fmul float %lambda, %lambda
  %mul35 = mul nsw i32 %ntype, 3
  %mul103 = fmul float %Alpha, %defsigma6
  %mul104 = fmul float %mul, %mul103
  %mul213 = fmul float %mul1, %mul103
  %mul338 = fmul float %Alpha, 0x3FD5555560000000
  %mul339 = fmul float %mul338, %lambda
  %mul340 = fmul float %sub, %mul339
  br label %for.body

for.body:                                         ; preds = %for.end, %for.body.lr.ph
  %indvars.iv769 = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next770, %for.end ]
  %dvdl.0766 = phi float [ 0.000000e+00, %for.body.lr.ph ], [ %dvdl.1.lcssa, %for.end ]
  %arrayidx = getelementptr inbounds i32* %shift, i64 %indvars.iv769
  %0 = load i32* %arrayidx, align 4, !tbaa !0
  %mul2 = mul nsw i32 %0, 3
  %idxprom3 = sext i32 %mul2 to i64
  %arrayidx4 = getelementptr inbounds float* %shiftvec, i64 %idxprom3
  %1 = load float* %arrayidx4, align 4, !tbaa !3
  %add = add nsw i32 %mul2, 1
  %idxprom5 = sext i32 %add to i64
  %arrayidx6 = getelementptr inbounds float* %shiftvec, i64 %idxprom5
  %2 = load float* %arrayidx6, align 4, !tbaa !3
  %add7 = add nsw i32 %mul2, 2
  %idxprom8 = sext i32 %add7 to i64
  %arrayidx9 = getelementptr inbounds float* %shiftvec, i64 %idxprom8
  %3 = load float* %arrayidx9, align 4, !tbaa !3
  %arrayidx11 = getelementptr inbounds i32* %iinr, i64 %indvars.iv769
  %4 = load i32* %arrayidx11, align 4, !tbaa !0
  %mul12 = mul nsw i32 %4, 3
  %arrayidx14 = getelementptr inbounds i32* %jindex, i64 %indvars.iv769
  %5 = load i32* %arrayidx14, align 4, !tbaa !0
  %indvars.iv.next770 = add i64 %indvars.iv769, 1
  %arrayidx17 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next770
  %6 = load i32* %arrayidx17, align 4, !tbaa !0
  %idxprom18 = sext i32 %mul12 to i64
  %arrayidx19 = getelementptr inbounds float* %pos, i64 %idxprom18
  %7 = load float* %arrayidx19, align 4, !tbaa !3
  %add20 = fadd float %1, %7
  %add21 = add nsw i32 %mul12, 1
  %idxprom22 = sext i32 %add21 to i64
  %arrayidx23 = getelementptr inbounds float* %pos, i64 %idxprom22
  %8 = load float* %arrayidx23, align 4, !tbaa !3
  %add24 = fadd float %2, %8
  %add25 = add nsw i32 %mul12, 2
  %idxprom26 = sext i32 %add25 to i64
  %arrayidx27 = getelementptr inbounds float* %pos, i64 %idxprom26
  %9 = load float* %arrayidx27, align 4, !tbaa !3
  %add28 = fadd float %3, %9
  %idxprom29 = sext i32 %4 to i64
  %arrayidx30 = getelementptr inbounds float* %charge, i64 %idxprom29
  %10 = load float* %arrayidx30, align 4, !tbaa !3
  %mul31 = fmul float %10, %facel
  %arrayidx33 = getelementptr inbounds float* %chargeB, i64 %idxprom29
  %11 = load float* %arrayidx33, align 4, !tbaa !3
  %mul34 = fmul float %11, %facel
  %arrayidx37 = getelementptr inbounds i32* %type, i64 %idxprom29
  %12 = load i32* %arrayidx37, align 4, !tbaa !0
  %mul38 = mul nsw i32 %12, %mul35
  %arrayidx41 = getelementptr inbounds i32* %typeB, i64 %idxprom29
  %13 = load i32* %arrayidx41, align 4, !tbaa !0
  %mul42 = mul nsw i32 %13, %mul35
  %cmp44752 = icmp slt i32 %5, %6
  br i1 %cmp44752, label %for.body45.lr.ph, label %for.end

for.body45.lr.ph:                                 ; preds = %for.body
  %14 = sext i32 %5 to i64
  br label %for.body45

for.body45:                                       ; preds = %for.body45.lr.ph, %if.end310
  %indvars.iv = phi i64 [ %14, %for.body45.lr.ph ], [ %indvars.iv.next, %if.end310 ]
  %vctot.0758 = phi float [ 0.000000e+00, %for.body45.lr.ph ], [ %add348, %if.end310 ]
  %fiz1.0757 = phi float [ 0.000000e+00, %for.body45.lr.ph ], [ %add354, %if.end310 ]
  %fiy1.0756 = phi float [ 0.000000e+00, %for.body45.lr.ph ], [ %add353, %if.end310 ]
  %fix1.0755 = phi float [ 0.000000e+00, %for.body45.lr.ph ], [ %add352, %if.end310 ]
  %dvdl.1754 = phi float [ %dvdl.0766, %for.body45.lr.ph ], [ %add347, %if.end310 ]
  %vnbtot.0753 = phi float [ 0.000000e+00, %for.body45.lr.ph ], [ %add319, %if.end310 ]
  %arrayidx47 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %15 = load i32* %arrayidx47, align 4, !tbaa !0
  %mul48 = mul nsw i32 %15, 3
  %idxprom49 = sext i32 %mul48 to i64
  %arrayidx50 = getelementptr inbounds float* %pos, i64 %idxprom49
  %16 = load float* %arrayidx50, align 4, !tbaa !3
  %add51 = add nsw i32 %mul48, 1
  %idxprom52 = sext i32 %add51 to i64
  %arrayidx53 = getelementptr inbounds float* %pos, i64 %idxprom52
  %17 = load float* %arrayidx53, align 4, !tbaa !3
  %add54 = add nsw i32 %mul48, 2
  %idxprom55 = sext i32 %add54 to i64
  %arrayidx56 = getelementptr inbounds float* %pos, i64 %idxprom55
  %18 = load float* %arrayidx56, align 4, !tbaa !3
  %sub57 = fsub float %add20, %16
  %sub58 = fsub float %add24, %17
  %sub59 = fsub float %add28, %18
  %mul60 = fmul float %sub57, %sub57
  %mul61 = fmul float %sub58, %sub58
  %add62 = fadd float %mul60, %mul61
  %mul63 = fmul float %sub59, %sub59
  %add64 = fadd float %add62, %mul63
  %conv = fpext float %add64 to double
  %call = tail call double @sqrt(double %conv) #2
  %idxprom67 = sext i32 %15 to i64
  %arrayidx68 = getelementptr inbounds i32* %type, i64 %idxprom67
  %19 = load i32* %arrayidx68, align 4, !tbaa !0
  %mul69 = mul nsw i32 %19, 3
  %add70 = add nsw i32 %mul69, %mul38
  %arrayidx72 = getelementptr inbounds i32* %typeB, i64 %idxprom67
  %20 = load i32* %arrayidx72, align 4, !tbaa !0
  %mul73 = mul nsw i32 %20, 3
  %add74 = add nsw i32 %mul73, %mul42
  %idxprom75 = sext i32 %add70 to i64
  %arrayidx76 = getelementptr inbounds float* %nbfp, i64 %idxprom75
  %21 = load float* %arrayidx76, align 4, !tbaa !3
  %idxprom77 = sext i32 %add74 to i64
  %arrayidx78 = getelementptr inbounds float* %nbfp, i64 %idxprom77
  %22 = load float* %arrayidx78, align 4, !tbaa !3
  %add79 = add nsw i32 %add70, 1
  %idxprom80 = sext i32 %add79 to i64
  %arrayidx81 = getelementptr inbounds float* %nbfp, i64 %idxprom80
  %23 = load float* %arrayidx81, align 4, !tbaa !3
  %add82 = add nsw i32 %add74, 1
  %idxprom83 = sext i32 %add82 to i64
  %arrayidx84 = getelementptr inbounds float* %nbfp, i64 %idxprom83
  %24 = load float* %arrayidx84, align 4, !tbaa !3
  %add85 = add nsw i32 %add70, 2
  %idxprom86 = sext i32 %add85 to i64
  %arrayidx87 = getelementptr inbounds float* %nbfp, i64 %idxprom86
  %25 = load float* %arrayidx87, align 4, !tbaa !3
  %add88 = add nsw i32 %add74, 2
  %idxprom89 = sext i32 %add88 to i64
  %arrayidx90 = getelementptr inbounds float* %nbfp, i64 %idxprom89
  %26 = load float* %arrayidx90, align 4, !tbaa !3
  %mul91 = fmul float %add64, %add64
  %mul92 = fmul float %add64, %mul91
  %arrayidx94 = getelementptr inbounds float* %charge, i64 %idxprom67
  %27 = load float* %arrayidx94, align 4, !tbaa !3
  %mul95 = fmul float %mul31, %27
  %cmp96 = fcmp une float %mul95, 0.000000e+00
  %cmp98 = fcmp ogt float %21, 0.000000e+00
  %or.cond = or i1 %cmp96, %cmp98
  %cmp101 = fcmp ogt float %23, 0.000000e+00
  %or.cond749 = or i1 %or.cond, %cmp101
  br i1 %or.cond749, label %if.then, label %if.end

if.then:                                          ; preds = %for.body45
  %add105 = fadd float %mul104, %mul92
  %conv106 = fpext float %add105 to double
  %call107 = tail call double @pow(double %conv106, double 0x3FC5555560000000) #2
  %conv108 = fptrunc double %call107 to float
  %conv111 = fdiv float 1.000000e+00, %conv108
  %mul112 = fmul float %conv111, %conv111
  %mul113 = fmul float %mul112, %mul112
  %mul114 = fmul float %conv111, %mul113
  %mul115 = fmul float %conv108, %tabscale
  %conv116 = fptosi float %mul115 to i32
  %conv117 = sitofp i32 %conv116 to float
  %sub118 = fsub float %mul115, %conv117
  %mul119 = fmul float %sub118, %sub118
  %mul120 = mul nsw i32 %conv116, 12
  %idxprom121 = sext i32 %mul120 to i64
  %arrayidx122 = getelementptr inbounds float* %VFtab, i64 %idxprom121
  %28 = load float* %arrayidx122, align 4, !tbaa !3
  %add123746 = or i32 %mul120, 1
  %idxprom124 = sext i32 %add123746 to i64
  %arrayidx125 = getelementptr inbounds float* %VFtab, i64 %idxprom124
  %29 = load float* %arrayidx125, align 4, !tbaa !3
  %add126747 = or i32 %mul120, 2
  %idxprom127 = sext i32 %add126747 to i64
  %arrayidx128 = getelementptr inbounds float* %VFtab, i64 %idxprom127
  %30 = load float* %arrayidx128, align 4, !tbaa !3
  %mul129 = fmul float %30, %sub118
  %add130748 = or i32 %mul120, 3
  %idxprom131 = sext i32 %add130748 to i64
  %arrayidx132 = getelementptr inbounds float* %VFtab, i64 %idxprom131
  %31 = load float* %arrayidx132, align 4, !tbaa !3
  %mul133 = fmul float %31, %mul119
  %add134 = fadd float %29, %mul129
  %add135 = fadd float %add134, %mul133
  %mul136 = fmul float %sub118, %add135
  %add137 = fadd float %28, %mul136
  %add138 = fadd float %mul129, %add135
  %mul139 = fmul float %mul133, 2.000000e+00
  %add140 = fadd float %mul139, %add138
  %mul141 = fmul float %mul95, %add137
  %mul142 = fmul float %mul95, %tabscale
  %mul143 = fmul float %mul142, %add140
  %add144 = add nsw i32 %mul120, 4
  %idxprom145 = sext i32 %add144 to i64
  %arrayidx146 = getelementptr inbounds float* %VFtab, i64 %idxprom145
  %32 = load float* %arrayidx146, align 4, !tbaa !3
  %add147 = add nsw i32 %mul120, 5
  %idxprom148 = sext i32 %add147 to i64
  %arrayidx149 = getelementptr inbounds float* %VFtab, i64 %idxprom148
  %33 = load float* %arrayidx149, align 4, !tbaa !3
  %add150 = add nsw i32 %mul120, 6
  %idxprom151 = sext i32 %add150 to i64
  %arrayidx152 = getelementptr inbounds float* %VFtab, i64 %idxprom151
  %34 = load float* %arrayidx152, align 4, !tbaa !3
  %mul153 = fmul float %sub118, %34
  %add154 = add nsw i32 %mul120, 7
  %idxprom155 = sext i32 %add154 to i64
  %arrayidx156 = getelementptr inbounds float* %VFtab, i64 %idxprom155
  %35 = load float* %arrayidx156, align 4, !tbaa !3
  %mul157 = fmul float %mul119, %35
  %add158 = fadd float %33, %mul153
  %add159 = fadd float %add158, %mul157
  %mul160 = fmul float %sub118, %add159
  %add161 = fadd float %32, %mul160
  %add162 = fadd float %mul153, %add159
  %mul163 = fmul float %mul157, 2.000000e+00
  %add164 = fadd float %mul163, %add162
  %mul165 = fmul float %21, %add161
  %mul166 = fmul float %21, %tabscale
  %mul167 = fmul float %mul166, %add164
  %mul168 = fmul float %25, %conv108
  %mul169 = fmul float %mul168, %tabscale
  %conv170 = fptosi float %mul169 to i32
  %conv171 = sitofp i32 %conv170 to float
  %sub172 = fsub float %mul169, %conv171
  %mul173 = fmul float %sub172, %sub172
  %mul174 = mul nsw i32 %conv170, 12
  %add175 = add nsw i32 %mul174, 8
  %idxprom176 = sext i32 %add175 to i64
  %arrayidx177 = getelementptr inbounds float* %VFtab, i64 %idxprom176
  %36 = load float* %arrayidx177, align 4, !tbaa !3
  %add178 = add nsw i32 %mul174, 9
  %idxprom179 = sext i32 %add178 to i64
  %arrayidx180 = getelementptr inbounds float* %VFtab, i64 %idxprom179
  %37 = load float* %arrayidx180, align 4, !tbaa !3
  %add181 = add nsw i32 %mul174, 10
  %idxprom182 = sext i32 %add181 to i64
  %arrayidx183 = getelementptr inbounds float* %VFtab, i64 %idxprom182
  %38 = load float* %arrayidx183, align 4, !tbaa !3
  %mul184 = fmul float %sub172, %38
  %add185 = add nsw i32 %mul174, 11
  %idxprom186 = sext i32 %add185 to i64
  %arrayidx187 = getelementptr inbounds float* %VFtab, i64 %idxprom186
  %39 = load float* %arrayidx187, align 4, !tbaa !3
  %mul188 = fmul float %mul173, %39
  %add189 = fadd float %37, %mul184
  %add190 = fadd float %add189, %mul188
  %mul191 = fmul float %sub172, %add190
  %add192 = fadd float %36, %mul191
  %add193 = fadd float %mul184, %add190
  %mul194 = fmul float %mul188, 2.000000e+00
  %add195 = fadd float %mul194, %add193
  %mul196 = fmul float %23, %add192
  %mul197 = fmul float %23, %25
  %mul198 = fmul float %mul197, %exptabscale
  %mul199 = fmul float %mul198, %add195
  br label %if.end

if.end:                                           ; preds = %for.body45, %if.then
  %FFRa.0 = phi float [ %mul199, %if.then ], [ 0.000000e+00, %for.body45 ]
  %VVRa.0 = phi float [ %mul196, %if.then ], [ 0.000000e+00, %for.body45 ]
  %FFDa.0 = phi float [ %mul167, %if.then ], [ 0.000000e+00, %for.body45 ]
  %VVDa.0 = phi float [ %mul165, %if.then ], [ 0.000000e+00, %for.body45 ]
  %FFCa.0 = phi float [ %mul143, %if.then ], [ 0.000000e+00, %for.body45 ]
  %VVCa.0 = phi float [ %mul141, %if.then ], [ 0.000000e+00, %for.body45 ]
  %rinv5a.0 = phi float [ %mul114, %if.then ], [ 0.000000e+00, %for.body45 ]
  %arrayidx201 = getelementptr inbounds float* %chargeB, i64 %idxprom67
  %40 = load float* %arrayidx201, align 4, !tbaa !3
  %mul202 = fmul float %mul34, %40
  %cmp203 = fcmp une float %mul202, 0.000000e+00
  %cmp206 = fcmp ogt float %22, 0.000000e+00
  %or.cond750 = or i1 %cmp203, %cmp206
  %cmp209 = fcmp ogt float %24, 0.000000e+00
  %or.cond751 = or i1 %or.cond750, %cmp209
  br i1 %or.cond751, label %if.then211, label %if.end310

if.then211:                                       ; preds = %if.end
  %add214 = fadd float %mul213, %mul92
  %conv215 = fpext float %add214 to double
  %call216 = tail call double @pow(double %conv215, double 0x3FC5555560000000) #2
  %conv217 = fptrunc double %call216 to float
  %conv220 = fdiv float 1.000000e+00, %conv217
  %mul221 = fmul float %conv220, %conv220
  %mul222 = fmul float %mul221, %mul221
  %mul223 = fmul float %conv220, %mul222
  %mul224 = fmul float %conv217, %tabscale
  %conv225 = fptosi float %mul224 to i32
  %conv226 = sitofp i32 %conv225 to float
  %sub227 = fsub float %mul224, %conv226
  %mul228 = fmul float %sub227, %sub227
  %mul229 = mul nsw i32 %conv225, 12
  %idxprom230 = sext i32 %mul229 to i64
  %arrayidx231 = getelementptr inbounds float* %VFtab, i64 %idxprom230
  %41 = load float* %arrayidx231, align 4, !tbaa !3
  %add232743 = or i32 %mul229, 1
  %idxprom233 = sext i32 %add232743 to i64
  %arrayidx234 = getelementptr inbounds float* %VFtab, i64 %idxprom233
  %42 = load float* %arrayidx234, align 4, !tbaa !3
  %add235744 = or i32 %mul229, 2
  %idxprom236 = sext i32 %add235744 to i64
  %arrayidx237 = getelementptr inbounds float* %VFtab, i64 %idxprom236
  %43 = load float* %arrayidx237, align 4, !tbaa !3
  %mul238 = fmul float %43, %sub227
  %add239745 = or i32 %mul229, 3
  %idxprom240 = sext i32 %add239745 to i64
  %arrayidx241 = getelementptr inbounds float* %VFtab, i64 %idxprom240
  %44 = load float* %arrayidx241, align 4, !tbaa !3
  %mul242 = fmul float %44, %mul228
  %add243 = fadd float %42, %mul238
  %add244 = fadd float %add243, %mul242
  %mul245 = fmul float %sub227, %add244
  %add246 = fadd float %41, %mul245
  %add247 = fadd float %mul238, %add244
  %mul248 = fmul float %mul242, 2.000000e+00
  %add249 = fadd float %mul248, %add247
  %mul250 = fmul float %mul202, %add246
  %mul251 = fmul float %mul202, %tabscale
  %mul252 = fmul float %mul251, %add249
  %add253 = add nsw i32 %mul229, 4
  %idxprom254 = sext i32 %add253 to i64
  %arrayidx255 = getelementptr inbounds float* %VFtab, i64 %idxprom254
  %45 = load float* %arrayidx255, align 4, !tbaa !3
  %add256 = add nsw i32 %mul229, 5
  %idxprom257 = sext i32 %add256 to i64
  %arrayidx258 = getelementptr inbounds float* %VFtab, i64 %idxprom257
  %46 = load float* %arrayidx258, align 4, !tbaa !3
  %add259 = add nsw i32 %mul229, 6
  %idxprom260 = sext i32 %add259 to i64
  %arrayidx261 = getelementptr inbounds float* %VFtab, i64 %idxprom260
  %47 = load float* %arrayidx261, align 4, !tbaa !3
  %mul262 = fmul float %sub227, %47
  %add263 = add nsw i32 %mul229, 7
  %idxprom264 = sext i32 %add263 to i64
  %arrayidx265 = getelementptr inbounds float* %VFtab, i64 %idxprom264
  %48 = load float* %arrayidx265, align 4, !tbaa !3
  %mul266 = fmul float %mul228, %48
  %add267 = fadd float %46, %mul262
  %add268 = fadd float %add267, %mul266
  %mul269 = fmul float %sub227, %add268
  %add270 = fadd float %45, %mul269
  %add271 = fadd float %mul262, %add268
  %mul272 = fmul float %mul266, 2.000000e+00
  %add273 = fadd float %mul272, %add271
  %mul274 = fmul float %22, %add270
  %mul275 = fmul float %22, %tabscale
  %mul276 = fmul float %mul275, %add273
  %mul277 = fmul float %26, %conv217
  %mul278 = fmul float %mul277, %tabscale
  %conv279 = fptosi float %mul278 to i32
  %conv280 = sitofp i32 %conv279 to float
  %sub281 = fsub float %mul278, %conv280
  %mul282 = fmul float %sub281, %sub281
  %mul283 = mul nsw i32 %conv279, 12
  %add284 = add nsw i32 %mul283, 8
  %idxprom285 = sext i32 %add284 to i64
  %arrayidx286 = getelementptr inbounds float* %VFtab, i64 %idxprom285
  %49 = load float* %arrayidx286, align 4, !tbaa !3
  %add287 = add nsw i32 %mul283, 9
  %idxprom288 = sext i32 %add287 to i64
  %arrayidx289 = getelementptr inbounds float* %VFtab, i64 %idxprom288
  %50 = load float* %arrayidx289, align 4, !tbaa !3
  %add290 = add nsw i32 %mul283, 10
  %idxprom291 = sext i32 %add290 to i64
  %arrayidx292 = getelementptr inbounds float* %VFtab, i64 %idxprom291
  %51 = load float* %arrayidx292, align 4, !tbaa !3
  %mul293 = fmul float %sub281, %51
  %add294 = add nsw i32 %mul283, 11
  %idxprom295 = sext i32 %add294 to i64
  %arrayidx296 = getelementptr inbounds float* %VFtab, i64 %idxprom295
  %52 = load float* %arrayidx296, align 4, !tbaa !3
  %mul297 = fmul float %mul282, %52
  %add298 = fadd float %50, %mul293
  %add299 = fadd float %add298, %mul297
  %mul300 = fmul float %sub281, %add299
  %add301 = fadd float %49, %mul300
  %add302 = fadd float %mul293, %add299
  %mul303 = fmul float %mul297, 2.000000e+00
  %add304 = fadd float %mul303, %add302
  %mul305 = fmul float %24, %add301
  %mul306 = fmul float %24, %26
  %mul307 = fmul float %mul306, %exptabscale
  %mul308 = fmul float %mul307, %add304
  br label %if.end310

if.end310:                                        ; preds = %if.end, %if.then211
  %FFRb.0 = phi float [ %mul308, %if.then211 ], [ 0.000000e+00, %if.end ]
  %VVRb.0 = phi float [ %mul305, %if.then211 ], [ 0.000000e+00, %if.end ]
  %FFDb.0 = phi float [ %mul276, %if.then211 ], [ 0.000000e+00, %if.end ]
  %VVDb.0 = phi float [ %mul274, %if.then211 ], [ 0.000000e+00, %if.end ]
  %FFCb.0 = phi float [ %mul252, %if.then211 ], [ 0.000000e+00, %if.end ]
  %VVCb.0 = phi float [ %mul250, %if.then211 ], [ 0.000000e+00, %if.end ]
  %rinv5b.0 = phi float [ %mul223, %if.then211 ], [ 0.000000e+00, %if.end ]
  %mul311 = fmul float %VVCb.0, %lambda
  %mul312 = fmul float %sub, %VVCa.0
  %add313 = fadd float %mul312, %mul311
  %add314 = fadd float %VVRb.0, %VVDb.0
  %mul315 = fmul float %add314, %lambda
  %add316 = fadd float %vnbtot.0753, %mul315
  %add317 = fadd float %VVRa.0, %VVDa.0
  %mul318 = fmul float %sub, %add317
  %add319 = fadd float %mul318, %add316
  %add320 = fadd float %FFDa.0, %FFCa.0
  %add321 = fadd float %FFRa.0, %add320
  %sub322 = fsub float -0.000000e+00, %add321
  %add323 = fadd float %FFDb.0, %FFCb.0
  %add324 = fadd float %FFRb.0, %add323
  %sub325 = fsub float -0.000000e+00, %add324
  %mul326 = fmul float %sub, %sub322
  %mul327 = fmul float %rinv5a.0, %mul326
  %mul328 = fmul float %lambda, %sub325
  %mul329 = fmul float %rinv5b.0, %mul328
  %add330 = fadd float %mul327, %mul329
  %mul331 = fmul float %mul91, %add330
  %add332 = fadd float %dvdl.1754, %VVCb.0
  %sub333 = fsub float %add332, %VVCa.0
  %add334 = fadd float %VVDb.0, %sub333
  %add335 = fadd float %VVRb.0, %add334
  %sub336 = fsub float %add335, %VVDa.0
  %sub337 = fsub float %sub336, %VVRa.0
  %mul341 = fmul float %defsigma6, %sub325
  %mul342 = fmul float %rinv5b.0, %mul341
  %mul343 = fmul float %defsigma6, %sub322
  %mul344 = fmul float %rinv5a.0, %mul343
  %sub345 = fsub float %mul342, %mul344
  %mul346 = fmul float %mul340, %sub345
  %add347 = fadd float %sub337, %mul346
  %add348 = fadd float %vctot.0758, %add313
  %mul349 = fmul float %sub57, %mul331
  %mul350 = fmul float %sub58, %mul331
  %mul351 = fmul float %sub59, %mul331
  %add352 = fadd float %fix1.0755, %mul349
  %add353 = fadd float %fiy1.0756, %mul350
  %add354 = fadd float %fiz1.0757, %mul351
  %arrayidx356 = getelementptr inbounds float* %faction, i64 %idxprom49
  %53 = load float* %arrayidx356, align 4, !tbaa !3
  %sub357 = fsub float %53, %mul349
  store float %sub357, float* %arrayidx356, align 4, !tbaa !3
  %arrayidx362 = getelementptr inbounds float* %faction, i64 %idxprom52
  %54 = load float* %arrayidx362, align 4, !tbaa !3
  %sub363 = fsub float %54, %mul350
  store float %sub363, float* %arrayidx362, align 4, !tbaa !3
  %arrayidx369 = getelementptr inbounds float* %faction, i64 %idxprom55
  %55 = load float* %arrayidx369, align 4, !tbaa !3
  %sub370 = fsub float %55, %mul351
  store float %sub370, float* %arrayidx369, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %56 = trunc i64 %indvars.iv.next to i32
  %cmp44 = icmp slt i32 %56, %6
  br i1 %cmp44, label %for.body45, label %for.end

for.end:                                          ; preds = %if.end310, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add348, %if.end310 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add354, %if.end310 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add353, %if.end310 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add352, %if.end310 ]
  %dvdl.1.lcssa = phi float [ %dvdl.0766, %for.body ], [ %add347, %if.end310 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add319, %if.end310 ]
  %arrayidx375 = getelementptr inbounds float* %faction, i64 %idxprom18
  %57 = load float* %arrayidx375, align 4, !tbaa !3
  %add376 = fadd float %fix1.0.lcssa, %57
  store float %add376, float* %arrayidx375, align 4, !tbaa !3
  %arrayidx381 = getelementptr inbounds float* %faction, i64 %idxprom22
  %58 = load float* %arrayidx381, align 4, !tbaa !3
  %add382 = fadd float %fiy1.0.lcssa, %58
  store float %add382, float* %arrayidx381, align 4, !tbaa !3
  %arrayidx388 = getelementptr inbounds float* %faction, i64 %idxprom26
  %59 = load float* %arrayidx388, align 4, !tbaa !3
  %add389 = fadd float %fiz1.0.lcssa, %59
  store float %add389, float* %arrayidx388, align 4, !tbaa !3
  %arrayidx394 = getelementptr inbounds float* %fshift, i64 %idxprom3
  %60 = load float* %arrayidx394, align 4, !tbaa !3
  %add395 = fadd float %fix1.0.lcssa, %60
  store float %add395, float* %arrayidx394, align 4, !tbaa !3
  %arrayidx400 = getelementptr inbounds float* %fshift, i64 %idxprom5
  %61 = load float* %arrayidx400, align 4, !tbaa !3
  %add401 = fadd float %fiy1.0.lcssa, %61
  store float %add401, float* %arrayidx400, align 4, !tbaa !3
  %arrayidx407 = getelementptr inbounds float* %fshift, i64 %idxprom8
  %62 = load float* %arrayidx407, align 4, !tbaa !3
  %add408 = fadd float %fiz1.0.lcssa, %62
  store float %add408, float* %arrayidx407, align 4, !tbaa !3
  %arrayidx413 = getelementptr inbounds i32* %gid, i64 %indvars.iv769
  %63 = load i32* %arrayidx413, align 4, !tbaa !0
  %idxprom414 = sext i32 %63 to i64
  %arrayidx415 = getelementptr inbounds float* %Vc, i64 %idxprom414
  %64 = load float* %arrayidx415, align 4, !tbaa !3
  %add416 = fadd float %vctot.0.lcssa, %64
  store float %add416, float* %arrayidx415, align 4, !tbaa !3
  %arrayidx420 = getelementptr inbounds float* %Vnb, i64 %idxprom414
  %65 = load float* %arrayidx420, align 4, !tbaa !3
  %add421 = fadd float %vnbtot.0.lcssa, %65
  store float %add421, float* %arrayidx420, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next770 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end426, label %for.body

for.end426:                                       ; preds = %for.end, %entry
  %dvdl.0.lcssa = phi float [ 0.000000e+00, %entry ], [ %dvdl.1.lcssa, %for.end ]
  %66 = load float* %dvdlambda, align 4, !tbaa !3
  %add427 = fadd float %dvdl.0.lcssa, %66
  store float %add427, float* %dvdlambda, align 4, !tbaa !3
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl3410(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* %VFtab, float %exptabscale, i32* nocapture %nsatoms) #0 {
entry:
  %cmp1173 = icmp sgt i32 %nri, 0
  br i1 %cmp1173, label %for.body, label %for.end607

for.body:                                         ; preds = %for.end592, %entry
  %indvars.iv1199 = phi i64 [ 0, %entry ], [ %indvars.iv.next1200, %for.end592 ]
  %0 = trunc i64 %indvars.iv1199 to i32
  %mul = mul nsw i32 %0, 3
  %idxprom = sext i32 %mul to i64
  %arrayidx = getelementptr inbounds i32* %nsatoms, i64 %idxprom
  %1 = load i32* %arrayidx, align 4, !tbaa !0
  %add = add nsw i32 %mul, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds i32* %nsatoms, i64 %idxprom2
  %2 = load i32* %arrayidx3, align 4, !tbaa !0
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds i32* %nsatoms, i64 %idxprom6
  %3 = load i32* %arrayidx7, align 4, !tbaa !0
  %arrayidx9 = getelementptr inbounds i32* %shift, i64 %indvars.iv1199
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %idxprom11 = sext i32 %mul10 to i64
  %arrayidx12 = getelementptr inbounds float* %shiftvec, i64 %idxprom11
  %5 = load float* %arrayidx12, align 4, !tbaa !3
  %add13 = add nsw i32 %mul10, 1
  %idxprom14 = sext i32 %add13 to i64
  %arrayidx15 = getelementptr inbounds float* %shiftvec, i64 %idxprom14
  %6 = load float* %arrayidx15, align 4, !tbaa !3
  %add16 = add nsw i32 %mul10, 2
  %idxprom17 = sext i32 %add16 to i64
  %arrayidx18 = getelementptr inbounds float* %shiftvec, i64 %idxprom17
  %7 = load float* %arrayidx18, align 4, !tbaa !3
  %arrayidx20 = getelementptr inbounds i32* %iinr, i64 %indvars.iv1199
  %8 = load i32* %arrayidx20, align 4, !tbaa !0
  %mul21 = mul i32 %8, 3
  %arrayidx23 = getelementptr inbounds i32* %jindex, i64 %indvars.iv1199
  %9 = load i32* %arrayidx23, align 4, !tbaa !0
  %indvars.iv.next1200 = add i64 %indvars.iv1199, 1
  %arrayidx26 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next1200
  %10 = load i32* %arrayidx26, align 4, !tbaa !0
  %cmp281129 = icmp sgt i32 %2, 0
  br i1 %cmp281129, label %for.body29.lr.ph, label %for.cond245.loopexit

for.body29.lr.ph:                                 ; preds = %for.body
  %cmp491118 = icmp slt i32 %9, %10
  %arrayidx222 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx228 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx235 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %11 = sext i32 %9 to i64
  %12 = sext i32 %8 to i64
  %13 = sext i32 %mul21 to i64
  %14 = add i32 %2, %8
  %15 = mul i32 %14, 3
  br label %for.body29

for.body29:                                       ; preds = %for.end, %for.body29.lr.ph
  %indvars.iv1177 = phi i64 [ %13, %for.body29.lr.ph ], [ %indvars.iv.next1178, %for.end ]
  %indvars.iv1175 = phi i64 [ %12, %for.body29.lr.ph ], [ %indvars.iv.next1176, %for.end ]
  %s.01132 = phi i32 [ 0, %for.body29.lr.ph ], [ %inc243, %for.end ]
  %vnbtot.01131 = phi float [ 0.000000e+00, %for.body29.lr.ph ], [ %vnbtot.1.lcssa, %for.end ]
  %vctot.01130 = phi float [ 0.000000e+00, %for.body29.lr.ph ], [ %vctot.1.lcssa, %for.end ]
  %arrayidx31 = getelementptr inbounds float* %pos, i64 %indvars.iv1177
  %16 = load float* %arrayidx31, align 4, !tbaa !3
  %add32 = fadd float %5, %16
  %17 = add nsw i64 %indvars.iv1177, 1
  %arrayidx35 = getelementptr inbounds float* %pos, i64 %17
  %18 = load float* %arrayidx35, align 4, !tbaa !3
  %add36 = fadd float %6, %18
  %19 = add nsw i64 %indvars.iv1177, 2
  %arrayidx39 = getelementptr inbounds float* %pos, i64 %19
  %20 = load float* %arrayidx39, align 4, !tbaa !3
  %add40 = fadd float %7, %20
  %arrayidx42 = getelementptr inbounds float* %charge, i64 %indvars.iv1175
  %21 = load float* %arrayidx42, align 4, !tbaa !3
  %mul43 = fmul float %21, %facel
  %arrayidx46 = getelementptr inbounds i32* %type, i64 %indvars.iv1175
  %22 = load i32* %arrayidx46, align 4, !tbaa !0
  %mul47 = mul i32 %22, %ntype
  br i1 %cmp491118, label %for.body50, label %for.end

for.body50:                                       ; preds = %for.body29, %for.body50
  %indvars.iv = phi i64 [ %indvars.iv.next, %for.body50 ], [ %11, %for.body29 ]
  %fiz1.01123 = phi float [ %add182, %for.body50 ], [ 0.000000e+00, %for.body29 ]
  %fiy1.01122 = phi float [ %add181, %for.body50 ], [ 0.000000e+00, %for.body29 ]
  %fix1.01121 = phi float [ %add180, %for.body50 ], [ 0.000000e+00, %for.body29 ]
  %vnbtot.11120 = phi float [ %add169, %for.body50 ], [ %vnbtot.01131, %for.body29 ]
  %vctot.11119 = phi float [ %add176, %for.body50 ], [ %vctot.01130, %for.body29 ]
  %arrayidx52 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %23 = load i32* %arrayidx52, align 4, !tbaa !0
  %mul53 = mul nsw i32 %23, 3
  %idxprom54 = sext i32 %mul53 to i64
  %arrayidx55 = getelementptr inbounds float* %pos, i64 %idxprom54
  %24 = load float* %arrayidx55, align 4, !tbaa !3
  %add56 = add nsw i32 %mul53, 1
  %idxprom57 = sext i32 %add56 to i64
  %arrayidx58 = getelementptr inbounds float* %pos, i64 %idxprom57
  %25 = load float* %arrayidx58, align 4, !tbaa !3
  %add59 = add nsw i32 %mul53, 2
  %idxprom60 = sext i32 %add59 to i64
  %arrayidx61 = getelementptr inbounds float* %pos, i64 %idxprom60
  %26 = load float* %arrayidx61, align 4, !tbaa !3
  %sub = fsub float %add32, %24
  %sub62 = fsub float %add36, %25
  %sub63 = fsub float %add40, %26
  %mul64 = fmul float %sub, %sub
  %mul65 = fmul float %sub62, %sub62
  %add66 = fadd float %mul64, %mul65
  %mul67 = fmul float %sub63, %sub63
  %add68 = fadd float %add66, %mul67
  %conv = fpext float %add68 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv69 = fptrunc double %div to float
  %mul70 = fmul float %add68, %conv69
  %mul71 = fmul float %mul70, %tabscale
  %conv72 = fptosi float %mul71 to i32
  %conv73 = sitofp i32 %conv72 to float
  %sub74 = fsub float %mul71, %conv73
  %mul75 = fmul float %sub74, %sub74
  %mul76 = mul nsw i32 %conv72, 12
  %idxprom77 = sext i32 %23 to i64
  %arrayidx78 = getelementptr inbounds float* %charge, i64 %idxprom77
  %27 = load float* %arrayidx78, align 4, !tbaa !3
  %mul79 = fmul float %mul43, %27
  %idxprom80 = sext i32 %mul76 to i64
  %arrayidx81 = getelementptr inbounds float* %VFtab, i64 %idxprom80
  %28 = load float* %arrayidx81, align 4, !tbaa !3
  %add821112 = or i32 %mul76, 1
  %idxprom83 = sext i32 %add821112 to i64
  %arrayidx84 = getelementptr inbounds float* %VFtab, i64 %idxprom83
  %29 = load float* %arrayidx84, align 4, !tbaa !3
  %add851113 = or i32 %mul76, 2
  %idxprom86 = sext i32 %add851113 to i64
  %arrayidx87 = getelementptr inbounds float* %VFtab, i64 %idxprom86
  %30 = load float* %arrayidx87, align 4, !tbaa !3
  %mul88 = fmul float %30, %sub74
  %add891114 = or i32 %mul76, 3
  %idxprom90 = sext i32 %add891114 to i64
  %arrayidx91 = getelementptr inbounds float* %VFtab, i64 %idxprom90
  %31 = load float* %arrayidx91, align 4, !tbaa !3
  %mul92 = fmul float %31, %mul75
  %add93 = fadd float %29, %mul88
  %add94 = fadd float %add93, %mul92
  %mul95 = fmul float %sub74, %add94
  %add96 = fadd float %28, %mul95
  %add97 = fadd float %mul88, %add94
  %mul98 = fmul float %mul92, 2.000000e+00
  %add99 = fadd float %mul98, %add97
  %mul100 = fmul float %mul79, %add96
  %mul101 = fmul float %mul79, %add99
  %arrayidx103 = getelementptr inbounds i32* %type, i64 %idxprom77
  %32 = load i32* %arrayidx103, align 4, !tbaa !0
  %tmp = add i32 %32, %mul47
  %tmp1115 = mul i32 %tmp, 3
  %idxprom106 = sext i32 %tmp1115 to i64
  %arrayidx107 = getelementptr inbounds float* %nbfp, i64 %idxprom106
  %33 = load float* %arrayidx107, align 4, !tbaa !3
  %add108 = add nsw i32 %tmp1115, 1
  %idxprom109 = sext i32 %add108 to i64
  %arrayidx110 = getelementptr inbounds float* %nbfp, i64 %idxprom109
  %34 = load float* %arrayidx110, align 4, !tbaa !3
  %add111 = add nsw i32 %tmp1115, 2
  %idxprom112 = sext i32 %add111 to i64
  %arrayidx113 = getelementptr inbounds float* %nbfp, i64 %idxprom112
  %35 = load float* %arrayidx113, align 4, !tbaa !3
  %add114 = add nsw i32 %mul76, 4
  %idxprom115 = sext i32 %add114 to i64
  %arrayidx116 = getelementptr inbounds float* %VFtab, i64 %idxprom115
  %36 = load float* %arrayidx116, align 4, !tbaa !3
  %add117 = add nsw i32 %mul76, 5
  %idxprom118 = sext i32 %add117 to i64
  %arrayidx119 = getelementptr inbounds float* %VFtab, i64 %idxprom118
  %37 = load float* %arrayidx119, align 4, !tbaa !3
  %add120 = add nsw i32 %mul76, 6
  %idxprom121 = sext i32 %add120 to i64
  %arrayidx122 = getelementptr inbounds float* %VFtab, i64 %idxprom121
  %38 = load float* %arrayidx122, align 4, !tbaa !3
  %mul123 = fmul float %sub74, %38
  %add124 = add nsw i32 %mul76, 7
  %idxprom125 = sext i32 %add124 to i64
  %arrayidx126 = getelementptr inbounds float* %VFtab, i64 %idxprom125
  %39 = load float* %arrayidx126, align 4, !tbaa !3
  %mul127 = fmul float %mul75, %39
  %add128 = fadd float %37, %mul123
  %add129 = fadd float %add128, %mul127
  %mul130 = fmul float %sub74, %add129
  %add131 = fadd float %36, %mul130
  %add132 = fadd float %mul123, %add129
  %mul133 = fmul float %mul127, 2.000000e+00
  %add134 = fadd float %mul133, %add132
  %mul135 = fmul float %33, %add131
  %mul136 = fmul float %33, %add134
  %mul137 = fmul float %mul70, %35
  %mul138 = fmul float %mul137, %exptabscale
  %conv139 = fptosi float %mul138 to i32
  %conv140 = sitofp i32 %conv139 to float
  %sub141 = fsub float %mul138, %conv140
  %mul142 = fmul float %sub141, %sub141
  %mul143 = mul nsw i32 %conv139, 12
  %add144 = add nsw i32 %mul143, 8
  %idxprom145 = sext i32 %add144 to i64
  %arrayidx146 = getelementptr inbounds float* %VFtab, i64 %idxprom145
  %40 = load float* %arrayidx146, align 4, !tbaa !3
  %add147 = add nsw i32 %mul143, 9
  %idxprom148 = sext i32 %add147 to i64
  %arrayidx149 = getelementptr inbounds float* %VFtab, i64 %idxprom148
  %41 = load float* %arrayidx149, align 4, !tbaa !3
  %add150 = add nsw i32 %mul143, 10
  %idxprom151 = sext i32 %add150 to i64
  %arrayidx152 = getelementptr inbounds float* %VFtab, i64 %idxprom151
  %42 = load float* %arrayidx152, align 4, !tbaa !3
  %mul153 = fmul float %sub141, %42
  %add154 = add nsw i32 %mul143, 11
  %idxprom155 = sext i32 %add154 to i64
  %arrayidx156 = getelementptr inbounds float* %VFtab, i64 %idxprom155
  %43 = load float* %arrayidx156, align 4, !tbaa !3
  %mul157 = fmul float %mul142, %43
  %add158 = fadd float %41, %mul153
  %add159 = fadd float %add158, %mul157
  %mul160 = fmul float %sub141, %add159
  %add161 = fadd float %40, %mul160
  %add162 = fadd float %mul153, %add159
  %mul163 = fmul float %mul157, 2.000000e+00
  %add164 = fadd float %mul163, %add162
  %mul165 = fmul float %34, %add161
  %mul166 = fmul float %34, %35
  %mul167 = fmul float %mul166, %add164
  %add168 = fadd float %vnbtot.11120, %mul135
  %add169 = fadd float %add168, %mul165
  %add170 = fadd float %mul101, %mul136
  %mul171 = fmul float %add170, %tabscale
  %mul172 = fmul float %mul167, %exptabscale
  %add173 = fadd float %mul171, %mul172
  %44 = fmul float %conv69, %add173
  %mul175 = fsub float -0.000000e+00, %44
  %add176 = fadd float %vctot.11119, %mul100
  %mul177 = fmul float %sub, %mul175
  %mul178 = fmul float %sub62, %mul175
  %mul179 = fmul float %sub63, %mul175
  %add180 = fadd float %fix1.01121, %mul177
  %add181 = fadd float %fiy1.01122, %mul178
  %add182 = fadd float %fiz1.01123, %mul179
  %arrayidx184 = getelementptr inbounds float* %faction, i64 %idxprom54
  %45 = load float* %arrayidx184, align 4, !tbaa !3
  %sub185 = fsub float %45, %mul177
  store float %sub185, float* %arrayidx184, align 4, !tbaa !3
  %arrayidx190 = getelementptr inbounds float* %faction, i64 %idxprom57
  %46 = load float* %arrayidx190, align 4, !tbaa !3
  %sub191 = fsub float %46, %mul178
  store float %sub191, float* %arrayidx190, align 4, !tbaa !3
  %arrayidx197 = getelementptr inbounds float* %faction, i64 %idxprom60
  %47 = load float* %arrayidx197, align 4, !tbaa !3
  %sub198 = fsub float %47, %mul179
  store float %sub198, float* %arrayidx197, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %48 = trunc i64 %indvars.iv.next to i32
  %cmp49 = icmp slt i32 %48, %10
  br i1 %cmp49, label %for.body50, label %for.end

for.end:                                          ; preds = %for.body50, %for.body29
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add182, %for.body50 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add181, %for.body50 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body29 ], [ %add180, %for.body50 ]
  %vnbtot.1.lcssa = phi float [ %vnbtot.01131, %for.body29 ], [ %add169, %for.body50 ]
  %vctot.1.lcssa = phi float [ %vctot.01130, %for.body29 ], [ %add176, %for.body50 ]
  %arrayidx203 = getelementptr inbounds float* %faction, i64 %indvars.iv1177
  %49 = load float* %arrayidx203, align 4, !tbaa !3
  %add204 = fadd float %fix1.0.lcssa, %49
  store float %add204, float* %arrayidx203, align 4, !tbaa !3
  %arrayidx209 = getelementptr inbounds float* %faction, i64 %17
  %50 = load float* %arrayidx209, align 4, !tbaa !3
  %add210 = fadd float %fiy1.0.lcssa, %50
  store float %add210, float* %arrayidx209, align 4, !tbaa !3
  %arrayidx216 = getelementptr inbounds float* %faction, i64 %19
  %51 = load float* %arrayidx216, align 4, !tbaa !3
  %add217 = fadd float %fiz1.0.lcssa, %51
  store float %add217, float* %arrayidx216, align 4, !tbaa !3
  %52 = load float* %arrayidx222, align 4, !tbaa !3
  %add223 = fadd float %fix1.0.lcssa, %52
  store float %add223, float* %arrayidx222, align 4, !tbaa !3
  %53 = load float* %arrayidx228, align 4, !tbaa !3
  %add229 = fadd float %fiy1.0.lcssa, %53
  store float %add229, float* %arrayidx228, align 4, !tbaa !3
  %54 = load float* %arrayidx235, align 4, !tbaa !3
  %add236 = fadd float %fiz1.0.lcssa, %54
  store float %add236, float* %arrayidx235, align 4, !tbaa !3
  %indvars.iv.next1176 = add i64 %indvars.iv1175, 1
  %indvars.iv.next1178 = add i64 %indvars.iv1177, 3
  %inc243 = add nsw i32 %s.01132, 1
  %exitcond = icmp eq i32 %inc243, %2
  br i1 %exitcond, label %for.cond27.for.cond245.loopexit_crit_edge, label %for.body29

for.cond27.for.cond245.loopexit_crit_edge:        ; preds = %for.end
  %55 = add i32 %2, %8
  br label %for.cond245.loopexit

for.cond245.loopexit:                             ; preds = %for.cond27.for.cond245.loopexit_crit_edge, %for.body
  %ii.0.lcssa = phi i32 [ %55, %for.cond27.for.cond245.loopexit_crit_edge ], [ %8, %for.body ]
  %ii3.0.lcssa = phi i32 [ %15, %for.cond27.for.cond245.loopexit_crit_edge ], [ %mul21, %for.body ]
  %vnbtot.0.lcssa = phi float [ %vnbtot.1.lcssa, %for.cond27.for.cond245.loopexit_crit_edge ], [ 0.000000e+00, %for.body ]
  %vctot.0.lcssa = phi float [ %vctot.1.lcssa, %for.cond27.for.cond245.loopexit_crit_edge ], [ 0.000000e+00, %for.body ]
  %cmp2461149 = icmp slt i32 %2, %3
  br i1 %cmp2461149, label %for.body248.lr.ph, label %for.cond397.loopexit

for.body248.lr.ph:                                ; preds = %for.cond245.loopexit
  %cmp2641139 = icmp slt i32 %9, %10
  %arrayidx374 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx380 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx387 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %56 = sext i32 %9 to i64
  %57 = sext i32 %ii.0.lcssa to i64
  %58 = sext i32 %ii3.0.lcssa to i64
  %59 = mul i32 %3, 3
  %60 = add i32 %ii.0.lcssa, %3
  br label %for.body248

for.body248:                                      ; preds = %for.end353, %for.body248.lr.ph
  %indvars.iv1185 = phi i64 [ %58, %for.body248.lr.ph ], [ %indvars.iv.next1186, %for.end353 ]
  %indvars.iv1183 = phi i64 [ %57, %for.body248.lr.ph ], [ %indvars.iv.next1184, %for.end353 ]
  %s.11151 = phi i32 [ %2, %for.body248.lr.ph ], [ %inc395, %for.end353 ]
  %vctot.21150 = phi float [ %vctot.0.lcssa, %for.body248.lr.ph ], [ %vctot.3.lcssa, %for.end353 ]
  %arrayidx250 = getelementptr inbounds float* %pos, i64 %indvars.iv1185
  %61 = load float* %arrayidx250, align 4, !tbaa !3
  %add251 = fadd float %5, %61
  %62 = add nsw i64 %indvars.iv1185, 1
  %arrayidx254 = getelementptr inbounds float* %pos, i64 %62
  %63 = load float* %arrayidx254, align 4, !tbaa !3
  %add255 = fadd float %6, %63
  %64 = add nsw i64 %indvars.iv1185, 2
  %arrayidx258 = getelementptr inbounds float* %pos, i64 %64
  %65 = load float* %arrayidx258, align 4, !tbaa !3
  %add259 = fadd float %7, %65
  %arrayidx261 = getelementptr inbounds float* %charge, i64 %indvars.iv1183
  %66 = load float* %arrayidx261, align 4, !tbaa !3
  %mul262 = fmul float %66, %facel
  br i1 %cmp2641139, label %for.body266, label %for.end353

for.body266:                                      ; preds = %for.body248, %for.body266
  %indvars.iv1181 = phi i64 [ %indvars.iv.next1182, %for.body266 ], [ %56, %for.body248 ]
  %fiz1.11143 = phi float [ %add331, %for.body266 ], [ 0.000000e+00, %for.body248 ]
  %fiy1.11142 = phi float [ %add330, %for.body266 ], [ 0.000000e+00, %for.body248 ]
  %fix1.11141 = phi float [ %add329, %for.body266 ], [ 0.000000e+00, %for.body248 ]
  %vctot.31140 = phi float [ %add325, %for.body266 ], [ %vctot.21150, %for.body248 ]
  %arrayidx268 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv1181
  %67 = load i32* %arrayidx268, align 4, !tbaa !0
  %mul269 = mul nsw i32 %67, 3
  %idxprom270 = sext i32 %mul269 to i64
  %arrayidx271 = getelementptr inbounds float* %pos, i64 %idxprom270
  %68 = load float* %arrayidx271, align 4, !tbaa !3
  %add272 = add nsw i32 %mul269, 1
  %idxprom273 = sext i32 %add272 to i64
  %arrayidx274 = getelementptr inbounds float* %pos, i64 %idxprom273
  %69 = load float* %arrayidx274, align 4, !tbaa !3
  %add275 = add nsw i32 %mul269, 2
  %idxprom276 = sext i32 %add275 to i64
  %arrayidx277 = getelementptr inbounds float* %pos, i64 %idxprom276
  %70 = load float* %arrayidx277, align 4, !tbaa !3
  %sub278 = fsub float %add251, %68
  %sub279 = fsub float %add255, %69
  %sub280 = fsub float %add259, %70
  %mul281 = fmul float %sub278, %sub278
  %mul282 = fmul float %sub279, %sub279
  %add283 = fadd float %mul281, %mul282
  %mul284 = fmul float %sub280, %sub280
  %add285 = fadd float %add283, %mul284
  %conv286 = fpext float %add285 to double
  %call287 = tail call double @sqrt(double %conv286) #2
  %div288 = fdiv double 1.000000e+00, %call287
  %conv289 = fptrunc double %div288 to float
  %mul290 = fmul float %add285, %conv289
  %mul291 = fmul float %mul290, %tabscale
  %conv292 = fptosi float %mul291 to i32
  %conv293 = sitofp i32 %conv292 to float
  %sub294 = fsub float %mul291, %conv293
  %mul295 = fmul float %sub294, %sub294
  %mul296 = mul nsw i32 %conv292, 12
  %idxprom297 = sext i32 %67 to i64
  %arrayidx298 = getelementptr inbounds float* %charge, i64 %idxprom297
  %71 = load float* %arrayidx298, align 4, !tbaa !3
  %mul299 = fmul float %mul262, %71
  %idxprom300 = sext i32 %mul296 to i64
  %arrayidx301 = getelementptr inbounds float* %VFtab, i64 %idxprom300
  %72 = load float* %arrayidx301, align 4, !tbaa !3
  %add3021109 = or i32 %mul296, 1
  %idxprom303 = sext i32 %add3021109 to i64
  %arrayidx304 = getelementptr inbounds float* %VFtab, i64 %idxprom303
  %73 = load float* %arrayidx304, align 4, !tbaa !3
  %add3051110 = or i32 %mul296, 2
  %idxprom306 = sext i32 %add3051110 to i64
  %arrayidx307 = getelementptr inbounds float* %VFtab, i64 %idxprom306
  %74 = load float* %arrayidx307, align 4, !tbaa !3
  %mul308 = fmul float %74, %sub294
  %add3091111 = or i32 %mul296, 3
  %idxprom310 = sext i32 %add3091111 to i64
  %arrayidx311 = getelementptr inbounds float* %VFtab, i64 %idxprom310
  %75 = load float* %arrayidx311, align 4, !tbaa !3
  %mul312 = fmul float %75, %mul295
  %add313 = fadd float %73, %mul308
  %add314 = fadd float %add313, %mul312
  %mul315 = fmul float %sub294, %add314
  %add316 = fadd float %72, %mul315
  %add317 = fadd float %mul308, %add314
  %mul318 = fmul float %mul312, 2.000000e+00
  %add319 = fadd float %mul318, %add317
  %mul320 = fmul float %mul299, %add316
  %mul321 = fmul float %mul299, %add319
  %mul322 = fmul float %mul321, %tabscale
  %76 = fmul float %conv289, %mul322
  %mul324 = fsub float -0.000000e+00, %76
  %add325 = fadd float %vctot.31140, %mul320
  %mul326 = fmul float %sub278, %mul324
  %mul327 = fmul float %sub279, %mul324
  %mul328 = fmul float %sub280, %mul324
  %add329 = fadd float %fix1.11141, %mul326
  %add330 = fadd float %fiy1.11142, %mul327
  %add331 = fadd float %fiz1.11143, %mul328
  %arrayidx333 = getelementptr inbounds float* %faction, i64 %idxprom270
  %77 = load float* %arrayidx333, align 4, !tbaa !3
  %sub334 = fsub float %77, %mul326
  store float %sub334, float* %arrayidx333, align 4, !tbaa !3
  %arrayidx339 = getelementptr inbounds float* %faction, i64 %idxprom273
  %78 = load float* %arrayidx339, align 4, !tbaa !3
  %sub340 = fsub float %78, %mul327
  store float %sub340, float* %arrayidx339, align 4, !tbaa !3
  %arrayidx346 = getelementptr inbounds float* %faction, i64 %idxprom276
  %79 = load float* %arrayidx346, align 4, !tbaa !3
  %sub347 = fsub float %79, %mul328
  store float %sub347, float* %arrayidx346, align 4, !tbaa !3
  %indvars.iv.next1182 = add i64 %indvars.iv1181, 1
  %80 = trunc i64 %indvars.iv.next1182 to i32
  %cmp264 = icmp slt i32 %80, %10
  br i1 %cmp264, label %for.body266, label %for.end353

for.end353:                                       ; preds = %for.body266, %for.body248
  %fiz1.1.lcssa = phi float [ 0.000000e+00, %for.body248 ], [ %add331, %for.body266 ]
  %fiy1.1.lcssa = phi float [ 0.000000e+00, %for.body248 ], [ %add330, %for.body266 ]
  %fix1.1.lcssa = phi float [ 0.000000e+00, %for.body248 ], [ %add329, %for.body266 ]
  %vctot.3.lcssa = phi float [ %vctot.21150, %for.body248 ], [ %add325, %for.body266 ]
  %arrayidx355 = getelementptr inbounds float* %faction, i64 %indvars.iv1185
  %81 = load float* %arrayidx355, align 4, !tbaa !3
  %add356 = fadd float %fix1.1.lcssa, %81
  store float %add356, float* %arrayidx355, align 4, !tbaa !3
  %arrayidx361 = getelementptr inbounds float* %faction, i64 %62
  %82 = load float* %arrayidx361, align 4, !tbaa !3
  %add362 = fadd float %fiy1.1.lcssa, %82
  store float %add362, float* %arrayidx361, align 4, !tbaa !3
  %arrayidx368 = getelementptr inbounds float* %faction, i64 %64
  %83 = load float* %arrayidx368, align 4, !tbaa !3
  %add369 = fadd float %fiz1.1.lcssa, %83
  store float %add369, float* %arrayidx368, align 4, !tbaa !3
  %84 = load float* %arrayidx374, align 4, !tbaa !3
  %add375 = fadd float %fix1.1.lcssa, %84
  store float %add375, float* %arrayidx374, align 4, !tbaa !3
  %85 = load float* %arrayidx380, align 4, !tbaa !3
  %add381 = fadd float %fiy1.1.lcssa, %85
  store float %add381, float* %arrayidx380, align 4, !tbaa !3
  %86 = load float* %arrayidx387, align 4, !tbaa !3
  %add388 = fadd float %fiz1.1.lcssa, %86
  store float %add388, float* %arrayidx387, align 4, !tbaa !3
  %indvars.iv.next1184 = add i64 %indvars.iv1183, 1
  %indvars.iv.next1186 = add i64 %indvars.iv1185, 3
  %inc395 = add nsw i32 %s.11151, 1
  %exitcond1189 = icmp eq i32 %inc395, %3
  br i1 %exitcond1189, label %for.cond245.for.cond397.loopexit_crit_edge, label %for.body248

for.cond245.for.cond397.loopexit_crit_edge:       ; preds = %for.end353
  %87 = add i32 %ii3.0.lcssa, %59
  %88 = mul i32 %2, -3
  %89 = add i32 %87, %88
  %90 = sub i32 %60, %2
  br label %for.cond397.loopexit

for.cond397.loopexit:                             ; preds = %for.cond245.for.cond397.loopexit_crit_edge, %for.cond245.loopexit
  %ii.1.lcssa = phi i32 [ %90, %for.cond245.for.cond397.loopexit_crit_edge ], [ %ii.0.lcssa, %for.cond245.loopexit ]
  %ii3.1.lcssa = phi i32 [ %89, %for.cond245.for.cond397.loopexit_crit_edge ], [ %ii3.0.lcssa, %for.cond245.loopexit ]
  %vctot.2.lcssa = phi float [ %vctot.3.lcssa, %for.cond245.for.cond397.loopexit_crit_edge ], [ %vctot.0.lcssa, %for.cond245.loopexit ]
  %cmp3981167 = icmp slt i32 %3, %1
  br i1 %cmp3981167, label %for.body400.lr.ph, label %for.end592

for.body400.lr.ph:                                ; preds = %for.cond397.loopexit
  %cmp4171157 = icmp slt i32 %9, %10
  %arrayidx570 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %arrayidx576 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %arrayidx583 = getelementptr inbounds float* %fshift, i64 %idxprom17
  %91 = sext i32 %9 to i64
  %92 = sext i32 %ii.1.lcssa to i64
  %93 = sext i32 %ii3.1.lcssa to i64
  br label %for.body400

for.body400:                                      ; preds = %for.end549, %for.body400.lr.ph
  %indvars.iv1194 = phi i64 [ %93, %for.body400.lr.ph ], [ %indvars.iv.next1195, %for.end549 ]
  %indvars.iv1192 = phi i64 [ %92, %for.body400.lr.ph ], [ %indvars.iv.next1193, %for.end549 ]
  %s.21169 = phi i32 [ %3, %for.body400.lr.ph ], [ %inc591, %for.end549 ]
  %vnbtot.21168 = phi float [ %vnbtot.0.lcssa, %for.body400.lr.ph ], [ %vnbtot.3.lcssa, %for.end549 ]
  %arrayidx402 = getelementptr inbounds float* %pos, i64 %indvars.iv1194
  %94 = load float* %arrayidx402, align 4, !tbaa !3
  %add403 = fadd float %5, %94
  %95 = add nsw i64 %indvars.iv1194, 1
  %arrayidx406 = getelementptr inbounds float* %pos, i64 %95
  %96 = load float* %arrayidx406, align 4, !tbaa !3
  %add407 = fadd float %6, %96
  %97 = add nsw i64 %indvars.iv1194, 2
  %arrayidx410 = getelementptr inbounds float* %pos, i64 %97
  %98 = load float* %arrayidx410, align 4, !tbaa !3
  %add411 = fadd float %7, %98
  %arrayidx414 = getelementptr inbounds i32* %type, i64 %indvars.iv1192
  %99 = load i32* %arrayidx414, align 4, !tbaa !0
  %mul415 = mul i32 %99, %ntype
  br i1 %cmp4171157, label %for.body419, label %for.end549

for.body419:                                      ; preds = %for.body400, %for.body419
  %indvars.iv1190 = phi i64 [ %indvars.iv.next1191, %for.body419 ], [ %91, %for.body400 ]
  %fiz1.21161 = phi float [ %add527, %for.body419 ], [ 0.000000e+00, %for.body400 ]
  %fiy1.21160 = phi float [ %add526, %for.body419 ], [ 0.000000e+00, %for.body400 ]
  %fix1.21159 = phi float [ %add525, %for.body419 ], [ 0.000000e+00, %for.body400 ]
  %vnbtot.31158 = phi float [ %add516, %for.body419 ], [ %vnbtot.21168, %for.body400 ]
  %arrayidx421 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv1190
  %100 = load i32* %arrayidx421, align 4, !tbaa !0
  %mul422 = mul nsw i32 %100, 3
  %idxprom423 = sext i32 %mul422 to i64
  %arrayidx424 = getelementptr inbounds float* %pos, i64 %idxprom423
  %101 = load float* %arrayidx424, align 4, !tbaa !3
  %add425 = add nsw i32 %mul422, 1
  %idxprom426 = sext i32 %add425 to i64
  %arrayidx427 = getelementptr inbounds float* %pos, i64 %idxprom426
  %102 = load float* %arrayidx427, align 4, !tbaa !3
  %add428 = add nsw i32 %mul422, 2
  %idxprom429 = sext i32 %add428 to i64
  %arrayidx430 = getelementptr inbounds float* %pos, i64 %idxprom429
  %103 = load float* %arrayidx430, align 4, !tbaa !3
  %sub431 = fsub float %add403, %101
  %sub432 = fsub float %add407, %102
  %sub433 = fsub float %add411, %103
  %mul434 = fmul float %sub431, %sub431
  %mul435 = fmul float %sub432, %sub432
  %add436 = fadd float %mul434, %mul435
  %mul437 = fmul float %sub433, %sub433
  %add438 = fadd float %add436, %mul437
  %conv439 = fpext float %add438 to double
  %call440 = tail call double @sqrt(double %conv439) #2
  %div441 = fdiv double 1.000000e+00, %call440
  %conv442 = fptrunc double %div441 to float
  %mul443 = fmul float %add438, %conv442
  %mul444 = fmul float %mul443, %tabscale
  %conv445 = fptosi float %mul444 to i32
  %conv446 = sitofp i32 %conv445 to float
  %sub447 = fsub float %mul444, %conv446
  %mul448 = fmul float %sub447, %sub447
  %mul449 = mul nsw i32 %conv445, 12
  %idxprom450 = sext i32 %100 to i64
  %arrayidx451 = getelementptr inbounds i32* %type, i64 %idxprom450
  %104 = load i32* %arrayidx451, align 4, !tbaa !0
  %tmp1116 = add i32 %104, %mul415
  %tmp1117 = mul i32 %tmp1116, 3
  %idxprom454 = sext i32 %tmp1117 to i64
  %arrayidx455 = getelementptr inbounds float* %nbfp, i64 %idxprom454
  %105 = load float* %arrayidx455, align 4, !tbaa !3
  %add456 = add nsw i32 %tmp1117, 1
  %idxprom457 = sext i32 %add456 to i64
  %arrayidx458 = getelementptr inbounds float* %nbfp, i64 %idxprom457
  %106 = load float* %arrayidx458, align 4, !tbaa !3
  %add459 = add nsw i32 %tmp1117, 2
  %idxprom460 = sext i32 %add459 to i64
  %arrayidx461 = getelementptr inbounds float* %nbfp, i64 %idxprom460
  %107 = load float* %arrayidx461, align 4, !tbaa !3
  %idxprom462 = sext i32 %mul449 to i64
  %arrayidx463 = getelementptr inbounds float* %VFtab, i64 %idxprom462
  %108 = load float* %arrayidx463, align 4, !tbaa !3
  %add4641106 = or i32 %mul449, 1
  %idxprom465 = sext i32 %add4641106 to i64
  %arrayidx466 = getelementptr inbounds float* %VFtab, i64 %idxprom465
  %109 = load float* %arrayidx466, align 4, !tbaa !3
  %add4671107 = or i32 %mul449, 2
  %idxprom468 = sext i32 %add4671107 to i64
  %arrayidx469 = getelementptr inbounds float* %VFtab, i64 %idxprom468
  %110 = load float* %arrayidx469, align 4, !tbaa !3
  %mul470 = fmul float %sub447, %110
  %add4711108 = or i32 %mul449, 3
  %idxprom472 = sext i32 %add4711108 to i64
  %arrayidx473 = getelementptr inbounds float* %VFtab, i64 %idxprom472
  %111 = load float* %arrayidx473, align 4, !tbaa !3
  %mul474 = fmul float %mul448, %111
  %add475 = fadd float %109, %mul470
  %add476 = fadd float %add475, %mul474
  %mul477 = fmul float %sub447, %add476
  %add478 = fadd float %108, %mul477
  %add479 = fadd float %mul470, %add476
  %mul480 = fmul float %mul474, 2.000000e+00
  %add481 = fadd float %mul480, %add479
  %mul482 = fmul float %105, %add478
  %mul483 = fmul float %105, %add481
  %mul484 = fmul float %mul443, %107
  %mul485 = fmul float %mul484, %exptabscale
  %conv486 = fptosi float %mul485 to i32
  %conv487 = sitofp i32 %conv486 to float
  %sub488 = fsub float %mul485, %conv487
  %mul489 = fmul float %sub488, %sub488
  %mul490 = mul nsw i32 %conv486, 12
  %add491 = add nsw i32 %mul490, 4
  %idxprom492 = sext i32 %add491 to i64
  %arrayidx493 = getelementptr inbounds float* %VFtab, i64 %idxprom492
  %112 = load float* %arrayidx493, align 4, !tbaa !3
  %add494 = add nsw i32 %mul490, 5
  %idxprom495 = sext i32 %add494 to i64
  %arrayidx496 = getelementptr inbounds float* %VFtab, i64 %idxprom495
  %113 = load float* %arrayidx496, align 4, !tbaa !3
  %add497 = add nsw i32 %mul490, 6
  %idxprom498 = sext i32 %add497 to i64
  %arrayidx499 = getelementptr inbounds float* %VFtab, i64 %idxprom498
  %114 = load float* %arrayidx499, align 4, !tbaa !3
  %mul500 = fmul float %sub488, %114
  %add501 = add nsw i32 %mul490, 7
  %idxprom502 = sext i32 %add501 to i64
  %arrayidx503 = getelementptr inbounds float* %VFtab, i64 %idxprom502
  %115 = load float* %arrayidx503, align 4, !tbaa !3
  %mul504 = fmul float %mul489, %115
  %add505 = fadd float %113, %mul500
  %add506 = fadd float %add505, %mul504
  %mul507 = fmul float %sub488, %add506
  %add508 = fadd float %112, %mul507
  %add509 = fadd float %mul500, %add506
  %mul510 = fmul float %mul504, 2.000000e+00
  %add511 = fadd float %mul510, %add509
  %mul512 = fmul float %106, %add508
  %mul513 = fmul float %106, %107
  %mul514 = fmul float %mul513, %add511
  %add515 = fadd float %vnbtot.31158, %mul482
  %add516 = fadd float %add515, %mul512
  %mul517 = fmul float %mul483, %tabscale
  %mul518 = fmul float %mul514, %exptabscale
  %add519 = fadd float %mul517, %mul518
  %116 = fmul float %conv442, %add519
  %mul521 = fsub float -0.000000e+00, %116
  %mul522 = fmul float %sub431, %mul521
  %mul523 = fmul float %sub432, %mul521
  %mul524 = fmul float %sub433, %mul521
  %add525 = fadd float %fix1.21159, %mul522
  %add526 = fadd float %fiy1.21160, %mul523
  %add527 = fadd float %fiz1.21161, %mul524
  %arrayidx529 = getelementptr inbounds float* %faction, i64 %idxprom423
  %117 = load float* %arrayidx529, align 4, !tbaa !3
  %sub530 = fsub float %117, %mul522
  store float %sub530, float* %arrayidx529, align 4, !tbaa !3
  %arrayidx535 = getelementptr inbounds float* %faction, i64 %idxprom426
  %118 = load float* %arrayidx535, align 4, !tbaa !3
  %sub536 = fsub float %118, %mul523
  store float %sub536, float* %arrayidx535, align 4, !tbaa !3
  %arrayidx542 = getelementptr inbounds float* %faction, i64 %idxprom429
  %119 = load float* %arrayidx542, align 4, !tbaa !3
  %sub543 = fsub float %119, %mul524
  store float %sub543, float* %arrayidx542, align 4, !tbaa !3
  %indvars.iv.next1191 = add i64 %indvars.iv1190, 1
  %120 = trunc i64 %indvars.iv.next1191 to i32
  %cmp417 = icmp slt i32 %120, %10
  br i1 %cmp417, label %for.body419, label %for.end549

for.end549:                                       ; preds = %for.body419, %for.body400
  %fiz1.2.lcssa = phi float [ 0.000000e+00, %for.body400 ], [ %add527, %for.body419 ]
  %fiy1.2.lcssa = phi float [ 0.000000e+00, %for.body400 ], [ %add526, %for.body419 ]
  %fix1.2.lcssa = phi float [ 0.000000e+00, %for.body400 ], [ %add525, %for.body419 ]
  %vnbtot.3.lcssa = phi float [ %vnbtot.21168, %for.body400 ], [ %add516, %for.body419 ]
  %arrayidx551 = getelementptr inbounds float* %faction, i64 %indvars.iv1194
  %121 = load float* %arrayidx551, align 4, !tbaa !3
  %add552 = fadd float %fix1.2.lcssa, %121
  store float %add552, float* %arrayidx551, align 4, !tbaa !3
  %arrayidx557 = getelementptr inbounds float* %faction, i64 %95
  %122 = load float* %arrayidx557, align 4, !tbaa !3
  %add558 = fadd float %fiy1.2.lcssa, %122
  store float %add558, float* %arrayidx557, align 4, !tbaa !3
  %arrayidx564 = getelementptr inbounds float* %faction, i64 %97
  %123 = load float* %arrayidx564, align 4, !tbaa !3
  %add565 = fadd float %fiz1.2.lcssa, %123
  store float %add565, float* %arrayidx564, align 4, !tbaa !3
  %124 = load float* %arrayidx570, align 4, !tbaa !3
  %add571 = fadd float %fix1.2.lcssa, %124
  store float %add571, float* %arrayidx570, align 4, !tbaa !3
  %125 = load float* %arrayidx576, align 4, !tbaa !3
  %add577 = fadd float %fiy1.2.lcssa, %125
  store float %add577, float* %arrayidx576, align 4, !tbaa !3
  %126 = load float* %arrayidx583, align 4, !tbaa !3
  %add584 = fadd float %fiz1.2.lcssa, %126
  store float %add584, float* %arrayidx583, align 4, !tbaa !3
  %indvars.iv.next1193 = add i64 %indvars.iv1192, 1
  %indvars.iv.next1195 = add i64 %indvars.iv1194, 3
  %inc591 = add nsw i32 %s.21169, 1
  %exitcond1198 = icmp eq i32 %inc591, %1
  br i1 %exitcond1198, label %for.end592, label %for.body400

for.end592:                                       ; preds = %for.end549, %for.cond397.loopexit
  %vnbtot.2.lcssa = phi float [ %vnbtot.0.lcssa, %for.cond397.loopexit ], [ %vnbtot.3.lcssa, %for.end549 ]
  %arrayidx594 = getelementptr inbounds i32* %gid, i64 %indvars.iv1199
  %127 = load i32* %arrayidx594, align 4, !tbaa !0
  %idxprom595 = sext i32 %127 to i64
  %arrayidx596 = getelementptr inbounds float* %Vc, i64 %idxprom595
  %128 = load float* %arrayidx596, align 4, !tbaa !3
  %add597 = fadd float %vctot.2.lcssa, %128
  store float %add597, float* %arrayidx596, align 4, !tbaa !3
  %arrayidx601 = getelementptr inbounds float* %Vnb, i64 %idxprom595
  %129 = load float* %arrayidx601, align 4, !tbaa !3
  %add602 = fadd float %vnbtot.2.lcssa, %129
  store float %add602, float* %arrayidx601, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next1200 to i32
  %exitcond1201 = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond1201, label %for.end607, label %for.body

for.end607:                                       ; preds = %for.end592, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl3420(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab, float %exptabscale) #0 {
entry:
  %0 = load i32* %iinr, align 4, !tbaa !0
  %idxprom = sext i32 %0 to i64
  %arrayidx1 = getelementptr inbounds float* %charge, i64 %idxprom
  %1 = load float* %arrayidx1, align 4, !tbaa !3
  %add = add nsw i32 %0, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds float* %charge, i64 %idxprom2
  %2 = load float* %arrayidx3, align 4, !tbaa !3
  %mul = fmul float %1, %facel
  %mul4 = fmul float %2, %facel
  %arrayidx7 = getelementptr inbounds i32* %type, i64 %idxprom
  %3 = load i32* %arrayidx7, align 4, !tbaa !0
  %mul8 = mul i32 %3, %ntype
  %cmp798 = icmp sgt i32 %nri, 0
  br i1 %cmp798, label %for.body, label %for.end431

for.body:                                         ; preds = %entry, %for.end.for.body_crit_edge
  %4 = phi i32 [ %.pre, %for.end.for.body_crit_edge ], [ %0, %entry ]
  %indvars.iv800 = phi i64 [ %indvars.iv.next801, %for.end.for.body_crit_edge ], [ 0, %entry ]
  %arrayidx10 = getelementptr inbounds i32* %shift, i64 %indvars.iv800
  %5 = load i32* %arrayidx10, align 4, !tbaa !0
  %mul11 = mul nsw i32 %5, 3
  %idxprom12 = sext i32 %mul11 to i64
  %arrayidx13 = getelementptr inbounds float* %shiftvec, i64 %idxprom12
  %6 = load float* %arrayidx13, align 4, !tbaa !3
  %add14 = add nsw i32 %mul11, 1
  %idxprom15 = sext i32 %add14 to i64
  %arrayidx16 = getelementptr inbounds float* %shiftvec, i64 %idxprom15
  %7 = load float* %arrayidx16, align 4, !tbaa !3
  %add17 = add nsw i32 %mul11, 2
  %idxprom18 = sext i32 %add17 to i64
  %arrayidx19 = getelementptr inbounds float* %shiftvec, i64 %idxprom18
  %8 = load float* %arrayidx19, align 4, !tbaa !3
  %mul22 = mul nsw i32 %4, 3
  %arrayidx24 = getelementptr inbounds i32* %jindex, i64 %indvars.iv800
  %9 = load i32* %arrayidx24, align 4, !tbaa !0
  %indvars.iv.next801 = add i64 %indvars.iv800, 1
  %arrayidx27 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next801
  %10 = load i32* %arrayidx27, align 4, !tbaa !0
  %idxprom28 = sext i32 %mul22 to i64
  %arrayidx29 = getelementptr inbounds float* %pos, i64 %idxprom28
  %11 = load float* %arrayidx29, align 4, !tbaa !3
  %add30 = fadd float %6, %11
  %add31 = add nsw i32 %mul22, 1
  %idxprom32 = sext i32 %add31 to i64
  %arrayidx33 = getelementptr inbounds float* %pos, i64 %idxprom32
  %12 = load float* %arrayidx33, align 4, !tbaa !3
  %add34 = fadd float %7, %12
  %add35 = add nsw i32 %mul22, 2
  %idxprom36 = sext i32 %add35 to i64
  %arrayidx37 = getelementptr inbounds float* %pos, i64 %idxprom36
  %13 = load float* %arrayidx37, align 4, !tbaa !3
  %add38 = fadd float %8, %13
  %add39 = add nsw i32 %mul22, 3
  %idxprom40 = sext i32 %add39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %14 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = fadd float %6, %14
  %add43 = add nsw i32 %mul22, 4
  %idxprom44 = sext i32 %add43 to i64
  %arrayidx45 = getelementptr inbounds float* %pos, i64 %idxprom44
  %15 = load float* %arrayidx45, align 4, !tbaa !3
  %add46 = fadd float %7, %15
  %add47 = add nsw i32 %mul22, 5
  %idxprom48 = sext i32 %add47 to i64
  %arrayidx49 = getelementptr inbounds float* %pos, i64 %idxprom48
  %16 = load float* %arrayidx49, align 4, !tbaa !3
  %add50 = fadd float %8, %16
  %add51 = add nsw i32 %mul22, 6
  %idxprom52 = sext i32 %add51 to i64
  %arrayidx53 = getelementptr inbounds float* %pos, i64 %idxprom52
  %17 = load float* %arrayidx53, align 4, !tbaa !3
  %add54 = fadd float %6, %17
  %add55 = add nsw i32 %mul22, 7
  %idxprom56 = sext i32 %add55 to i64
  %arrayidx57 = getelementptr inbounds float* %pos, i64 %idxprom56
  %18 = load float* %arrayidx57, align 4, !tbaa !3
  %add58 = fadd float %7, %18
  %add59 = add nsw i32 %mul22, 8
  %idxprom60 = sext i32 %add59 to i64
  %arrayidx61 = getelementptr inbounds float* %pos, i64 %idxprom60
  %19 = load float* %arrayidx61, align 4, !tbaa !3
  %add62 = fadd float %8, %19
  %cmp64775 = icmp slt i32 %9, %10
  br i1 %cmp64775, label %for.body65.lr.ph, label %for.end

for.body65.lr.ph:                                 ; preds = %for.body
  %20 = sext i32 %9 to i64
  br label %for.body65

for.body65:                                       ; preds = %for.body65.lr.ph, %for.body65
  %indvars.iv = phi i64 [ %20, %for.body65.lr.ph ], [ %indvars.iv.next, %for.body65 ]
  %vctot.0786 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add313, %for.body65 ]
  %vnbtot.0785 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add208, %for.body65 ]
  %fix1.0784 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add219, %for.body65 ]
  %fiy1.0783 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add220, %for.body65 ]
  %fiz1.0782 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add221, %for.body65 ]
  %fix2.0781 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add272, %for.body65 ]
  %fiy2.0780 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add273, %for.body65 ]
  %fiz2.0779 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add274, %for.body65 ]
  %fix3.0778 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add317, %for.body65 ]
  %fiy3.0777 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add318, %for.body65 ]
  %fiz3.0776 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add319, %for.body65 ]
  %arrayidx67 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %21 = load i32* %arrayidx67, align 4, !tbaa !0
  %mul68 = mul nsw i32 %21, 3
  %idxprom69 = sext i32 %mul68 to i64
  %arrayidx70 = getelementptr inbounds float* %pos, i64 %idxprom69
  %22 = load float* %arrayidx70, align 4, !tbaa !3
  %add71 = add nsw i32 %mul68, 1
  %idxprom72 = sext i32 %add71 to i64
  %arrayidx73 = getelementptr inbounds float* %pos, i64 %idxprom72
  %23 = load float* %arrayidx73, align 4, !tbaa !3
  %add74 = add nsw i32 %mul68, 2
  %idxprom75 = sext i32 %add74 to i64
  %arrayidx76 = getelementptr inbounds float* %pos, i64 %idxprom75
  %24 = load float* %arrayidx76, align 4, !tbaa !3
  %sub = fsub float %add30, %22
  %sub77 = fsub float %add34, %23
  %sub78 = fsub float %add38, %24
  %mul79 = fmul float %sub, %sub
  %mul80 = fmul float %sub77, %sub77
  %add81 = fadd float %mul79, %mul80
  %mul82 = fmul float %sub78, %sub78
  %add83 = fadd float %add81, %mul82
  %sub84 = fsub float %add42, %22
  %sub85 = fsub float %add46, %23
  %sub86 = fsub float %add50, %24
  %mul87 = fmul float %sub84, %sub84
  %mul88 = fmul float %sub85, %sub85
  %add89 = fadd float %mul87, %mul88
  %mul90 = fmul float %sub86, %sub86
  %add91 = fadd float %add89, %mul90
  %sub92 = fsub float %add54, %22
  %sub93 = fsub float %add58, %23
  %sub94 = fsub float %add62, %24
  %mul95 = fmul float %sub92, %sub92
  %mul96 = fmul float %sub93, %sub93
  %add97 = fadd float %mul95, %mul96
  %mul98 = fmul float %sub94, %sub94
  %add99 = fadd float %add97, %mul98
  %conv = fpext float %add83 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv100 = fptrunc double %div to float
  %conv101 = fpext float %add91 to double
  %call102 = tail call double @sqrt(double %conv101) #2
  %div103 = fdiv double 1.000000e+00, %call102
  %conv104 = fptrunc double %div103 to float
  %conv105 = fpext float %add99 to double
  %call106 = tail call double @sqrt(double %conv105) #2
  %div107 = fdiv double 1.000000e+00, %call106
  %conv108 = fptrunc double %div107 to float
  %mul109 = fmul float %add83, %conv100
  %mul110 = fmul float %mul109, %tabscale
  %conv111 = fptosi float %mul110 to i32
  %conv112 = sitofp i32 %conv111 to float
  %sub113 = fsub float %mul110, %conv112
  %mul114 = fmul float %sub113, %sub113
  %mul115 = mul nsw i32 %conv111, 12
  %idxprom116 = sext i32 %21 to i64
  %arrayidx117 = getelementptr inbounds float* %charge, i64 %idxprom116
  %25 = load float* %arrayidx117, align 4, !tbaa !3
  %mul118 = fmul float %mul, %25
  %idxprom119 = sext i32 %mul115 to i64
  %arrayidx120 = getelementptr inbounds float* %VFtab, i64 %idxprom119
  %26 = load float* %arrayidx120, align 4, !tbaa !3
  %add121765 = or i32 %mul115, 1
  %idxprom122 = sext i32 %add121765 to i64
  %arrayidx123 = getelementptr inbounds float* %VFtab, i64 %idxprom122
  %27 = load float* %arrayidx123, align 4, !tbaa !3
  %add124766 = or i32 %mul115, 2
  %idxprom125 = sext i32 %add124766 to i64
  %arrayidx126 = getelementptr inbounds float* %VFtab, i64 %idxprom125
  %28 = load float* %arrayidx126, align 4, !tbaa !3
  %mul127 = fmul float %sub113, %28
  %add128767 = or i32 %mul115, 3
  %idxprom129 = sext i32 %add128767 to i64
  %arrayidx130 = getelementptr inbounds float* %VFtab, i64 %idxprom129
  %29 = load float* %arrayidx130, align 4, !tbaa !3
  %mul131 = fmul float %mul114, %29
  %add132 = fadd float %27, %mul127
  %add133 = fadd float %add132, %mul131
  %mul134 = fmul float %sub113, %add133
  %add135 = fadd float %26, %mul134
  %add136 = fadd float %mul127, %add133
  %mul137 = fmul float %mul131, 2.000000e+00
  %add138 = fadd float %mul137, %add136
  %mul139 = fmul float %mul118, %add135
  %mul140 = fmul float %mul118, %add138
  %arrayidx142 = getelementptr inbounds i32* %type, i64 %idxprom116
  %30 = load i32* %arrayidx142, align 4, !tbaa !0
  %tmp = add i32 %30, %mul8
  %tmp774 = mul i32 %tmp, 3
  %idxprom145 = sext i32 %tmp774 to i64
  %arrayidx146 = getelementptr inbounds float* %nbfp, i64 %idxprom145
  %31 = load float* %arrayidx146, align 4, !tbaa !3
  %add147 = add nsw i32 %tmp774, 1
  %idxprom148 = sext i32 %add147 to i64
  %arrayidx149 = getelementptr inbounds float* %nbfp, i64 %idxprom148
  %32 = load float* %arrayidx149, align 4, !tbaa !3
  %add150 = add nsw i32 %tmp774, 2
  %idxprom151 = sext i32 %add150 to i64
  %arrayidx152 = getelementptr inbounds float* %nbfp, i64 %idxprom151
  %33 = load float* %arrayidx152, align 4, !tbaa !3
  %add153 = add nsw i32 %mul115, 4
  %idxprom154 = sext i32 %add153 to i64
  %arrayidx155 = getelementptr inbounds float* %VFtab, i64 %idxprom154
  %34 = load float* %arrayidx155, align 4, !tbaa !3
  %add156 = add nsw i32 %mul115, 5
  %idxprom157 = sext i32 %add156 to i64
  %arrayidx158 = getelementptr inbounds float* %VFtab, i64 %idxprom157
  %35 = load float* %arrayidx158, align 4, !tbaa !3
  %add159 = add nsw i32 %mul115, 6
  %idxprom160 = sext i32 %add159 to i64
  %arrayidx161 = getelementptr inbounds float* %VFtab, i64 %idxprom160
  %36 = load float* %arrayidx161, align 4, !tbaa !3
  %mul162 = fmul float %sub113, %36
  %add163 = add nsw i32 %mul115, 7
  %idxprom164 = sext i32 %add163 to i64
  %arrayidx165 = getelementptr inbounds float* %VFtab, i64 %idxprom164
  %37 = load float* %arrayidx165, align 4, !tbaa !3
  %mul166 = fmul float %mul114, %37
  %add167 = fadd float %35, %mul162
  %add168 = fadd float %add167, %mul166
  %mul169 = fmul float %sub113, %add168
  %add170 = fadd float %34, %mul169
  %add171 = fadd float %mul162, %add168
  %mul172 = fmul float %mul166, 2.000000e+00
  %add173 = fadd float %mul172, %add171
  %mul174 = fmul float %31, %add170
  %mul175 = fmul float %31, %add173
  %mul176 = fmul float %mul109, %33
  %mul177 = fmul float %mul176, %exptabscale
  %conv178 = fptosi float %mul177 to i32
  %conv179 = sitofp i32 %conv178 to float
  %sub180 = fsub float %mul177, %conv179
  %mul181 = fmul float %sub180, %sub180
  %mul182 = mul nsw i32 %conv178, 12
  %add183 = add nsw i32 %mul182, 8
  %idxprom184 = sext i32 %add183 to i64
  %arrayidx185 = getelementptr inbounds float* %VFtab, i64 %idxprom184
  %38 = load float* %arrayidx185, align 4, !tbaa !3
  %add186 = add nsw i32 %mul182, 9
  %idxprom187 = sext i32 %add186 to i64
  %arrayidx188 = getelementptr inbounds float* %VFtab, i64 %idxprom187
  %39 = load float* %arrayidx188, align 4, !tbaa !3
  %add189 = add nsw i32 %mul182, 10
  %idxprom190 = sext i32 %add189 to i64
  %arrayidx191 = getelementptr inbounds float* %VFtab, i64 %idxprom190
  %40 = load float* %arrayidx191, align 4, !tbaa !3
  %mul192 = fmul float %sub180, %40
  %add193 = add nsw i32 %mul182, 11
  %idxprom194 = sext i32 %add193 to i64
  %arrayidx195 = getelementptr inbounds float* %VFtab, i64 %idxprom194
  %41 = load float* %arrayidx195, align 4, !tbaa !3
  %mul196 = fmul float %mul181, %41
  %add197 = fadd float %39, %mul192
  %add198 = fadd float %add197, %mul196
  %mul199 = fmul float %sub180, %add198
  %add200 = fadd float %38, %mul199
  %add201 = fadd float %mul192, %add198
  %mul202 = fmul float %mul196, 2.000000e+00
  %add203 = fadd float %mul202, %add201
  %mul204 = fmul float %32, %add200
  %mul205 = fmul float %32, %33
  %mul206 = fmul float %mul205, %add203
  %add207 = fadd float %vnbtot.0785, %mul174
  %add208 = fadd float %add207, %mul204
  %add209 = fadd float %mul140, %mul175
  %mul210 = fmul float %add209, %tabscale
  %mul211 = fmul float %mul206, %exptabscale
  %add212 = fadd float %mul210, %mul211
  %42 = fmul float %conv100, %add212
  %mul214 = fsub float -0.000000e+00, %42
  %add215 = fadd float %vctot.0786, %mul139
  %mul216 = fmul float %sub, %mul214
  %mul217 = fmul float %sub77, %mul214
  %mul218 = fmul float %sub78, %mul214
  %add219 = fadd float %fix1.0784, %mul216
  %add220 = fadd float %fiy1.0783, %mul217
  %add221 = fadd float %fiz1.0782, %mul218
  %arrayidx223 = getelementptr inbounds float* %faction, i64 %idxprom69
  %43 = load float* %arrayidx223, align 4, !tbaa !3
  %sub224 = fsub float %43, %mul216
  %arrayidx227 = getelementptr inbounds float* %faction, i64 %idxprom72
  %44 = load float* %arrayidx227, align 4, !tbaa !3
  %sub228 = fsub float %44, %mul217
  %arrayidx231 = getelementptr inbounds float* %faction, i64 %idxprom75
  %45 = load float* %arrayidx231, align 4, !tbaa !3
  %sub232 = fsub float %45, %mul218
  %mul233 = fmul float %add91, %conv104
  %mul234 = fmul float %mul233, %tabscale
  %conv235 = fptosi float %mul234 to i32
  %conv236 = sitofp i32 %conv235 to float
  %sub237 = fsub float %mul234, %conv236
  %mul238 = fmul float %sub237, %sub237
  %mul239 = mul nsw i32 %conv235, 12
  %mul242 = fmul float %mul4, %25
  %idxprom243 = sext i32 %mul239 to i64
  %arrayidx244 = getelementptr inbounds float* %VFtab, i64 %idxprom243
  %46 = load float* %arrayidx244, align 4, !tbaa !3
  %add245768 = or i32 %mul239, 1
  %idxprom246 = sext i32 %add245768 to i64
  %arrayidx247 = getelementptr inbounds float* %VFtab, i64 %idxprom246
  %47 = load float* %arrayidx247, align 4, !tbaa !3
  %add248769 = or i32 %mul239, 2
  %idxprom249 = sext i32 %add248769 to i64
  %arrayidx250 = getelementptr inbounds float* %VFtab, i64 %idxprom249
  %48 = load float* %arrayidx250, align 4, !tbaa !3
  %mul251 = fmul float %sub237, %48
  %add252770 = or i32 %mul239, 3
  %idxprom253 = sext i32 %add252770 to i64
  %arrayidx254 = getelementptr inbounds float* %VFtab, i64 %idxprom253
  %49 = load float* %arrayidx254, align 4, !tbaa !3
  %mul255 = fmul float %mul238, %49
  %add256 = fadd float %47, %mul251
  %add257 = fadd float %add256, %mul255
  %mul258 = fmul float %sub237, %add257
  %add259 = fadd float %46, %mul258
  %add260 = fadd float %mul251, %add257
  %mul261 = fmul float %mul255, 2.000000e+00
  %add262 = fadd float %mul261, %add260
  %mul263 = fmul float %mul242, %add259
  %mul264 = fmul float %mul242, %add262
  %mul265 = fmul float %mul264, %tabscale
  %50 = fmul float %conv104, %mul265
  %mul267 = fsub float -0.000000e+00, %50
  %add268 = fadd float %add215, %mul263
  %mul269 = fmul float %sub84, %mul267
  %mul270 = fmul float %sub85, %mul267
  %mul271 = fmul float %sub86, %mul267
  %add272 = fadd float %fix2.0781, %mul269
  %add273 = fadd float %fiy2.0780, %mul270
  %add274 = fadd float %fiz2.0779, %mul271
  %sub275 = fsub float %sub224, %mul269
  %sub276 = fsub float %sub228, %mul270
  %sub277 = fsub float %sub232, %mul271
  %mul278 = fmul float %add99, %conv108
  %mul279 = fmul float %mul278, %tabscale
  %conv280 = fptosi float %mul279 to i32
  %conv281 = sitofp i32 %conv280 to float
  %sub282 = fsub float %mul279, %conv281
  %mul283 = fmul float %sub282, %sub282
  %mul284 = mul nsw i32 %conv280, 12
  %idxprom288 = sext i32 %mul284 to i64
  %arrayidx289 = getelementptr inbounds float* %VFtab, i64 %idxprom288
  %51 = load float* %arrayidx289, align 4, !tbaa !3
  %add290771 = or i32 %mul284, 1
  %idxprom291 = sext i32 %add290771 to i64
  %arrayidx292 = getelementptr inbounds float* %VFtab, i64 %idxprom291
  %52 = load float* %arrayidx292, align 4, !tbaa !3
  %add293772 = or i32 %mul284, 2
  %idxprom294 = sext i32 %add293772 to i64
  %arrayidx295 = getelementptr inbounds float* %VFtab, i64 %idxprom294
  %53 = load float* %arrayidx295, align 4, !tbaa !3
  %mul296 = fmul float %sub282, %53
  %add297773 = or i32 %mul284, 3
  %idxprom298 = sext i32 %add297773 to i64
  %arrayidx299 = getelementptr inbounds float* %VFtab, i64 %idxprom298
  %54 = load float* %arrayidx299, align 4, !tbaa !3
  %mul300 = fmul float %mul283, %54
  %add301 = fadd float %52, %mul296
  %add302 = fadd float %add301, %mul300
  %mul303 = fmul float %sub282, %add302
  %add304 = fadd float %51, %mul303
  %add305 = fadd float %mul296, %add302
  %mul306 = fmul float %mul300, 2.000000e+00
  %add307 = fadd float %mul306, %add305
  %mul308 = fmul float %mul242, %add304
  %mul309 = fmul float %mul242, %add307
  %mul310 = fmul float %mul309, %tabscale
  %55 = fmul float %conv108, %mul310
  %mul312 = fsub float -0.000000e+00, %55
  %add313 = fadd float %add268, %mul308
  %mul314 = fmul float %sub92, %mul312
  %mul315 = fmul float %sub93, %mul312
  %mul316 = fmul float %sub94, %mul312
  %add317 = fadd float %fix3.0778, %mul314
  %add318 = fadd float %fiy3.0777, %mul315
  %add319 = fadd float %fiz3.0776, %mul316
  %sub320 = fsub float %sub275, %mul314
  store float %sub320, float* %arrayidx223, align 4, !tbaa !3
  %sub323 = fsub float %sub276, %mul315
  store float %sub323, float* %arrayidx227, align 4, !tbaa !3
  %sub327 = fsub float %sub277, %mul316
  store float %sub327, float* %arrayidx231, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %56 = trunc i64 %indvars.iv.next to i32
  %cmp64 = icmp slt i32 %56, %10
  br i1 %cmp64, label %for.body65, label %for.end

for.end:                                          ; preds = %for.body65, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add313, %for.body65 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add208, %for.body65 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add219, %for.body65 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add220, %for.body65 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add221, %for.body65 ]
  %fix2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add272, %for.body65 ]
  %fiy2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add273, %for.body65 ]
  %fiz2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add274, %for.body65 ]
  %fix3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add317, %for.body65 ]
  %fiy3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add318, %for.body65 ]
  %fiz3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add319, %for.body65 ]
  %arrayidx332 = getelementptr inbounds float* %faction, i64 %idxprom28
  %57 = load float* %arrayidx332, align 4, !tbaa !3
  %add333 = fadd float %fix1.0.lcssa, %57
  store float %add333, float* %arrayidx332, align 4, !tbaa !3
  %arrayidx338 = getelementptr inbounds float* %faction, i64 %idxprom32
  %58 = load float* %arrayidx338, align 4, !tbaa !3
  %add339 = fadd float %fiy1.0.lcssa, %58
  store float %add339, float* %arrayidx338, align 4, !tbaa !3
  %arrayidx345 = getelementptr inbounds float* %faction, i64 %idxprom36
  %59 = load float* %arrayidx345, align 4, !tbaa !3
  %add346 = fadd float %fiz1.0.lcssa, %59
  store float %add346, float* %arrayidx345, align 4, !tbaa !3
  %arrayidx352 = getelementptr inbounds float* %faction, i64 %idxprom40
  %60 = load float* %arrayidx352, align 4, !tbaa !3
  %add353 = fadd float %fix2.0.lcssa, %60
  store float %add353, float* %arrayidx352, align 4, !tbaa !3
  %arrayidx359 = getelementptr inbounds float* %faction, i64 %idxprom44
  %61 = load float* %arrayidx359, align 4, !tbaa !3
  %add360 = fadd float %fiy2.0.lcssa, %61
  store float %add360, float* %arrayidx359, align 4, !tbaa !3
  %arrayidx366 = getelementptr inbounds float* %faction, i64 %idxprom48
  %62 = load float* %arrayidx366, align 4, !tbaa !3
  %add367 = fadd float %fiz2.0.lcssa, %62
  store float %add367, float* %arrayidx366, align 4, !tbaa !3
  %arrayidx373 = getelementptr inbounds float* %faction, i64 %idxprom52
  %63 = load float* %arrayidx373, align 4, !tbaa !3
  %add374 = fadd float %fix3.0.lcssa, %63
  store float %add374, float* %arrayidx373, align 4, !tbaa !3
  %arrayidx380 = getelementptr inbounds float* %faction, i64 %idxprom56
  %64 = load float* %arrayidx380, align 4, !tbaa !3
  %add381 = fadd float %fiy3.0.lcssa, %64
  store float %add381, float* %arrayidx380, align 4, !tbaa !3
  %arrayidx387 = getelementptr inbounds float* %faction, i64 %idxprom60
  %65 = load float* %arrayidx387, align 4, !tbaa !3
  %add388 = fadd float %fiz3.0.lcssa, %65
  store float %add388, float* %arrayidx387, align 4, !tbaa !3
  %arrayidx393 = getelementptr inbounds float* %fshift, i64 %idxprom12
  %66 = load float* %arrayidx393, align 4, !tbaa !3
  %add394 = fadd float %fix1.0.lcssa, %66
  %add395 = fadd float %fix2.0.lcssa, %add394
  %add396 = fadd float %fix3.0.lcssa, %add395
  store float %add396, float* %arrayidx393, align 4, !tbaa !3
  %arrayidx401 = getelementptr inbounds float* %fshift, i64 %idxprom15
  %67 = load float* %arrayidx401, align 4, !tbaa !3
  %add402 = fadd float %fiy1.0.lcssa, %67
  %add403 = fadd float %fiy2.0.lcssa, %add402
  %add404 = fadd float %fiy3.0.lcssa, %add403
  store float %add404, float* %arrayidx401, align 4, !tbaa !3
  %arrayidx410 = getelementptr inbounds float* %fshift, i64 %idxprom18
  %68 = load float* %arrayidx410, align 4, !tbaa !3
  %add411 = fadd float %fiz1.0.lcssa, %68
  %add412 = fadd float %fiz2.0.lcssa, %add411
  %add413 = fadd float %fiz3.0.lcssa, %add412
  store float %add413, float* %arrayidx410, align 4, !tbaa !3
  %arrayidx418 = getelementptr inbounds i32* %gid, i64 %indvars.iv800
  %69 = load i32* %arrayidx418, align 4, !tbaa !0
  %idxprom419 = sext i32 %69 to i64
  %arrayidx420 = getelementptr inbounds float* %Vc, i64 %idxprom419
  %70 = load float* %arrayidx420, align 4, !tbaa !3
  %add421 = fadd float %vctot.0.lcssa, %70
  store float %add421, float* %arrayidx420, align 4, !tbaa !3
  %arrayidx425 = getelementptr inbounds float* %Vnb, i64 %idxprom419
  %71 = load float* %arrayidx425, align 4, !tbaa !3
  %add426 = fadd float %vnbtot.0.lcssa, %71
  store float %add426, float* %arrayidx425, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next801 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end431, label %for.end.for.body_crit_edge

for.end.for.body_crit_edge:                       ; preds = %for.end
  %arrayidx21.phi.trans.insert = getelementptr inbounds i32* %iinr, i64 %indvars.iv.next801
  %.pre = load i32* %arrayidx21.phi.trans.insert, align 4, !tbaa !0
  br label %for.body

for.end431:                                       ; preds = %for.end, %entry
  ret void
}

; Function Attrs: nounwind optsize uwtable
define void @inl3430(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* %VFtab, float %exptabscale) #0 {
entry:
  %0 = load i32* %iinr, align 4, !tbaa !0
  %idxprom = sext i32 %0 to i64
  %arrayidx1 = getelementptr inbounds float* %charge, i64 %idxprom
  %1 = load float* %arrayidx1, align 4, !tbaa !3
  %add = add nsw i32 %0, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds float* %charge, i64 %idxprom2
  %2 = load float* %arrayidx3, align 4, !tbaa !3
  %mul = fmul float %1, %facel
  %mul4 = fmul float %1, %mul
  %mul6 = fmul float %mul, %2
  %mul7 = fmul float %2, %facel
  %mul8 = fmul float %2, %mul7
  %mul9 = mul nsw i32 %ntype, 3
  %arrayidx11 = getelementptr inbounds i32* %type, i64 %idxprom
  %3 = load i32* %arrayidx11, align 4, !tbaa !0
  %mul121510 = add i32 %mul9, 3
  %add16 = mul i32 %3, %mul121510
  %idxprom17 = sext i32 %add16 to i64
  %arrayidx18 = getelementptr inbounds float* %nbfp, i64 %idxprom17
  %4 = load float* %arrayidx18, align 4, !tbaa !3
  %add19 = add nsw i32 %add16, 1
  %idxprom20 = sext i32 %add19 to i64
  %arrayidx21 = getelementptr inbounds float* %nbfp, i64 %idxprom20
  %5 = load float* %arrayidx21, align 4, !tbaa !3
  %add22 = add nsw i32 %add16, 2
  %idxprom23 = sext i32 %add22 to i64
  %arrayidx24 = getelementptr inbounds float* %nbfp, i64 %idxprom23
  %6 = load float* %arrayidx24, align 4, !tbaa !3
  %cmp1561 = icmp sgt i32 %nri, 0
  br i1 %cmp1561, label %for.body.lr.ph, label %for.end804

for.body.lr.ph:                                   ; preds = %entry
  %mul296 = fmul float %5, %6
  br label %for.body

for.body:                                         ; preds = %for.end.for.body_crit_edge, %for.body.lr.ph
  %7 = phi i32 [ %0, %for.body.lr.ph ], [ %.pre, %for.end.for.body_crit_edge ]
  %indvars.iv1563 = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next1564, %for.end.for.body_crit_edge ]
  %arrayidx26 = getelementptr inbounds i32* %shift, i64 %indvars.iv1563
  %8 = load i32* %arrayidx26, align 4, !tbaa !0
  %mul27 = mul nsw i32 %8, 3
  %idxprom28 = sext i32 %mul27 to i64
  %arrayidx29 = getelementptr inbounds float* %shiftvec, i64 %idxprom28
  %9 = load float* %arrayidx29, align 4, !tbaa !3
  %add30 = add nsw i32 %mul27, 1
  %idxprom31 = sext i32 %add30 to i64
  %arrayidx32 = getelementptr inbounds float* %shiftvec, i64 %idxprom31
  %10 = load float* %arrayidx32, align 4, !tbaa !3
  %add33 = add nsw i32 %mul27, 2
  %idxprom34 = sext i32 %add33 to i64
  %arrayidx35 = getelementptr inbounds float* %shiftvec, i64 %idxprom34
  %11 = load float* %arrayidx35, align 4, !tbaa !3
  %mul38 = mul nsw i32 %7, 3
  %arrayidx40 = getelementptr inbounds i32* %jindex, i64 %indvars.iv1563
  %12 = load i32* %arrayidx40, align 4, !tbaa !0
  %indvars.iv.next1564 = add i64 %indvars.iv1563, 1
  %arrayidx43 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next1564
  %13 = load i32* %arrayidx43, align 4, !tbaa !0
  %idxprom44 = sext i32 %mul38 to i64
  %arrayidx45 = getelementptr inbounds float* %pos, i64 %idxprom44
  %14 = load float* %arrayidx45, align 4, !tbaa !3
  %add46 = fadd float %9, %14
  %add47 = add nsw i32 %mul38, 1
  %idxprom48 = sext i32 %add47 to i64
  %arrayidx49 = getelementptr inbounds float* %pos, i64 %idxprom48
  %15 = load float* %arrayidx49, align 4, !tbaa !3
  %add50 = fadd float %10, %15
  %add51 = add nsw i32 %mul38, 2
  %idxprom52 = sext i32 %add51 to i64
  %arrayidx53 = getelementptr inbounds float* %pos, i64 %idxprom52
  %16 = load float* %arrayidx53, align 4, !tbaa !3
  %add54 = fadd float %11, %16
  %add55 = add nsw i32 %mul38, 3
  %idxprom56 = sext i32 %add55 to i64
  %arrayidx57 = getelementptr inbounds float* %pos, i64 %idxprom56
  %17 = load float* %arrayidx57, align 4, !tbaa !3
  %add58 = fadd float %9, %17
  %add59 = add nsw i32 %mul38, 4
  %idxprom60 = sext i32 %add59 to i64
  %arrayidx61 = getelementptr inbounds float* %pos, i64 %idxprom60
  %18 = load float* %arrayidx61, align 4, !tbaa !3
  %add62 = fadd float %10, %18
  %add63 = add nsw i32 %mul38, 5
  %idxprom64 = sext i32 %add63 to i64
  %arrayidx65 = getelementptr inbounds float* %pos, i64 %idxprom64
  %19 = load float* %arrayidx65, align 4, !tbaa !3
  %add66 = fadd float %11, %19
  %add67 = add nsw i32 %mul38, 6
  %idxprom68 = sext i32 %add67 to i64
  %arrayidx69 = getelementptr inbounds float* %pos, i64 %idxprom68
  %20 = load float* %arrayidx69, align 4, !tbaa !3
  %add70 = fadd float %9, %20
  %add71 = add nsw i32 %mul38, 7
  %idxprom72 = sext i32 %add71 to i64
  %arrayidx73 = getelementptr inbounds float* %pos, i64 %idxprom72
  %21 = load float* %arrayidx73, align 4, !tbaa !3
  %add74 = fadd float %10, %21
  %add75 = add nsw i32 %mul38, 8
  %idxprom76 = sext i32 %add75 to i64
  %arrayidx77 = getelementptr inbounds float* %pos, i64 %idxprom76
  %22 = load float* %arrayidx77, align 4, !tbaa !3
  %add78 = fadd float %11, %22
  %cmp801538 = icmp slt i32 %12, %13
  br i1 %cmp801538, label %for.body81.lr.ph, label %for.end

for.body81.lr.ph:                                 ; preds = %for.body
  %23 = sext i32 %12 to i64
  br label %for.body81

for.body81:                                       ; preds = %for.body81.lr.ph, %for.body81
  %indvars.iv = phi i64 [ %23, %for.body81.lr.ph ], [ %indvars.iv.next, %for.body81 ]
  %vctot.01549 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add685, %for.body81 ]
  %vnbtot.01548 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add299, %for.body81 ]
  %fix1.01547 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add411, %for.body81 ]
  %fiy1.01546 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add412, %for.body81 ]
  %fiz1.01545 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add413, %for.body81 ]
  %fix2.01544 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add546, %for.body81 ]
  %fiy2.01543 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add547, %for.body81 ]
  %fiz2.01542 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add548, %for.body81 ]
  %fix3.01541 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add689, %for.body81 ]
  %fiy3.01540 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add690, %for.body81 ]
  %fiz3.01539 = phi float [ 0.000000e+00, %for.body81.lr.ph ], [ %add691, %for.body81 ]
  %arrayidx83 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %24 = load i32* %arrayidx83, align 4, !tbaa !0
  %mul84 = mul nsw i32 %24, 3
  %idxprom85 = sext i32 %mul84 to i64
  %arrayidx86 = getelementptr inbounds float* %pos, i64 %idxprom85
  %25 = load float* %arrayidx86, align 4, !tbaa !3
  %add87 = add nsw i32 %mul84, 1
  %idxprom88 = sext i32 %add87 to i64
  %arrayidx89 = getelementptr inbounds float* %pos, i64 %idxprom88
  %26 = load float* %arrayidx89, align 4, !tbaa !3
  %add90 = add nsw i32 %mul84, 2
  %idxprom91 = sext i32 %add90 to i64
  %arrayidx92 = getelementptr inbounds float* %pos, i64 %idxprom91
  %27 = load float* %arrayidx92, align 4, !tbaa !3
  %add93 = add nsw i32 %mul84, 3
  %idxprom94 = sext i32 %add93 to i64
  %arrayidx95 = getelementptr inbounds float* %pos, i64 %idxprom94
  %28 = load float* %arrayidx95, align 4, !tbaa !3
  %add96 = add nsw i32 %mul84, 4
  %idxprom97 = sext i32 %add96 to i64
  %arrayidx98 = getelementptr inbounds float* %pos, i64 %idxprom97
  %29 = load float* %arrayidx98, align 4, !tbaa !3
  %add99 = add nsw i32 %mul84, 5
  %idxprom100 = sext i32 %add99 to i64
  %arrayidx101 = getelementptr inbounds float* %pos, i64 %idxprom100
  %30 = load float* %arrayidx101, align 4, !tbaa !3
  %add102 = add nsw i32 %mul84, 6
  %idxprom103 = sext i32 %add102 to i64
  %arrayidx104 = getelementptr inbounds float* %pos, i64 %idxprom103
  %31 = load float* %arrayidx104, align 4, !tbaa !3
  %add105 = add nsw i32 %mul84, 7
  %idxprom106 = sext i32 %add105 to i64
  %arrayidx107 = getelementptr inbounds float* %pos, i64 %idxprom106
  %32 = load float* %arrayidx107, align 4, !tbaa !3
  %add108 = add nsw i32 %mul84, 8
  %idxprom109 = sext i32 %add108 to i64
  %arrayidx110 = getelementptr inbounds float* %pos, i64 %idxprom109
  %33 = load float* %arrayidx110, align 4, !tbaa !3
  %sub = fsub float %add46, %25
  %sub111 = fsub float %add50, %26
  %sub112 = fsub float %add54, %27
  %mul113 = fmul float %sub, %sub
  %mul114 = fmul float %sub111, %sub111
  %add115 = fadd float %mul113, %mul114
  %mul116 = fmul float %sub112, %sub112
  %add117 = fadd float %add115, %mul116
  %sub118 = fsub float %add46, %28
  %sub119 = fsub float %add50, %29
  %sub120 = fsub float %add54, %30
  %mul121 = fmul float %sub118, %sub118
  %mul122 = fmul float %sub119, %sub119
  %add123 = fadd float %mul121, %mul122
  %mul124 = fmul float %sub120, %sub120
  %add125 = fadd float %add123, %mul124
  %sub126 = fsub float %add46, %31
  %sub127 = fsub float %add50, %32
  %sub128 = fsub float %add54, %33
  %mul129 = fmul float %sub126, %sub126
  %mul130 = fmul float %sub127, %sub127
  %add131 = fadd float %mul129, %mul130
  %mul132 = fmul float %sub128, %sub128
  %add133 = fadd float %add131, %mul132
  %sub134 = fsub float %add58, %25
  %sub135 = fsub float %add62, %26
  %sub136 = fsub float %add66, %27
  %mul137 = fmul float %sub134, %sub134
  %mul138 = fmul float %sub135, %sub135
  %add139 = fadd float %mul137, %mul138
  %mul140 = fmul float %sub136, %sub136
  %add141 = fadd float %add139, %mul140
  %sub142 = fsub float %add58, %28
  %sub143 = fsub float %add62, %29
  %sub144 = fsub float %add66, %30
  %mul145 = fmul float %sub142, %sub142
  %mul146 = fmul float %sub143, %sub143
  %add147 = fadd float %mul145, %mul146
  %mul148 = fmul float %sub144, %sub144
  %add149 = fadd float %add147, %mul148
  %sub150 = fsub float %add58, %31
  %sub151 = fsub float %add62, %32
  %sub152 = fsub float %add66, %33
  %mul153 = fmul float %sub150, %sub150
  %mul154 = fmul float %sub151, %sub151
  %add155 = fadd float %mul153, %mul154
  %mul156 = fmul float %sub152, %sub152
  %add157 = fadd float %add155, %mul156
  %sub158 = fsub float %add70, %25
  %sub159 = fsub float %add74, %26
  %sub160 = fsub float %add78, %27
  %mul161 = fmul float %sub158, %sub158
  %mul162 = fmul float %sub159, %sub159
  %add163 = fadd float %mul161, %mul162
  %mul164 = fmul float %sub160, %sub160
  %add165 = fadd float %add163, %mul164
  %sub166 = fsub float %add70, %28
  %sub167 = fsub float %add74, %29
  %sub168 = fsub float %add78, %30
  %mul169 = fmul float %sub166, %sub166
  %mul170 = fmul float %sub167, %sub167
  %add171 = fadd float %mul169, %mul170
  %mul172 = fmul float %sub168, %sub168
  %add173 = fadd float %add171, %mul172
  %sub174 = fsub float %add70, %31
  %sub175 = fsub float %add74, %32
  %sub176 = fsub float %add78, %33
  %mul177 = fmul float %sub174, %sub174
  %mul178 = fmul float %sub175, %sub175
  %add179 = fadd float %mul177, %mul178
  %mul180 = fmul float %sub176, %sub176
  %add181 = fadd float %add179, %mul180
  %conv = fpext float %add117 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv182 = fptrunc double %div to float
  %conv183 = fpext float %add141 to double
  %call184 = tail call double @sqrt(double %conv183) #2
  %div185 = fdiv double 1.000000e+00, %call184
  %conv186 = fptrunc double %div185 to float
  %conv187 = fpext float %add165 to double
  %call188 = tail call double @sqrt(double %conv187) #2
  %div189 = fdiv double 1.000000e+00, %call188
  %conv190 = fptrunc double %div189 to float
  %conv191 = fpext float %add125 to double
  %call192 = tail call double @sqrt(double %conv191) #2
  %div193 = fdiv double 1.000000e+00, %call192
  %conv194 = fptrunc double %div193 to float
  %conv195 = fpext float %add149 to double
  %call196 = tail call double @sqrt(double %conv195) #2
  %div197 = fdiv double 1.000000e+00, %call196
  %conv198 = fptrunc double %div197 to float
  %conv199 = fpext float %add173 to double
  %call200 = tail call double @sqrt(double %conv199) #2
  %div201 = fdiv double 1.000000e+00, %call200
  %conv202 = fptrunc double %div201 to float
  %conv203 = fpext float %add133 to double
  %call204 = tail call double @sqrt(double %conv203) #2
  %div205 = fdiv double 1.000000e+00, %call204
  %conv206 = fptrunc double %div205 to float
  %conv207 = fpext float %add157 to double
  %call208 = tail call double @sqrt(double %conv207) #2
  %div209 = fdiv double 1.000000e+00, %call208
  %conv210 = fptrunc double %div209 to float
  %conv211 = fpext float %add181 to double
  %call212 = tail call double @sqrt(double %conv211) #2
  %div213 = fdiv double 1.000000e+00, %call212
  %conv214 = fptrunc double %div213 to float
  %mul215 = fmul float %add117, %conv182
  %mul216 = fmul float %mul215, %tabscale
  %conv217 = fptosi float %mul216 to i32
  %conv218 = sitofp i32 %conv217 to float
  %sub219 = fsub float %mul216, %conv218
  %mul220 = fmul float %sub219, %sub219
  %mul221 = mul nsw i32 %conv217, 12
  %idxprom222 = sext i32 %mul221 to i64
  %arrayidx223 = getelementptr inbounds float* %VFtab, i64 %idxprom222
  %34 = load float* %arrayidx223, align 4, !tbaa !3
  %add2241511 = or i32 %mul221, 1
  %idxprom225 = sext i32 %add2241511 to i64
  %arrayidx226 = getelementptr inbounds float* %VFtab, i64 %idxprom225
  %35 = load float* %arrayidx226, align 4, !tbaa !3
  %add2271512 = or i32 %mul221, 2
  %idxprom228 = sext i32 %add2271512 to i64
  %arrayidx229 = getelementptr inbounds float* %VFtab, i64 %idxprom228
  %36 = load float* %arrayidx229, align 4, !tbaa !3
  %mul230 = fmul float %sub219, %36
  %add2311513 = or i32 %mul221, 3
  %idxprom232 = sext i32 %add2311513 to i64
  %arrayidx233 = getelementptr inbounds float* %VFtab, i64 %idxprom232
  %37 = load float* %arrayidx233, align 4, !tbaa !3
  %mul234 = fmul float %mul220, %37
  %add235 = fadd float %35, %mul230
  %add236 = fadd float %add235, %mul234
  %mul237 = fmul float %sub219, %add236
  %add238 = fadd float %34, %mul237
  %add239 = fadd float %mul230, %add236
  %mul240 = fmul float %mul234, 2.000000e+00
  %add241 = fadd float %mul240, %add239
  %mul242 = fmul float %mul4, %add238
  %mul243 = fmul float %mul4, %add241
  %add244 = add nsw i32 %mul221, 4
  %idxprom245 = sext i32 %add244 to i64
  %arrayidx246 = getelementptr inbounds float* %VFtab, i64 %idxprom245
  %38 = load float* %arrayidx246, align 4, !tbaa !3
  %add247 = add nsw i32 %mul221, 5
  %idxprom248 = sext i32 %add247 to i64
  %arrayidx249 = getelementptr inbounds float* %VFtab, i64 %idxprom248
  %39 = load float* %arrayidx249, align 4, !tbaa !3
  %add250 = add nsw i32 %mul221, 6
  %idxprom251 = sext i32 %add250 to i64
  %arrayidx252 = getelementptr inbounds float* %VFtab, i64 %idxprom251
  %40 = load float* %arrayidx252, align 4, !tbaa !3
  %mul253 = fmul float %sub219, %40
  %add254 = add nsw i32 %mul221, 7
  %idxprom255 = sext i32 %add254 to i64
  %arrayidx256 = getelementptr inbounds float* %VFtab, i64 %idxprom255
  %41 = load float* %arrayidx256, align 4, !tbaa !3
  %mul257 = fmul float %mul220, %41
  %add258 = fadd float %39, %mul253
  %add259 = fadd float %add258, %mul257
  %mul260 = fmul float %sub219, %add259
  %add261 = fadd float %38, %mul260
  %add262 = fadd float %mul253, %add259
  %mul263 = fmul float %mul257, 2.000000e+00
  %add264 = fadd float %mul263, %add262
  %mul265 = fmul float %4, %add261
  %mul266 = fmul float %4, %add264
  %mul267 = fmul float %6, %mul215
  %mul268 = fmul float %mul267, %exptabscale
  %conv269 = fptosi float %mul268 to i32
  %conv270 = sitofp i32 %conv269 to float
  %sub271 = fsub float %mul268, %conv270
  %mul272 = fmul float %sub271, %sub271
  %mul273 = mul nsw i32 %conv269, 12
  %add274 = add nsw i32 %mul273, 8
  %idxprom275 = sext i32 %add274 to i64
  %arrayidx276 = getelementptr inbounds float* %VFtab, i64 %idxprom275
  %42 = load float* %arrayidx276, align 4, !tbaa !3
  %add277 = add nsw i32 %mul273, 9
  %idxprom278 = sext i32 %add277 to i64
  %arrayidx279 = getelementptr inbounds float* %VFtab, i64 %idxprom278
  %43 = load float* %arrayidx279, align 4, !tbaa !3
  %add280 = add nsw i32 %mul273, 10
  %idxprom281 = sext i32 %add280 to i64
  %arrayidx282 = getelementptr inbounds float* %VFtab, i64 %idxprom281
  %44 = load float* %arrayidx282, align 4, !tbaa !3
  %mul283 = fmul float %sub271, %44
  %add284 = add nsw i32 %mul273, 11
  %idxprom285 = sext i32 %add284 to i64
  %arrayidx286 = getelementptr inbounds float* %VFtab, i64 %idxprom285
  %45 = load float* %arrayidx286, align 4, !tbaa !3
  %mul287 = fmul float %mul272, %45
  %add288 = fadd float %43, %mul283
  %add289 = fadd float %add288, %mul287
  %mul290 = fmul float %sub271, %add289
  %add291 = fadd float %42, %mul290
  %add292 = fadd float %mul283, %add289
  %mul293 = fmul float %mul287, 2.000000e+00
  %add294 = fadd float %mul293, %add292
  %mul295 = fmul float %5, %add291
  %mul297 = fmul float %mul296, %add294
  %add298 = fadd float %vnbtot.01548, %mul265
  %add299 = fadd float %add298, %mul295
  %add300 = fadd float %mul243, %mul266
  %mul301 = fmul float %add300, %tabscale
  %mul302 = fmul float %mul297, %exptabscale
  %add303 = fadd float %mul301, %mul302
  %46 = fmul float %conv182, %add303
  %mul305 = fsub float -0.000000e+00, %46
  %add306 = fadd float %vctot.01549, %mul242
  %mul307 = fmul float %sub, %mul305
  %mul308 = fmul float %sub111, %mul305
  %mul309 = fmul float %sub112, %mul305
  %add310 = fadd float %fix1.01547, %mul307
  %add311 = fadd float %fiy1.01546, %mul308
  %add312 = fadd float %fiz1.01545, %mul309
  %arrayidx314 = getelementptr inbounds float* %faction, i64 %idxprom85
  %47 = load float* %arrayidx314, align 4, !tbaa !3
  %sub315 = fsub float %47, %mul307
  %arrayidx318 = getelementptr inbounds float* %faction, i64 %idxprom88
  %48 = load float* %arrayidx318, align 4, !tbaa !3
  %sub319 = fsub float %48, %mul308
  %arrayidx322 = getelementptr inbounds float* %faction, i64 %idxprom91
  %49 = load float* %arrayidx322, align 4, !tbaa !3
  %sub323 = fsub float %49, %mul309
  %mul324 = fmul float %add125, %conv194
  %mul325 = fmul float %mul324, %tabscale
  %conv326 = fptosi float %mul325 to i32
  %conv327 = sitofp i32 %conv326 to float
  %sub328 = fsub float %mul325, %conv327
  %mul329 = fmul float %sub328, %sub328
  %mul330 = mul nsw i32 %conv326, 12
  %idxprom331 = sext i32 %mul330 to i64
  %arrayidx332 = getelementptr inbounds float* %VFtab, i64 %idxprom331
  %50 = load float* %arrayidx332, align 4, !tbaa !3
  %add3331514 = or i32 %mul330, 1
  %idxprom334 = sext i32 %add3331514 to i64
  %arrayidx335 = getelementptr inbounds float* %VFtab, i64 %idxprom334
  %51 = load float* %arrayidx335, align 4, !tbaa !3
  %add3361515 = or i32 %mul330, 2
  %idxprom337 = sext i32 %add3361515 to i64
  %arrayidx338 = getelementptr inbounds float* %VFtab, i64 %idxprom337
  %52 = load float* %arrayidx338, align 4, !tbaa !3
  %mul339 = fmul float %sub328, %52
  %add3401516 = or i32 %mul330, 3
  %idxprom341 = sext i32 %add3401516 to i64
  %arrayidx342 = getelementptr inbounds float* %VFtab, i64 %idxprom341
  %53 = load float* %arrayidx342, align 4, !tbaa !3
  %mul343 = fmul float %mul329, %53
  %add344 = fadd float %51, %mul339
  %add345 = fadd float %add344, %mul343
  %mul346 = fmul float %sub328, %add345
  %add347 = fadd float %50, %mul346
  %add348 = fadd float %mul339, %add345
  %mul349 = fmul float %mul343, 2.000000e+00
  %add350 = fadd float %mul349, %add348
  %mul351 = fmul float %mul6, %add347
  %mul352 = fmul float %mul6, %add350
  %mul353 = fmul float %mul352, %tabscale
  %54 = fmul float %conv194, %mul353
  %mul355 = fsub float -0.000000e+00, %54
  %add356 = fadd float %add306, %mul351
  %mul357 = fmul float %sub118, %mul355
  %mul358 = fmul float %sub119, %mul355
  %mul359 = fmul float %sub120, %mul355
  %add360 = fadd float %add310, %mul357
  %add361 = fadd float %add311, %mul358
  %add362 = fadd float %add312, %mul359
  %arrayidx365 = getelementptr inbounds float* %faction, i64 %idxprom94
  %55 = load float* %arrayidx365, align 4, !tbaa !3
  %sub366 = fsub float %55, %mul357
  %arrayidx369 = getelementptr inbounds float* %faction, i64 %idxprom97
  %56 = load float* %arrayidx369, align 4, !tbaa !3
  %sub370 = fsub float %56, %mul358
  %arrayidx373 = getelementptr inbounds float* %faction, i64 %idxprom100
  %57 = load float* %arrayidx373, align 4, !tbaa !3
  %sub374 = fsub float %57, %mul359
  %mul375 = fmul float %add133, %conv206
  %mul376 = fmul float %mul375, %tabscale
  %conv377 = fptosi float %mul376 to i32
  %conv378 = sitofp i32 %conv377 to float
  %sub379 = fsub float %mul376, %conv378
  %mul380 = fmul float %sub379, %sub379
  %mul381 = mul nsw i32 %conv377, 12
  %idxprom382 = sext i32 %mul381 to i64
  %arrayidx383 = getelementptr inbounds float* %VFtab, i64 %idxprom382
  %58 = load float* %arrayidx383, align 4, !tbaa !3
  %add3841517 = or i32 %mul381, 1
  %idxprom385 = sext i32 %add3841517 to i64
  %arrayidx386 = getelementptr inbounds float* %VFtab, i64 %idxprom385
  %59 = load float* %arrayidx386, align 4, !tbaa !3
  %add3871518 = or i32 %mul381, 2
  %idxprom388 = sext i32 %add3871518 to i64
  %arrayidx389 = getelementptr inbounds float* %VFtab, i64 %idxprom388
  %60 = load float* %arrayidx389, align 4, !tbaa !3
  %mul390 = fmul float %sub379, %60
  %add3911519 = or i32 %mul381, 3
  %idxprom392 = sext i32 %add3911519 to i64
  %arrayidx393 = getelementptr inbounds float* %VFtab, i64 %idxprom392
  %61 = load float* %arrayidx393, align 4, !tbaa !3
  %mul394 = fmul float %mul380, %61
  %add395 = fadd float %59, %mul390
  %add396 = fadd float %add395, %mul394
  %mul397 = fmul float %sub379, %add396
  %add398 = fadd float %58, %mul397
  %add399 = fadd float %mul390, %add396
  %mul400 = fmul float %mul394, 2.000000e+00
  %add401 = fadd float %mul400, %add399
  %mul402 = fmul float %mul6, %add398
  %mul403 = fmul float %mul6, %add401
  %mul404 = fmul float %mul403, %tabscale
  %62 = fmul float %conv206, %mul404
  %mul406 = fsub float -0.000000e+00, %62
  %add407 = fadd float %add356, %mul402
  %mul408 = fmul float %sub126, %mul406
  %mul409 = fmul float %sub127, %mul406
  %mul410 = fmul float %sub128, %mul406
  %add411 = fadd float %add360, %mul408
  %add412 = fadd float %add361, %mul409
  %add413 = fadd float %add362, %mul410
  %arrayidx416 = getelementptr inbounds float* %faction, i64 %idxprom103
  %63 = load float* %arrayidx416, align 4, !tbaa !3
  %sub417 = fsub float %63, %mul408
  %arrayidx420 = getelementptr inbounds float* %faction, i64 %idxprom106
  %64 = load float* %arrayidx420, align 4, !tbaa !3
  %sub421 = fsub float %64, %mul409
  %arrayidx424 = getelementptr inbounds float* %faction, i64 %idxprom109
  %65 = load float* %arrayidx424, align 4, !tbaa !3
  %sub425 = fsub float %65, %mul410
  %mul426 = fmul float %add141, %conv186
  %mul427 = fmul float %mul426, %tabscale
  %conv428 = fptosi float %mul427 to i32
  %conv429 = sitofp i32 %conv428 to float
  %sub430 = fsub float %mul427, %conv429
  %mul431 = fmul float %sub430, %sub430
  %mul432 = mul nsw i32 %conv428, 12
  %idxprom433 = sext i32 %mul432 to i64
  %arrayidx434 = getelementptr inbounds float* %VFtab, i64 %idxprom433
  %66 = load float* %arrayidx434, align 4, !tbaa !3
  %add4351520 = or i32 %mul432, 1
  %idxprom436 = sext i32 %add4351520 to i64
  %arrayidx437 = getelementptr inbounds float* %VFtab, i64 %idxprom436
  %67 = load float* %arrayidx437, align 4, !tbaa !3
  %add4381521 = or i32 %mul432, 2
  %idxprom439 = sext i32 %add4381521 to i64
  %arrayidx440 = getelementptr inbounds float* %VFtab, i64 %idxprom439
  %68 = load float* %arrayidx440, align 4, !tbaa !3
  %mul441 = fmul float %sub430, %68
  %add4421522 = or i32 %mul432, 3
  %idxprom443 = sext i32 %add4421522 to i64
  %arrayidx444 = getelementptr inbounds float* %VFtab, i64 %idxprom443
  %69 = load float* %arrayidx444, align 4, !tbaa !3
  %mul445 = fmul float %mul431, %69
  %add446 = fadd float %67, %mul441
  %add447 = fadd float %add446, %mul445
  %mul448 = fmul float %sub430, %add447
  %add449 = fadd float %66, %mul448
  %add450 = fadd float %mul441, %add447
  %mul451 = fmul float %mul445, 2.000000e+00
  %add452 = fadd float %mul451, %add450
  %mul453 = fmul float %mul6, %add449
  %mul454 = fmul float %mul6, %add452
  %mul455 = fmul float %mul454, %tabscale
  %70 = fmul float %conv186, %mul455
  %mul457 = fsub float -0.000000e+00, %70
  %add458 = fadd float %add407, %mul453
  %mul459 = fmul float %sub134, %mul457
  %mul460 = fmul float %sub135, %mul457
  %mul461 = fmul float %sub136, %mul457
  %add462 = fadd float %fix2.01544, %mul459
  %add463 = fadd float %fiy2.01543, %mul460
  %add464 = fadd float %fiz2.01542, %mul461
  %sub465 = fsub float %sub315, %mul459
  %sub466 = fsub float %sub319, %mul460
  %sub467 = fsub float %sub323, %mul461
  %mul468 = fmul float %add149, %conv198
  %mul469 = fmul float %mul468, %tabscale
  %conv470 = fptosi float %mul469 to i32
  %conv471 = sitofp i32 %conv470 to float
  %sub472 = fsub float %mul469, %conv471
  %mul473 = fmul float %sub472, %sub472
  %mul474 = mul nsw i32 %conv470, 12
  %idxprom475 = sext i32 %mul474 to i64
  %arrayidx476 = getelementptr inbounds float* %VFtab, i64 %idxprom475
  %71 = load float* %arrayidx476, align 4, !tbaa !3
  %add4771523 = or i32 %mul474, 1
  %idxprom478 = sext i32 %add4771523 to i64
  %arrayidx479 = getelementptr inbounds float* %VFtab, i64 %idxprom478
  %72 = load float* %arrayidx479, align 4, !tbaa !3
  %add4801524 = or i32 %mul474, 2
  %idxprom481 = sext i32 %add4801524 to i64
  %arrayidx482 = getelementptr inbounds float* %VFtab, i64 %idxprom481
  %73 = load float* %arrayidx482, align 4, !tbaa !3
  %mul483 = fmul float %sub472, %73
  %add4841525 = or i32 %mul474, 3
  %idxprom485 = sext i32 %add4841525 to i64
  %arrayidx486 = getelementptr inbounds float* %VFtab, i64 %idxprom485
  %74 = load float* %arrayidx486, align 4, !tbaa !3
  %mul487 = fmul float %mul473, %74
  %add488 = fadd float %72, %mul483
  %add489 = fadd float %add488, %mul487
  %mul490 = fmul float %sub472, %add489
  %add491 = fadd float %71, %mul490
  %add492 = fadd float %mul483, %add489
  %mul493 = fmul float %mul487, 2.000000e+00
  %add494 = fadd float %mul493, %add492
  %mul495 = fmul float %mul8, %add491
  %mul496 = fmul float %mul8, %add494
  %mul497 = fmul float %mul496, %tabscale
  %75 = fmul float %conv198, %mul497
  %mul499 = fsub float -0.000000e+00, %75
  %add500 = fadd float %add458, %mul495
  %mul501 = fmul float %sub142, %mul499
  %mul502 = fmul float %sub143, %mul499
  %mul503 = fmul float %sub144, %mul499
  %add504 = fadd float %add462, %mul501
  %add505 = fadd float %add463, %mul502
  %add506 = fadd float %add464, %mul503
  %sub507 = fsub float %sub366, %mul501
  %sub508 = fsub float %sub370, %mul502
  %sub509 = fsub float %sub374, %mul503
  %mul510 = fmul float %add157, %conv210
  %mul511 = fmul float %mul510, %tabscale
  %conv512 = fptosi float %mul511 to i32
  %conv513 = sitofp i32 %conv512 to float
  %sub514 = fsub float %mul511, %conv513
  %mul515 = fmul float %sub514, %sub514
  %mul516 = mul nsw i32 %conv512, 12
  %idxprom517 = sext i32 %mul516 to i64
  %arrayidx518 = getelementptr inbounds float* %VFtab, i64 %idxprom517
  %76 = load float* %arrayidx518, align 4, !tbaa !3
  %add5191526 = or i32 %mul516, 1
  %idxprom520 = sext i32 %add5191526 to i64
  %arrayidx521 = getelementptr inbounds float* %VFtab, i64 %idxprom520
  %77 = load float* %arrayidx521, align 4, !tbaa !3
  %add5221527 = or i32 %mul516, 2
  %idxprom523 = sext i32 %add5221527 to i64
  %arrayidx524 = getelementptr inbounds float* %VFtab, i64 %idxprom523
  %78 = load float* %arrayidx524, align 4, !tbaa !3
  %mul525 = fmul float %sub514, %78
  %add5261528 = or i32 %mul516, 3
  %idxprom527 = sext i32 %add5261528 to i64
  %arrayidx528 = getelementptr inbounds float* %VFtab, i64 %idxprom527
  %79 = load float* %arrayidx528, align 4, !tbaa !3
  %mul529 = fmul float %mul515, %79
  %add530 = fadd float %77, %mul525
  %add531 = fadd float %add530, %mul529
  %mul532 = fmul float %sub514, %add531
  %add533 = fadd float %76, %mul532
  %add534 = fadd float %mul525, %add531
  %mul535 = fmul float %mul529, 2.000000e+00
  %add536 = fadd float %mul535, %add534
  %mul537 = fmul float %mul8, %add533
  %mul538 = fmul float %mul8, %add536
  %mul539 = fmul float %mul538, %tabscale
  %80 = fmul float %conv210, %mul539
  %mul541 = fsub float -0.000000e+00, %80
  %add542 = fadd float %add500, %mul537
  %mul543 = fmul float %sub150, %mul541
  %mul544 = fmul float %sub151, %mul541
  %mul545 = fmul float %sub152, %mul541
  %add546 = fadd float %add504, %mul543
  %add547 = fadd float %add505, %mul544
  %add548 = fadd float %add506, %mul545
  %sub549 = fsub float %sub417, %mul543
  %sub550 = fsub float %sub421, %mul544
  %sub551 = fsub float %sub425, %mul545
  %mul552 = fmul float %add165, %conv190
  %mul553 = fmul float %mul552, %tabscale
  %conv554 = fptosi float %mul553 to i32
  %conv555 = sitofp i32 %conv554 to float
  %sub556 = fsub float %mul553, %conv555
  %mul557 = fmul float %sub556, %sub556
  %mul558 = mul nsw i32 %conv554, 12
  %idxprom559 = sext i32 %mul558 to i64
  %arrayidx560 = getelementptr inbounds float* %VFtab, i64 %idxprom559
  %81 = load float* %arrayidx560, align 4, !tbaa !3
  %add5611529 = or i32 %mul558, 1
  %idxprom562 = sext i32 %add5611529 to i64
  %arrayidx563 = getelementptr inbounds float* %VFtab, i64 %idxprom562
  %82 = load float* %arrayidx563, align 4, !tbaa !3
  %add5641530 = or i32 %mul558, 2
  %idxprom565 = sext i32 %add5641530 to i64
  %arrayidx566 = getelementptr inbounds float* %VFtab, i64 %idxprom565
  %83 = load float* %arrayidx566, align 4, !tbaa !3
  %mul567 = fmul float %sub556, %83
  %add5681531 = or i32 %mul558, 3
  %idxprom569 = sext i32 %add5681531 to i64
  %arrayidx570 = getelementptr inbounds float* %VFtab, i64 %idxprom569
  %84 = load float* %arrayidx570, align 4, !tbaa !3
  %mul571 = fmul float %mul557, %84
  %add572 = fadd float %82, %mul567
  %add573 = fadd float %add572, %mul571
  %mul574 = fmul float %sub556, %add573
  %add575 = fadd float %81, %mul574
  %add576 = fadd float %mul567, %add573
  %mul577 = fmul float %mul571, 2.000000e+00
  %add578 = fadd float %mul577, %add576
  %mul579 = fmul float %mul6, %add575
  %mul580 = fmul float %mul6, %add578
  %mul581 = fmul float %mul580, %tabscale
  %85 = fmul float %conv190, %mul581
  %mul583 = fsub float -0.000000e+00, %85
  %add584 = fadd float %add542, %mul579
  %mul585 = fmul float %sub158, %mul583
  %mul586 = fmul float %sub159, %mul583
  %mul587 = fmul float %sub160, %mul583
  %add588 = fadd float %fix3.01541, %mul585
  %add589 = fadd float %fiy3.01540, %mul586
  %add590 = fadd float %fiz3.01539, %mul587
  %sub591 = fsub float %sub465, %mul585
  store float %sub591, float* %arrayidx314, align 4, !tbaa !3
  %sub594 = fsub float %sub466, %mul586
  store float %sub594, float* %arrayidx318, align 4, !tbaa !3
  %sub598 = fsub float %sub467, %mul587
  store float %sub598, float* %arrayidx322, align 4, !tbaa !3
  %mul602 = fmul float %add173, %conv202
  %mul603 = fmul float %mul602, %tabscale
  %conv604 = fptosi float %mul603 to i32
  %conv605 = sitofp i32 %conv604 to float
  %sub606 = fsub float %mul603, %conv605
  %mul607 = fmul float %sub606, %sub606
  %mul608 = mul nsw i32 %conv604, 12
  %idxprom609 = sext i32 %mul608 to i64
  %arrayidx610 = getelementptr inbounds float* %VFtab, i64 %idxprom609
  %86 = load float* %arrayidx610, align 4, !tbaa !3
  %add6111532 = or i32 %mul608, 1
  %idxprom612 = sext i32 %add6111532 to i64
  %arrayidx613 = getelementptr inbounds float* %VFtab, i64 %idxprom612
  %87 = load float* %arrayidx613, align 4, !tbaa !3
  %add6141533 = or i32 %mul608, 2
  %idxprom615 = sext i32 %add6141533 to i64
  %arrayidx616 = getelementptr inbounds float* %VFtab, i64 %idxprom615
  %88 = load float* %arrayidx616, align 4, !tbaa !3
  %mul617 = fmul float %sub606, %88
  %add6181534 = or i32 %mul608, 3
  %idxprom619 = sext i32 %add6181534 to i64
  %arrayidx620 = getelementptr inbounds float* %VFtab, i64 %idxprom619
  %89 = load float* %arrayidx620, align 4, !tbaa !3
  %mul621 = fmul float %mul607, %89
  %add622 = fadd float %87, %mul617
  %add623 = fadd float %add622, %mul621
  %mul624 = fmul float %sub606, %add623
  %add625 = fadd float %86, %mul624
  %add626 = fadd float %mul617, %add623
  %mul627 = fmul float %mul621, 2.000000e+00
  %add628 = fadd float %mul627, %add626
  %mul629 = fmul float %mul8, %add625
  %mul630 = fmul float %mul8, %add628
  %mul631 = fmul float %mul630, %tabscale
  %90 = fmul float %conv202, %mul631
  %mul633 = fsub float -0.000000e+00, %90
  %add634 = fadd float %add584, %mul629
  %mul635 = fmul float %sub166, %mul633
  %mul636 = fmul float %sub167, %mul633
  %mul637 = fmul float %sub168, %mul633
  %add638 = fadd float %add588, %mul635
  %add639 = fadd float %add589, %mul636
  %add640 = fadd float %add590, %mul637
  %sub641 = fsub float %sub507, %mul635
  store float %sub641, float* %arrayidx365, align 4, !tbaa !3
  %sub645 = fsub float %sub508, %mul636
  store float %sub645, float* %arrayidx369, align 4, !tbaa !3
  %sub649 = fsub float %sub509, %mul637
  store float %sub649, float* %arrayidx373, align 4, !tbaa !3
  %mul653 = fmul float %add181, %conv214
  %mul654 = fmul float %mul653, %tabscale
  %conv655 = fptosi float %mul654 to i32
  %conv656 = sitofp i32 %conv655 to float
  %sub657 = fsub float %mul654, %conv656
  %mul658 = fmul float %sub657, %sub657
  %mul659 = mul nsw i32 %conv655, 12
  %idxprom660 = sext i32 %mul659 to i64
  %arrayidx661 = getelementptr inbounds float* %VFtab, i64 %idxprom660
  %91 = load float* %arrayidx661, align 4, !tbaa !3
  %add6621535 = or i32 %mul659, 1
  %idxprom663 = sext i32 %add6621535 to i64
  %arrayidx664 = getelementptr inbounds float* %VFtab, i64 %idxprom663
  %92 = load float* %arrayidx664, align 4, !tbaa !3
  %add6651536 = or i32 %mul659, 2
  %idxprom666 = sext i32 %add6651536 to i64
  %arrayidx667 = getelementptr inbounds float* %VFtab, i64 %idxprom666
  %93 = load float* %arrayidx667, align 4, !tbaa !3
  %mul668 = fmul float %sub657, %93
  %add6691537 = or i32 %mul659, 3
  %idxprom670 = sext i32 %add6691537 to i64
  %arrayidx671 = getelementptr inbounds float* %VFtab, i64 %idxprom670
  %94 = load float* %arrayidx671, align 4, !tbaa !3
  %mul672 = fmul float %mul658, %94
  %add673 = fadd float %92, %mul668
  %add674 = fadd float %add673, %mul672
  %mul675 = fmul float %sub657, %add674
  %add676 = fadd float %91, %mul675
  %add677 = fadd float %mul668, %add674
  %mul678 = fmul float %mul672, 2.000000e+00
  %add679 = fadd float %mul678, %add677
  %mul680 = fmul float %mul8, %add676
  %mul681 = fmul float %mul8, %add679
  %mul682 = fmul float %mul681, %tabscale
  %95 = fmul float %conv214, %mul682
  %mul684 = fsub float -0.000000e+00, %95
  %add685 = fadd float %add634, %mul680
  %mul686 = fmul float %sub174, %mul684
  %mul687 = fmul float %sub175, %mul684
  %mul688 = fmul float %sub176, %mul684
  %add689 = fadd float %add638, %mul686
  %add690 = fadd float %add639, %mul687
  %add691 = fadd float %add640, %mul688
  %sub692 = fsub float %sub549, %mul686
  store float %sub692, float* %arrayidx416, align 4, !tbaa !3
  %sub696 = fsub float %sub550, %mul687
  store float %sub696, float* %arrayidx420, align 4, !tbaa !3
  %sub700 = fsub float %sub551, %mul688
  store float %sub700, float* %arrayidx424, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %96 = trunc i64 %indvars.iv.next to i32
  %cmp80 = icmp slt i32 %96, %13
  br i1 %cmp80, label %for.body81, label %for.end

for.end:                                          ; preds = %for.body81, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add685, %for.body81 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add299, %for.body81 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add411, %for.body81 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add412, %for.body81 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add413, %for.body81 ]
  %fix2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add546, %for.body81 ]
  %fiy2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add547, %for.body81 ]
  %fiz2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add548, %for.body81 ]
  %fix3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add689, %for.body81 ]
  %fiy3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add690, %for.body81 ]
  %fiz3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add691, %for.body81 ]
  %arrayidx705 = getelementptr inbounds float* %faction, i64 %idxprom44
  %97 = load float* %arrayidx705, align 4, !tbaa !3
  %add706 = fadd float %fix1.0.lcssa, %97
  store float %add706, float* %arrayidx705, align 4, !tbaa !3
  %arrayidx711 = getelementptr inbounds float* %faction, i64 %idxprom48
  %98 = load float* %arrayidx711, align 4, !tbaa !3
  %add712 = fadd float %fiy1.0.lcssa, %98
  store float %add712, float* %arrayidx711, align 4, !tbaa !3
  %arrayidx718 = getelementptr inbounds float* %faction, i64 %idxprom52
  %99 = load float* %arrayidx718, align 4, !tbaa !3
  %add719 = fadd float %fiz1.0.lcssa, %99
  store float %add719, float* %arrayidx718, align 4, !tbaa !3
  %arrayidx725 = getelementptr inbounds float* %faction, i64 %idxprom56
  %100 = load float* %arrayidx725, align 4, !tbaa !3
  %add726 = fadd float %fix2.0.lcssa, %100
  store float %add726, float* %arrayidx725, align 4, !tbaa !3
  %arrayidx732 = getelementptr inbounds float* %faction, i64 %idxprom60
  %101 = load float* %arrayidx732, align 4, !tbaa !3
  %add733 = fadd float %fiy2.0.lcssa, %101
  store float %add733, float* %arrayidx732, align 4, !tbaa !3
  %arrayidx739 = getelementptr inbounds float* %faction, i64 %idxprom64
  %102 = load float* %arrayidx739, align 4, !tbaa !3
  %add740 = fadd float %fiz2.0.lcssa, %102
  store float %add740, float* %arrayidx739, align 4, !tbaa !3
  %arrayidx746 = getelementptr inbounds float* %faction, i64 %idxprom68
  %103 = load float* %arrayidx746, align 4, !tbaa !3
  %add747 = fadd float %fix3.0.lcssa, %103
  store float %add747, float* %arrayidx746, align 4, !tbaa !3
  %arrayidx753 = getelementptr inbounds float* %faction, i64 %idxprom72
  %104 = load float* %arrayidx753, align 4, !tbaa !3
  %add754 = fadd float %fiy3.0.lcssa, %104
  store float %add754, float* %arrayidx753, align 4, !tbaa !3
  %arrayidx760 = getelementptr inbounds float* %faction, i64 %idxprom76
  %105 = load float* %arrayidx760, align 4, !tbaa !3
  %add761 = fadd float %fiz3.0.lcssa, %105
  store float %add761, float* %arrayidx760, align 4, !tbaa !3
  %arrayidx766 = getelementptr inbounds float* %fshift, i64 %idxprom28
  %106 = load float* %arrayidx766, align 4, !tbaa !3
  %add767 = fadd float %fix1.0.lcssa, %106
  %add768 = fadd float %fix2.0.lcssa, %add767
  %add769 = fadd float %fix3.0.lcssa, %add768
  store float %add769, float* %arrayidx766, align 4, !tbaa !3
  %arrayidx774 = getelementptr inbounds float* %fshift, i64 %idxprom31
  %107 = load float* %arrayidx774, align 4, !tbaa !3
  %add775 = fadd float %fiy1.0.lcssa, %107
  %add776 = fadd float %fiy2.0.lcssa, %add775
  %add777 = fadd float %fiy3.0.lcssa, %add776
  store float %add777, float* %arrayidx774, align 4, !tbaa !3
  %arrayidx783 = getelementptr inbounds float* %fshift, i64 %idxprom34
  %108 = load float* %arrayidx783, align 4, !tbaa !3
  %add784 = fadd float %fiz1.0.lcssa, %108
  %add785 = fadd float %fiz2.0.lcssa, %add784
  %add786 = fadd float %fiz3.0.lcssa, %add785
  store float %add786, float* %arrayidx783, align 4, !tbaa !3
  %arrayidx791 = getelementptr inbounds i32* %gid, i64 %indvars.iv1563
  %109 = load i32* %arrayidx791, align 4, !tbaa !0
  %idxprom792 = sext i32 %109 to i64
  %arrayidx793 = getelementptr inbounds float* %Vc, i64 %idxprom792
  %110 = load float* %arrayidx793, align 4, !tbaa !3
  %add794 = fadd float %vctot.0.lcssa, %110
  store float %add794, float* %arrayidx793, align 4, !tbaa !3
  %arrayidx798 = getelementptr inbounds float* %Vnb, i64 %idxprom792
  %111 = load float* %arrayidx798, align 4, !tbaa !3
  %add799 = fadd float %vnbtot.0.lcssa, %111
  store float %add799, float* %arrayidx798, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next1564 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end804, label %for.end.for.body_crit_edge

for.end.for.body_crit_edge:                       ; preds = %for.end
  %arrayidx37.phi.trans.insert = getelementptr inbounds i32* %iinr, i64 %indvars.iv.next1564
  %.pre = load i32* %arrayidx37.phi.trans.insert, align 4, !tbaa !0
  br label %for.body

for.end804:                                       ; preds = %for.end, %entry
  ret void
}

attributes #0 = { nounwind optsize uwtable "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #1 = { nounwind optsize "less-precise-fpmad"="false" "no-frame-pointer-elim"="false" "no-frame-pointer-elim-non-leaf"="false" "no-infs-fp-math"="false" "no-nans-fp-math"="false" "unsafe-fp-math"="false" "use-soft-float"="false" }
attributes #2 = { nounwind optsize }

!0 = metadata !{metadata !"int", metadata !1}
!1 = metadata !{metadata !"omnipotent char", metadata !2}
!2 = metadata !{metadata !"Simple C/C++ TBAA"}
!3 = metadata !{metadata !"float", metadata !1}
