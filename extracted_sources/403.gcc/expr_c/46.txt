void
do_jump (exp, if_false_label, if_true_label)
     tree exp;
     rtx if_false_label, if_true_label;
{
  enum tree_code code = TREE_CODE (exp);
  /* Some cases need to create a label to jump to
     in order to properly fall through.
     These cases set DROP_THROUGH_LABEL nonzero.  */
  rtx drop_through_label = 0;
  rtx temp;
  int i;
  tree type;
  enum machine_mode mode;

#ifdef MAX_INTEGER_COMPUTATION_MODE
  check_max_integer_computation_mode (exp);
#endif

  emit_queue ();

  switch (code)
    {
    case ERROR_MARK:
      break;

    case INTEGER_CST:
      temp = integer_zerop (exp) ? if_false_label : if_true_label;
      if (temp)
	emit_jump (temp);
      break;

#if 0
      /* This is not true with #pragma weak  */
    case ADDR_EXPR:
      /* The address of something can never be zero.  */
      if (if_true_label)
	emit_jump (if_true_label);
      break;
#endif

    case NOP_EXPR:
      if (TREE_CODE (TREE_OPERAND (exp, 0)) == COMPONENT_REF
	  || TREE_CODE (TREE_OPERAND (exp, 0)) == BIT_FIELD_REF
	  || TREE_CODE (TREE_OPERAND (exp, 0)) == ARRAY_REF
	  || TREE_CODE (TREE_OPERAND (exp, 0)) == ARRAY_RANGE_REF)
	goto normal;
    case CONVERT_EXPR:
      /* If we are narrowing the operand, we have to do the compare in the
	 narrower mode.  */
      if ((TYPE_PRECISION (TREE_TYPE (exp))
	   < TYPE_PRECISION (TREE_TYPE (TREE_OPERAND (exp, 0)))))
	goto normal;
    case NON_LVALUE_EXPR:
    case REFERENCE_EXPR:
    case ABS_EXPR:
    case NEGATE_EXPR:
    case LROTATE_EXPR:
    case RROTATE_EXPR:
      /* These cannot change zero->non-zero or vice versa.  */
      do_jump (TREE_OPERAND (exp, 0), if_false_label, if_true_label);
      break;

    case WITH_RECORD_EXPR:
      /* Put the object on the placeholder list, recurse through our first
	 operand, and pop the list.  */
      placeholder_list = tree_cons (TREE_OPERAND (exp, 1), NULL_TREE,
				    placeholder_list);
      do_jump (TREE_OPERAND (exp, 0), if_false_label, if_true_label);
      placeholder_list = TREE_CHAIN (placeholder_list);
      break;

#if 0
      /* This is never less insns than evaluating the PLUS_EXPR followed by
	 a test and can be longer if the test is eliminated.  */
    case PLUS_EXPR:
      /* Reduce to minus.  */
      exp = build (MINUS_EXPR, TREE_TYPE (exp),
		   TREE_OPERAND (exp, 0),
		   fold (build1 (NEGATE_EXPR, TREE_TYPE (TREE_OPERAND (exp, 1)),
				 TREE_OPERAND (exp, 1))));
      /* Process as MINUS.  */
#endif

    case MINUS_EXPR:
      /* Non-zero iff operands of minus differ.  */
      do_compare_and_jump (build (NE_EXPR, TREE_TYPE (exp),
				  TREE_OPERAND (exp, 0),
				  TREE_OPERAND (exp, 1)),
			   NE, NE, if_false_label, if_true_label);
      break;

    case BIT_AND_EXPR:
      /* If we are AND'ing with a small constant, do this comparison in the
	 smallest type that fits.  If the machine doesn't have comparisons
	 that small, it will be converted back to the wider comparison.
	 This helps if we are testing the sign bit of a narrower object.
	 combine can't do this for us because it can't know whether a
	 ZERO_EXTRACT or a compare in a smaller mode exists, but we do.  */

      if (! SLOW_BYTE_ACCESS
	  && TREE_CODE (TREE_OPERAND (exp, 1)) == INTEGER_CST
	  && TYPE_PRECISION (TREE_TYPE (exp)) <= HOST_BITS_PER_WIDE_INT
	  && (i = tree_floor_log2 (TREE_OPERAND (exp, 1))) >= 0
	  && (mode = mode_for_size (i + 1, MODE_INT, 0)) != BLKmode
	  && (type = type_for_mode (mode, 1)) != 0
	  && TYPE_PRECISION (type) < TYPE_PRECISION (TREE_TYPE (exp))
	  && (cmp_optab->handlers[(int) TYPE_MODE (type)].insn_code
	      != CODE_FOR_nothing))
	{
	  do_jump (convert (type, exp), if_false_label, if_true_label);
	  break;
	}
      goto normal;

    case TRUTH_NOT_EXPR:
      do_jump (TREE_OPERAND (exp, 0), if_true_label, if_false_label);
      break;

    case TRUTH_ANDIF_EXPR:
      if (if_false_label == 0)
	if_false_label = drop_through_label = gen_label_rtx ();
      do_jump (TREE_OPERAND (exp, 0), if_false_label, NULL_RTX);
      start_cleanup_deferral ();
      do_jump (TREE_OPERAND (exp, 1), if_false_label, if_true_label);
      end_cleanup_deferral ();
      break;

    case TRUTH_ORIF_EXPR:
      if (if_true_label == 0)
	if_true_label = drop_through_label = gen_label_rtx ();
      do_jump (TREE_OPERAND (exp, 0), NULL_RTX, if_true_label);
      start_cleanup_deferral ();
      do_jump (TREE_OPERAND (exp, 1), if_false_label, if_true_label);
      end_cleanup_deferral ();
      break;

    case COMPOUND_EXPR:
      push_temp_slots ();
      expand_expr (TREE_OPERAND (exp, 0), const0_rtx, VOIDmode, 0);
      preserve_temp_slots (NULL_RTX);
      free_temp_slots ();
      pop_temp_slots ();
      emit_queue ();
      do_pending_stack_adjust ();
      do_jump (TREE_OPERAND (exp, 1), if_false_label, if_true_label);
      break;

    case COMPONENT_REF:
    case BIT_FIELD_REF:
    case ARRAY_REF:
    case ARRAY_RANGE_REF:
      {
	HOST_WIDE_INT bitsize, bitpos;
	int unsignedp;
	enum machine_mode mode;
	tree type;
	tree offset;
	int volatilep = 0;

	/* Get description of this reference.  We don't actually care
	   about the underlying object here.  */
	get_inner_reference (exp, &bitsize, &bitpos, &offset, &mode,
			     &unsignedp, &volatilep);

	type = type_for_size (bitsize, unsignedp);
	if (! SLOW_BYTE_ACCESS
	    && type != 0 && bitsize >= 0
	    && TYPE_PRECISION (type) < TYPE_PRECISION (TREE_TYPE (exp))
	    && (cmp_optab->handlers[(int) TYPE_MODE (type)].insn_code
		!= CODE_FOR_nothing))
	  {
	    do_jump (convert (type, exp), if_false_label, if_true_label);
	    break;
	  }
	goto normal;
      }

    case COND_EXPR:
      /* Do (a ? 1 : 0) and (a ? 0 : 1) as special cases.  */
      if (integer_onep (TREE_OPERAND (exp, 1))
	  && integer_zerop (TREE_OPERAND (exp, 2)))
	do_jump (TREE_OPERAND (exp, 0), if_false_label, if_true_label);

      else if (integer_zerop (TREE_OPERAND (exp, 1))
	       && integer_onep (TREE_OPERAND (exp, 2)))
	do_jump (TREE_OPERAND (exp, 0), if_true_label, if_false_label);

      else
	{
	  rtx label1 = gen_label_rtx ();
	  drop_through_label = gen_label_rtx ();

	  do_jump (TREE_OPERAND (exp, 0), label1, NULL_RTX);

	  start_cleanup_deferral ();
	  /* Now the THEN-expression.  */
	  do_jump (TREE_OPERAND (exp, 1),
		   if_false_label ? if_false_label : drop_through_label,
		   if_true_label ? if_true_label : drop_through_label);
	  /* In case the do_jump just above never jumps.  */
	  do_pending_stack_adjust ();
	  emit_label (label1);

	  /* Now the ELSE-expression.  */
	  do_jump (TREE_OPERAND (exp, 2),
		   if_false_label ? if_false_label : drop_through_label,
		   if_true_label ? if_true_label : drop_through_label);
	  end_cleanup_deferral ();
	}
      break;

    case EQ_EXPR:
      {
	tree inner_type = TREE_TYPE (TREE_OPERAND (exp, 0));

	if (GET_MODE_CLASS (TYPE_MODE (inner_type)) == MODE_COMPLEX_FLOAT
	    || GET_MODE_CLASS (TYPE_MODE (inner_type)) == MODE_COMPLEX_INT)
	  {
	    tree exp0 = save_expr (TREE_OPERAND (exp, 0));
	    tree exp1 = save_expr (TREE_OPERAND (exp, 1));
	    do_jump
	      (fold
	       (build (TRUTH_ANDIF_EXPR, TREE_TYPE (exp),
		       fold (build (EQ_EXPR, TREE_TYPE (exp),
				    fold (build1 (REALPART_EXPR,
						  TREE_TYPE (inner_type),
						  exp0)),
				    fold (build1 (REALPART_EXPR,
						  TREE_TYPE (inner_type),
						  exp1)))),
		       fold (build (EQ_EXPR, TREE_TYPE (exp),
				    fold (build1 (IMAGPART_EXPR,
						  TREE_TYPE (inner_type),
						  exp0)),
				    fold (build1 (IMAGPART_EXPR,
						  TREE_TYPE (inner_type),
						  exp1)))))),
	       if_false_label, if_true_label);
	  }

	else if (integer_zerop (TREE_OPERAND (exp, 1)))
	  do_jump (TREE_OPERAND (exp, 0), if_true_label, if_false_label);

	else if (GET_MODE_CLASS (TYPE_MODE (inner_type)) == MODE_INT
		 && !can_compare_p (EQ, TYPE_MODE (inner_type), ccp_jump))
	  do_jump_by_parts_equality (exp, if_false_label, if_true_label);
	else
	  do_compare_and_jump (exp, EQ, EQ, if_false_label, if_true_label);
	break;
      }

    case NE_EXPR:
      {
	tree inner_type = TREE_TYPE (TREE_OPERAND (exp, 0));

	if (GET_MODE_CLASS (TYPE_MODE (inner_type)) == MODE_COMPLEX_FLOAT
	    || GET_MODE_CLASS (TYPE_MODE (inner_type)) == MODE_COMPLEX_INT)
	  {
	    tree exp0 = save_expr (TREE_OPERAND (exp, 0));
	    tree exp1 = save_expr (TREE_OPERAND (exp, 1));
	    do_jump
	      (fold
	       (build (TRUTH_ORIF_EXPR, TREE_TYPE (exp),
		       fold (build (NE_EXPR, TREE_TYPE (exp),
				    fold (build1 (REALPART_EXPR,
						  TREE_TYPE (inner_type),
						  exp0)),
				    fold (build1 (REALPART_EXPR,
						  TREE_TYPE (inner_type),
						  exp1)))),
		       fold (build (NE_EXPR, TREE_TYPE (exp),
				    fold (build1 (IMAGPART_EXPR,
						  TREE_TYPE (inner_type),
						  exp0)),
				    fold (build1 (IMAGPART_EXPR,
						  TREE_TYPE (inner_type),
						  exp1)))))),
	       if_false_label, if_true_label);
	  }

	else if (integer_zerop (TREE_OPERAND (exp, 1)))
	  do_jump (TREE_OPERAND (exp, 0), if_false_label, if_true_label);

	else if (GET_MODE_CLASS (TYPE_MODE (inner_type)) == MODE_INT
		 && !can_compare_p (NE, TYPE_MODE (inner_type), ccp_jump))
	  do_jump_by_parts_equality (exp, if_true_label, if_false_label);
	else
	  do_compare_and_jump (exp, NE, NE, if_false_label, if_true_label);
	break;
      }

    case LT_EXPR:
      mode = TYPE_MODE (TREE_TYPE (TREE_OPERAND (exp, 0)));
      if (GET_MODE_CLASS (mode) == MODE_INT
	  && ! can_compare_p (LT, mode, ccp_jump))
	do_jump_by_parts_greater (exp, 1, if_false_label, if_true_label);
      else
	do_compare_and_jump (exp, LT, LTU, if_false_label, if_true_label);
      break;

    case LE_EXPR:
      mode = TYPE_MODE (TREE_TYPE (TREE_OPERAND (exp, 0)));
      if (GET_MODE_CLASS (mode) == MODE_INT
	  && ! can_compare_p (LE, mode, ccp_jump))
	do_jump_by_parts_greater (exp, 0, if_true_label, if_false_label);
      else
	do_compare_and_jump (exp, LE, LEU, if_false_label, if_true_label);
      break;

    case GT_EXPR:
      mode = TYPE_MODE (TREE_TYPE (TREE_OPERAND (exp, 0)));
      if (GET_MODE_CLASS (mode) == MODE_INT
	  && ! can_compare_p (GT, mode, ccp_jump))
	do_jump_by_parts_greater (exp, 0, if_false_label, if_true_label);
      else
	do_compare_and_jump (exp, GT, GTU, if_false_label, if_true_label);
      break;

    case GE_EXPR:
      mode = TYPE_MODE (TREE_TYPE (TREE_OPERAND (exp, 0)));
      if (GET_MODE_CLASS (mode) == MODE_INT
	  && ! can_compare_p (GE, mode, ccp_jump))
	do_jump_by_parts_greater (exp, 1, if_true_label, if_false_label);
      else
	do_compare_and_jump (exp, GE, GEU, if_false_label, if_true_label);
      break;

    case UNORDERED_EXPR:
    case ORDERED_EXPR:
      {
	enum rtx_code cmp, rcmp;
	int do_rev;

	if (code == UNORDERED_EXPR)
	  cmp = UNORDERED, rcmp = ORDERED;
	else
	  cmp = ORDERED, rcmp = UNORDERED;
	mode = TYPE_MODE (TREE_TYPE (TREE_OPERAND (exp, 0)));

	do_rev = 0;
	if (! can_compare_p (cmp, mode, ccp_jump)
	    && (can_compare_p (rcmp, mode, ccp_jump)
		/* If the target doesn't provide either UNORDERED or ORDERED
		   comparisons, canonicalize on UNORDERED for the library.  */
		|| rcmp == UNORDERED))
	  do_rev = 1;

        if (! do_rev)
	  do_compare_and_jump (exp, cmp, cmp, if_false_label, if_true_label);
	else
	  do_compare_and_jump (exp, rcmp, rcmp, if_true_label, if_false_label);
      }
      break;

    {
      enum rtx_code rcode1;
      enum tree_code tcode2;

      case UNLT_EXPR:
	rcode1 = UNLT;
	tcode2 = LT_EXPR;
	goto unordered_bcc;
      case UNLE_EXPR:
	rcode1 = UNLE;
	tcode2 = LE_EXPR;
	goto unordered_bcc;
      case UNGT_EXPR:
	rcode1 = UNGT;
	tcode2 = GT_EXPR;
	goto unordered_bcc;
      case UNGE_EXPR:
	rcode1 = UNGE;
	tcode2 = GE_EXPR;
	goto unordered_bcc;
      case UNEQ_EXPR:
	rcode1 = UNEQ;
	tcode2 = EQ_EXPR;
	goto unordered_bcc;

      unordered_bcc:
        mode = TYPE_MODE (TREE_TYPE (TREE_OPERAND (exp, 0)));
	if (can_compare_p (rcode1, mode, ccp_jump))
	  do_compare_and_jump (exp, rcode1, rcode1, if_false_label,
			       if_true_label);
	else
	  {
	    tree op0 = save_expr (TREE_OPERAND (exp, 0));
	    tree op1 = save_expr (TREE_OPERAND (exp, 1));
	    tree cmp0, cmp1;

	    /* If the target doesn't support combined unordered
	       compares, decompose into UNORDERED + comparison.  */
	    cmp0 = fold (build (UNORDERED_EXPR, TREE_TYPE (exp), op0, op1));
	    cmp1 = fold (build (tcode2, TREE_TYPE (exp), op0, op1));
	    exp = build (TRUTH_ORIF_EXPR, TREE_TYPE (exp), cmp0, cmp1);
	    do_jump (exp, if_false_label, if_true_label);
	  }
      }
      break;

      /* Special case:
		__builtin_expect (<test>, 0)	and
		__builtin_expect (<test>, 1)

	 We need to do this here, so that <test> is not converted to a SCC
	 operation on machines that use condition code registers and COMPARE
	 like the PowerPC, and then the jump is done based on whether the SCC
	 operation produced a 1 or 0.  */
    case CALL_EXPR:
      /* Check for a built-in function.  */
      if (TREE_CODE (TREE_OPERAND (exp, 0)) == ADDR_EXPR)
	{
	  tree fndecl = TREE_OPERAND (TREE_OPERAND (exp, 0), 0);
	  tree arglist = TREE_OPERAND (exp, 1);

	  if (TREE_CODE (fndecl) == FUNCTION_DECL
	      && DECL_BUILT_IN (fndecl)
	      && DECL_FUNCTION_CODE (fndecl) == BUILT_IN_EXPECT
	      && arglist != NULL_TREE
	      && TREE_CHAIN (arglist) != NULL_TREE)
	    {
	      rtx seq = expand_builtin_expect_jump (exp, if_false_label,
						    if_true_label);

	      if (seq != NULL_RTX)
		{
		  emit_insn (seq);
		  return;
		}
	    }
	}
      /* fall through and generate the normal code.  */

    default:
    normal:
      temp = expand_expr (exp, NULL_RTX, VOIDmode, 0);
#if 0
      /* This is not needed any more and causes poor code since it causes
	 comparisons and tests from non-SI objects to have different code
	 sequences.  */
      /* Copy to register to avoid generating bad insns by cse
	 from (set (mem ...) (arithop))  (set (cc0) (mem ...)).  */
      if (!cse_not_expected && GET_CODE (temp) == MEM)
	temp = copy_to_reg (temp);
#endif
      do_pending_stack_adjust ();
      /* Do any postincrements in the expression that was tested.  */
      emit_queue ();

      if (GET_CODE (temp) == CONST_INT 
	  || (GET_CODE (temp) == CONST_DOUBLE && GET_MODE (temp) == VOIDmode)
	  || GET_CODE (temp) == LABEL_REF)
	{
	  rtx target = temp == const0_rtx ? if_false_label : if_true_label;
	  if (target)
	    emit_jump (target);
	}
      else if (GET_MODE_CLASS (GET_MODE (temp)) == MODE_INT
	       && ! can_compare_p (NE, GET_MODE (temp), ccp_jump))
	/* Note swapping the labels gives us not-equal.  */
	do_jump_by_parts_equality_rtx (temp, if_true_label, if_false_label);
      else if (GET_MODE (temp) != VOIDmode)
	do_compare_rtx_and_jump (temp, CONST0_RTX (GET_MODE (temp)),
				 NE, TREE_UNSIGNED (TREE_TYPE (exp)),
				 GET_MODE (temp), NULL_RTX,
				 if_false_label, if_true_label);
      else
	abort ();
    }

  if (drop_through_label)
    {
      /* If do_jump produces code that might be jumped around,
	 do any stack adjusts from that code, before the place
	 where control merges in.  */
      do_pending_stack_adjust ();
      emit_label (drop_through_label);
    }
}
