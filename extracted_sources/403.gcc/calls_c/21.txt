static rtx
emit_library_call_value_1 (retval, orgfun, value, fn_type, outmode, nargs, p)
     int retval;
     rtx orgfun;
     rtx value;
     enum libcall_type fn_type;
     enum machine_mode outmode;
     int nargs;
     va_list p;
{
  /* Total size in bytes of all the stack-parms scanned so far.  */
  struct args_size args_size;
  /* Size of arguments before any adjustments (such as rounding).  */
  struct args_size original_args_size;
  int argnum;
  rtx fun;
  int inc;
  int count;
  struct args_size alignment_pad;
  rtx argblock = 0;
  CUMULATIVE_ARGS args_so_far;
  struct arg
  {
    rtx value;
    enum machine_mode mode;
    rtx reg;
    int partial;
    struct args_size offset;
    struct args_size size;
    rtx save_area;
  };
  struct arg *argvec;
  int old_inhibit_defer_pop = inhibit_defer_pop;
  rtx call_fusage = 0;
  rtx mem_value = 0;
  rtx valreg;
  int pcc_struct_value = 0;
  int struct_value_size = 0;
  int flags;
  int reg_parm_stack_space = 0;
  int needed;
  rtx before_call;

#ifdef REG_PARM_STACK_SPACE
  /* Define the boundary of the register parm stack space that needs to be
     save, if any.  */
  int low_to_save = -1, high_to_save = 0;
  rtx save_area = 0;            /* Place that it is saved.  */
#endif

  /* Size of the stack reserved for parameter registers.  */
  int initial_highest_arg_in_use = highest_outgoing_arg_in_use;
  char *initial_stack_usage_map = stack_usage_map;

#ifdef REG_PARM_STACK_SPACE
#ifdef MAYBE_REG_PARM_STACK_SPACE
  reg_parm_stack_space = MAYBE_REG_PARM_STACK_SPACE;
#else
  reg_parm_stack_space = REG_PARM_STACK_SPACE ((tree) 0);
#endif
#endif

  /* By default, library functions can not throw.  */
  flags = ECF_NOTHROW;

  switch (fn_type)
    {
    case LCT_NORMAL:
      break;
    case LCT_CONST:
      flags |= ECF_CONST;
      break;
    case LCT_PURE:
      flags |= ECF_PURE;
      break;
    case LCT_CONST_MAKE_BLOCK:
      flags |= ECF_CONST | ECF_LIBCALL_BLOCK;
      break;
    case LCT_PURE_MAKE_BLOCK:
      flags |= ECF_PURE | ECF_LIBCALL_BLOCK;
      break;
    case LCT_NORETURN:
      flags |= ECF_NORETURN;
      break;
    case LCT_THROW:
      flags = ECF_NORETURN;
      break;
    case LCT_ALWAYS_RETURN:
      flags = ECF_ALWAYS_RETURN;
      break;
    case LCT_RETURNS_TWICE:
      flags = ECF_RETURNS_TWICE;
      break;
    }
  fun = orgfun;

  /* Ensure current function's preferred stack boundary is at least
     what we need.  */
  if (cfun->preferred_stack_boundary < PREFERRED_STACK_BOUNDARY)
    cfun->preferred_stack_boundary = PREFERRED_STACK_BOUNDARY;

  /* If this kind of value comes back in memory,
     decide where in memory it should come back.  */
  if (outmode != VOIDmode && aggregate_value_p (type_for_mode (outmode, 0)))
    {
#ifdef PCC_STATIC_STRUCT_RETURN
      rtx pointer_reg
	= hard_function_value (build_pointer_type (type_for_mode (outmode, 0)),
			       0, 0);
      mem_value = gen_rtx_MEM (outmode, pointer_reg);
      pcc_struct_value = 1;
      if (value == 0)
	value = gen_reg_rtx (outmode);
#else /* not PCC_STATIC_STRUCT_RETURN */
      struct_value_size = GET_MODE_SIZE (outmode);
      if (value != 0 && GET_CODE (value) == MEM)
	mem_value = value;
      else
	mem_value = assign_temp (type_for_mode (outmode, 0), 0, 1, 1);
#endif

      /* This call returns a big structure.  */
      flags &= ~(ECF_CONST | ECF_PURE | ECF_LIBCALL_BLOCK);
    }

  /* ??? Unfinished: must pass the memory address as an argument.  */

  /* Copy all the libcall-arguments out of the varargs data
     and into a vector ARGVEC.

     Compute how to pass each argument.  We only support a very small subset
     of the full argument passing conventions to limit complexity here since
     library functions shouldn't have many args.  */

  argvec = (struct arg *) alloca ((nargs + 1) * sizeof (struct arg));
  memset ((char *) argvec, 0, (nargs + 1) * sizeof (struct arg));

#ifdef INIT_CUMULATIVE_LIBCALL_ARGS
  INIT_CUMULATIVE_LIBCALL_ARGS (args_so_far, outmode, fun);
#else
  INIT_CUMULATIVE_ARGS (args_so_far, NULL_TREE, fun, 0);
#endif

  args_size.constant = 0;
  args_size.var = 0;

  count = 0;

  /* Now we are about to start emitting insns that can be deleted
     if a libcall is deleted.  */
  if (flags & ECF_LIBCALL_BLOCK)
    start_sequence ();

  push_temp_slots ();

  /* If there's a structure value address to be passed,
     either pass it in the special place, or pass it as an extra argument.  */
  if (mem_value && struct_value_rtx == 0 && ! pcc_struct_value)
    {
      rtx addr = XEXP (mem_value, 0);
      nargs++;

      /* Make sure it is a reasonable operand for a move or push insn.  */
      if (GET_CODE (addr) != REG && GET_CODE (addr) != MEM
	  && ! (CONSTANT_P (addr) && LEGITIMATE_CONSTANT_P (addr)))
	addr = force_operand (addr, NULL_RTX);

      argvec[count].value = addr;
      argvec[count].mode = Pmode;
      argvec[count].partial = 0;

      argvec[count].reg = FUNCTION_ARG (args_so_far, Pmode, NULL_TREE, 1);
#ifdef FUNCTION_ARG_PARTIAL_NREGS
      if (FUNCTION_ARG_PARTIAL_NREGS (args_so_far, Pmode, NULL_TREE, 1))
	abort ();
#endif

      locate_and_pad_parm (Pmode, NULL_TREE,
#ifdef STACK_PARMS_IN_REG_PARM_AREA
                           1,
#else
			   argvec[count].reg != 0,
#endif
			   NULL_TREE, &args_size, &argvec[count].offset,
			   &argvec[count].size, &alignment_pad);

      if (argvec[count].reg == 0 || argvec[count].partial != 0
	  || reg_parm_stack_space > 0)
	args_size.constant += argvec[count].size.constant;

      FUNCTION_ARG_ADVANCE (args_so_far, Pmode, (tree) 0, 1);

      count++;
    }

  for (; count < nargs; count++)
    {
      rtx val = va_arg (p, rtx);
      enum machine_mode mode = va_arg (p, enum machine_mode);

      /* We cannot convert the arg value to the mode the library wants here;
	 must do it earlier where we know the signedness of the arg.  */
      if (mode == BLKmode
	  || (GET_MODE (val) != mode && GET_MODE (val) != VOIDmode))
	abort ();

      /* On some machines, there's no way to pass a float to a library fcn.
	 Pass it as a double instead.  */
#ifdef LIBGCC_NEEDS_DOUBLE
      if (LIBGCC_NEEDS_DOUBLE && mode == SFmode)
	val = convert_modes (DFmode, SFmode, val, 0), mode = DFmode;
#endif

      /* There's no need to call protect_from_queue, because
	 either emit_move_insn or emit_push_insn will do that.  */

      /* Make sure it is a reasonable operand for a move or push insn.  */
      if (GET_CODE (val) != REG && GET_CODE (val) != MEM
	  && ! (CONSTANT_P (val) && LEGITIMATE_CONSTANT_P (val)))
	val = force_operand (val, NULL_RTX);

#ifdef FUNCTION_ARG_PASS_BY_REFERENCE
      if (FUNCTION_ARG_PASS_BY_REFERENCE (args_so_far, mode, NULL_TREE, 1))
	{
	  rtx slot;
	  int must_copy = 1
#ifdef FUNCTION_ARG_CALLEE_COPIES	  
	    && ! FUNCTION_ARG_CALLEE_COPIES (args_so_far, mode,
					     NULL_TREE, 1)
#endif
	    ;

	  if (GET_MODE (val) == MEM && ! must_copy)
	    slot = val;
	  else if (must_copy)
	    {
	      slot = assign_temp (type_for_mode (mode, 0), 0, 1, 1);
	      emit_move_insn (slot, val);
	    }
	  else
	    {
	      tree type = type_for_mode (mode, 0);

	      slot = gen_rtx_MEM (mode,
				  expand_expr (build1 (ADDR_EXPR,
						       build_pointer_type
						       (type),
						       make_tree (type, val)),
					       NULL_RTX, VOIDmode, 0));
	    }

	  call_fusage = gen_rtx_EXPR_LIST (VOIDmode,
					   gen_rtx_USE (VOIDmode, slot),
					   call_fusage);
	  if (must_copy)
	    call_fusage = gen_rtx_EXPR_LIST (VOIDmode,
					     gen_rtx_CLOBBER (VOIDmode,
							      slot),
					     call_fusage);

	  mode = Pmode;
	  val = force_operand (XEXP (slot, 0), NULL_RTX);
	}
#endif

      argvec[count].value = val;
      argvec[count].mode = mode;

      argvec[count].reg = FUNCTION_ARG (args_so_far, mode, NULL_TREE, 1);

#ifdef FUNCTION_ARG_PARTIAL_NREGS
      argvec[count].partial
	= FUNCTION_ARG_PARTIAL_NREGS (args_so_far, mode, NULL_TREE, 1);
#else
      argvec[count].partial = 0;
#endif

      locate_and_pad_parm (mode, NULL_TREE,
#ifdef STACK_PARMS_IN_REG_PARM_AREA
			   1,
#else
			   argvec[count].reg != 0,
#endif
			   NULL_TREE, &args_size, &argvec[count].offset,
			   &argvec[count].size, &alignment_pad);

      if (argvec[count].size.var)
	abort ();

      if (reg_parm_stack_space == 0 && argvec[count].partial)
	argvec[count].size.constant -= argvec[count].partial * UNITS_PER_WORD;

      if (argvec[count].reg == 0 || argvec[count].partial != 0
	  || reg_parm_stack_space > 0)
	args_size.constant += argvec[count].size.constant;

      FUNCTION_ARG_ADVANCE (args_so_far, mode, (tree) 0, 1);
    }

#ifdef FINAL_REG_PARM_STACK_SPACE
  reg_parm_stack_space = FINAL_REG_PARM_STACK_SPACE (args_size.constant,
						     args_size.var);
#endif
  /* If this machine requires an external definition for library
     functions, write one out.  */
  assemble_external_libcall (fun);

  original_args_size = args_size;
  args_size.constant = (((args_size.constant
			  + stack_pointer_delta
			  + STACK_BYTES - 1)
			  / STACK_BYTES
			  * STACK_BYTES)
			 - stack_pointer_delta);

  args_size.constant = MAX (args_size.constant,
			    reg_parm_stack_space);

#ifndef OUTGOING_REG_PARM_STACK_SPACE
  args_size.constant -= reg_parm_stack_space;
#endif

  if (args_size.constant > current_function_outgoing_args_size)
    current_function_outgoing_args_size = args_size.constant;

  if (ACCUMULATE_OUTGOING_ARGS)
    {
      /* Since the stack pointer will never be pushed, it is possible for
	 the evaluation of a parm to clobber something we have already
	 written to the stack.  Since most function calls on RISC machines
	 do not use the stack, this is uncommon, but must work correctly.

	 Therefore, we save any area of the stack that was already written
	 and that we are using.  Here we set up to do this by making a new
	 stack usage map from the old one.

	 Another approach might be to try to reorder the argument
	 evaluations to avoid this conflicting stack usage.  */

      needed = args_size.constant;

#ifndef OUTGOING_REG_PARM_STACK_SPACE
      /* Since we will be writing into the entire argument area, the
	 map must be allocated for its entire size, not just the part that
	 is the responsibility of the caller.  */
      needed += reg_parm_stack_space;
#endif

#ifdef ARGS_GROW_DOWNWARD
      highest_outgoing_arg_in_use = MAX (initial_highest_arg_in_use,
					 needed + 1);
#else
      highest_outgoing_arg_in_use = MAX (initial_highest_arg_in_use,
					 needed);
#endif
      stack_usage_map = (char *) alloca (highest_outgoing_arg_in_use);

      if (initial_highest_arg_in_use)
	memcpy (stack_usage_map, initial_stack_usage_map,
		initial_highest_arg_in_use);

      if (initial_highest_arg_in_use != highest_outgoing_arg_in_use)
	memset (&stack_usage_map[initial_highest_arg_in_use], 0,
	       highest_outgoing_arg_in_use - initial_highest_arg_in_use);
      needed = 0;

      /* We must be careful to use virtual regs before they're instantiated,
         and real regs afterwards.  Loop optimization, for example, can create
	 new libcalls after we've instantiated the virtual regs, and if we
	 use virtuals anyway, they won't match the rtl patterns.  */

      if (virtuals_instantiated)
	argblock = plus_constant (stack_pointer_rtx, STACK_POINTER_OFFSET);
      else
	argblock = virtual_outgoing_args_rtx;
    }
  else
    {
      if (!PUSH_ARGS)
	argblock = push_block (GEN_INT (args_size.constant), 0, 0);
    }

  /* If we push args individually in reverse order, perform stack alignment
     before the first push (the last arg).  */
  if (argblock == 0 && PUSH_ARGS_REVERSED)
    anti_adjust_stack (GEN_INT (args_size.constant
				- original_args_size.constant));

  if (PUSH_ARGS_REVERSED)
    {
      inc = -1;
      argnum = nargs - 1;
    }
  else
    {
      inc = 1;
      argnum = 0;
    }

#ifdef REG_PARM_STACK_SPACE
  if (ACCUMULATE_OUTGOING_ARGS)
    {
      /* The argument list is the property of the called routine and it
	 may clobber it.  If the fixed area has been used for previous
	 parameters, we must save and restore it.

	 Here we compute the boundary of the that needs to be saved, if any.  */

#ifdef ARGS_GROW_DOWNWARD
      for (count = 0; count < reg_parm_stack_space + 1; count++)
#else
      for (count = 0; count < reg_parm_stack_space; count++)
#endif
	{
	  if (count >= highest_outgoing_arg_in_use
	      || stack_usage_map[count] == 0)
	    continue;

	  if (low_to_save == -1)
	    low_to_save = count;

	  high_to_save = count;
	}

      if (low_to_save >= 0)
	{
	  int num_to_save = high_to_save - low_to_save + 1;
	  enum machine_mode save_mode
	    = mode_for_size (num_to_save * BITS_PER_UNIT, MODE_INT, 1);
	  rtx stack_area;

	  /* If we don't have the required alignment, must do this in BLKmode.  */
	  if ((low_to_save & (MIN (GET_MODE_SIZE (save_mode),
				   BIGGEST_ALIGNMENT / UNITS_PER_WORD) - 1)))
	    save_mode = BLKmode;

#ifdef ARGS_GROW_DOWNWARD
	  stack_area = gen_rtx_MEM (save_mode,
				    memory_address (save_mode,
						    plus_constant (argblock,
								   -high_to_save)));
#else
	  stack_area = gen_rtx_MEM (save_mode,
				    memory_address (save_mode,
						    plus_constant (argblock,
								   low_to_save)));
#endif
	  if (save_mode == BLKmode)
	    {
	      save_area = assign_stack_temp (BLKmode, num_to_save, 0);
	      set_mem_align (save_area, PARM_BOUNDARY);
	      emit_block_move (validize_mem (save_area), stack_area,
			       GEN_INT (num_to_save));
	    }
	  else
	    {
	      save_area = gen_reg_rtx (save_mode);
	      emit_move_insn (save_area, stack_area);
	    }
	}
    }
#endif

  /* Push the args that need to be pushed.  */

  /* ARGNUM indexes the ARGVEC array in the order in which the arguments
     are to be pushed.  */
  for (count = 0; count < nargs; count++, argnum += inc)
    {
      enum machine_mode mode = argvec[argnum].mode;
      rtx val = argvec[argnum].value;
      rtx reg = argvec[argnum].reg;
      int partial = argvec[argnum].partial;
      int lower_bound = 0, upper_bound = 0, i;

      if (! (reg != 0 && partial == 0))
	{
	  if (ACCUMULATE_OUTGOING_ARGS)
	    {
	      /* If this is being stored into a pre-allocated, fixed-size,
		 stack area, save any previous data at that location.  */

#ifdef ARGS_GROW_DOWNWARD
	      /* stack_slot is negative, but we want to index stack_usage_map
		 with positive values.  */
	      upper_bound = -argvec[argnum].offset.constant + 1;
	      lower_bound = upper_bound - argvec[argnum].size.constant;
#else
	      lower_bound = argvec[argnum].offset.constant;
	      upper_bound = lower_bound + argvec[argnum].size.constant;
#endif

	      for (i = lower_bound; i < upper_bound; i++)
		if (stack_usage_map[i]
		    /* Don't store things in the fixed argument area at this
		       point; it has already been saved.  */
		    && i > reg_parm_stack_space)
		  break;

	      if (i != upper_bound)
		{
		  /* We need to make a save area.  See what mode we can make
		     it.  */
		  enum machine_mode save_mode
		    = mode_for_size (argvec[argnum].size.constant
				     * BITS_PER_UNIT,
				     MODE_INT, 1);
		  rtx stack_area
		    = gen_rtx_MEM
		      (save_mode,
		       memory_address
		       (save_mode,
			plus_constant (argblock,
				       argvec[argnum].offset.constant)));
		  argvec[argnum].save_area = gen_reg_rtx (save_mode);

		  emit_move_insn (argvec[argnum].save_area, stack_area);
		}
	    }

	  emit_push_insn (val, mode, NULL_TREE, NULL_RTX, 0, partial, reg, 0,
			  argblock, GEN_INT (argvec[argnum].offset.constant),
			  reg_parm_stack_space, ARGS_SIZE_RTX (alignment_pad));

	  /* Now mark the segment we just used.  */
	  if (ACCUMULATE_OUTGOING_ARGS)
	    for (i = lower_bound; i < upper_bound; i++)
	      stack_usage_map[i] = 1;

	  NO_DEFER_POP;
	}
    }

  /* If we pushed args in forward order, perform stack alignment
     after pushing the last arg.  */
  if (argblock == 0 && !PUSH_ARGS_REVERSED)
    anti_adjust_stack (GEN_INT (args_size.constant
				- original_args_size.constant));

  if (PUSH_ARGS_REVERSED)
    argnum = nargs - 1;
  else
    argnum = 0;

  fun = prepare_call_address (fun, NULL_TREE, &call_fusage, 0, 0);

  /* Now load any reg parms into their regs.  */

  /* ARGNUM indexes the ARGVEC array in the order in which the arguments
     are to be pushed.  */
  for (count = 0; count < nargs; count++, argnum += inc)
    {
      rtx val = argvec[argnum].value;
      rtx reg = argvec[argnum].reg;
      int partial = argvec[argnum].partial;

      /* Handle calls that pass values in multiple non-contiguous
	 locations.  The PA64 has examples of this for library calls.  */
      if (reg != 0 && GET_CODE (reg) == PARALLEL)
	emit_group_load (reg, val, GET_MODE_SIZE (GET_MODE (val)));
      else if (reg != 0 && partial == 0)
	emit_move_insn (reg, val);

      NO_DEFER_POP;
    }

  /* Any regs containing parms remain in use through the call.  */
  for (count = 0; count < nargs; count++)
    {
      rtx reg = argvec[count].reg;
      if (reg != 0 && GET_CODE (reg) == PARALLEL)
	use_group_regs (&call_fusage, reg);
      else if (reg != 0)
	use_reg (&call_fusage, reg);
    }

  /* Pass the function the address in which to return a structure value.  */
  if (mem_value != 0 && struct_value_rtx != 0 && ! pcc_struct_value)
    {
      emit_move_insn (struct_value_rtx,
		      force_reg (Pmode,
				 force_operand (XEXP (mem_value, 0),
						NULL_RTX)));
      if (GET_CODE (struct_value_rtx) == REG)
	use_reg (&call_fusage, struct_value_rtx);
    }

  /* Don't allow popping to be deferred, since then
     cse'ing of library calls could delete a call and leave the pop.  */
  NO_DEFER_POP;
  valreg = (mem_value == 0 && outmode != VOIDmode
	    ? hard_libcall_value (outmode) : NULL_RTX);

  /* Stack must be properly aligned now.  */
  if (stack_pointer_delta & (PREFERRED_STACK_BOUNDARY / BITS_PER_UNIT - 1))
    abort ();

  before_call = get_last_insn ();

  /* We pass the old value of inhibit_defer_pop + 1 to emit_call_1, which
     will set inhibit_defer_pop to that value.  */
  /* The return type is needed to decide how many bytes the function pops.
     Signedness plays no role in that, so for simplicity, we pretend it's
     always signed.  We also assume that the list of arguments passed has
     no impact, so we pretend it is unknown.  */

  emit_call_1 (fun,
	       get_identifier (XSTR (orgfun, 0)),
	       build_function_type (outmode == VOIDmode ? void_type_node
				    : type_for_mode (outmode, 0), NULL_TREE),
	       original_args_size.constant, args_size.constant,
	       struct_value_size,
	       FUNCTION_ARG (args_so_far, VOIDmode, void_type_node, 1),
	       valreg,
	       old_inhibit_defer_pop + 1, call_fusage, flags, & args_so_far);

  /* For calls to `setjmp', etc., inform flow.c it should complain
     if nonvolatile values are live.  For functions that cannot return,
     inform flow that control does not fall through.  */

  if (flags & (ECF_NORETURN | ECF_LONGJMP))
    {
      /* The barrier note must be emitted
	 immediately after the CALL_INSN.  Some ports emit more than
	 just a CALL_INSN above, so we must search for it here.  */

      rtx last = get_last_insn ();
      while (GET_CODE (last) != CALL_INSN)
	{
	  last = PREV_INSN (last);
	  /* There was no CALL_INSN?  */
	  if (last == before_call)
	    abort ();
	}

      emit_barrier_after (last);
    }

  /* Now restore inhibit_defer_pop to its actual original value.  */
  OK_DEFER_POP;

  /* If call is cse'able, make appropriate pair of reg-notes around it.
     Test valreg so we don't crash; may safely ignore `const'
     if return type is void.  Disable for PARALLEL return values, because
     we have no way to move such values into a pseudo register.  */
  if (flags & ECF_LIBCALL_BLOCK)
    {
      rtx insns;

      if (valreg == 0 || GET_CODE (valreg) == PARALLEL)
	{
	  insns = get_insns ();
	  end_sequence ();
	  emit_insns (insns);
	}
      else
	{
	  rtx note = 0;
	  rtx temp = gen_reg_rtx (GET_MODE (valreg));
	  int i;

	  /* Construct an "equal form" for the value which mentions all the
	     arguments in order as well as the function name.  */
	  for (i = 0; i < nargs; i++)
	    note = gen_rtx_EXPR_LIST (VOIDmode, argvec[i].value, note);
	  note = gen_rtx_EXPR_LIST (VOIDmode, fun, note);

	  insns = get_insns ();
	  end_sequence ();

	  if (flags & ECF_PURE)
	    note = gen_rtx_EXPR_LIST (VOIDmode,
			gen_rtx_USE (VOIDmode,
				     gen_rtx_MEM (BLKmode,
						  gen_rtx_SCRATCH (VOIDmode))),
			note);

	  emit_libcall_block (insns, temp, valreg, note);

	  valreg = temp;
	}
    }
  pop_temp_slots ();

  /* Copy the value to the right place.  */
  if (outmode != VOIDmode && retval)
    {
      if (mem_value)
	{
	  if (value == 0)
	    value = mem_value;
	  if (value != mem_value)
	    emit_move_insn (value, mem_value);
	}
      else if (value != 0)
	emit_move_insn (value, hard_libcall_value (outmode));
      else
	value = hard_libcall_value (outmode);
    }

  if (ACCUMULATE_OUTGOING_ARGS)
    {
#ifdef REG_PARM_STACK_SPACE
      if (save_area)
	{
	  enum machine_mode save_mode = GET_MODE (save_area);
#ifdef ARGS_GROW_DOWNWARD
	  rtx stack_area
	    = gen_rtx_MEM (save_mode,
			   memory_address (save_mode,
					   plus_constant (argblock,
							  - high_to_save)));
#else
	  rtx stack_area
	    = gen_rtx_MEM (save_mode,
			   memory_address (save_mode,
					   plus_constant (argblock, low_to_save)));
#endif

	  set_mem_align (stack_area, PARM_BOUNDARY);
	  if (save_mode != BLKmode)
	    emit_move_insn (stack_area, save_area);
	  else
	    emit_block_move (stack_area, validize_mem (save_area),
			     GEN_INT (high_to_save - low_to_save + 1));
	}
#endif

      /* If we saved any argument areas, restore them.  */
      for (count = 0; count < nargs; count++)
	if (argvec[count].save_area)
	  {
	    enum machine_mode save_mode = GET_MODE (argvec[count].save_area);
	    rtx stack_area
	      = gen_rtx_MEM (save_mode,
			     memory_address
			     (save_mode,
			      plus_constant (argblock,
					     argvec[count].offset.constant)));

	    emit_move_insn (stack_area, argvec[count].save_area);
	  }

      highest_outgoing_arg_in_use = initial_highest_arg_in_use;
      stack_usage_map = initial_stack_usage_map;
    }

  return value;

}
