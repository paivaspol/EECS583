define void @_ZN3pov7MTimesAEPA4_dS1_([4 x double]* nocapture %result, [4 x double]* nocapture %matrix2) #0 {
entry:
  tail call void @llvm.dbg.value(metadata !{[4 x double]* %result}, i64 0, metadata !37), !dbg !401
  tail call void @llvm.dbg.value(metadata !{[4 x double]* %matrix2}, i64 0, metadata !38), !dbg !401
  %arrayidx1 = getelementptr inbounds [4 x double]* %result, i64 0, i64 0, !dbg !402
  %0 = load double* %arrayidx1, align 8, !dbg !402, !tbaa !397
  tail call void @llvm.dbg.value(metadata !{double %0}, i64 0, metadata !39), !dbg !402
  %arrayidx3 = getelementptr inbounds [4 x double]* %result, i64 0, i64 1, !dbg !403
  %1 = load double* %arrayidx3, align 8, !dbg !403, !tbaa !397
  tail call void @llvm.dbg.value(metadata !{double %1}, i64 0, metadata !40), !dbg !403
  %arrayidx5 = getelementptr inbounds [4 x double]* %result, i64 0, i64 2, !dbg !404
  %2 = load double* %arrayidx5, align 8, !dbg !404, !tbaa !397
  tail call void @llvm.dbg.value(metadata !{double %2}, i64 0, metadata !41), !dbg !404
  %arrayidx7 = getelementptr inbounds [4 x double]* %result, i64 0, i64 3, !dbg !405
  %3 = load double* %arrayidx7, align 8, !dbg !405, !tbaa !397
  tail call void @llvm.dbg.value(metadata !{double %3}, i64 0, metadata !42), !dbg !405
  %arrayidx9 = getelementptr inbounds [4 x double]* %matrix2, i64 0, i64 0, !dbg !406
  %4 = load double* %arrayidx9, align 8, !dbg !406, !tbaa !397
  %mul = fmul double %0, %4, !dbg !406
  %arrayidx11 = getelementptr inbounds [4 x double]* %matrix2, i64 1, i64 0, !dbg !406
  %5 = load double* %arrayidx11, align 8, !dbg !406, !tbaa !397
  %mul12 = fmul double %1, %5, !dbg !406
  %add = fadd double %mul, %mul12, !dbg !406
  %arrayidx14 = getelementptr inbounds [4 x double]* %matrix2, i64 2, i64 0, !dbg !406
  %6 = load double* %arrayidx14, align 8, !dbg !406, !tbaa !397
  %mul15 = fmul double %2, %6, !dbg !406
  %add16 = fadd double %add, %mul15, !dbg !406
  %arrayidx18 = getelementptr inbounds [4 x double]* %matrix2, i64 3, i64 0, !dbg !406
  %7 = load double* %arrayidx18, align 8, !dbg !406, !tbaa !397
  %mul19 = fmul double %3, %7, !dbg !406
  %add20 = fadd double %add16, %mul19, !dbg !406
  store double %add20, double* %arrayidx1, align 8, !dbg !406, !tbaa !397
  %arrayidx24 = getelementptr inbounds [4 x double]* %matrix2, i64 0, i64 1, !dbg !407
  %8 = load double* %arrayidx24, align 8, !dbg !407, !tbaa !397
  %mul25 = fmul double %0, %8, !dbg !407
  %arrayidx27 = getelementptr inbounds [4 x double]* %matrix2, i64 1, i64 1, !dbg !407
  %9 = load double* %arrayidx27, align 8, !dbg !407, !tbaa !397
  %mul28 = fmul double %1, %9, !dbg !407
  %add29 = fadd double %mul25, %mul28, !dbg !407
  %arrayidx31 = getelementptr inbounds [4 x double]* %matrix2, i64 2, i64 1, !dbg !407
  %10 = load double* %arrayidx31, align 8, !dbg !407, !tbaa !397
  %mul32 = fmul double %2, %10, !dbg !407
  %add33 = fadd double %add29, %mul32, !dbg !407
  %arrayidx35 = getelementptr inbounds [4 x double]* %matrix2, i64 3, i64 1, !dbg !407
  %11 = load double* %arrayidx35, align 8, !dbg !407, !tbaa !397
  %mul36 = fmul double %3, %11, !dbg !407
  %add37 = fadd double %add33, %mul36, !dbg !407
  store double %add37, double* %arrayidx3, align 8, !dbg !407, !tbaa !397
  %arrayidx41 = getelementptr inbounds [4 x double]* %matrix2, i64 0, i64 2, !dbg !408
  %12 = load double* %arrayidx41, align 8, !dbg !408, !tbaa !397
  %mul42 = fmul double %0, %12, !dbg !408
  %arrayidx44 = getelementptr inbounds [4 x double]* %matrix2, i64 1, i64 2, !dbg !408
  %13 = load double* %arrayidx44, align 8, !dbg !408, !tbaa !397
  %mul45 = fmul double %1, %13, !dbg !408
  %add46 = fadd double %mul42, %mul45, !dbg !408
  %arrayidx48 = getelementptr inbounds [4 x double]* %matrix2, i64 2, i64 2, !dbg !408
  %14 = load double* %arrayidx48, align 8, !dbg !408, !tbaa !397
  %mul49 = fmul double %2, %14, !dbg !408
  %add50 = fadd double %add46, %mul49, !dbg !408
  %arrayidx52 = getelementptr inbounds [4 x double]* %matrix2, i64 3, i64 2, !dbg !408
  %15 = load double* %arrayidx52, align 8, !dbg !408, !tbaa !397
  %mul53 = fmul double %3, %15, !dbg !408
  %add54 = fadd double %add50, %mul53, !dbg !408
  store double %add54, double* %arrayidx5, align 8, !dbg !408, !tbaa !397
  %arrayidx58 = getelementptr inbounds [4 x double]* %matrix2, i64 0, i64 3, !dbg !409
  %16 = load double* %arrayidx58, align 8, !dbg !409, !tbaa !397
  %mul59 = fmul double %0, %16, !dbg !409
  %arrayidx61 = getelementptr inbounds [4 x double]* %matrix2, i64 1, i64 3, !dbg !409
  %17 = load double* %arrayidx61, align 8, !dbg !409, !tbaa !397
  %mul62 = fmul double %1, %17, !dbg !409
  %add63 = fadd double %mul59, %mul62, !dbg !409
  %arrayidx65 = getelementptr inbounds [4 x double]* %matrix2, i64 2, i64 3, !dbg !409
  %18 = load double* %arrayidx65, align 8, !dbg !409, !tbaa !397
  %mul66 = fmul double %2, %18, !dbg !409
  %add67 = fadd double %add63, %mul66, !dbg !409
  %arrayidx69 = getelementptr inbounds [4 x double]* %matrix2, i64 3, i64 3, !dbg !409
  %19 = load double* %arrayidx69, align 8, !dbg !409, !tbaa !397
  %mul70 = fmul double %3, %19, !dbg !409
  %add71 = fadd double %add67, %mul70, !dbg !409
  store double %add71, double* %arrayidx7, align 8, !dbg !409, !tbaa !397
  %arrayidx75 = getelementptr inbounds [4 x double]* %result, i64 1, i64 0, !dbg !410
  %20 = load double* %arrayidx75, align 8, !dbg !410, !tbaa !397
  tail call void @llvm.dbg.value(metadata !{double %20}, i64 0, metadata !39), !dbg !410
  %arrayidx77 = getelementptr inbounds [4 x double]* %result, i64 1, i64 1, !dbg !411
  %21 = load double* %arrayidx77, align 8, !dbg !411, !tbaa !397
  tail call void @llvm.dbg.value(metadata !{double %21}, i64 0, metadata !40), !dbg !411
  %arrayidx79 = getelementptr inbounds [4 x double]* %result, i64 1, i64 2, !dbg !412
  %22 = load double* %arrayidx79, align 8, !dbg !412, !tbaa !397
  tail call void @llvm.dbg.value(metadata !{double %22}, i64 0, metadata !41), !dbg !412
  %arrayidx81 = getelementptr inbounds [4 x double]* %result, i64 1, i64 3, !dbg !413
  %23 = load double* %arrayidx81, align 8, !dbg !413, !tbaa !397
  tail call void @llvm.dbg.value(metadata !{double %23}, i64 0, metadata !42), !dbg !413
  %24 = load double* %arrayidx9, align 8, !dbg !414, !tbaa !397
  %mul84 = fmul double %20, %24, !dbg !414
  %25 = load double* %arrayidx11, align 8, !dbg !414, !tbaa !397
  %mul87 = fmul double %21, %25, !dbg !414
  %add88 = fadd double %mul84, %mul87, !dbg !414
  %26 = load double* %arrayidx14, align 8, !dbg !414, !tbaa !397
  %mul91 = fmul double %22, %26, !dbg !414
  %add92 = fadd double %add88, %mul91, !dbg !414
  %27 = load double* %arrayidx18, align 8, !dbg !414, !tbaa !397
  %mul95 = fmul double %23, %27, !dbg !414
  %add96 = fadd double %add92, %mul95, !dbg !414
  store double %add96, double* %arrayidx75, align 8, !dbg !414, !tbaa !397
  %28 = load double* %arrayidx24, align 8, !dbg !415, !tbaa !397
  %mul101 = fmul double %20, %28, !dbg !415
  %29 = load double* %arrayidx27, align 8, !dbg !415, !tbaa !397
  %mul104 = fmul double %21, %29, !dbg !415
  %add105 = fadd double %mul101, %mul104, !dbg !415
  %30 = load double* %arrayidx31, align 8, !dbg !415, !tbaa !397
  %mul108 = fmul double %22, %30, !dbg !415
  %add109 = fadd double %add105, %mul108, !dbg !415
  %31 = load double* %arrayidx35, align 8, !dbg !415, !tbaa !397
  %mul112 = fmul double %23, %31, !dbg !415
  %add113 = fadd double %add109, %mul112, !dbg !415
  store double %add113, double* %arrayidx77, align 8, !dbg !415, !tbaa !397
  %32 = load double* %arrayidx41, align 8, !dbg !416, !tbaa !397
  %mul118 = fmul double %20, %32, !dbg !416
  %33 = load double* %arrayidx44, align 8, !dbg !416, !tbaa !397
  %mul121 = fmul double %21, %33, !dbg !416
  %add122 = fadd double %mul118, %mul121, !dbg !416
  %34 = load double* %arrayidx48, align 8, !dbg !416, !tbaa !397
  %mul125 = fmul double %22, %34, !dbg !416
  %add126 = fadd double %add122, %mul125, !dbg !416
  %35 = load double* %arrayidx52, align 8, !dbg !416, !tbaa !397
  %mul129 = fmul double %23, %35, !dbg !416
  %add130 = fadd double %add126, %mul129, !dbg !416
  store double %add130, double* %arrayidx79, align 8, !dbg !416, !tbaa !397
  %36 = load double* %arrayidx58, align 8, !dbg !417, !tbaa !397
  %mul135 = fmul double %20, %36, !dbg !417
  %37 = load double* %arrayidx61, align 8, !dbg !417, !tbaa !397
  %mul138 = fmul double %21, %37, !dbg !417
  %add139 = fadd double %mul135, %mul138, !dbg !417
  %38 = load double* %arrayidx65, align 8, !dbg !417, !tbaa !397
  %mul142 = fmul double %22, %38, !dbg !417
  %add143 = fadd double %add139, %mul142, !dbg !417
  %39 = load double* %arrayidx69, align 8, !dbg !417, !tbaa !397
  %mul146 = fmul double %23, %39, !dbg !417
  %add147 = fadd double %add143, %mul146, !dbg !417
  store double %add147, double* %arrayidx81, align 8, !dbg !417, !tbaa !397
  %arrayidx151 = getelementptr inbounds [4 x double]* %result, i64 2, i64 0, !dbg !418
  %40 = load double* %arrayidx151, align 8, !dbg !418, !tbaa !397
  tail call void @llvm.dbg.value(metadata !{double %40}, i64 0, metadata !39), !dbg !418
  %arrayidx153 = getelementptr inbounds [4 x double]* %result, i64 2, i64 1, !dbg !419
  %41 = load double* %arrayidx153, align 8, !dbg !419, !tbaa !397
  tail call void @llvm.dbg.value(metadata !{double %41}, i64 0, metadata !40), !dbg !419
  %arrayidx155 = getelementptr inbounds [4 x double]* %result, i64 2, i64 2, !dbg !420
  %42 = load double* %arrayidx155, align 8, !dbg !420, !tbaa !397
  tail call void @llvm.dbg.value(metadata !{double %42}, i64 0, metadata !41), !dbg !420
  %arrayidx157 = getelementptr inbounds [4 x double]* %result, i64 2, i64 3, !dbg !421
  %43 = load double* %arrayidx157, align 8, !dbg !421, !tbaa !397
  tail call void @llvm.dbg.value(metadata !{double %43}, i64 0, metadata !42), !dbg !421
  %44 = load double* %arrayidx9, align 8, !dbg !422, !tbaa !397
  %mul160 = fmul double %40, %44, !dbg !422
  %45 = load double* %arrayidx11, align 8, !dbg !422, !tbaa !397
  %mul163 = fmul double %41, %45, !dbg !422
  %add164 = fadd double %mul160, %mul163, !dbg !422
  %46 = load double* %arrayidx14, align 8, !dbg !422, !tbaa !397
  %mul167 = fmul double %42, %46, !dbg !422
  %add168 = fadd double %add164, %mul167, !dbg !422
  %47 = load double* %arrayidx18, align 8, !dbg !422, !tbaa !397
  %mul171 = fmul double %43, %47, !dbg !422
  %add172 = fadd double %add168, %mul171, !dbg !422
  store double %add172, double* %arrayidx151, align 8, !dbg !422, !tbaa !397
  %48 = load double* %arrayidx24, align 8, !dbg !423, !tbaa !397
  %mul177 = fmul double %40, %48, !dbg !423
  %49 = load double* %arrayidx27, align 8, !dbg !423, !tbaa !397
  %mul180 = fmul double %41, %49, !dbg !423
  %add181 = fadd double %mul177, %mul180, !dbg !423
  %50 = load double* %arrayidx31, align 8, !dbg !423, !tbaa !397
  %mul184 = fmul double %42, %50, !dbg !423
  %add185 = fadd double %add181, %mul184, !dbg !423
  %51 = load double* %arrayidx35, align 8, !dbg !423, !tbaa !397
  %mul188 = fmul double %43, %51, !dbg !423
  %add189 = fadd double %add185, %mul188, !dbg !423
  store double %add189, double* %arrayidx153, align 8, !dbg !423, !tbaa !397
  %52 = load double* %arrayidx41, align 8, !dbg !424, !tbaa !397
  %mul194 = fmul double %40, %52, !dbg !424
  %53 = load double* %arrayidx44, align 8, !dbg !424, !tbaa !397
  %mul197 = fmul double %41, %53, !dbg !424
  %add198 = fadd double %mul194, %mul197, !dbg !424
  %54 = load double* %arrayidx48, align 8, !dbg !424, !tbaa !397
  %mul201 = fmul double %42, %54, !dbg !424
  %add202 = fadd double %add198, %mul201, !dbg !424
  %55 = load double* %arrayidx52, align 8, !dbg !424, !tbaa !397
  %mul205 = fmul double %43, %55, !dbg !424
  %add206 = fadd double %add202, %mul205, !dbg !424
  store double %add206, double* %arrayidx155, align 8, !dbg !424, !tbaa !397
  %56 = load double* %arrayidx58, align 8, !dbg !425, !tbaa !397
  %mul211 = fmul double %40, %56, !dbg !425
  %57 = load double* %arrayidx61, align 8, !dbg !425, !tbaa !397
  %mul214 = fmul double %41, %57, !dbg !425
  %add215 = fadd double %mul211, %mul214, !dbg !425
  %58 = load double* %arrayidx65, align 8, !dbg !425, !tbaa !397
  %mul218 = fmul double %42, %58, !dbg !425
  %add219 = fadd double %add215, %mul218, !dbg !425
  %59 = load double* %arrayidx69, align 8, !dbg !425, !tbaa !397
  %mul222 = fmul double %43, %59, !dbg !425
  %add223 = fadd double %add219, %mul222, !dbg !425
  store double %add223, double* %arrayidx157, align 8, !dbg !425, !tbaa !397
  %arrayidx227 = getelementptr inbounds [4 x double]* %result, i64 3, i64 0, !dbg !426
  %60 = load double* %arrayidx227, align 8, !dbg !426, !tbaa !397
  tail call void @llvm.dbg.value(metadata !{double %60}, i64 0, metadata !39), !dbg !426
  %arrayidx229 = getelementptr inbounds [4 x double]* %result, i64 3, i64 1, !dbg !427
  %61 = load double* %arrayidx229, align 8, !dbg !427, !tbaa !397
  tail call void @llvm.dbg.value(metadata !{double %61}, i64 0, metadata !40), !dbg !427
  %arrayidx231 = getelementptr inbounds [4 x double]* %result, i64 3, i64 2, !dbg !428
  %62 = load double* %arrayidx231, align 8, !dbg !428, !tbaa !397
  tail call void @llvm.dbg.value(metadata !{double %62}, i64 0, metadata !41), !dbg !428
  %arrayidx233 = getelementptr inbounds [4 x double]* %result, i64 3, i64 3, !dbg !429
  %63 = load double* %arrayidx233, align 8, !dbg !429, !tbaa !397
  tail call void @llvm.dbg.value(metadata !{double %63}, i64 0, metadata !42), !dbg !429
  %64 = load double* %arrayidx9, align 8, !dbg !430, !tbaa !397
  %mul236 = fmul double %60, %64, !dbg !430
  %65 = load double* %arrayidx11, align 8, !dbg !430, !tbaa !397
  %mul239 = fmul double %61, %65, !dbg !430
  %add240 = fadd double %mul236, %mul239, !dbg !430
  %66 = load double* %arrayidx14, align 8, !dbg !430, !tbaa !397
  %mul243 = fmul double %62, %66, !dbg !430
  %add244 = fadd double %add240, %mul243, !dbg !430
  %67 = load double* %arrayidx18, align 8, !dbg !430, !tbaa !397
  %mul247 = fmul double %63, %67, !dbg !430
  %add248 = fadd double %add244, %mul247, !dbg !430
  store double %add248, double* %arrayidx227, align 8, !dbg !430, !tbaa !397
  %68 = load double* %arrayidx24, align 8, !dbg !431, !tbaa !397
  %mul253 = fmul double %60, %68, !dbg !431
  %69 = load double* %arrayidx27, align 8, !dbg !431, !tbaa !397
  %mul256 = fmul double %61, %69, !dbg !431
  %add257 = fadd double %mul253, %mul256, !dbg !431
  %70 = load double* %arrayidx31, align 8, !dbg !431, !tbaa !397
  %mul260 = fmul double %62, %70, !dbg !431
  %add261 = fadd double %add257, %mul260, !dbg !431
  %71 = load double* %arrayidx35, align 8, !dbg !431, !tbaa !397
  %mul264 = fmul double %63, %71, !dbg !431
  %add265 = fadd double %add261, %mul264, !dbg !431
  store double %add265, double* %arrayidx229, align 8, !dbg !431, !tbaa !397
  %72 = load double* %arrayidx41, align 8, !dbg !432, !tbaa !397
  %mul270 = fmul double %60, %72, !dbg !432
  %73 = load double* %arrayidx44, align 8, !dbg !432, !tbaa !397
  %mul273 = fmul double %61, %73, !dbg !432
  %add274 = fadd double %mul270, %mul273, !dbg !432
  %74 = load double* %arrayidx48, align 8, !dbg !432, !tbaa !397
  %mul277 = fmul double %62, %74, !dbg !432
  %add278 = fadd double %add274, %mul277, !dbg !432
  %75 = load double* %arrayidx52, align 8, !dbg !432, !tbaa !397
  %mul281 = fmul double %63, %75, !dbg !432
  %add282 = fadd double %add278, %mul281, !dbg !432
  store double %add282, double* %arrayidx231, align 8, !dbg !432, !tbaa !397
  %76 = load double* %arrayidx58, align 8, !dbg !433, !tbaa !397
  %mul287 = fmul double %60, %76, !dbg !433
  %77 = load double* %arrayidx61, align 8, !dbg !433, !tbaa !397
  %mul290 = fmul double %61, %77, !dbg !433
  %add291 = fadd double %mul287, %mul290, !dbg !433
  %78 = load double* %arrayidx65, align 8, !dbg !433, !tbaa !397
  %mul294 = fmul double %62, %78, !dbg !433
  %add295 = fadd double %add291, %mul294, !dbg !433
  %79 = load double* %arrayidx69, align 8, !dbg !433, !tbaa !397
  %mul298 = fmul double %63, %79, !dbg !433
  %add299 = fadd double %add295, %mul298, !dbg !433
  store double %add299, double* %arrayidx233, align 8, !dbg !433, !tbaa !397
  ret void, !dbg !434
}
