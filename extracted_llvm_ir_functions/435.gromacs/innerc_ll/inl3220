define void @inl3220(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab) #0 {
entry:
  %0 = load i32* %iinr, align 4, !tbaa !0
  %idxprom = sext i32 %0 to i64
  %arrayidx1 = getelementptr inbounds float* %charge, i64 %idxprom
  %1 = load float* %arrayidx1, align 4, !tbaa !3
  %add = add nsw i32 %0, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds float* %charge, i64 %idxprom2
  %2 = load float* %arrayidx3, align 4, !tbaa !3
  %mul = fmul float %1, %facel
  %mul4 = fmul float %2, %facel
  %arrayidx7 = getelementptr inbounds i32* %type, i64 %idxprom
  %3 = load i32* %arrayidx7, align 4, !tbaa !0
  %mul8 = mul i32 %3, %ntype
  %cmp710 = icmp sgt i32 %nri, 0
  br i1 %cmp710, label %for.body, label %for.end389

for.body:                                         ; preds = %entry, %for.end.for.body_crit_edge
  %4 = phi i32 [ %.pre, %for.end.for.body_crit_edge ], [ %0, %entry ]
  %indvars.iv712 = phi i64 [ %indvars.iv.next713, %for.end.for.body_crit_edge ], [ 0, %entry ]
  %arrayidx10 = getelementptr inbounds i32* %shift, i64 %indvars.iv712
  %5 = load i32* %arrayidx10, align 4, !tbaa !0
  %mul11 = mul nsw i32 %5, 3
  %idxprom12 = sext i32 %mul11 to i64
  %arrayidx13 = getelementptr inbounds float* %shiftvec, i64 %idxprom12
  %6 = load float* %arrayidx13, align 4, !tbaa !3
  %add14 = add nsw i32 %mul11, 1
  %idxprom15 = sext i32 %add14 to i64
  %arrayidx16 = getelementptr inbounds float* %shiftvec, i64 %idxprom15
  %7 = load float* %arrayidx16, align 4, !tbaa !3
  %add17 = add nsw i32 %mul11, 2
  %idxprom18 = sext i32 %add17 to i64
  %arrayidx19 = getelementptr inbounds float* %shiftvec, i64 %idxprom18
  %8 = load float* %arrayidx19, align 4, !tbaa !3
  %mul22 = mul nsw i32 %4, 3
  %arrayidx24 = getelementptr inbounds i32* %jindex, i64 %indvars.iv712
  %9 = load i32* %arrayidx24, align 4, !tbaa !0
  %indvars.iv.next713 = add i64 %indvars.iv712, 1
  %arrayidx27 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next713
  %10 = load i32* %arrayidx27, align 4, !tbaa !0
  %idxprom28 = sext i32 %mul22 to i64
  %arrayidx29 = getelementptr inbounds float* %pos, i64 %idxprom28
  %11 = load float* %arrayidx29, align 4, !tbaa !3
  %add30 = fadd float %6, %11
  %add31 = add nsw i32 %mul22, 1
  %idxprom32 = sext i32 %add31 to i64
  %arrayidx33 = getelementptr inbounds float* %pos, i64 %idxprom32
  %12 = load float* %arrayidx33, align 4, !tbaa !3
  %add34 = fadd float %7, %12
  %add35 = add nsw i32 %mul22, 2
  %idxprom36 = sext i32 %add35 to i64
  %arrayidx37 = getelementptr inbounds float* %pos, i64 %idxprom36
  %13 = load float* %arrayidx37, align 4, !tbaa !3
  %add38 = fadd float %8, %13
  %add39 = add nsw i32 %mul22, 3
  %idxprom40 = sext i32 %add39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %14 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = fadd float %6, %14
  %add43 = add nsw i32 %mul22, 4
  %idxprom44 = sext i32 %add43 to i64
  %arrayidx45 = getelementptr inbounds float* %pos, i64 %idxprom44
  %15 = load float* %arrayidx45, align 4, !tbaa !3
  %add46 = fadd float %7, %15
  %add47 = add nsw i32 %mul22, 5
  %idxprom48 = sext i32 %add47 to i64
  %arrayidx49 = getelementptr inbounds float* %pos, i64 %idxprom48
  %16 = load float* %arrayidx49, align 4, !tbaa !3
  %add50 = fadd float %8, %16
  %add51 = add nsw i32 %mul22, 6
  %idxprom52 = sext i32 %add51 to i64
  %arrayidx53 = getelementptr inbounds float* %pos, i64 %idxprom52
  %17 = load float* %arrayidx53, align 4, !tbaa !3
  %add54 = fadd float %6, %17
  %add55 = add nsw i32 %mul22, 7
  %idxprom56 = sext i32 %add55 to i64
  %arrayidx57 = getelementptr inbounds float* %pos, i64 %idxprom56
  %18 = load float* %arrayidx57, align 4, !tbaa !3
  %add58 = fadd float %7, %18
  %add59 = add nsw i32 %mul22, 8
  %idxprom60 = sext i32 %add59 to i64
  %arrayidx61 = getelementptr inbounds float* %pos, i64 %idxprom60
  %19 = load float* %arrayidx61, align 4, !tbaa !3
  %add62 = fadd float %8, %19
  %cmp64687 = icmp slt i32 %9, %10
  br i1 %cmp64687, label %for.body65.lr.ph, label %for.end

for.body65.lr.ph:                                 ; preds = %for.body
  %20 = sext i32 %9 to i64
  br label %for.body65

for.body65:                                       ; preds = %for.body65.lr.ph, %for.body65
  %indvars.iv = phi i64 [ %20, %for.body65.lr.ph ], [ %indvars.iv.next, %for.body65 ]
  %vctot.0698 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add271, %for.body65 ]
  %vnbtot.0697 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %sub134, %for.body65 ]
  %fix1.0696 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add177, %for.body65 ]
  %fiy1.0695 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add178, %for.body65 ]
  %fiz1.0694 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add179, %for.body65 ]
  %fix2.0693 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add230, %for.body65 ]
  %fiy2.0692 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add231, %for.body65 ]
  %fiz2.0691 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add232, %for.body65 ]
  %fix3.0690 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add275, %for.body65 ]
  %fiy3.0689 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add276, %for.body65 ]
  %fiz3.0688 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add277, %for.body65 ]
  %arrayidx67 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %21 = load i32* %arrayidx67, align 4, !tbaa !0
  %mul68 = mul nsw i32 %21, 3
  %idxprom69 = sext i32 %mul68 to i64
  %arrayidx70 = getelementptr inbounds float* %pos, i64 %idxprom69
  %22 = load float* %arrayidx70, align 4, !tbaa !3
  %add71 = add nsw i32 %mul68, 1
  %idxprom72 = sext i32 %add71 to i64
  %arrayidx73 = getelementptr inbounds float* %pos, i64 %idxprom72
  %23 = load float* %arrayidx73, align 4, !tbaa !3
  %add74 = add nsw i32 %mul68, 2
  %idxprom75 = sext i32 %add74 to i64
  %arrayidx76 = getelementptr inbounds float* %pos, i64 %idxprom75
  %24 = load float* %arrayidx76, align 4, !tbaa !3
  %sub = fsub float %add30, %22
  %sub77 = fsub float %add34, %23
  %sub78 = fsub float %add38, %24
  %mul79 = fmul float %sub, %sub
  %mul80 = fmul float %sub77, %sub77
  %add81 = fadd float %mul79, %mul80
  %mul82 = fmul float %sub78, %sub78
  %add83 = fadd float %add81, %mul82
  %sub84 = fsub float %add42, %22
  %sub85 = fsub float %add46, %23
  %sub86 = fsub float %add50, %24
  %mul87 = fmul float %sub84, %sub84
  %mul88 = fmul float %sub85, %sub85
  %add89 = fadd float %mul87, %mul88
  %mul90 = fmul float %sub86, %sub86
  %add91 = fadd float %add89, %mul90
  %sub92 = fsub float %add54, %22
  %sub93 = fsub float %add58, %23
  %sub94 = fsub float %add62, %24
  %mul95 = fmul float %sub92, %sub92
  %mul96 = fmul float %sub93, %sub93
  %add97 = fadd float %mul95, %mul96
  %mul98 = fmul float %sub94, %sub94
  %add99 = fadd float %add97, %mul98
  %conv = fpext float %add83 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv100 = fptrunc double %div to float
  %conv101 = fpext float %add91 to double
  %call102 = tail call double @sqrt(double %conv101) #2
  %div103 = fdiv double 1.000000e+00, %call102
  %conv104 = fptrunc double %div103 to float
  %conv105 = fpext float %add99 to double
  %call106 = tail call double @sqrt(double %conv105) #2
  %div107 = fdiv double 1.000000e+00, %call106
  %conv108 = fptrunc double %div107 to float
  %mul109 = fmul float %add83, %conv100
  %mul110 = fmul float %conv100, %conv100
  %mul111 = fmul float %mul110, %mul110
  %mul112 = fmul float %mul110, %mul111
  %idxprom113 = sext i32 %21 to i64
  %arrayidx114 = getelementptr inbounds i32* %type, i64 %idxprom113
  %25 = load i32* %arrayidx114, align 4, !tbaa !0
  %tmp = add i32 %25, %mul8
  %tmp686 = mul i32 %tmp, 3
  %idxprom117 = sext i32 %tmp686 to i64
  %arrayidx118 = getelementptr inbounds float* %nbfp, i64 %idxprom117
  %26 = load float* %arrayidx118, align 4, !tbaa !3
  %mul119 = fmul float %mul112, %26
  %add120 = add nsw i32 %tmp686, 2
  %idxprom121 = sext i32 %add120 to i64
  %arrayidx122 = getelementptr inbounds float* %nbfp, i64 %idxprom121
  %27 = load float* %arrayidx122, align 4, !tbaa !3
  %mul123 = fmul float %mul109, %27
  %sub124 = fsub float -0.000000e+00, %mul123
  %conv125 = fpext float %sub124 to double
  %call126 = tail call double @exp(double %conv125) #2
  %add127 = add nsw i32 %tmp686, 1
  %idxprom128 = sext i32 %add127 to i64
  %arrayidx129 = getelementptr inbounds float* %nbfp, i64 %idxprom128
  %28 = load float* %arrayidx129, align 4, !tbaa !3
  %conv130 = fpext float %28 to double
  %mul131 = fmul double %call126, %conv130
  %conv132 = fptrunc double %mul131 to float
  %add133 = fadd float %vnbtot.0697, %conv132
  %sub134 = fsub float %add133, %mul119
  %mul135 = fmul float %mul109, %tabscale
  %conv136 = fptosi float %mul135 to i32
  %conv137 = sitofp i32 %conv136 to float
  %sub138 = fsub float %mul135, %conv137
  %mul139 = fmul float %sub138, %sub138
  %mul140 = shl nsw i32 %conv136, 2
  %arrayidx142 = getelementptr inbounds float* %charge, i64 %idxprom113
  %29 = load float* %arrayidx142, align 4, !tbaa !3
  %mul143 = fmul float %mul, %29
  %idxprom144 = sext i32 %mul140 to i64
  %arrayidx145 = getelementptr inbounds float* %VFtab, i64 %idxprom144
  %30 = load float* %arrayidx145, align 4, !tbaa !3
  %add146677 = or i32 %mul140, 1
  %idxprom147 = sext i32 %add146677 to i64
  %arrayidx148 = getelementptr inbounds float* %VFtab, i64 %idxprom147
  %31 = load float* %arrayidx148, align 4, !tbaa !3
  %add149678 = or i32 %mul140, 2
  %idxprom150 = sext i32 %add149678 to i64
  %arrayidx151 = getelementptr inbounds float* %VFtab, i64 %idxprom150
  %32 = load float* %arrayidx151, align 4, !tbaa !3
  %mul152 = fmul float %sub138, %32
  %add153679 = or i32 %mul140, 3
  %idxprom154 = sext i32 %add153679 to i64
  %arrayidx155 = getelementptr inbounds float* %VFtab, i64 %idxprom154
  %33 = load float* %arrayidx155, align 4, !tbaa !3
  %mul156 = fmul float %mul139, %33
  %add157 = fadd float %31, %mul152
  %add158 = fadd float %add157, %mul156
  %mul159 = fmul float %sub138, %add158
  %add160 = fadd float %30, %mul159
  %add161 = fadd float %mul152, %add158
  %mul162 = fmul float %mul156, 2.000000e+00
  %add163 = fadd float %mul162, %add161
  %mul164 = fmul float %mul143, %add160
  %mul165 = fmul float %mul143, %add163
  %mul166 = fmul float %mul123, %conv132
  %mul167 = fmul float %mul119, 6.000000e+00
  %sub168 = fsub float %mul166, %mul167
  %mul169 = fmul float %conv100, %sub168
  %mul170 = fmul float %mul165, %tabscale
  %sub171 = fsub float %mul169, %mul170
  %mul172 = fmul float %conv100, %sub171
  %add173 = fadd float %vctot.0698, %mul164
  %mul174 = fmul float %sub, %mul172
  %mul175 = fmul float %sub77, %mul172
  %mul176 = fmul float %sub78, %mul172
  %add177 = fadd float %fix1.0696, %mul174
  %add178 = fadd float %fiy1.0695, %mul175
  %add179 = fadd float %fiz1.0694, %mul176
  %arrayidx181 = getelementptr inbounds float* %faction, i64 %idxprom69
  %34 = load float* %arrayidx181, align 4, !tbaa !3
  %sub182 = fsub float %34, %mul174
  %arrayidx185 = getelementptr inbounds float* %faction, i64 %idxprom72
  %35 = load float* %arrayidx185, align 4, !tbaa !3
  %sub186 = fsub float %35, %mul175
  %arrayidx189 = getelementptr inbounds float* %faction, i64 %idxprom75
  %36 = load float* %arrayidx189, align 4, !tbaa !3
  %sub190 = fsub float %36, %mul176
  %mul191 = fmul float %add91, %conv104
  %mul192 = fmul float %mul191, %tabscale
  %conv193 = fptosi float %mul192 to i32
  %conv194 = sitofp i32 %conv193 to float
  %sub195 = fsub float %mul192, %conv194
  %mul196 = fmul float %sub195, %sub195
  %mul197 = shl nsw i32 %conv193, 2
  %mul200 = fmul float %mul4, %29
  %idxprom201 = sext i32 %mul197 to i64
  %arrayidx202 = getelementptr inbounds float* %VFtab, i64 %idxprom201
  %37 = load float* %arrayidx202, align 4, !tbaa !3
  %add203680 = or i32 %mul197, 1
  %idxprom204 = sext i32 %add203680 to i64
  %arrayidx205 = getelementptr inbounds float* %VFtab, i64 %idxprom204
  %38 = load float* %arrayidx205, align 4, !tbaa !3
  %add206681 = or i32 %mul197, 2
  %idxprom207 = sext i32 %add206681 to i64
  %arrayidx208 = getelementptr inbounds float* %VFtab, i64 %idxprom207
  %39 = load float* %arrayidx208, align 4, !tbaa !3
  %mul209 = fmul float %sub195, %39
  %add210682 = or i32 %mul197, 3
  %idxprom211 = sext i32 %add210682 to i64
  %arrayidx212 = getelementptr inbounds float* %VFtab, i64 %idxprom211
  %40 = load float* %arrayidx212, align 4, !tbaa !3
  %mul213 = fmul float %mul196, %40
  %add214 = fadd float %38, %mul209
  %add215 = fadd float %add214, %mul213
  %mul216 = fmul float %sub195, %add215
  %add217 = fadd float %37, %mul216
  %add218 = fadd float %mul209, %add215
  %mul219 = fmul float %mul213, 2.000000e+00
  %add220 = fadd float %mul219, %add218
  %mul221 = fmul float %mul200, %add217
  %mul222 = fmul float %mul200, %add220
  %mul223 = fmul float %mul222, %tabscale
  %41 = fmul float %conv104, %mul223
  %mul225 = fsub float -0.000000e+00, %41
  %add226 = fadd float %add173, %mul221
  %mul227 = fmul float %sub84, %mul225
  %mul228 = fmul float %sub85, %mul225
  %mul229 = fmul float %sub86, %mul225
  %add230 = fadd float %fix2.0693, %mul227
  %add231 = fadd float %fiy2.0692, %mul228
  %add232 = fadd float %fiz2.0691, %mul229
  %sub233 = fsub float %sub182, %mul227
  %sub234 = fsub float %sub186, %mul228
  %sub235 = fsub float %sub190, %mul229
  %mul236 = fmul float %add99, %conv108
  %mul237 = fmul float %mul236, %tabscale
  %conv238 = fptosi float %mul237 to i32
  %conv239 = sitofp i32 %conv238 to float
  %sub240 = fsub float %mul237, %conv239
  %mul241 = fmul float %sub240, %sub240
  %mul242 = shl nsw i32 %conv238, 2
  %idxprom246 = sext i32 %mul242 to i64
  %arrayidx247 = getelementptr inbounds float* %VFtab, i64 %idxprom246
  %42 = load float* %arrayidx247, align 4, !tbaa !3
  %add248683 = or i32 %mul242, 1
  %idxprom249 = sext i32 %add248683 to i64
  %arrayidx250 = getelementptr inbounds float* %VFtab, i64 %idxprom249
  %43 = load float* %arrayidx250, align 4, !tbaa !3
  %add251684 = or i32 %mul242, 2
  %idxprom252 = sext i32 %add251684 to i64
  %arrayidx253 = getelementptr inbounds float* %VFtab, i64 %idxprom252
  %44 = load float* %arrayidx253, align 4, !tbaa !3
  %mul254 = fmul float %sub240, %44
  %add255685 = or i32 %mul242, 3
  %idxprom256 = sext i32 %add255685 to i64
  %arrayidx257 = getelementptr inbounds float* %VFtab, i64 %idxprom256
  %45 = load float* %arrayidx257, align 4, !tbaa !3
  %mul258 = fmul float %mul241, %45
  %add259 = fadd float %43, %mul254
  %add260 = fadd float %add259, %mul258
  %mul261 = fmul float %sub240, %add260
  %add262 = fadd float %42, %mul261
  %add263 = fadd float %mul254, %add260
  %mul264 = fmul float %mul258, 2.000000e+00
  %add265 = fadd float %mul264, %add263
  %mul266 = fmul float %mul200, %add262
  %mul267 = fmul float %mul200, %add265
  %mul268 = fmul float %mul267, %tabscale
  %46 = fmul float %conv108, %mul268
  %mul270 = fsub float -0.000000e+00, %46
  %add271 = fadd float %add226, %mul266
  %mul272 = fmul float %sub92, %mul270
  %mul273 = fmul float %sub93, %mul270
  %mul274 = fmul float %sub94, %mul270
  %add275 = fadd float %fix3.0690, %mul272
  %add276 = fadd float %fiy3.0689, %mul273
  %add277 = fadd float %fiz3.0688, %mul274
  %sub278 = fsub float %sub233, %mul272
  store float %sub278, float* %arrayidx181, align 4, !tbaa !3
  %sub281 = fsub float %sub234, %mul273
  store float %sub281, float* %arrayidx185, align 4, !tbaa !3
  %sub285 = fsub float %sub235, %mul274
  store float %sub285, float* %arrayidx189, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %47 = trunc i64 %indvars.iv.next to i32
  %cmp64 = icmp slt i32 %47, %10
  br i1 %cmp64, label %for.body65, label %for.end

for.end:                                          ; preds = %for.body65, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add271, %for.body65 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %sub134, %for.body65 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add177, %for.body65 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add178, %for.body65 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add179, %for.body65 ]
  %fix2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add230, %for.body65 ]
  %fiy2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add231, %for.body65 ]
  %fiz2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add232, %for.body65 ]
  %fix3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add275, %for.body65 ]
  %fiy3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add276, %for.body65 ]
  %fiz3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add277, %for.body65 ]
  %arrayidx290 = getelementptr inbounds float* %faction, i64 %idxprom28
  %48 = load float* %arrayidx290, align 4, !tbaa !3
  %add291 = fadd float %fix1.0.lcssa, %48
  store float %add291, float* %arrayidx290, align 4, !tbaa !3
  %arrayidx296 = getelementptr inbounds float* %faction, i64 %idxprom32
  %49 = load float* %arrayidx296, align 4, !tbaa !3
  %add297 = fadd float %fiy1.0.lcssa, %49
  store float %add297, float* %arrayidx296, align 4, !tbaa !3
  %arrayidx303 = getelementptr inbounds float* %faction, i64 %idxprom36
  %50 = load float* %arrayidx303, align 4, !tbaa !3
  %add304 = fadd float %fiz1.0.lcssa, %50
  store float %add304, float* %arrayidx303, align 4, !tbaa !3
  %arrayidx310 = getelementptr inbounds float* %faction, i64 %idxprom40
  %51 = load float* %arrayidx310, align 4, !tbaa !3
  %add311 = fadd float %fix2.0.lcssa, %51
  store float %add311, float* %arrayidx310, align 4, !tbaa !3
  %arrayidx317 = getelementptr inbounds float* %faction, i64 %idxprom44
  %52 = load float* %arrayidx317, align 4, !tbaa !3
  %add318 = fadd float %fiy2.0.lcssa, %52
  store float %add318, float* %arrayidx317, align 4, !tbaa !3
  %arrayidx324 = getelementptr inbounds float* %faction, i64 %idxprom48
  %53 = load float* %arrayidx324, align 4, !tbaa !3
  %add325 = fadd float %fiz2.0.lcssa, %53
  store float %add325, float* %arrayidx324, align 4, !tbaa !3
  %arrayidx331 = getelementptr inbounds float* %faction, i64 %idxprom52
  %54 = load float* %arrayidx331, align 4, !tbaa !3
  %add332 = fadd float %fix3.0.lcssa, %54
  store float %add332, float* %arrayidx331, align 4, !tbaa !3
  %arrayidx338 = getelementptr inbounds float* %faction, i64 %idxprom56
  %55 = load float* %arrayidx338, align 4, !tbaa !3
  %add339 = fadd float %fiy3.0.lcssa, %55
  store float %add339, float* %arrayidx338, align 4, !tbaa !3
  %arrayidx345 = getelementptr inbounds float* %faction, i64 %idxprom60
  %56 = load float* %arrayidx345, align 4, !tbaa !3
  %add346 = fadd float %fiz3.0.lcssa, %56
  store float %add346, float* %arrayidx345, align 4, !tbaa !3
  %arrayidx351 = getelementptr inbounds float* %fshift, i64 %idxprom12
  %57 = load float* %arrayidx351, align 4, !tbaa !3
  %add352 = fadd float %fix1.0.lcssa, %57
  %add353 = fadd float %fix2.0.lcssa, %add352
  %add354 = fadd float %fix3.0.lcssa, %add353
  store float %add354, float* %arrayidx351, align 4, !tbaa !3
  %arrayidx359 = getelementptr inbounds float* %fshift, i64 %idxprom15
  %58 = load float* %arrayidx359, align 4, !tbaa !3
  %add360 = fadd float %fiy1.0.lcssa, %58
  %add361 = fadd float %fiy2.0.lcssa, %add360
  %add362 = fadd float %fiy3.0.lcssa, %add361
  store float %add362, float* %arrayidx359, align 4, !tbaa !3
  %arrayidx368 = getelementptr inbounds float* %fshift, i64 %idxprom18
  %59 = load float* %arrayidx368, align 4, !tbaa !3
  %add369 = fadd float %fiz1.0.lcssa, %59
  %add370 = fadd float %fiz2.0.lcssa, %add369
  %add371 = fadd float %fiz3.0.lcssa, %add370
  store float %add371, float* %arrayidx368, align 4, !tbaa !3
  %arrayidx376 = getelementptr inbounds i32* %gid, i64 %indvars.iv712
  %60 = load i32* %arrayidx376, align 4, !tbaa !0
  %idxprom377 = sext i32 %60 to i64
  %arrayidx378 = getelementptr inbounds float* %Vc, i64 %idxprom377
  %61 = load float* %arrayidx378, align 4, !tbaa !3
  %add379 = fadd float %vctot.0.lcssa, %61
  store float %add379, float* %arrayidx378, align 4, !tbaa !3
  %arrayidx383 = getelementptr inbounds float* %Vnb, i64 %idxprom377
  %62 = load float* %arrayidx383, align 4, !tbaa !3
  %add384 = fadd float %vnbtot.0.lcssa, %62
  store float %add384, float* %arrayidx383, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next713 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end389, label %for.end.for.body_crit_edge

for.end.for.body_crit_edge:                       ; preds = %for.end
  %arrayidx21.phi.trans.insert = getelementptr inbounds i32* %iinr, i64 %indvars.iv.next713
  %.pre = load i32* %arrayidx21.phi.trans.insert, align 4, !tbaa !0
  br label %for.body

for.end389:                                       ; preds = %for.end, %entry
  ret void
}
