define void @inl3402(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* %VFtab, float %exptabscale, float %lambda, float* nocapture %dvdlambda, float* nocapture %chargeB, i32* nocapture %typeB, float %Alpha, float %defsigma6) #0 {
entry:
  %sub = fsub float 1.000000e+00, %lambda
  %cmp765 = icmp sgt i32 %nri, 0
  br i1 %cmp765, label %for.body.lr.ph, label %for.end426

for.body.lr.ph:                                   ; preds = %entry
  %mul1 = fmul float %sub, %sub
  %mul = fmul float %lambda, %lambda
  %mul35 = mul nsw i32 %ntype, 3
  %mul103 = fmul float %Alpha, %defsigma6
  %mul104 = fmul float %mul, %mul103
  %mul213 = fmul float %mul1, %mul103
  %mul338 = fmul float %Alpha, 0x3FD5555560000000
  %mul339 = fmul float %mul338, %lambda
  %mul340 = fmul float %sub, %mul339
  br label %for.body

for.body:                                         ; preds = %for.end, %for.body.lr.ph
  %indvars.iv769 = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next770, %for.end ]
  %dvdl.0766 = phi float [ 0.000000e+00, %for.body.lr.ph ], [ %dvdl.1.lcssa, %for.end ]
  %arrayidx = getelementptr inbounds i32* %shift, i64 %indvars.iv769
  %0 = load i32* %arrayidx, align 4, !tbaa !0
  %mul2 = mul nsw i32 %0, 3
  %idxprom3 = sext i32 %mul2 to i64
  %arrayidx4 = getelementptr inbounds float* %shiftvec, i64 %idxprom3
  %1 = load float* %arrayidx4, align 4, !tbaa !3
  %add = add nsw i32 %mul2, 1
  %idxprom5 = sext i32 %add to i64
  %arrayidx6 = getelementptr inbounds float* %shiftvec, i64 %idxprom5
  %2 = load float* %arrayidx6, align 4, !tbaa !3
  %add7 = add nsw i32 %mul2, 2
  %idxprom8 = sext i32 %add7 to i64
  %arrayidx9 = getelementptr inbounds float* %shiftvec, i64 %idxprom8
  %3 = load float* %arrayidx9, align 4, !tbaa !3
  %arrayidx11 = getelementptr inbounds i32* %iinr, i64 %indvars.iv769
  %4 = load i32* %arrayidx11, align 4, !tbaa !0
  %mul12 = mul nsw i32 %4, 3
  %arrayidx14 = getelementptr inbounds i32* %jindex, i64 %indvars.iv769
  %5 = load i32* %arrayidx14, align 4, !tbaa !0
  %indvars.iv.next770 = add i64 %indvars.iv769, 1
  %arrayidx17 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next770
  %6 = load i32* %arrayidx17, align 4, !tbaa !0
  %idxprom18 = sext i32 %mul12 to i64
  %arrayidx19 = getelementptr inbounds float* %pos, i64 %idxprom18
  %7 = load float* %arrayidx19, align 4, !tbaa !3
  %add20 = fadd float %1, %7
  %add21 = add nsw i32 %mul12, 1
  %idxprom22 = sext i32 %add21 to i64
  %arrayidx23 = getelementptr inbounds float* %pos, i64 %idxprom22
  %8 = load float* %arrayidx23, align 4, !tbaa !3
  %add24 = fadd float %2, %8
  %add25 = add nsw i32 %mul12, 2
  %idxprom26 = sext i32 %add25 to i64
  %arrayidx27 = getelementptr inbounds float* %pos, i64 %idxprom26
  %9 = load float* %arrayidx27, align 4, !tbaa !3
  %add28 = fadd float %3, %9
  %idxprom29 = sext i32 %4 to i64
  %arrayidx30 = getelementptr inbounds float* %charge, i64 %idxprom29
  %10 = load float* %arrayidx30, align 4, !tbaa !3
  %mul31 = fmul float %10, %facel
  %arrayidx33 = getelementptr inbounds float* %chargeB, i64 %idxprom29
  %11 = load float* %arrayidx33, align 4, !tbaa !3
  %mul34 = fmul float %11, %facel
  %arrayidx37 = getelementptr inbounds i32* %type, i64 %idxprom29
  %12 = load i32* %arrayidx37, align 4, !tbaa !0
  %mul38 = mul nsw i32 %12, %mul35
  %arrayidx41 = getelementptr inbounds i32* %typeB, i64 %idxprom29
  %13 = load i32* %arrayidx41, align 4, !tbaa !0
  %mul42 = mul nsw i32 %13, %mul35
  %cmp44752 = icmp slt i32 %5, %6
  br i1 %cmp44752, label %for.body45.lr.ph, label %for.end

for.body45.lr.ph:                                 ; preds = %for.body
  %14 = sext i32 %5 to i64
  br label %for.body45

for.body45:                                       ; preds = %for.body45.lr.ph, %if.end310
  %indvars.iv = phi i64 [ %14, %for.body45.lr.ph ], [ %indvars.iv.next, %if.end310 ]
  %vctot.0758 = phi float [ 0.000000e+00, %for.body45.lr.ph ], [ %add348, %if.end310 ]
  %fiz1.0757 = phi float [ 0.000000e+00, %for.body45.lr.ph ], [ %add354, %if.end310 ]
  %fiy1.0756 = phi float [ 0.000000e+00, %for.body45.lr.ph ], [ %add353, %if.end310 ]
  %fix1.0755 = phi float [ 0.000000e+00, %for.body45.lr.ph ], [ %add352, %if.end310 ]
  %dvdl.1754 = phi float [ %dvdl.0766, %for.body45.lr.ph ], [ %add347, %if.end310 ]
  %vnbtot.0753 = phi float [ 0.000000e+00, %for.body45.lr.ph ], [ %add319, %if.end310 ]
  %arrayidx47 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %15 = load i32* %arrayidx47, align 4, !tbaa !0
  %mul48 = mul nsw i32 %15, 3
  %idxprom49 = sext i32 %mul48 to i64
  %arrayidx50 = getelementptr inbounds float* %pos, i64 %idxprom49
  %16 = load float* %arrayidx50, align 4, !tbaa !3
  %add51 = add nsw i32 %mul48, 1
  %idxprom52 = sext i32 %add51 to i64
  %arrayidx53 = getelementptr inbounds float* %pos, i64 %idxprom52
  %17 = load float* %arrayidx53, align 4, !tbaa !3
  %add54 = add nsw i32 %mul48, 2
  %idxprom55 = sext i32 %add54 to i64
  %arrayidx56 = getelementptr inbounds float* %pos, i64 %idxprom55
  %18 = load float* %arrayidx56, align 4, !tbaa !3
  %sub57 = fsub float %add20, %16
  %sub58 = fsub float %add24, %17
  %sub59 = fsub float %add28, %18
  %mul60 = fmul float %sub57, %sub57
  %mul61 = fmul float %sub58, %sub58
  %add62 = fadd float %mul60, %mul61
  %mul63 = fmul float %sub59, %sub59
  %add64 = fadd float %add62, %mul63
  %conv = fpext float %add64 to double
  %call = tail call double @sqrt(double %conv) #2
  %idxprom67 = sext i32 %15 to i64
  %arrayidx68 = getelementptr inbounds i32* %type, i64 %idxprom67
  %19 = load i32* %arrayidx68, align 4, !tbaa !0
  %mul69 = mul nsw i32 %19, 3
  %add70 = add nsw i32 %mul69, %mul38
  %arrayidx72 = getelementptr inbounds i32* %typeB, i64 %idxprom67
  %20 = load i32* %arrayidx72, align 4, !tbaa !0
  %mul73 = mul nsw i32 %20, 3
  %add74 = add nsw i32 %mul73, %mul42
  %idxprom75 = sext i32 %add70 to i64
  %arrayidx76 = getelementptr inbounds float* %nbfp, i64 %idxprom75
  %21 = load float* %arrayidx76, align 4, !tbaa !3
  %idxprom77 = sext i32 %add74 to i64
  %arrayidx78 = getelementptr inbounds float* %nbfp, i64 %idxprom77
  %22 = load float* %arrayidx78, align 4, !tbaa !3
  %add79 = add nsw i32 %add70, 1
  %idxprom80 = sext i32 %add79 to i64
  %arrayidx81 = getelementptr inbounds float* %nbfp, i64 %idxprom80
  %23 = load float* %arrayidx81, align 4, !tbaa !3
  %add82 = add nsw i32 %add74, 1
  %idxprom83 = sext i32 %add82 to i64
  %arrayidx84 = getelementptr inbounds float* %nbfp, i64 %idxprom83
  %24 = load float* %arrayidx84, align 4, !tbaa !3
  %add85 = add nsw i32 %add70, 2
  %idxprom86 = sext i32 %add85 to i64
  %arrayidx87 = getelementptr inbounds float* %nbfp, i64 %idxprom86
  %25 = load float* %arrayidx87, align 4, !tbaa !3
  %add88 = add nsw i32 %add74, 2
  %idxprom89 = sext i32 %add88 to i64
  %arrayidx90 = getelementptr inbounds float* %nbfp, i64 %idxprom89
  %26 = load float* %arrayidx90, align 4, !tbaa !3
  %mul91 = fmul float %add64, %add64
  %mul92 = fmul float %add64, %mul91
  %arrayidx94 = getelementptr inbounds float* %charge, i64 %idxprom67
  %27 = load float* %arrayidx94, align 4, !tbaa !3
  %mul95 = fmul float %mul31, %27
  %cmp96 = fcmp une float %mul95, 0.000000e+00
  %cmp98 = fcmp ogt float %21, 0.000000e+00
  %or.cond = or i1 %cmp96, %cmp98
  %cmp101 = fcmp ogt float %23, 0.000000e+00
  %or.cond749 = or i1 %or.cond, %cmp101
  br i1 %or.cond749, label %if.then, label %if.end

if.then:                                          ; preds = %for.body45
  %add105 = fadd float %mul104, %mul92
  %conv106 = fpext float %add105 to double
  %call107 = tail call double @pow(double %conv106, double 0x3FC5555560000000) #2
  %conv108 = fptrunc double %call107 to float
  %conv111 = fdiv float 1.000000e+00, %conv108
  %mul112 = fmul float %conv111, %conv111
  %mul113 = fmul float %mul112, %mul112
  %mul114 = fmul float %conv111, %mul113
  %mul115 = fmul float %conv108, %tabscale
  %conv116 = fptosi float %mul115 to i32
  %conv117 = sitofp i32 %conv116 to float
  %sub118 = fsub float %mul115, %conv117
  %mul119 = fmul float %sub118, %sub118
  %mul120 = mul nsw i32 %conv116, 12
  %idxprom121 = sext i32 %mul120 to i64
  %arrayidx122 = getelementptr inbounds float* %VFtab, i64 %idxprom121
  %28 = load float* %arrayidx122, align 4, !tbaa !3
  %add123746 = or i32 %mul120, 1
  %idxprom124 = sext i32 %add123746 to i64
  %arrayidx125 = getelementptr inbounds float* %VFtab, i64 %idxprom124
  %29 = load float* %arrayidx125, align 4, !tbaa !3
  %add126747 = or i32 %mul120, 2
  %idxprom127 = sext i32 %add126747 to i64
  %arrayidx128 = getelementptr inbounds float* %VFtab, i64 %idxprom127
  %30 = load float* %arrayidx128, align 4, !tbaa !3
  %mul129 = fmul float %30, %sub118
  %add130748 = or i32 %mul120, 3
  %idxprom131 = sext i32 %add130748 to i64
  %arrayidx132 = getelementptr inbounds float* %VFtab, i64 %idxprom131
  %31 = load float* %arrayidx132, align 4, !tbaa !3
  %mul133 = fmul float %31, %mul119
  %add134 = fadd float %29, %mul129
  %add135 = fadd float %add134, %mul133
  %mul136 = fmul float %sub118, %add135
  %add137 = fadd float %28, %mul136
  %add138 = fadd float %mul129, %add135
  %mul139 = fmul float %mul133, 2.000000e+00
  %add140 = fadd float %mul139, %add138
  %mul141 = fmul float %mul95, %add137
  %mul142 = fmul float %mul95, %tabscale
  %mul143 = fmul float %mul142, %add140
  %add144 = add nsw i32 %mul120, 4
  %idxprom145 = sext i32 %add144 to i64
  %arrayidx146 = getelementptr inbounds float* %VFtab, i64 %idxprom145
  %32 = load float* %arrayidx146, align 4, !tbaa !3
  %add147 = add nsw i32 %mul120, 5
  %idxprom148 = sext i32 %add147 to i64
  %arrayidx149 = getelementptr inbounds float* %VFtab, i64 %idxprom148
  %33 = load float* %arrayidx149, align 4, !tbaa !3
  %add150 = add nsw i32 %mul120, 6
  %idxprom151 = sext i32 %add150 to i64
  %arrayidx152 = getelementptr inbounds float* %VFtab, i64 %idxprom151
  %34 = load float* %arrayidx152, align 4, !tbaa !3
  %mul153 = fmul float %sub118, %34
  %add154 = add nsw i32 %mul120, 7
  %idxprom155 = sext i32 %add154 to i64
  %arrayidx156 = getelementptr inbounds float* %VFtab, i64 %idxprom155
  %35 = load float* %arrayidx156, align 4, !tbaa !3
  %mul157 = fmul float %mul119, %35
  %add158 = fadd float %33, %mul153
  %add159 = fadd float %add158, %mul157
  %mul160 = fmul float %sub118, %add159
  %add161 = fadd float %32, %mul160
  %add162 = fadd float %mul153, %add159
  %mul163 = fmul float %mul157, 2.000000e+00
  %add164 = fadd float %mul163, %add162
  %mul165 = fmul float %21, %add161
  %mul166 = fmul float %21, %tabscale
  %mul167 = fmul float %mul166, %add164
  %mul168 = fmul float %25, %conv108
  %mul169 = fmul float %mul168, %tabscale
  %conv170 = fptosi float %mul169 to i32
  %conv171 = sitofp i32 %conv170 to float
  %sub172 = fsub float %mul169, %conv171
  %mul173 = fmul float %sub172, %sub172
  %mul174 = mul nsw i32 %conv170, 12
  %add175 = add nsw i32 %mul174, 8
  %idxprom176 = sext i32 %add175 to i64
  %arrayidx177 = getelementptr inbounds float* %VFtab, i64 %idxprom176
  %36 = load float* %arrayidx177, align 4, !tbaa !3
  %add178 = add nsw i32 %mul174, 9
  %idxprom179 = sext i32 %add178 to i64
  %arrayidx180 = getelementptr inbounds float* %VFtab, i64 %idxprom179
  %37 = load float* %arrayidx180, align 4, !tbaa !3
  %add181 = add nsw i32 %mul174, 10
  %idxprom182 = sext i32 %add181 to i64
  %arrayidx183 = getelementptr inbounds float* %VFtab, i64 %idxprom182
  %38 = load float* %arrayidx183, align 4, !tbaa !3
  %mul184 = fmul float %sub172, %38
  %add185 = add nsw i32 %mul174, 11
  %idxprom186 = sext i32 %add185 to i64
  %arrayidx187 = getelementptr inbounds float* %VFtab, i64 %idxprom186
  %39 = load float* %arrayidx187, align 4, !tbaa !3
  %mul188 = fmul float %mul173, %39
  %add189 = fadd float %37, %mul184
  %add190 = fadd float %add189, %mul188
  %mul191 = fmul float %sub172, %add190
  %add192 = fadd float %36, %mul191
  %add193 = fadd float %mul184, %add190
  %mul194 = fmul float %mul188, 2.000000e+00
  %add195 = fadd float %mul194, %add193
  %mul196 = fmul float %23, %add192
  %mul197 = fmul float %23, %25
  %mul198 = fmul float %mul197, %exptabscale
  %mul199 = fmul float %mul198, %add195
  br label %if.end

if.end:                                           ; preds = %for.body45, %if.then
  %FFRa.0 = phi float [ %mul199, %if.then ], [ 0.000000e+00, %for.body45 ]
  %VVRa.0 = phi float [ %mul196, %if.then ], [ 0.000000e+00, %for.body45 ]
  %FFDa.0 = phi float [ %mul167, %if.then ], [ 0.000000e+00, %for.body45 ]
  %VVDa.0 = phi float [ %mul165, %if.then ], [ 0.000000e+00, %for.body45 ]
  %FFCa.0 = phi float [ %mul143, %if.then ], [ 0.000000e+00, %for.body45 ]
  %VVCa.0 = phi float [ %mul141, %if.then ], [ 0.000000e+00, %for.body45 ]
  %rinv5a.0 = phi float [ %mul114, %if.then ], [ 0.000000e+00, %for.body45 ]
  %arrayidx201 = getelementptr inbounds float* %chargeB, i64 %idxprom67
  %40 = load float* %arrayidx201, align 4, !tbaa !3
  %mul202 = fmul float %mul34, %40
  %cmp203 = fcmp une float %mul202, 0.000000e+00
  %cmp206 = fcmp ogt float %22, 0.000000e+00
  %or.cond750 = or i1 %cmp203, %cmp206
  %cmp209 = fcmp ogt float %24, 0.000000e+00
  %or.cond751 = or i1 %or.cond750, %cmp209
  br i1 %or.cond751, label %if.then211, label %if.end310

if.then211:                                       ; preds = %if.end
  %add214 = fadd float %mul213, %mul92
  %conv215 = fpext float %add214 to double
  %call216 = tail call double @pow(double %conv215, double 0x3FC5555560000000) #2
  %conv217 = fptrunc double %call216 to float
  %conv220 = fdiv float 1.000000e+00, %conv217
  %mul221 = fmul float %conv220, %conv220
  %mul222 = fmul float %mul221, %mul221
  %mul223 = fmul float %conv220, %mul222
  %mul224 = fmul float %conv217, %tabscale
  %conv225 = fptosi float %mul224 to i32
  %conv226 = sitofp i32 %conv225 to float
  %sub227 = fsub float %mul224, %conv226
  %mul228 = fmul float %sub227, %sub227
  %mul229 = mul nsw i32 %conv225, 12
  %idxprom230 = sext i32 %mul229 to i64
  %arrayidx231 = getelementptr inbounds float* %VFtab, i64 %idxprom230
  %41 = load float* %arrayidx231, align 4, !tbaa !3
  %add232743 = or i32 %mul229, 1
  %idxprom233 = sext i32 %add232743 to i64
  %arrayidx234 = getelementptr inbounds float* %VFtab, i64 %idxprom233
  %42 = load float* %arrayidx234, align 4, !tbaa !3
  %add235744 = or i32 %mul229, 2
  %idxprom236 = sext i32 %add235744 to i64
  %arrayidx237 = getelementptr inbounds float* %VFtab, i64 %idxprom236
  %43 = load float* %arrayidx237, align 4, !tbaa !3
  %mul238 = fmul float %43, %sub227
  %add239745 = or i32 %mul229, 3
  %idxprom240 = sext i32 %add239745 to i64
  %arrayidx241 = getelementptr inbounds float* %VFtab, i64 %idxprom240
  %44 = load float* %arrayidx241, align 4, !tbaa !3
  %mul242 = fmul float %44, %mul228
  %add243 = fadd float %42, %mul238
  %add244 = fadd float %add243, %mul242
  %mul245 = fmul float %sub227, %add244
  %add246 = fadd float %41, %mul245
  %add247 = fadd float %mul238, %add244
  %mul248 = fmul float %mul242, 2.000000e+00
  %add249 = fadd float %mul248, %add247
  %mul250 = fmul float %mul202, %add246
  %mul251 = fmul float %mul202, %tabscale
  %mul252 = fmul float %mul251, %add249
  %add253 = add nsw i32 %mul229, 4
  %idxprom254 = sext i32 %add253 to i64
  %arrayidx255 = getelementptr inbounds float* %VFtab, i64 %idxprom254
  %45 = load float* %arrayidx255, align 4, !tbaa !3
  %add256 = add nsw i32 %mul229, 5
  %idxprom257 = sext i32 %add256 to i64
  %arrayidx258 = getelementptr inbounds float* %VFtab, i64 %idxprom257
  %46 = load float* %arrayidx258, align 4, !tbaa !3
  %add259 = add nsw i32 %mul229, 6
  %idxprom260 = sext i32 %add259 to i64
  %arrayidx261 = getelementptr inbounds float* %VFtab, i64 %idxprom260
  %47 = load float* %arrayidx261, align 4, !tbaa !3
  %mul262 = fmul float %sub227, %47
  %add263 = add nsw i32 %mul229, 7
  %idxprom264 = sext i32 %add263 to i64
  %arrayidx265 = getelementptr inbounds float* %VFtab, i64 %idxprom264
  %48 = load float* %arrayidx265, align 4, !tbaa !3
  %mul266 = fmul float %mul228, %48
  %add267 = fadd float %46, %mul262
  %add268 = fadd float %add267, %mul266
  %mul269 = fmul float %sub227, %add268
  %add270 = fadd float %45, %mul269
  %add271 = fadd float %mul262, %add268
  %mul272 = fmul float %mul266, 2.000000e+00
  %add273 = fadd float %mul272, %add271
  %mul274 = fmul float %22, %add270
  %mul275 = fmul float %22, %tabscale
  %mul276 = fmul float %mul275, %add273
  %mul277 = fmul float %26, %conv217
  %mul278 = fmul float %mul277, %tabscale
  %conv279 = fptosi float %mul278 to i32
  %conv280 = sitofp i32 %conv279 to float
  %sub281 = fsub float %mul278, %conv280
  %mul282 = fmul float %sub281, %sub281
  %mul283 = mul nsw i32 %conv279, 12
  %add284 = add nsw i32 %mul283, 8
  %idxprom285 = sext i32 %add284 to i64
  %arrayidx286 = getelementptr inbounds float* %VFtab, i64 %idxprom285
  %49 = load float* %arrayidx286, align 4, !tbaa !3
  %add287 = add nsw i32 %mul283, 9
  %idxprom288 = sext i32 %add287 to i64
  %arrayidx289 = getelementptr inbounds float* %VFtab, i64 %idxprom288
  %50 = load float* %arrayidx289, align 4, !tbaa !3
  %add290 = add nsw i32 %mul283, 10
  %idxprom291 = sext i32 %add290 to i64
  %arrayidx292 = getelementptr inbounds float* %VFtab, i64 %idxprom291
  %51 = load float* %arrayidx292, align 4, !tbaa !3
  %mul293 = fmul float %sub281, %51
  %add294 = add nsw i32 %mul283, 11
  %idxprom295 = sext i32 %add294 to i64
  %arrayidx296 = getelementptr inbounds float* %VFtab, i64 %idxprom295
  %52 = load float* %arrayidx296, align 4, !tbaa !3
  %mul297 = fmul float %mul282, %52
  %add298 = fadd float %50, %mul293
  %add299 = fadd float %add298, %mul297
  %mul300 = fmul float %sub281, %add299
  %add301 = fadd float %49, %mul300
  %add302 = fadd float %mul293, %add299
  %mul303 = fmul float %mul297, 2.000000e+00
  %add304 = fadd float %mul303, %add302
  %mul305 = fmul float %24, %add301
  %mul306 = fmul float %24, %26
  %mul307 = fmul float %mul306, %exptabscale
  %mul308 = fmul float %mul307, %add304
  br label %if.end310

if.end310:                                        ; preds = %if.end, %if.then211
  %FFRb.0 = phi float [ %mul308, %if.then211 ], [ 0.000000e+00, %if.end ]
  %VVRb.0 = phi float [ %mul305, %if.then211 ], [ 0.000000e+00, %if.end ]
  %FFDb.0 = phi float [ %mul276, %if.then211 ], [ 0.000000e+00, %if.end ]
  %VVDb.0 = phi float [ %mul274, %if.then211 ], [ 0.000000e+00, %if.end ]
  %FFCb.0 = phi float [ %mul252, %if.then211 ], [ 0.000000e+00, %if.end ]
  %VVCb.0 = phi float [ %mul250, %if.then211 ], [ 0.000000e+00, %if.end ]
  %rinv5b.0 = phi float [ %mul223, %if.then211 ], [ 0.000000e+00, %if.end ]
  %mul311 = fmul float %VVCb.0, %lambda
  %mul312 = fmul float %sub, %VVCa.0
  %add313 = fadd float %mul312, %mul311
  %add314 = fadd float %VVRb.0, %VVDb.0
  %mul315 = fmul float %add314, %lambda
  %add316 = fadd float %vnbtot.0753, %mul315
  %add317 = fadd float %VVRa.0, %VVDa.0
  %mul318 = fmul float %sub, %add317
  %add319 = fadd float %mul318, %add316
  %add320 = fadd float %FFDa.0, %FFCa.0
  %add321 = fadd float %FFRa.0, %add320
  %sub322 = fsub float -0.000000e+00, %add321
  %add323 = fadd float %FFDb.0, %FFCb.0
  %add324 = fadd float %FFRb.0, %add323
  %sub325 = fsub float -0.000000e+00, %add324
  %mul326 = fmul float %sub, %sub322
  %mul327 = fmul float %rinv5a.0, %mul326
  %mul328 = fmul float %lambda, %sub325
  %mul329 = fmul float %rinv5b.0, %mul328
  %add330 = fadd float %mul327, %mul329
  %mul331 = fmul float %mul91, %add330
  %add332 = fadd float %dvdl.1754, %VVCb.0
  %sub333 = fsub float %add332, %VVCa.0
  %add334 = fadd float %VVDb.0, %sub333
  %add335 = fadd float %VVRb.0, %add334
  %sub336 = fsub float %add335, %VVDa.0
  %sub337 = fsub float %sub336, %VVRa.0
  %mul341 = fmul float %defsigma6, %sub325
  %mul342 = fmul float %rinv5b.0, %mul341
  %mul343 = fmul float %defsigma6, %sub322
  %mul344 = fmul float %rinv5a.0, %mul343
  %sub345 = fsub float %mul342, %mul344
  %mul346 = fmul float %mul340, %sub345
  %add347 = fadd float %sub337, %mul346
  %add348 = fadd float %vctot.0758, %add313
  %mul349 = fmul float %sub57, %mul331
  %mul350 = fmul float %sub58, %mul331
  %mul351 = fmul float %sub59, %mul331
  %add352 = fadd float %fix1.0755, %mul349
  %add353 = fadd float %fiy1.0756, %mul350
  %add354 = fadd float %fiz1.0757, %mul351
  %arrayidx356 = getelementptr inbounds float* %faction, i64 %idxprom49
  %53 = load float* %arrayidx356, align 4, !tbaa !3
  %sub357 = fsub float %53, %mul349
  store float %sub357, float* %arrayidx356, align 4, !tbaa !3
  %arrayidx362 = getelementptr inbounds float* %faction, i64 %idxprom52
  %54 = load float* %arrayidx362, align 4, !tbaa !3
  %sub363 = fsub float %54, %mul350
  store float %sub363, float* %arrayidx362, align 4, !tbaa !3
  %arrayidx369 = getelementptr inbounds float* %faction, i64 %idxprom55
  %55 = load float* %arrayidx369, align 4, !tbaa !3
  %sub370 = fsub float %55, %mul351
  store float %sub370, float* %arrayidx369, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %56 = trunc i64 %indvars.iv.next to i32
  %cmp44 = icmp slt i32 %56, %6
  br i1 %cmp44, label %for.body45, label %for.end

for.end:                                          ; preds = %if.end310, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add348, %if.end310 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add354, %if.end310 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add353, %if.end310 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add352, %if.end310 ]
  %dvdl.1.lcssa = phi float [ %dvdl.0766, %for.body ], [ %add347, %if.end310 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add319, %if.end310 ]
  %arrayidx375 = getelementptr inbounds float* %faction, i64 %idxprom18
  %57 = load float* %arrayidx375, align 4, !tbaa !3
  %add376 = fadd float %fix1.0.lcssa, %57
  store float %add376, float* %arrayidx375, align 4, !tbaa !3
  %arrayidx381 = getelementptr inbounds float* %faction, i64 %idxprom22
  %58 = load float* %arrayidx381, align 4, !tbaa !3
  %add382 = fadd float %fiy1.0.lcssa, %58
  store float %add382, float* %arrayidx381, align 4, !tbaa !3
  %arrayidx388 = getelementptr inbounds float* %faction, i64 %idxprom26
  %59 = load float* %arrayidx388, align 4, !tbaa !3
  %add389 = fadd float %fiz1.0.lcssa, %59
  store float %add389, float* %arrayidx388, align 4, !tbaa !3
  %arrayidx394 = getelementptr inbounds float* %fshift, i64 %idxprom3
  %60 = load float* %arrayidx394, align 4, !tbaa !3
  %add395 = fadd float %fix1.0.lcssa, %60
  store float %add395, float* %arrayidx394, align 4, !tbaa !3
  %arrayidx400 = getelementptr inbounds float* %fshift, i64 %idxprom5
  %61 = load float* %arrayidx400, align 4, !tbaa !3
  %add401 = fadd float %fiy1.0.lcssa, %61
  store float %add401, float* %arrayidx400, align 4, !tbaa !3
  %arrayidx407 = getelementptr inbounds float* %fshift, i64 %idxprom8
  %62 = load float* %arrayidx407, align 4, !tbaa !3
  %add408 = fadd float %fiz1.0.lcssa, %62
  store float %add408, float* %arrayidx407, align 4, !tbaa !3
  %arrayidx413 = getelementptr inbounds i32* %gid, i64 %indvars.iv769
  %63 = load i32* %arrayidx413, align 4, !tbaa !0
  %idxprom414 = sext i32 %63 to i64
  %arrayidx415 = getelementptr inbounds float* %Vc, i64 %idxprom414
  %64 = load float* %arrayidx415, align 4, !tbaa !3
  %add416 = fadd float %vctot.0.lcssa, %64
  store float %add416, float* %arrayidx415, align 4, !tbaa !3
  %arrayidx420 = getelementptr inbounds float* %Vnb, i64 %idxprom414
  %65 = load float* %arrayidx420, align 4, !tbaa !3
  %add421 = fadd float %vnbtot.0.lcssa, %65
  store float %add421, float* %arrayidx420, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next770 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end426, label %for.body

for.end426:                                       ; preds = %for.end, %entry
  %dvdl.0.lcssa = phi float [ 0.000000e+00, %entry ], [ %dvdl.1.lcssa, %for.end ]
  %66 = load float* %dvdlambda, align 4, !tbaa !3
  %add427 = fadd float %dvdl.0.lcssa, %66
  store float %add427, float* %dvdlambda, align 4, !tbaa !3
  ret void
}
