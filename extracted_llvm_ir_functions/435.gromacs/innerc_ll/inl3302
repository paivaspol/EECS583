define void @inl3302(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* %VFtab, float %lambda, float* nocapture %dvdlambda, float* nocapture %chargeB, i32* nocapture %typeB, float %Alpha, float %defsigma6) #0 {
entry:
  %sub = fsub float 1.000000e+00, %lambda
  %mul = fmul float %lambda, %lambda
  %mul1 = fmul float %sub, %sub
  %cmp748 = icmp sgt i32 %nri, 0
  br i1 %cmp748, label %for.body.lr.ph, label %for.end421

for.body.lr.ph:                                   ; preds = %entry
  %mul35 = shl nsw i32 %ntype, 1
  %mul333 = fmul float %Alpha, 0x3FD5555560000000
  %mul334 = fmul float %mul333, %lambda
  %mul335 = fmul float %sub, %mul334
  br label %for.body

for.body:                                         ; preds = %for.end, %for.body.lr.ph
  %indvars.iv752 = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next753, %for.end ]
  %dvdl.0749 = phi float [ 0.000000e+00, %for.body.lr.ph ], [ %dvdl.1.lcssa, %for.end ]
  %arrayidx = getelementptr inbounds i32* %shift, i64 %indvars.iv752
  %0 = load i32* %arrayidx, align 4, !tbaa !0
  %mul2 = mul nsw i32 %0, 3
  %idxprom3 = sext i32 %mul2 to i64
  %arrayidx4 = getelementptr inbounds float* %shiftvec, i64 %idxprom3
  %1 = load float* %arrayidx4, align 4, !tbaa !3
  %add = add nsw i32 %mul2, 1
  %idxprom5 = sext i32 %add to i64
  %arrayidx6 = getelementptr inbounds float* %shiftvec, i64 %idxprom5
  %2 = load float* %arrayidx6, align 4, !tbaa !3
  %add7 = add nsw i32 %mul2, 2
  %idxprom8 = sext i32 %add7 to i64
  %arrayidx9 = getelementptr inbounds float* %shiftvec, i64 %idxprom8
  %3 = load float* %arrayidx9, align 4, !tbaa !3
  %arrayidx11 = getelementptr inbounds i32* %iinr, i64 %indvars.iv752
  %4 = load i32* %arrayidx11, align 4, !tbaa !0
  %mul12 = mul nsw i32 %4, 3
  %arrayidx14 = getelementptr inbounds i32* %jindex, i64 %indvars.iv752
  %5 = load i32* %arrayidx14, align 4, !tbaa !0
  %indvars.iv.next753 = add i64 %indvars.iv752, 1
  %arrayidx17 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next753
  %6 = load i32* %arrayidx17, align 4, !tbaa !0
  %idxprom18 = sext i32 %mul12 to i64
  %arrayidx19 = getelementptr inbounds float* %pos, i64 %idxprom18
  %7 = load float* %arrayidx19, align 4, !tbaa !3
  %add20 = fadd float %1, %7
  %add21 = add nsw i32 %mul12, 1
  %idxprom22 = sext i32 %add21 to i64
  %arrayidx23 = getelementptr inbounds float* %pos, i64 %idxprom22
  %8 = load float* %arrayidx23, align 4, !tbaa !3
  %add24 = fadd float %2, %8
  %add25 = add nsw i32 %mul12, 2
  %idxprom26 = sext i32 %add25 to i64
  %arrayidx27 = getelementptr inbounds float* %pos, i64 %idxprom26
  %9 = load float* %arrayidx27, align 4, !tbaa !3
  %add28 = fadd float %3, %9
  %idxprom29 = sext i32 %4 to i64
  %arrayidx30 = getelementptr inbounds float* %charge, i64 %idxprom29
  %10 = load float* %arrayidx30, align 4, !tbaa !3
  %mul31 = fmul float %10, %facel
  %arrayidx33 = getelementptr inbounds float* %chargeB, i64 %idxprom29
  %11 = load float* %arrayidx33, align 4, !tbaa !3
  %mul34 = fmul float %11, %facel
  %arrayidx37 = getelementptr inbounds i32* %type, i64 %idxprom29
  %12 = load i32* %arrayidx37, align 4, !tbaa !0
  %mul38 = mul nsw i32 %12, %mul35
  %arrayidx41 = getelementptr inbounds i32* %typeB, i64 %idxprom29
  %13 = load i32* %arrayidx41, align 4, !tbaa !0
  %mul42 = mul nsw i32 %13, %mul35
  %cmp44735 = icmp slt i32 %5, %6
  br i1 %cmp44735, label %for.body45.lr.ph, label %for.end

for.body45.lr.ph:                                 ; preds = %for.body
  %14 = sext i32 %5 to i64
  br label %for.body45

for.body45:                                       ; preds = %for.body45.lr.ph, %if.end305
  %indvars.iv = phi i64 [ %14, %for.body45.lr.ph ], [ %indvars.iv.next, %if.end305 ]
  %vctot.0741 = phi float [ 0.000000e+00, %for.body45.lr.ph ], [ %add343, %if.end305 ]
  %fiz1.0740 = phi float [ 0.000000e+00, %for.body45.lr.ph ], [ %add349, %if.end305 ]
  %fiy1.0739 = phi float [ 0.000000e+00, %for.body45.lr.ph ], [ %add348, %if.end305 ]
  %fix1.0738 = phi float [ 0.000000e+00, %for.body45.lr.ph ], [ %add347, %if.end305 ]
  %dvdl.1737 = phi float [ %dvdl.0749, %for.body45.lr.ph ], [ %add342, %if.end305 ]
  %vnbtot.0736 = phi float [ 0.000000e+00, %for.body45.lr.ph ], [ %add314, %if.end305 ]
  %arrayidx47 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %15 = load i32* %arrayidx47, align 4, !tbaa !0
  %mul48 = mul nsw i32 %15, 3
  %idxprom49 = sext i32 %mul48 to i64
  %arrayidx50 = getelementptr inbounds float* %pos, i64 %idxprom49
  %16 = load float* %arrayidx50, align 4, !tbaa !3
  %add51 = add nsw i32 %mul48, 1
  %idxprom52 = sext i32 %add51 to i64
  %arrayidx53 = getelementptr inbounds float* %pos, i64 %idxprom52
  %17 = load float* %arrayidx53, align 4, !tbaa !3
  %add54 = add nsw i32 %mul48, 2
  %idxprom55 = sext i32 %add54 to i64
  %arrayidx56 = getelementptr inbounds float* %pos, i64 %idxprom55
  %18 = load float* %arrayidx56, align 4, !tbaa !3
  %sub57 = fsub float %add20, %16
  %sub58 = fsub float %add24, %17
  %sub59 = fsub float %add28, %18
  %mul60 = fmul float %sub57, %sub57
  %mul61 = fmul float %sub58, %sub58
  %add62 = fadd float %mul60, %mul61
  %mul63 = fmul float %sub59, %sub59
  %add64 = fadd float %add62, %mul63
  %conv = fpext float %add64 to double
  %call = tail call double @sqrt(double %conv) #2
  %idxprom67 = sext i32 %15 to i64
  %arrayidx68 = getelementptr inbounds i32* %type, i64 %idxprom67
  %19 = load i32* %arrayidx68, align 4, !tbaa !0
  %mul69 = shl nsw i32 %19, 1
  %add70 = add nsw i32 %mul69, %mul38
  %arrayidx72 = getelementptr inbounds i32* %typeB, i64 %idxprom67
  %20 = load i32* %arrayidx72, align 4, !tbaa !0
  %mul73 = shl nsw i32 %20, 1
  %add74 = add nsw i32 %mul73, %mul42
  %idxprom75 = sext i32 %add70 to i64
  %arrayidx76 = getelementptr inbounds float* %nbfp, i64 %idxprom75
  %21 = load float* %arrayidx76, align 4, !tbaa !3
  %idxprom77 = sext i32 %add74 to i64
  %arrayidx78 = getelementptr inbounds float* %nbfp, i64 %idxprom77
  %22 = load float* %arrayidx78, align 4, !tbaa !3
  %add79723 = or i32 %add70, 1
  %idxprom80 = sext i32 %add79723 to i64
  %arrayidx81 = getelementptr inbounds float* %nbfp, i64 %idxprom80
  %23 = load float* %arrayidx81, align 4, !tbaa !3
  %add82724 = or i32 %add74, 1
  %idxprom83 = sext i32 %add82724 to i64
  %arrayidx84 = getelementptr inbounds float* %nbfp, i64 %idxprom83
  %24 = load float* %arrayidx84, align 4, !tbaa !3
  %cmp85 = fcmp ogt float %21, 0.000000e+00
  %cmp87 = fcmp ogt float %23, 0.000000e+00
  %or.cond = and i1 %cmp85, %cmp87
  br i1 %or.cond, label %if.then, label %if.end

if.then:                                          ; preds = %for.body45
  %div89 = fdiv float %23, %21
  br label %if.end

if.end:                                           ; preds = %for.body45, %if.then
  %sigma6a.0 = phi float [ %div89, %if.then ], [ %defsigma6, %for.body45 ]
  %cmp90 = fcmp ogt float %22, 0.000000e+00
  %cmp93 = fcmp ogt float %24, 0.000000e+00
  %or.cond731 = and i1 %cmp90, %cmp93
  br i1 %or.cond731, label %if.then95, label %if.end98

if.then95:                                        ; preds = %if.end
  %div96 = fdiv float %24, %22
  br label %if.end98

if.end98:                                         ; preds = %if.end, %if.then95
  %sigma6b.0 = phi float [ %div96, %if.then95 ], [ %defsigma6, %if.end ]
  %mul99 = fmul float %add64, %add64
  %mul100 = fmul float %add64, %mul99
  %arrayidx102 = getelementptr inbounds float* %charge, i64 %idxprom67
  %25 = load float* %arrayidx102, align 4, !tbaa !3
  %mul103 = fmul float %mul31, %25
  %cmp104 = fcmp une float %mul103, 0.000000e+00
  %brmerge = or i1 %cmp104, %cmp85
  %or.cond732 = or i1 %brmerge, %cmp87
  br i1 %or.cond732, label %if.then111, label %if.end202

if.then111:                                       ; preds = %if.end98
  %mul112 = fmul float %sigma6a.0, %Alpha
  %mul113 = fmul float %mul, %mul112
  %add114 = fadd float %mul100, %mul113
  %conv115 = fpext float %add114 to double
  %call116 = tail call double @pow(double %conv115, double 0x3FC5555560000000) #2
  %conv117 = fptrunc double %call116 to float
  %conv120 = fdiv float 1.000000e+00, %conv117
  %mul121 = fmul float %conv120, %conv120
  %mul122 = fmul float %mul121, %mul121
  %mul123 = fmul float %conv120, %mul122
  %mul124 = fmul float %conv117, %tabscale
  %conv125 = fptosi float %mul124 to i32
  %conv126 = sitofp i32 %conv125 to float
  %sub127 = fsub float %mul124, %conv126
  %mul128 = fmul float %sub127, %sub127
  %mul129 = mul nsw i32 %conv125, 12
  %idxprom130 = sext i32 %mul129 to i64
  %arrayidx131 = getelementptr inbounds float* %VFtab, i64 %idxprom130
  %26 = load float* %arrayidx131, align 4, !tbaa !3
  %add132728 = or i32 %mul129, 1
  %idxprom133 = sext i32 %add132728 to i64
  %arrayidx134 = getelementptr inbounds float* %VFtab, i64 %idxprom133
  %27 = load float* %arrayidx134, align 4, !tbaa !3
  %add135729 = or i32 %mul129, 2
  %idxprom136 = sext i32 %add135729 to i64
  %arrayidx137 = getelementptr inbounds float* %VFtab, i64 %idxprom136
  %28 = load float* %arrayidx137, align 4, !tbaa !3
  %mul138 = fmul float %28, %sub127
  %add139730 = or i32 %mul129, 3
  %idxprom140 = sext i32 %add139730 to i64
  %arrayidx141 = getelementptr inbounds float* %VFtab, i64 %idxprom140
  %29 = load float* %arrayidx141, align 4, !tbaa !3
  %mul142 = fmul float %29, %mul128
  %add143 = fadd float %27, %mul138
  %add144 = fadd float %add143, %mul142
  %mul145 = fmul float %sub127, %add144
  %add146 = fadd float %26, %mul145
  %add147 = fadd float %mul138, %add144
  %mul148 = fmul float %mul142, 2.000000e+00
  %add149 = fadd float %mul148, %add147
  %mul150 = fmul float %mul103, %add146
  %mul151 = fmul float %mul103, %tabscale
  %mul152 = fmul float %mul151, %add149
  %add153 = add nsw i32 %mul129, 4
  %idxprom154 = sext i32 %add153 to i64
  %arrayidx155 = getelementptr inbounds float* %VFtab, i64 %idxprom154
  %30 = load float* %arrayidx155, align 4, !tbaa !3
  %add156 = add nsw i32 %mul129, 5
  %idxprom157 = sext i32 %add156 to i64
  %arrayidx158 = getelementptr inbounds float* %VFtab, i64 %idxprom157
  %31 = load float* %arrayidx158, align 4, !tbaa !3
  %add159 = add nsw i32 %mul129, 6
  %idxprom160 = sext i32 %add159 to i64
  %arrayidx161 = getelementptr inbounds float* %VFtab, i64 %idxprom160
  %32 = load float* %arrayidx161, align 4, !tbaa !3
  %mul162 = fmul float %sub127, %32
  %add163 = add nsw i32 %mul129, 7
  %idxprom164 = sext i32 %add163 to i64
  %arrayidx165 = getelementptr inbounds float* %VFtab, i64 %idxprom164
  %33 = load float* %arrayidx165, align 4, !tbaa !3
  %mul166 = fmul float %mul128, %33
  %add167 = fadd float %31, %mul162
  %add168 = fadd float %add167, %mul166
  %mul169 = fmul float %sub127, %add168
  %add170 = fadd float %30, %mul169
  %add171 = fadd float %mul162, %add168
  %mul172 = fmul float %mul166, 2.000000e+00
  %add173 = fadd float %mul172, %add171
  %mul174 = fmul float %21, %add170
  %mul175 = fmul float %21, %tabscale
  %mul176 = fmul float %mul175, %add173
  %add177 = add nsw i32 %mul129, 8
  %idxprom178 = sext i32 %add177 to i64
  %arrayidx179 = getelementptr inbounds float* %VFtab, i64 %idxprom178
  %34 = load float* %arrayidx179, align 4, !tbaa !3
  %add180 = add nsw i32 %mul129, 9
  %idxprom181 = sext i32 %add180 to i64
  %arrayidx182 = getelementptr inbounds float* %VFtab, i64 %idxprom181
  %35 = load float* %arrayidx182, align 4, !tbaa !3
  %add183 = add nsw i32 %mul129, 10
  %idxprom184 = sext i32 %add183 to i64
  %arrayidx185 = getelementptr inbounds float* %VFtab, i64 %idxprom184
  %36 = load float* %arrayidx185, align 4, !tbaa !3
  %mul186 = fmul float %sub127, %36
  %add187 = add nsw i32 %mul129, 11
  %idxprom188 = sext i32 %add187 to i64
  %arrayidx189 = getelementptr inbounds float* %VFtab, i64 %idxprom188
  %37 = load float* %arrayidx189, align 4, !tbaa !3
  %mul190 = fmul float %mul128, %37
  %add191 = fadd float %35, %mul186
  %add192 = fadd float %add191, %mul190
  %mul193 = fmul float %sub127, %add192
  %add194 = fadd float %34, %mul193
  %add195 = fadd float %mul186, %add192
  %mul196 = fmul float %mul190, 2.000000e+00
  %add197 = fadd float %mul196, %add195
  %mul198 = fmul float %23, %add194
  %mul199 = fmul float %23, %tabscale
  %mul200 = fmul float %mul199, %add197
  br label %if.end202

if.end202:                                        ; preds = %if.end98, %if.then111
  %FFRa.0 = phi float [ %mul200, %if.then111 ], [ 0.000000e+00, %if.end98 ]
  %VVRa.0 = phi float [ %mul198, %if.then111 ], [ 0.000000e+00, %if.end98 ]
  %FFDa.0 = phi float [ %mul176, %if.then111 ], [ 0.000000e+00, %if.end98 ]
  %VVDa.0 = phi float [ %mul174, %if.then111 ], [ 0.000000e+00, %if.end98 ]
  %FFCa.0 = phi float [ %mul152, %if.then111 ], [ 0.000000e+00, %if.end98 ]
  %VVCa.0 = phi float [ %mul150, %if.then111 ], [ 0.000000e+00, %if.end98 ]
  %rinv5a.0 = phi float [ %mul123, %if.then111 ], [ 0.000000e+00, %if.end98 ]
  %arrayidx204 = getelementptr inbounds float* %chargeB, i64 %idxprom67
  %38 = load float* %arrayidx204, align 4, !tbaa !3
  %mul205 = fmul float %mul34, %38
  %cmp206 = fcmp une float %mul205, 0.000000e+00
  %brmerge733 = or i1 %cmp206, %cmp90
  %or.cond734 = or i1 %brmerge733, %cmp93
  br i1 %or.cond734, label %if.then214, label %if.end305

if.then214:                                       ; preds = %if.end202
  %mul215 = fmul float %sigma6b.0, %Alpha
  %mul216 = fmul float %mul1, %mul215
  %add217 = fadd float %mul100, %mul216
  %conv218 = fpext float %add217 to double
  %call219 = tail call double @pow(double %conv218, double 0x3FC5555560000000) #2
  %conv220 = fptrunc double %call219 to float
  %conv223 = fdiv float 1.000000e+00, %conv220
  %mul224 = fmul float %conv223, %conv223
  %mul225 = fmul float %mul224, %mul224
  %mul226 = fmul float %conv223, %mul225
  %mul227 = fmul float %conv220, %tabscale
  %conv228 = fptosi float %mul227 to i32
  %conv229 = sitofp i32 %conv228 to float
  %sub230 = fsub float %mul227, %conv229
  %mul231 = fmul float %sub230, %sub230
  %mul232 = mul nsw i32 %conv228, 12
  %idxprom233 = sext i32 %mul232 to i64
  %arrayidx234 = getelementptr inbounds float* %VFtab, i64 %idxprom233
  %39 = load float* %arrayidx234, align 4, !tbaa !3
  %add235725 = or i32 %mul232, 1
  %idxprom236 = sext i32 %add235725 to i64
  %arrayidx237 = getelementptr inbounds float* %VFtab, i64 %idxprom236
  %40 = load float* %arrayidx237, align 4, !tbaa !3
  %add238726 = or i32 %mul232, 2
  %idxprom239 = sext i32 %add238726 to i64
  %arrayidx240 = getelementptr inbounds float* %VFtab, i64 %idxprom239
  %41 = load float* %arrayidx240, align 4, !tbaa !3
  %mul241 = fmul float %41, %sub230
  %add242727 = or i32 %mul232, 3
  %idxprom243 = sext i32 %add242727 to i64
  %arrayidx244 = getelementptr inbounds float* %VFtab, i64 %idxprom243
  %42 = load float* %arrayidx244, align 4, !tbaa !3
  %mul245 = fmul float %42, %mul231
  %add246 = fadd float %40, %mul241
  %add247 = fadd float %add246, %mul245
  %mul248 = fmul float %sub230, %add247
  %add249 = fadd float %39, %mul248
  %add250 = fadd float %mul241, %add247
  %mul251 = fmul float %mul245, 2.000000e+00
  %add252 = fadd float %mul251, %add250
  %mul253 = fmul float %mul205, %add249
  %mul254 = fmul float %mul205, %tabscale
  %mul255 = fmul float %mul254, %add252
  %add256 = add nsw i32 %mul232, 4
  %idxprom257 = sext i32 %add256 to i64
  %arrayidx258 = getelementptr inbounds float* %VFtab, i64 %idxprom257
  %43 = load float* %arrayidx258, align 4, !tbaa !3
  %add259 = add nsw i32 %mul232, 5
  %idxprom260 = sext i32 %add259 to i64
  %arrayidx261 = getelementptr inbounds float* %VFtab, i64 %idxprom260
  %44 = load float* %arrayidx261, align 4, !tbaa !3
  %add262 = add nsw i32 %mul232, 6
  %idxprom263 = sext i32 %add262 to i64
  %arrayidx264 = getelementptr inbounds float* %VFtab, i64 %idxprom263
  %45 = load float* %arrayidx264, align 4, !tbaa !3
  %mul265 = fmul float %sub230, %45
  %add266 = add nsw i32 %mul232, 7
  %idxprom267 = sext i32 %add266 to i64
  %arrayidx268 = getelementptr inbounds float* %VFtab, i64 %idxprom267
  %46 = load float* %arrayidx268, align 4, !tbaa !3
  %mul269 = fmul float %mul231, %46
  %add270 = fadd float %44, %mul265
  %add271 = fadd float %add270, %mul269
  %mul272 = fmul float %sub230, %add271
  %add273 = fadd float %43, %mul272
  %add274 = fadd float %mul265, %add271
  %mul275 = fmul float %mul269, 2.000000e+00
  %add276 = fadd float %mul275, %add274
  %mul277 = fmul float %22, %add273
  %mul278 = fmul float %22, %tabscale
  %mul279 = fmul float %mul278, %add276
  %add280 = add nsw i32 %mul232, 8
  %idxprom281 = sext i32 %add280 to i64
  %arrayidx282 = getelementptr inbounds float* %VFtab, i64 %idxprom281
  %47 = load float* %arrayidx282, align 4, !tbaa !3
  %add283 = add nsw i32 %mul232, 9
  %idxprom284 = sext i32 %add283 to i64
  %arrayidx285 = getelementptr inbounds float* %VFtab, i64 %idxprom284
  %48 = load float* %arrayidx285, align 4, !tbaa !3
  %add286 = add nsw i32 %mul232, 10
  %idxprom287 = sext i32 %add286 to i64
  %arrayidx288 = getelementptr inbounds float* %VFtab, i64 %idxprom287
  %49 = load float* %arrayidx288, align 4, !tbaa !3
  %mul289 = fmul float %sub230, %49
  %add290 = add nsw i32 %mul232, 11
  %idxprom291 = sext i32 %add290 to i64
  %arrayidx292 = getelementptr inbounds float* %VFtab, i64 %idxprom291
  %50 = load float* %arrayidx292, align 4, !tbaa !3
  %mul293 = fmul float %mul231, %50
  %add294 = fadd float %48, %mul289
  %add295 = fadd float %add294, %mul293
  %mul296 = fmul float %sub230, %add295
  %add297 = fadd float %47, %mul296
  %add298 = fadd float %mul289, %add295
  %mul299 = fmul float %mul293, 2.000000e+00
  %add300 = fadd float %mul299, %add298
  %mul301 = fmul float %24, %add297
  %mul302 = fmul float %24, %tabscale
  %mul303 = fmul float %mul302, %add300
  br label %if.end305

if.end305:                                        ; preds = %if.end202, %if.then214
  %FFRb.0 = phi float [ %mul303, %if.then214 ], [ 0.000000e+00, %if.end202 ]
  %VVRb.0 = phi float [ %mul301, %if.then214 ], [ 0.000000e+00, %if.end202 ]
  %FFDb.0 = phi float [ %mul279, %if.then214 ], [ 0.000000e+00, %if.end202 ]
  %VVDb.0 = phi float [ %mul277, %if.then214 ], [ 0.000000e+00, %if.end202 ]
  %FFCb.0 = phi float [ %mul255, %if.then214 ], [ 0.000000e+00, %if.end202 ]
  %VVCb.0 = phi float [ %mul253, %if.then214 ], [ 0.000000e+00, %if.end202 ]
  %rinv5b.0 = phi float [ %mul226, %if.then214 ], [ 0.000000e+00, %if.end202 ]
  %mul306 = fmul float %VVCb.0, %lambda
  %mul307 = fmul float %sub, %VVCa.0
  %add308 = fadd float %mul307, %mul306
  %add309 = fadd float %VVRb.0, %VVDb.0
  %mul310 = fmul float %add309, %lambda
  %add311 = fadd float %vnbtot.0736, %mul310
  %add312 = fadd float %VVRa.0, %VVDa.0
  %mul313 = fmul float %sub, %add312
  %add314 = fadd float %mul313, %add311
  %add315 = fadd float %FFDa.0, %FFCa.0
  %add316 = fadd float %FFRa.0, %add315
  %sub317 = fsub float -0.000000e+00, %add316
  %add318 = fadd float %FFDb.0, %FFCb.0
  %add319 = fadd float %FFRb.0, %add318
  %sub320 = fsub float -0.000000e+00, %add319
  %mul321 = fmul float %sub, %sub317
  %mul322 = fmul float %rinv5a.0, %mul321
  %mul323 = fmul float %lambda, %sub320
  %mul324 = fmul float %rinv5b.0, %mul323
  %add325 = fadd float %mul322, %mul324
  %mul326 = fmul float %mul99, %add325
  %add327 = fadd float %dvdl.1737, %VVCb.0
  %sub328 = fsub float %add327, %VVCa.0
  %add329 = fadd float %VVDb.0, %sub328
  %add330 = fadd float %VVRb.0, %add329
  %sub331 = fsub float %add330, %VVDa.0
  %sub332 = fsub float %sub331, %VVRa.0
  %mul336 = fmul float %sigma6b.0, %sub320
  %mul337 = fmul float %rinv5b.0, %mul336
  %mul338 = fmul float %sigma6a.0, %sub317
  %mul339 = fmul float %rinv5a.0, %mul338
  %sub340 = fsub float %mul337, %mul339
  %mul341 = fmul float %mul335, %sub340
  %add342 = fadd float %sub332, %mul341
  %add343 = fadd float %vctot.0741, %add308
  %mul344 = fmul float %sub57, %mul326
  %mul345 = fmul float %sub58, %mul326
  %mul346 = fmul float %sub59, %mul326
  %add347 = fadd float %fix1.0738, %mul344
  %add348 = fadd float %fiy1.0739, %mul345
  %add349 = fadd float %fiz1.0740, %mul346
  %arrayidx351 = getelementptr inbounds float* %faction, i64 %idxprom49
  %51 = load float* %arrayidx351, align 4, !tbaa !3
  %sub352 = fsub float %51, %mul344
  store float %sub352, float* %arrayidx351, align 4, !tbaa !3
  %arrayidx357 = getelementptr inbounds float* %faction, i64 %idxprom52
  %52 = load float* %arrayidx357, align 4, !tbaa !3
  %sub358 = fsub float %52, %mul345
  store float %sub358, float* %arrayidx357, align 4, !tbaa !3
  %arrayidx364 = getelementptr inbounds float* %faction, i64 %idxprom55
  %53 = load float* %arrayidx364, align 4, !tbaa !3
  %sub365 = fsub float %53, %mul346
  store float %sub365, float* %arrayidx364, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %54 = trunc i64 %indvars.iv.next to i32
  %cmp44 = icmp slt i32 %54, %6
  br i1 %cmp44, label %for.body45, label %for.end

for.end:                                          ; preds = %if.end305, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add343, %if.end305 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add349, %if.end305 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add348, %if.end305 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add347, %if.end305 ]
  %dvdl.1.lcssa = phi float [ %dvdl.0749, %for.body ], [ %add342, %if.end305 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add314, %if.end305 ]
  %arrayidx370 = getelementptr inbounds float* %faction, i64 %idxprom18
  %55 = load float* %arrayidx370, align 4, !tbaa !3
  %add371 = fadd float %fix1.0.lcssa, %55
  store float %add371, float* %arrayidx370, align 4, !tbaa !3
  %arrayidx376 = getelementptr inbounds float* %faction, i64 %idxprom22
  %56 = load float* %arrayidx376, align 4, !tbaa !3
  %add377 = fadd float %fiy1.0.lcssa, %56
  store float %add377, float* %arrayidx376, align 4, !tbaa !3
  %arrayidx383 = getelementptr inbounds float* %faction, i64 %idxprom26
  %57 = load float* %arrayidx383, align 4, !tbaa !3
  %add384 = fadd float %fiz1.0.lcssa, %57
  store float %add384, float* %arrayidx383, align 4, !tbaa !3
  %arrayidx389 = getelementptr inbounds float* %fshift, i64 %idxprom3
  %58 = load float* %arrayidx389, align 4, !tbaa !3
  %add390 = fadd float %fix1.0.lcssa, %58
  store float %add390, float* %arrayidx389, align 4, !tbaa !3
  %arrayidx395 = getelementptr inbounds float* %fshift, i64 %idxprom5
  %59 = load float* %arrayidx395, align 4, !tbaa !3
  %add396 = fadd float %fiy1.0.lcssa, %59
  store float %add396, float* %arrayidx395, align 4, !tbaa !3
  %arrayidx402 = getelementptr inbounds float* %fshift, i64 %idxprom8
  %60 = load float* %arrayidx402, align 4, !tbaa !3
  %add403 = fadd float %fiz1.0.lcssa, %60
  store float %add403, float* %arrayidx402, align 4, !tbaa !3
  %arrayidx408 = getelementptr inbounds i32* %gid, i64 %indvars.iv752
  %61 = load i32* %arrayidx408, align 4, !tbaa !0
  %idxprom409 = sext i32 %61 to i64
  %arrayidx410 = getelementptr inbounds float* %Vc, i64 %idxprom409
  %62 = load float* %arrayidx410, align 4, !tbaa !3
  %add411 = fadd float %vctot.0.lcssa, %62
  store float %add411, float* %arrayidx410, align 4, !tbaa !3
  %arrayidx415 = getelementptr inbounds float* %Vnb, i64 %idxprom409
  %63 = load float* %arrayidx415, align 4, !tbaa !3
  %add416 = fadd float %vnbtot.0.lcssa, %63
  store float %add416, float* %arrayidx415, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next753 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end421, label %for.body

for.end421:                                       ; preds = %for.end, %entry
  %dvdl.0.lcssa = phi float [ 0.000000e+00, %entry ], [ %dvdl.1.lcssa, %for.end ]
  %64 = load float* %dvdlambda, align 4, !tbaa !3
  %add422 = fadd float %dvdl.0.lcssa, %64
  store float %add422, float* %dvdlambda, align 4, !tbaa !3
  ret void
}
