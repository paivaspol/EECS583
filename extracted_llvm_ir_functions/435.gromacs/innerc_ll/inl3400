define void @inl3400(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab, float %exptabscale) #0 {
entry:
  %cmp419 = icmp sgt i32 %nri, 0
  br i1 %cmp419, label %for.body, label %for.end240

for.body:                                         ; preds = %for.end, %entry
  %indvars.iv421 = phi i64 [ 0, %entry ], [ %indvars.iv.next422, %for.end ]
  %arrayidx = getelementptr inbounds i32* %shift, i64 %indvars.iv421
  %0 = load i32* %arrayidx, align 4, !tbaa !0
  %mul = mul nsw i32 %0, 3
  %idxprom1 = sext i32 %mul to i64
  %arrayidx2 = getelementptr inbounds float* %shiftvec, i64 %idxprom1
  %1 = load float* %arrayidx2, align 4, !tbaa !3
  %add = add nsw i32 %mul, 1
  %idxprom3 = sext i32 %add to i64
  %arrayidx4 = getelementptr inbounds float* %shiftvec, i64 %idxprom3
  %2 = load float* %arrayidx4, align 4, !tbaa !3
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds float* %shiftvec, i64 %idxprom6
  %3 = load float* %arrayidx7, align 4, !tbaa !3
  %arrayidx9 = getelementptr inbounds i32* %iinr, i64 %indvars.iv421
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %arrayidx12 = getelementptr inbounds i32* %jindex, i64 %indvars.iv421
  %5 = load i32* %arrayidx12, align 4, !tbaa !0
  %indvars.iv.next422 = add i64 %indvars.iv421, 1
  %arrayidx15 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next422
  %6 = load i32* %arrayidx15, align 4, !tbaa !0
  %idxprom16 = sext i32 %mul10 to i64
  %arrayidx17 = getelementptr inbounds float* %pos, i64 %idxprom16
  %7 = load float* %arrayidx17, align 4, !tbaa !3
  %add18 = fadd float %1, %7
  %add19 = add nsw i32 %mul10, 1
  %idxprom20 = sext i32 %add19 to i64
  %arrayidx21 = getelementptr inbounds float* %pos, i64 %idxprom20
  %8 = load float* %arrayidx21, align 4, !tbaa !3
  %add22 = fadd float %2, %8
  %add23 = add nsw i32 %mul10, 2
  %idxprom24 = sext i32 %add23 to i64
  %arrayidx25 = getelementptr inbounds float* %pos, i64 %idxprom24
  %9 = load float* %arrayidx25, align 4, !tbaa !3
  %add26 = fadd float %3, %9
  %idxprom27 = sext i32 %4 to i64
  %arrayidx28 = getelementptr inbounds float* %charge, i64 %idxprom27
  %10 = load float* %arrayidx28, align 4, !tbaa !3
  %mul29 = fmul float %10, %facel
  %arrayidx32 = getelementptr inbounds i32* %type, i64 %idxprom27
  %11 = load i32* %arrayidx32, align 4, !tbaa !0
  %mul33 = mul i32 %11, %ntype
  %cmp35408 = icmp slt i32 %5, %6
  br i1 %cmp35408, label %for.body36.lr.ph, label %for.end

for.body36.lr.ph:                                 ; preds = %for.body
  %12 = sext i32 %5 to i64
  br label %for.body36

for.body36:                                       ; preds = %for.body36.lr.ph, %for.body36
  %indvars.iv = phi i64 [ %12, %for.body36.lr.ph ], [ %indvars.iv.next, %for.body36 ]
  %vctot.0413 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add162, %for.body36 ]
  %vnbtot.0412 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add155, %for.body36 ]
  %fix1.0411 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add166, %for.body36 ]
  %fiy1.0410 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add167, %for.body36 ]
  %fiz1.0409 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add168, %for.body36 ]
  %arrayidx38 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %13 = load i32* %arrayidx38, align 4, !tbaa !0
  %mul39 = mul nsw i32 %13, 3
  %idxprom40 = sext i32 %mul39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %14 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = add nsw i32 %mul39, 1
  %idxprom43 = sext i32 %add42 to i64
  %arrayidx44 = getelementptr inbounds float* %pos, i64 %idxprom43
  %15 = load float* %arrayidx44, align 4, !tbaa !3
  %add45 = add nsw i32 %mul39, 2
  %idxprom46 = sext i32 %add45 to i64
  %arrayidx47 = getelementptr inbounds float* %pos, i64 %idxprom46
  %16 = load float* %arrayidx47, align 4, !tbaa !3
  %sub = fsub float %add18, %14
  %sub48 = fsub float %add22, %15
  %sub49 = fsub float %add26, %16
  %mul50 = fmul float %sub, %sub
  %mul51 = fmul float %sub48, %sub48
  %add52 = fadd float %mul50, %mul51
  %mul53 = fmul float %sub49, %sub49
  %add54 = fadd float %add52, %mul53
  %conv = fpext float %add54 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv55 = fptrunc double %div to float
  %mul56 = fmul float %add54, %conv55
  %mul57 = fmul float %mul56, %tabscale
  %conv58 = fptosi float %mul57 to i32
  %conv59 = sitofp i32 %conv58 to float
  %sub60 = fsub float %mul57, %conv59
  %mul61 = fmul float %sub60, %sub60
  %mul62 = mul nsw i32 %conv58, 12
  %idxprom63 = sext i32 %13 to i64
  %arrayidx64 = getelementptr inbounds float* %charge, i64 %idxprom63
  %17 = load float* %arrayidx64, align 4, !tbaa !3
  %mul65 = fmul float %mul29, %17
  %idxprom66 = sext i32 %mul62 to i64
  %arrayidx67 = getelementptr inbounds float* %VFtab, i64 %idxprom66
  %18 = load float* %arrayidx67, align 4, !tbaa !3
  %add68404 = or i32 %mul62, 1
  %idxprom69 = sext i32 %add68404 to i64
  %arrayidx70 = getelementptr inbounds float* %VFtab, i64 %idxprom69
  %19 = load float* %arrayidx70, align 4, !tbaa !3
  %add71405 = or i32 %mul62, 2
  %idxprom72 = sext i32 %add71405 to i64
  %arrayidx73 = getelementptr inbounds float* %VFtab, i64 %idxprom72
  %20 = load float* %arrayidx73, align 4, !tbaa !3
  %mul74 = fmul float %20, %sub60
  %add75406 = or i32 %mul62, 3
  %idxprom76 = sext i32 %add75406 to i64
  %arrayidx77 = getelementptr inbounds float* %VFtab, i64 %idxprom76
  %21 = load float* %arrayidx77, align 4, !tbaa !3
  %mul78 = fmul float %21, %mul61
  %add79 = fadd float %19, %mul74
  %add80 = fadd float %add79, %mul78
  %mul81 = fmul float %sub60, %add80
  %add82 = fadd float %18, %mul81
  %add83 = fadd float %mul74, %add80
  %mul84 = fmul float %mul78, 2.000000e+00
  %add85 = fadd float %mul84, %add83
  %mul86 = fmul float %mul65, %add82
  %mul87 = fmul float %mul65, %add85
  %arrayidx89 = getelementptr inbounds i32* %type, i64 %idxprom63
  %22 = load i32* %arrayidx89, align 4, !tbaa !0
  %tmp = add i32 %22, %mul33
  %tmp407 = mul i32 %tmp, 3
  %idxprom92 = sext i32 %tmp407 to i64
  %arrayidx93 = getelementptr inbounds float* %nbfp, i64 %idxprom92
  %23 = load float* %arrayidx93, align 4, !tbaa !3
  %add94 = add nsw i32 %tmp407, 1
  %idxprom95 = sext i32 %add94 to i64
  %arrayidx96 = getelementptr inbounds float* %nbfp, i64 %idxprom95
  %24 = load float* %arrayidx96, align 4, !tbaa !3
  %add97 = add nsw i32 %tmp407, 2
  %idxprom98 = sext i32 %add97 to i64
  %arrayidx99 = getelementptr inbounds float* %nbfp, i64 %idxprom98
  %25 = load float* %arrayidx99, align 4, !tbaa !3
  %add100 = add nsw i32 %mul62, 4
  %idxprom101 = sext i32 %add100 to i64
  %arrayidx102 = getelementptr inbounds float* %VFtab, i64 %idxprom101
  %26 = load float* %arrayidx102, align 4, !tbaa !3
  %add103 = add nsw i32 %mul62, 5
  %idxprom104 = sext i32 %add103 to i64
  %arrayidx105 = getelementptr inbounds float* %VFtab, i64 %idxprom104
  %27 = load float* %arrayidx105, align 4, !tbaa !3
  %add106 = add nsw i32 %mul62, 6
  %idxprom107 = sext i32 %add106 to i64
  %arrayidx108 = getelementptr inbounds float* %VFtab, i64 %idxprom107
  %28 = load float* %arrayidx108, align 4, !tbaa !3
  %mul109 = fmul float %sub60, %28
  %add110 = add nsw i32 %mul62, 7
  %idxprom111 = sext i32 %add110 to i64
  %arrayidx112 = getelementptr inbounds float* %VFtab, i64 %idxprom111
  %29 = load float* %arrayidx112, align 4, !tbaa !3
  %mul113 = fmul float %mul61, %29
  %add114 = fadd float %27, %mul109
  %add115 = fadd float %add114, %mul113
  %mul116 = fmul float %sub60, %add115
  %add117 = fadd float %26, %mul116
  %add118 = fadd float %mul109, %add115
  %mul119 = fmul float %mul113, 2.000000e+00
  %add120 = fadd float %mul119, %add118
  %mul121 = fmul float %23, %add117
  %mul122 = fmul float %23, %add120
  %mul123 = fmul float %mul56, %25
  %mul124 = fmul float %mul123, %exptabscale
  %conv125 = fptosi float %mul124 to i32
  %conv126 = sitofp i32 %conv125 to float
  %sub127 = fsub float %mul124, %conv126
  %mul128 = fmul float %sub127, %sub127
  %mul129 = mul nsw i32 %conv125, 12
  %add130 = add nsw i32 %mul129, 8
  %idxprom131 = sext i32 %add130 to i64
  %arrayidx132 = getelementptr inbounds float* %VFtab, i64 %idxprom131
  %30 = load float* %arrayidx132, align 4, !tbaa !3
  %add133 = add nsw i32 %mul129, 9
  %idxprom134 = sext i32 %add133 to i64
  %arrayidx135 = getelementptr inbounds float* %VFtab, i64 %idxprom134
  %31 = load float* %arrayidx135, align 4, !tbaa !3
  %add136 = add nsw i32 %mul129, 10
  %idxprom137 = sext i32 %add136 to i64
  %arrayidx138 = getelementptr inbounds float* %VFtab, i64 %idxprom137
  %32 = load float* %arrayidx138, align 4, !tbaa !3
  %mul139 = fmul float %sub127, %32
  %add140 = add nsw i32 %mul129, 11
  %idxprom141 = sext i32 %add140 to i64
  %arrayidx142 = getelementptr inbounds float* %VFtab, i64 %idxprom141
  %33 = load float* %arrayidx142, align 4, !tbaa !3
  %mul143 = fmul float %mul128, %33
  %add144 = fadd float %31, %mul139
  %add145 = fadd float %add144, %mul143
  %mul146 = fmul float %sub127, %add145
  %add147 = fadd float %30, %mul146
  %add148 = fadd float %mul139, %add145
  %mul149 = fmul float %mul143, 2.000000e+00
  %add150 = fadd float %mul149, %add148
  %mul151 = fmul float %24, %add147
  %mul152 = fmul float %24, %25
  %mul153 = fmul float %mul152, %add150
  %add154 = fadd float %vnbtot.0412, %mul121
  %add155 = fadd float %add154, %mul151
  %add156 = fadd float %mul87, %mul122
  %mul157 = fmul float %add156, %tabscale
  %mul158 = fmul float %mul153, %exptabscale
  %add159 = fadd float %mul157, %mul158
  %34 = fmul float %conv55, %add159
  %mul161 = fsub float -0.000000e+00, %34
  %add162 = fadd float %vctot.0413, %mul86
  %mul163 = fmul float %sub, %mul161
  %mul164 = fmul float %sub48, %mul161
  %mul165 = fmul float %sub49, %mul161
  %add166 = fadd float %fix1.0411, %mul163
  %add167 = fadd float %fiy1.0410, %mul164
  %add168 = fadd float %fiz1.0409, %mul165
  %arrayidx170 = getelementptr inbounds float* %faction, i64 %idxprom40
  %35 = load float* %arrayidx170, align 4, !tbaa !3
  %sub171 = fsub float %35, %mul163
  store float %sub171, float* %arrayidx170, align 4, !tbaa !3
  %arrayidx176 = getelementptr inbounds float* %faction, i64 %idxprom43
  %36 = load float* %arrayidx176, align 4, !tbaa !3
  %sub177 = fsub float %36, %mul164
  store float %sub177, float* %arrayidx176, align 4, !tbaa !3
  %arrayidx183 = getelementptr inbounds float* %faction, i64 %idxprom46
  %37 = load float* %arrayidx183, align 4, !tbaa !3
  %sub184 = fsub float %37, %mul165
  store float %sub184, float* %arrayidx183, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %38 = trunc i64 %indvars.iv.next to i32
  %cmp35 = icmp slt i32 %38, %6
  br i1 %cmp35, label %for.body36, label %for.end

for.end:                                          ; preds = %for.body36, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add162, %for.body36 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add155, %for.body36 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add166, %for.body36 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add167, %for.body36 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add168, %for.body36 ]
  %arrayidx189 = getelementptr inbounds float* %faction, i64 %idxprom16
  %39 = load float* %arrayidx189, align 4, !tbaa !3
  %add190 = fadd float %fix1.0.lcssa, %39
  store float %add190, float* %arrayidx189, align 4, !tbaa !3
  %arrayidx195 = getelementptr inbounds float* %faction, i64 %idxprom20
  %40 = load float* %arrayidx195, align 4, !tbaa !3
  %add196 = fadd float %fiy1.0.lcssa, %40
  store float %add196, float* %arrayidx195, align 4, !tbaa !3
  %arrayidx202 = getelementptr inbounds float* %faction, i64 %idxprom24
  %41 = load float* %arrayidx202, align 4, !tbaa !3
  %add203 = fadd float %fiz1.0.lcssa, %41
  store float %add203, float* %arrayidx202, align 4, !tbaa !3
  %arrayidx208 = getelementptr inbounds float* %fshift, i64 %idxprom1
  %42 = load float* %arrayidx208, align 4, !tbaa !3
  %add209 = fadd float %fix1.0.lcssa, %42
  store float %add209, float* %arrayidx208, align 4, !tbaa !3
  %arrayidx214 = getelementptr inbounds float* %fshift, i64 %idxprom3
  %43 = load float* %arrayidx214, align 4, !tbaa !3
  %add215 = fadd float %fiy1.0.lcssa, %43
  store float %add215, float* %arrayidx214, align 4, !tbaa !3
  %arrayidx221 = getelementptr inbounds float* %fshift, i64 %idxprom6
  %44 = load float* %arrayidx221, align 4, !tbaa !3
  %add222 = fadd float %fiz1.0.lcssa, %44
  store float %add222, float* %arrayidx221, align 4, !tbaa !3
  %arrayidx227 = getelementptr inbounds i32* %gid, i64 %indvars.iv421
  %45 = load i32* %arrayidx227, align 4, !tbaa !0
  %idxprom228 = sext i32 %45 to i64
  %arrayidx229 = getelementptr inbounds float* %Vc, i64 %idxprom228
  %46 = load float* %arrayidx229, align 4, !tbaa !3
  %add230 = fadd float %vctot.0.lcssa, %46
  store float %add230, float* %arrayidx229, align 4, !tbaa !3
  %arrayidx234 = getelementptr inbounds float* %Vnb, i64 %idxprom228
  %47 = load float* %arrayidx234, align 4, !tbaa !3
  %add235 = fadd float %vnbtot.0.lcssa, %47
  store float %add235, float* %arrayidx234, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next422 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end240, label %for.body

for.end240:                                       ; preds = %for.end, %entry
  ret void
}
