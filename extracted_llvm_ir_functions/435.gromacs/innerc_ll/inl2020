define void @inl2020(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, float %krf, float %crf) #0 {
entry:
  %0 = load i32* %iinr, align 4, !tbaa !0
  %idxprom = sext i32 %0 to i64
  %arrayidx1 = getelementptr inbounds float* %charge, i64 %idxprom
  %1 = load float* %arrayidx1, align 4, !tbaa !3
  %add = add nsw i32 %0, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds float* %charge, i64 %idxprom2
  %2 = load float* %arrayidx3, align 4, !tbaa !3
  %mul = fmul float %1, %facel
  %mul4 = fmul float %2, %facel
  %cmp509 = icmp sgt i32 %nri, 0
  br i1 %cmp509, label %for.body, label %for.end282

for.body:                                         ; preds = %entry, %for.end.for.body_crit_edge
  %3 = phi i32 [ %.pre, %for.end.for.body_crit_edge ], [ %0, %entry ]
  %indvars.iv511 = phi i64 [ %indvars.iv.next512, %for.end.for.body_crit_edge ], [ 0, %entry ]
  %arrayidx6 = getelementptr inbounds i32* %shift, i64 %indvars.iv511
  %4 = load i32* %arrayidx6, align 4, !tbaa !0
  %mul7 = mul nsw i32 %4, 3
  %idxprom8 = sext i32 %mul7 to i64
  %arrayidx9 = getelementptr inbounds float* %shiftvec, i64 %idxprom8
  %5 = load float* %arrayidx9, align 4, !tbaa !3
  %add10 = add nsw i32 %mul7, 1
  %idxprom11 = sext i32 %add10 to i64
  %arrayidx12 = getelementptr inbounds float* %shiftvec, i64 %idxprom11
  %6 = load float* %arrayidx12, align 4, !tbaa !3
  %add13 = add nsw i32 %mul7, 2
  %idxprom14 = sext i32 %add13 to i64
  %arrayidx15 = getelementptr inbounds float* %shiftvec, i64 %idxprom14
  %7 = load float* %arrayidx15, align 4, !tbaa !3
  %mul18 = mul nsw i32 %3, 3
  %arrayidx20 = getelementptr inbounds i32* %jindex, i64 %indvars.iv511
  %8 = load i32* %arrayidx20, align 4, !tbaa !0
  %indvars.iv.next512 = add i64 %indvars.iv511, 1
  %arrayidx23 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next512
  %9 = load i32* %arrayidx23, align 4, !tbaa !0
  %idxprom24 = sext i32 %mul18 to i64
  %arrayidx25 = getelementptr inbounds float* %pos, i64 %idxprom24
  %10 = load float* %arrayidx25, align 4, !tbaa !3
  %add26 = fadd float %5, %10
  %add27 = add nsw i32 %mul18, 1
  %idxprom28 = sext i32 %add27 to i64
  %arrayidx29 = getelementptr inbounds float* %pos, i64 %idxprom28
  %11 = load float* %arrayidx29, align 4, !tbaa !3
  %add30 = fadd float %6, %11
  %add31 = add nsw i32 %mul18, 2
  %idxprom32 = sext i32 %add31 to i64
  %arrayidx33 = getelementptr inbounds float* %pos, i64 %idxprom32
  %12 = load float* %arrayidx33, align 4, !tbaa !3
  %add34 = fadd float %7, %12
  %add35 = add nsw i32 %mul18, 3
  %idxprom36 = sext i32 %add35 to i64
  %arrayidx37 = getelementptr inbounds float* %pos, i64 %idxprom36
  %13 = load float* %arrayidx37, align 4, !tbaa !3
  %add38 = fadd float %5, %13
  %add39 = add nsw i32 %mul18, 4
  %idxprom40 = sext i32 %add39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %14 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = fadd float %6, %14
  %add43 = add nsw i32 %mul18, 5
  %idxprom44 = sext i32 %add43 to i64
  %arrayidx45 = getelementptr inbounds float* %pos, i64 %idxprom44
  %15 = load float* %arrayidx45, align 4, !tbaa !3
  %add46 = fadd float %7, %15
  %add47 = add nsw i32 %mul18, 6
  %idxprom48 = sext i32 %add47 to i64
  %arrayidx49 = getelementptr inbounds float* %pos, i64 %idxprom48
  %16 = load float* %arrayidx49, align 4, !tbaa !3
  %add50 = fadd float %5, %16
  %add51 = add nsw i32 %mul18, 7
  %idxprom52 = sext i32 %add51 to i64
  %arrayidx53 = getelementptr inbounds float* %pos, i64 %idxprom52
  %17 = load float* %arrayidx53, align 4, !tbaa !3
  %add54 = fadd float %6, %17
  %add55 = add nsw i32 %mul18, 8
  %idxprom56 = sext i32 %add55 to i64
  %arrayidx57 = getelementptr inbounds float* %pos, i64 %idxprom56
  %18 = load float* %arrayidx57, align 4, !tbaa !3
  %add58 = fadd float %7, %18
  %cmp60488 = icmp slt i32 %8, %9
  br i1 %cmp60488, label %for.body61.lr.ph, label %for.end

for.body61.lr.ph:                                 ; preds = %for.body
  %19 = sext i32 %8 to i64
  br label %for.body61

for.body61:                                       ; preds = %for.body61.lr.ph, %for.body61
  %indvars.iv = phi i64 [ %19, %for.body61.lr.ph ], [ %indvars.iv.next, %for.body61 ]
  %vctot.0498 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add169, %for.body61 ]
  %fix1.0497 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add121, %for.body61 ]
  %fiy1.0496 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add122, %for.body61 ]
  %fiz1.0495 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add123, %for.body61 ]
  %fix2.0494 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add151, %for.body61 ]
  %fiy2.0493 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add152, %for.body61 ]
  %fiz2.0492 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add153, %for.body61 ]
  %fix3.0491 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add173, %for.body61 ]
  %fiy3.0490 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add174, %for.body61 ]
  %fiz3.0489 = phi float [ 0.000000e+00, %for.body61.lr.ph ], [ %add175, %for.body61 ]
  %arrayidx63 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %20 = load i32* %arrayidx63, align 4, !tbaa !0
  %mul64 = mul nsw i32 %20, 3
  %idxprom65 = sext i32 %mul64 to i64
  %arrayidx66 = getelementptr inbounds float* %pos, i64 %idxprom65
  %21 = load float* %arrayidx66, align 4, !tbaa !3
  %add67 = add nsw i32 %mul64, 1
  %idxprom68 = sext i32 %add67 to i64
  %arrayidx69 = getelementptr inbounds float* %pos, i64 %idxprom68
  %22 = load float* %arrayidx69, align 4, !tbaa !3
  %add70 = add nsw i32 %mul64, 2
  %idxprom71 = sext i32 %add70 to i64
  %arrayidx72 = getelementptr inbounds float* %pos, i64 %idxprom71
  %23 = load float* %arrayidx72, align 4, !tbaa !3
  %sub = fsub float %add26, %21
  %sub73 = fsub float %add30, %22
  %sub74 = fsub float %add34, %23
  %mul75 = fmul float %sub, %sub
  %mul76 = fmul float %sub73, %sub73
  %add77 = fadd float %mul75, %mul76
  %mul78 = fmul float %sub74, %sub74
  %add79 = fadd float %add77, %mul78
  %sub80 = fsub float %add38, %21
  %sub81 = fsub float %add42, %22
  %sub82 = fsub float %add46, %23
  %mul83 = fmul float %sub80, %sub80
  %mul84 = fmul float %sub81, %sub81
  %add85 = fadd float %mul83, %mul84
  %mul86 = fmul float %sub82, %sub82
  %add87 = fadd float %add85, %mul86
  %sub88 = fsub float %add50, %21
  %sub89 = fsub float %add54, %22
  %sub90 = fsub float %add58, %23
  %mul91 = fmul float %sub88, %sub88
  %mul92 = fmul float %sub89, %sub89
  %add93 = fadd float %mul91, %mul92
  %mul94 = fmul float %sub90, %sub90
  %add95 = fadd float %add93, %mul94
  %conv = fpext float %add79 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv96 = fptrunc double %div to float
  %conv97 = fpext float %add87 to double
  %call98 = tail call double @sqrt(double %conv97) #2
  %div99 = fdiv double 1.000000e+00, %call98
  %conv100 = fptrunc double %div99 to float
  %conv101 = fpext float %add95 to double
  %call102 = tail call double @sqrt(double %conv101) #2
  %div103 = fdiv double 1.000000e+00, %call102
  %conv104 = fptrunc double %div103 to float
  %mul105 = fmul float %conv96, %conv96
  %idxprom106 = sext i32 %20 to i64
  %arrayidx107 = getelementptr inbounds float* %charge, i64 %idxprom106
  %24 = load float* %arrayidx107, align 4, !tbaa !3
  %mul108 = fmul float %mul, %24
  %mul109 = fmul float %add79, %krf
  %add110 = fadd float %conv96, %mul109
  %sub111 = fsub float %add110, %crf
  %mul112 = fmul float %sub111, %mul108
  %mul113 = fmul float %mul109, 2.000000e+00
  %sub114 = fsub float %conv96, %mul113
  %mul115 = fmul float %sub114, %mul108
  %mul116 = fmul float %mul105, %mul115
  %add117 = fadd float %vctot.0498, %mul112
  %mul118 = fmul float %sub, %mul116
  %mul119 = fmul float %sub73, %mul116
  %mul120 = fmul float %sub74, %mul116
  %add121 = fadd float %fix1.0497, %mul118
  %add122 = fadd float %fiy1.0496, %mul119
  %add123 = fadd float %fiz1.0495, %mul120
  %arrayidx125 = getelementptr inbounds float* %faction, i64 %idxprom65
  %25 = load float* %arrayidx125, align 4, !tbaa !3
  %sub126 = fsub float %25, %mul118
  %arrayidx129 = getelementptr inbounds float* %faction, i64 %idxprom68
  %26 = load float* %arrayidx129, align 4, !tbaa !3
  %sub130 = fsub float %26, %mul119
  %arrayidx133 = getelementptr inbounds float* %faction, i64 %idxprom71
  %27 = load float* %arrayidx133, align 4, !tbaa !3
  %sub134 = fsub float %27, %mul120
  %mul135 = fmul float %conv100, %conv100
  %mul138 = fmul float %mul4, %24
  %mul139 = fmul float %add87, %krf
  %add140 = fadd float %mul139, %conv100
  %sub141 = fsub float %add140, %crf
  %mul142 = fmul float %sub141, %mul138
  %mul143 = fmul float %mul139, 2.000000e+00
  %sub144 = fsub float %conv100, %mul143
  %mul145 = fmul float %sub144, %mul138
  %mul146 = fmul float %mul135, %mul145
  %add147 = fadd float %mul142, %add117
  %mul148 = fmul float %sub80, %mul146
  %mul149 = fmul float %sub81, %mul146
  %mul150 = fmul float %sub82, %mul146
  %add151 = fadd float %fix2.0494, %mul148
  %add152 = fadd float %fiy2.0493, %mul149
  %add153 = fadd float %fiz2.0492, %mul150
  %sub154 = fsub float %sub126, %mul148
  %sub155 = fsub float %sub130, %mul149
  %sub156 = fsub float %sub134, %mul150
  %mul157 = fmul float %conv104, %conv104
  %mul161 = fmul float %add95, %krf
  %add162 = fadd float %mul161, %conv104
  %sub163 = fsub float %add162, %crf
  %mul164 = fmul float %mul138, %sub163
  %mul165 = fmul float %mul161, 2.000000e+00
  %sub166 = fsub float %conv104, %mul165
  %mul167 = fmul float %mul138, %sub166
  %mul168 = fmul float %mul157, %mul167
  %add169 = fadd float %mul164, %add147
  %mul170 = fmul float %sub88, %mul168
  %mul171 = fmul float %sub89, %mul168
  %mul172 = fmul float %sub90, %mul168
  %add173 = fadd float %fix3.0491, %mul170
  %add174 = fadd float %fiy3.0490, %mul171
  %add175 = fadd float %fiz3.0489, %mul172
  %sub176 = fsub float %sub154, %mul170
  store float %sub176, float* %arrayidx125, align 4, !tbaa !3
  %sub179 = fsub float %sub155, %mul171
  store float %sub179, float* %arrayidx129, align 4, !tbaa !3
  %sub183 = fsub float %sub156, %mul172
  store float %sub183, float* %arrayidx133, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %28 = trunc i64 %indvars.iv.next to i32
  %cmp60 = icmp slt i32 %28, %9
  br i1 %cmp60, label %for.body61, label %for.end

for.end:                                          ; preds = %for.body61, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add169, %for.body61 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add121, %for.body61 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add122, %for.body61 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add123, %for.body61 ]
  %fix2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add151, %for.body61 ]
  %fiy2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add152, %for.body61 ]
  %fiz2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add153, %for.body61 ]
  %fix3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add173, %for.body61 ]
  %fiy3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add174, %for.body61 ]
  %fiz3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add175, %for.body61 ]
  %arrayidx188 = getelementptr inbounds float* %faction, i64 %idxprom24
  %29 = load float* %arrayidx188, align 4, !tbaa !3
  %add189 = fadd float %fix1.0.lcssa, %29
  store float %add189, float* %arrayidx188, align 4, !tbaa !3
  %arrayidx194 = getelementptr inbounds float* %faction, i64 %idxprom28
  %30 = load float* %arrayidx194, align 4, !tbaa !3
  %add195 = fadd float %fiy1.0.lcssa, %30
  store float %add195, float* %arrayidx194, align 4, !tbaa !3
  %arrayidx201 = getelementptr inbounds float* %faction, i64 %idxprom32
  %31 = load float* %arrayidx201, align 4, !tbaa !3
  %add202 = fadd float %fiz1.0.lcssa, %31
  store float %add202, float* %arrayidx201, align 4, !tbaa !3
  %arrayidx208 = getelementptr inbounds float* %faction, i64 %idxprom36
  %32 = load float* %arrayidx208, align 4, !tbaa !3
  %add209 = fadd float %fix2.0.lcssa, %32
  store float %add209, float* %arrayidx208, align 4, !tbaa !3
  %arrayidx215 = getelementptr inbounds float* %faction, i64 %idxprom40
  %33 = load float* %arrayidx215, align 4, !tbaa !3
  %add216 = fadd float %fiy2.0.lcssa, %33
  store float %add216, float* %arrayidx215, align 4, !tbaa !3
  %arrayidx222 = getelementptr inbounds float* %faction, i64 %idxprom44
  %34 = load float* %arrayidx222, align 4, !tbaa !3
  %add223 = fadd float %fiz2.0.lcssa, %34
  store float %add223, float* %arrayidx222, align 4, !tbaa !3
  %arrayidx229 = getelementptr inbounds float* %faction, i64 %idxprom48
  %35 = load float* %arrayidx229, align 4, !tbaa !3
  %add230 = fadd float %fix3.0.lcssa, %35
  store float %add230, float* %arrayidx229, align 4, !tbaa !3
  %arrayidx236 = getelementptr inbounds float* %faction, i64 %idxprom52
  %36 = load float* %arrayidx236, align 4, !tbaa !3
  %add237 = fadd float %fiy3.0.lcssa, %36
  store float %add237, float* %arrayidx236, align 4, !tbaa !3
  %arrayidx243 = getelementptr inbounds float* %faction, i64 %idxprom56
  %37 = load float* %arrayidx243, align 4, !tbaa !3
  %add244 = fadd float %fiz3.0.lcssa, %37
  store float %add244, float* %arrayidx243, align 4, !tbaa !3
  %arrayidx249 = getelementptr inbounds float* %fshift, i64 %idxprom8
  %38 = load float* %arrayidx249, align 4, !tbaa !3
  %add250 = fadd float %fix1.0.lcssa, %38
  %add251 = fadd float %fix2.0.lcssa, %add250
  %add252 = fadd float %fix3.0.lcssa, %add251
  store float %add252, float* %arrayidx249, align 4, !tbaa !3
  %arrayidx257 = getelementptr inbounds float* %fshift, i64 %idxprom11
  %39 = load float* %arrayidx257, align 4, !tbaa !3
  %add258 = fadd float %fiy1.0.lcssa, %39
  %add259 = fadd float %fiy2.0.lcssa, %add258
  %add260 = fadd float %fiy3.0.lcssa, %add259
  store float %add260, float* %arrayidx257, align 4, !tbaa !3
  %arrayidx266 = getelementptr inbounds float* %fshift, i64 %idxprom14
  %40 = load float* %arrayidx266, align 4, !tbaa !3
  %add267 = fadd float %fiz1.0.lcssa, %40
  %add268 = fadd float %fiz2.0.lcssa, %add267
  %add269 = fadd float %fiz3.0.lcssa, %add268
  store float %add269, float* %arrayidx266, align 4, !tbaa !3
  %arrayidx274 = getelementptr inbounds i32* %gid, i64 %indvars.iv511
  %41 = load i32* %arrayidx274, align 4, !tbaa !0
  %idxprom275 = sext i32 %41 to i64
  %arrayidx276 = getelementptr inbounds float* %Vc, i64 %idxprom275
  %42 = load float* %arrayidx276, align 4, !tbaa !3
  %add277 = fadd float %vctot.0.lcssa, %42
  store float %add277, float* %arrayidx276, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next512 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end282, label %for.end.for.body_crit_edge

for.end.for.body_crit_edge:                       ; preds = %for.end
  %arrayidx17.phi.trans.insert = getelementptr inbounds i32* %iinr, i64 %indvars.iv.next512
  %.pre = load i32* %arrayidx17.phi.trans.insert, align 4, !tbaa !0
  br label %for.body

for.end282:                                       ; preds = %for.end, %entry
  ret void
}
