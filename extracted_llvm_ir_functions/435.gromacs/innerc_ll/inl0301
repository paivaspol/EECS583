define void @inl0301(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab, float %lambda, float* nocapture %dvdlambda, i32* nocapture %typeB) #0 {
entry:
  %sub = fsub float 1.000000e+00, %lambda
  %cmp381 = icmp sgt i32 %nri, 0
  br i1 %cmp381, label %for.body.lr.ph, label %for.end218

for.body.lr.ph:                                   ; preds = %entry
  %mul27 = shl nsw i32 %ntype, 1
  br label %for.body

for.body:                                         ; preds = %for.end, %for.body.lr.ph
  %indvars.iv385 = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next386, %for.end ]
  %dvdl.0382 = phi float [ 0.000000e+00, %for.body.lr.ph ], [ %dvdl.1.lcssa, %for.end ]
  %arrayidx = getelementptr inbounds i32* %shift, i64 %indvars.iv385
  %0 = load i32* %arrayidx, align 4, !tbaa !0
  %mul = mul nsw i32 %0, 3
  %idxprom1 = sext i32 %mul to i64
  %arrayidx2 = getelementptr inbounds float* %shiftvec, i64 %idxprom1
  %1 = load float* %arrayidx2, align 4, !tbaa !3
  %add = add nsw i32 %mul, 1
  %idxprom3 = sext i32 %add to i64
  %arrayidx4 = getelementptr inbounds float* %shiftvec, i64 %idxprom3
  %2 = load float* %arrayidx4, align 4, !tbaa !3
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds float* %shiftvec, i64 %idxprom6
  %3 = load float* %arrayidx7, align 4, !tbaa !3
  %arrayidx9 = getelementptr inbounds i32* %iinr, i64 %indvars.iv385
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %arrayidx12 = getelementptr inbounds i32* %jindex, i64 %indvars.iv385
  %5 = load i32* %arrayidx12, align 4, !tbaa !0
  %indvars.iv.next386 = add i64 %indvars.iv385, 1
  %arrayidx15 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next386
  %6 = load i32* %arrayidx15, align 4, !tbaa !0
  %idxprom16 = sext i32 %mul10 to i64
  %arrayidx17 = getelementptr inbounds float* %pos, i64 %idxprom16
  %7 = load float* %arrayidx17, align 4, !tbaa !3
  %add18 = fadd float %1, %7
  %add19 = add nsw i32 %mul10, 1
  %idxprom20 = sext i32 %add19 to i64
  %arrayidx21 = getelementptr inbounds float* %pos, i64 %idxprom20
  %8 = load float* %arrayidx21, align 4, !tbaa !3
  %add22 = fadd float %2, %8
  %add23 = add nsw i32 %mul10, 2
  %idxprom24 = sext i32 %add23 to i64
  %arrayidx25 = getelementptr inbounds float* %pos, i64 %idxprom24
  %9 = load float* %arrayidx25, align 4, !tbaa !3
  %add26 = fadd float %3, %9
  %idxprom28 = sext i32 %4 to i64
  %arrayidx29 = getelementptr inbounds i32* %type, i64 %idxprom28
  %10 = load i32* %arrayidx29, align 4, !tbaa !0
  %mul30 = mul nsw i32 %10, %mul27
  %arrayidx33 = getelementptr inbounds i32* %typeB, i64 %idxprom28
  %11 = load i32* %arrayidx33, align 4, !tbaa !0
  %mul34 = mul nsw i32 %11, %mul27
  %cmp36370 = icmp slt i32 %5, %6
  br i1 %cmp36370, label %for.body37.lr.ph, label %for.end

for.body37.lr.ph:                                 ; preds = %for.body
  %12 = sext i32 %5 to i64
  br label %for.body37

for.body37:                                       ; preds = %for.body37.lr.ph, %for.body37
  %indvars.iv = phi i64 [ %12, %for.body37.lr.ph ], [ %indvars.iv.next, %for.body37 ]
  %dvdl.1375 = phi float [ %dvdl.0382, %for.body37.lr.ph ], [ %add141, %for.body37 ]
  %vnbtot.0374 = phi float [ 0.000000e+00, %for.body37.lr.ph ], [ %add138, %for.body37 ]
  %fix1.0373 = phi float [ 0.000000e+00, %for.body37.lr.ph ], [ %add149, %for.body37 ]
  %fiy1.0372 = phi float [ 0.000000e+00, %for.body37.lr.ph ], [ %add150, %for.body37 ]
  %fiz1.0371 = phi float [ 0.000000e+00, %for.body37.lr.ph ], [ %add151, %for.body37 ]
  %arrayidx39 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %13 = load i32* %arrayidx39, align 4, !tbaa !0
  %mul40 = mul nsw i32 %13, 3
  %idxprom41 = sext i32 %mul40 to i64
  %arrayidx42 = getelementptr inbounds float* %pos, i64 %idxprom41
  %14 = load float* %arrayidx42, align 4, !tbaa !3
  %add43 = add nsw i32 %mul40, 1
  %idxprom44 = sext i32 %add43 to i64
  %arrayidx45 = getelementptr inbounds float* %pos, i64 %idxprom44
  %15 = load float* %arrayidx45, align 4, !tbaa !3
  %add46 = add nsw i32 %mul40, 2
  %idxprom47 = sext i32 %add46 to i64
  %arrayidx48 = getelementptr inbounds float* %pos, i64 %idxprom47
  %16 = load float* %arrayidx48, align 4, !tbaa !3
  %sub49 = fsub float %add18, %14
  %sub50 = fsub float %add22, %15
  %sub51 = fsub float %add26, %16
  %mul52 = fmul float %sub49, %sub49
  %mul53 = fmul float %sub50, %sub50
  %add54 = fadd float %mul52, %mul53
  %mul55 = fmul float %sub51, %sub51
  %add56 = fadd float %add54, %mul55
  %conv = fpext float %add56 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv57 = fptrunc double %div to float
  %mul58 = fmul float %add56, %conv57
  %mul59 = fmul float %mul58, %tabscale
  %conv60 = fptosi float %mul59 to i32
  %conv61 = sitofp i32 %conv60 to float
  %sub62 = fsub float %mul59, %conv61
  %mul63 = fmul float %sub62, %sub62
  %mul64 = shl nsw i32 %conv60, 3
  %idxprom65 = sext i32 %13 to i64
  %arrayidx66 = getelementptr inbounds i32* %type, i64 %idxprom65
  %17 = load i32* %arrayidx66, align 4, !tbaa !0
  %mul67 = shl nsw i32 %17, 1
  %add68 = add nsw i32 %mul67, %mul30
  %arrayidx70 = getelementptr inbounds i32* %typeB, i64 %idxprom65
  %18 = load i32* %arrayidx70, align 4, !tbaa !0
  %mul71 = shl nsw i32 %18, 1
  %add72 = add nsw i32 %mul71, %mul34
  %idxprom73 = sext i32 %add68 to i64
  %arrayidx74 = getelementptr inbounds float* %nbfp, i64 %idxprom73
  %19 = load float* %arrayidx74, align 4, !tbaa !3
  %idxprom75 = sext i32 %add72 to i64
  %arrayidx76 = getelementptr inbounds float* %nbfp, i64 %idxprom75
  %20 = load float* %arrayidx76, align 4, !tbaa !3
  %mul77 = fmul float %sub, %19
  %mul78 = fmul float %20, %lambda
  %add79 = fadd float %mul77, %mul78
  %add80361 = or i32 %add68, 1
  %idxprom81 = sext i32 %add80361 to i64
  %arrayidx82 = getelementptr inbounds float* %nbfp, i64 %idxprom81
  %21 = load float* %arrayidx82, align 4, !tbaa !3
  %add83362 = or i32 %add72, 1
  %idxprom84 = sext i32 %add83362 to i64
  %arrayidx85 = getelementptr inbounds float* %nbfp, i64 %idxprom84
  %22 = load float* %arrayidx85, align 4, !tbaa !3
  %mul86 = fmul float %sub, %21
  %mul87 = fmul float %22, %lambda
  %add88 = fadd float %mul86, %mul87
  %idxprom89 = sext i32 %mul64 to i64
  %arrayidx90 = getelementptr inbounds float* %VFtab, i64 %idxprom89
  %23 = load float* %arrayidx90, align 4, !tbaa !3
  %add91363 = or i32 %mul64, 1
  %idxprom92 = sext i32 %add91363 to i64
  %arrayidx93 = getelementptr inbounds float* %VFtab, i64 %idxprom92
  %24 = load float* %arrayidx93, align 4, !tbaa !3
  %add94364 = or i32 %mul64, 2
  %idxprom95 = sext i32 %add94364 to i64
  %arrayidx96 = getelementptr inbounds float* %VFtab, i64 %idxprom95
  %25 = load float* %arrayidx96, align 4, !tbaa !3
  %mul97 = fmul float %sub62, %25
  %add98365 = or i32 %mul64, 3
  %idxprom99 = sext i32 %add98365 to i64
  %arrayidx100 = getelementptr inbounds float* %VFtab, i64 %idxprom99
  %26 = load float* %arrayidx100, align 4, !tbaa !3
  %mul101 = fmul float %mul63, %26
  %add102 = fadd float %24, %mul97
  %add103 = fadd float %add102, %mul101
  %mul104 = fmul float %sub62, %add103
  %add105 = fadd float %23, %mul104
  %add106 = fadd float %mul97, %add103
  %mul107 = fmul float %mul101, 2.000000e+00
  %add108 = fadd float %mul107, %add106
  %mul109 = fmul float %add79, %add105
  %mul110 = fmul float %add79, %add108
  %sub111 = fsub float %20, %19
  %mul112 = fmul float %sub111, %add105
  %add113 = fadd float %dvdl.1375, %mul112
  %add114366 = or i32 %mul64, 4
  %idxprom115 = sext i32 %add114366 to i64
  %arrayidx116 = getelementptr inbounds float* %VFtab, i64 %idxprom115
  %27 = load float* %arrayidx116, align 4, !tbaa !3
  %add117367 = or i32 %mul64, 5
  %idxprom118 = sext i32 %add117367 to i64
  %arrayidx119 = getelementptr inbounds float* %VFtab, i64 %idxprom118
  %28 = load float* %arrayidx119, align 4, !tbaa !3
  %add120368 = or i32 %mul64, 6
  %idxprom121 = sext i32 %add120368 to i64
  %arrayidx122 = getelementptr inbounds float* %VFtab, i64 %idxprom121
  %29 = load float* %arrayidx122, align 4, !tbaa !3
  %mul123 = fmul float %sub62, %29
  %add124369 = or i32 %mul64, 7
  %idxprom125 = sext i32 %add124369 to i64
  %arrayidx126 = getelementptr inbounds float* %VFtab, i64 %idxprom125
  %30 = load float* %arrayidx126, align 4, !tbaa !3
  %mul127 = fmul float %mul63, %30
  %add128 = fadd float %28, %mul123
  %add129 = fadd float %add128, %mul127
  %mul130 = fmul float %sub62, %add129
  %add131 = fadd float %27, %mul130
  %add132 = fadd float %mul123, %add129
  %mul133 = fmul float %mul127, 2.000000e+00
  %add134 = fadd float %mul133, %add132
  %mul135 = fmul float %add88, %add131
  %mul136 = fmul float %add88, %add134
  %add137 = fadd float %vnbtot.0374, %mul109
  %add138 = fadd float %add137, %mul135
  %sub139 = fsub float %22, %21
  %mul140 = fmul float %sub139, %add131
  %add141 = fadd float %add113, %mul140
  %add142 = fadd float %mul110, %mul136
  %mul143 = fmul float %add142, %tabscale
  %31 = fmul float %conv57, %mul143
  %mul145 = fsub float -0.000000e+00, %31
  %mul146 = fmul float %sub49, %mul145
  %mul147 = fmul float %sub50, %mul145
  %mul148 = fmul float %sub51, %mul145
  %add149 = fadd float %fix1.0373, %mul146
  %add150 = fadd float %fiy1.0372, %mul147
  %add151 = fadd float %fiz1.0371, %mul148
  %arrayidx153 = getelementptr inbounds float* %faction, i64 %idxprom41
  %32 = load float* %arrayidx153, align 4, !tbaa !3
  %sub154 = fsub float %32, %mul146
  store float %sub154, float* %arrayidx153, align 4, !tbaa !3
  %arrayidx159 = getelementptr inbounds float* %faction, i64 %idxprom44
  %33 = load float* %arrayidx159, align 4, !tbaa !3
  %sub160 = fsub float %33, %mul147
  store float %sub160, float* %arrayidx159, align 4, !tbaa !3
  %arrayidx166 = getelementptr inbounds float* %faction, i64 %idxprom47
  %34 = load float* %arrayidx166, align 4, !tbaa !3
  %sub167 = fsub float %34, %mul148
  store float %sub167, float* %arrayidx166, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %35 = trunc i64 %indvars.iv.next to i32
  %cmp36 = icmp slt i32 %35, %6
  br i1 %cmp36, label %for.body37, label %for.end

for.end:                                          ; preds = %for.body37, %for.body
  %dvdl.1.lcssa = phi float [ %dvdl.0382, %for.body ], [ %add141, %for.body37 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add138, %for.body37 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add149, %for.body37 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add150, %for.body37 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add151, %for.body37 ]
  %arrayidx172 = getelementptr inbounds float* %faction, i64 %idxprom16
  %36 = load float* %arrayidx172, align 4, !tbaa !3
  %add173 = fadd float %fix1.0.lcssa, %36
  store float %add173, float* %arrayidx172, align 4, !tbaa !3
  %arrayidx178 = getelementptr inbounds float* %faction, i64 %idxprom20
  %37 = load float* %arrayidx178, align 4, !tbaa !3
  %add179 = fadd float %fiy1.0.lcssa, %37
  store float %add179, float* %arrayidx178, align 4, !tbaa !3
  %arrayidx185 = getelementptr inbounds float* %faction, i64 %idxprom24
  %38 = load float* %arrayidx185, align 4, !tbaa !3
  %add186 = fadd float %fiz1.0.lcssa, %38
  store float %add186, float* %arrayidx185, align 4, !tbaa !3
  %arrayidx191 = getelementptr inbounds float* %fshift, i64 %idxprom1
  %39 = load float* %arrayidx191, align 4, !tbaa !3
  %add192 = fadd float %fix1.0.lcssa, %39
  store float %add192, float* %arrayidx191, align 4, !tbaa !3
  %arrayidx197 = getelementptr inbounds float* %fshift, i64 %idxprom3
  %40 = load float* %arrayidx197, align 4, !tbaa !3
  %add198 = fadd float %fiy1.0.lcssa, %40
  store float %add198, float* %arrayidx197, align 4, !tbaa !3
  %arrayidx204 = getelementptr inbounds float* %fshift, i64 %idxprom6
  %41 = load float* %arrayidx204, align 4, !tbaa !3
  %add205 = fadd float %fiz1.0.lcssa, %41
  store float %add205, float* %arrayidx204, align 4, !tbaa !3
  %arrayidx210 = getelementptr inbounds i32* %gid, i64 %indvars.iv385
  %42 = load i32* %arrayidx210, align 4, !tbaa !0
  %idxprom211 = sext i32 %42 to i64
  %arrayidx212 = getelementptr inbounds float* %Vnb, i64 %idxprom211
  %43 = load float* %arrayidx212, align 4, !tbaa !3
  %add213 = fadd float %vnbtot.0.lcssa, %43
  store float %add213, float* %arrayidx212, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next386 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end218, label %for.body

for.end218:                                       ; preds = %for.end, %entry
  %dvdl.0.lcssa = phi float [ 0.000000e+00, %entry ], [ %dvdl.1.lcssa, %for.end ]
  %44 = load float* %dvdlambda, align 4, !tbaa !3
  %add219 = fadd float %dvdl.0.lcssa, %44
  store float %add219, float* %dvdlambda, align 4, !tbaa !3
  ret void
}
