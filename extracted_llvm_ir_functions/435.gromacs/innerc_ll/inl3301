define void @inl3301(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab, float %lambda, float* nocapture %dvdlambda, float* nocapture %chargeB, i32* nocapture %typeB) #0 {
entry:
  %sub = fsub float 1.000000e+00, %lambda
  %cmp467 = icmp sgt i32 %nri, 0
  br i1 %cmp467, label %for.body.lr.ph, label %for.end266

for.body.lr.ph:                                   ; preds = %entry
  %mul33 = shl nsw i32 %ntype, 1
  br label %for.body

for.body:                                         ; preds = %for.end, %for.body.lr.ph
  %indvars.iv471 = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next472, %for.end ]
  %dvdl.0468 = phi float [ 0.000000e+00, %for.body.lr.ph ], [ %dvdl.1.lcssa, %for.end ]
  %arrayidx = getelementptr inbounds i32* %shift, i64 %indvars.iv471
  %0 = load i32* %arrayidx, align 4, !tbaa !0
  %mul = mul nsw i32 %0, 3
  %idxprom1 = sext i32 %mul to i64
  %arrayidx2 = getelementptr inbounds float* %shiftvec, i64 %idxprom1
  %1 = load float* %arrayidx2, align 4, !tbaa !3
  %add = add nsw i32 %mul, 1
  %idxprom3 = sext i32 %add to i64
  %arrayidx4 = getelementptr inbounds float* %shiftvec, i64 %idxprom3
  %2 = load float* %arrayidx4, align 4, !tbaa !3
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds float* %shiftvec, i64 %idxprom6
  %3 = load float* %arrayidx7, align 4, !tbaa !3
  %arrayidx9 = getelementptr inbounds i32* %iinr, i64 %indvars.iv471
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %arrayidx12 = getelementptr inbounds i32* %jindex, i64 %indvars.iv471
  %5 = load i32* %arrayidx12, align 4, !tbaa !0
  %indvars.iv.next472 = add i64 %indvars.iv471, 1
  %arrayidx15 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next472
  %6 = load i32* %arrayidx15, align 4, !tbaa !0
  %idxprom16 = sext i32 %mul10 to i64
  %arrayidx17 = getelementptr inbounds float* %pos, i64 %idxprom16
  %7 = load float* %arrayidx17, align 4, !tbaa !3
  %add18 = fadd float %1, %7
  %add19 = add nsw i32 %mul10, 1
  %idxprom20 = sext i32 %add19 to i64
  %arrayidx21 = getelementptr inbounds float* %pos, i64 %idxprom20
  %8 = load float* %arrayidx21, align 4, !tbaa !3
  %add22 = fadd float %2, %8
  %add23 = add nsw i32 %mul10, 2
  %idxprom24 = sext i32 %add23 to i64
  %arrayidx25 = getelementptr inbounds float* %pos, i64 %idxprom24
  %9 = load float* %arrayidx25, align 4, !tbaa !3
  %add26 = fadd float %3, %9
  %idxprom27 = sext i32 %4 to i64
  %arrayidx28 = getelementptr inbounds float* %charge, i64 %idxprom27
  %10 = load float* %arrayidx28, align 4, !tbaa !3
  %mul29 = fmul float %10, %facel
  %arrayidx31 = getelementptr inbounds float* %chargeB, i64 %idxprom27
  %11 = load float* %arrayidx31, align 4, !tbaa !3
  %mul32 = fmul float %11, %facel
  %arrayidx35 = getelementptr inbounds i32* %type, i64 %idxprom27
  %12 = load i32* %arrayidx35, align 4, !tbaa !0
  %mul36 = mul nsw i32 %12, %mul33
  %arrayidx39 = getelementptr inbounds i32* %typeB, i64 %idxprom27
  %13 = load i32* %arrayidx39, align 4, !tbaa !0
  %mul40 = mul nsw i32 %13, %mul33
  %cmp42454 = icmp slt i32 %5, %6
  br i1 %cmp42454, label %for.body43.lr.ph, label %for.end

for.body43.lr.ph:                                 ; preds = %for.body
  %14 = sext i32 %5 to i64
  br label %for.body43

for.body43:                                       ; preds = %for.body43.lr.ph, %for.body43
  %indvars.iv = phi i64 [ %14, %for.body43.lr.ph ], [ %indvars.iv.next, %for.body43 ]
  %vctot.0460 = phi float [ 0.000000e+00, %for.body43.lr.ph ], [ %add188, %for.body43 ]
  %dvdl.1459 = phi float [ %dvdl.0468, %for.body43.lr.ph ], [ %add182, %for.body43 ]
  %vnbtot.0458 = phi float [ 0.000000e+00, %for.body43.lr.ph ], [ %add179, %for.body43 ]
  %fix1.0457 = phi float [ 0.000000e+00, %for.body43.lr.ph ], [ %add192, %for.body43 ]
  %fiy1.0456 = phi float [ 0.000000e+00, %for.body43.lr.ph ], [ %add193, %for.body43 ]
  %fiz1.0455 = phi float [ 0.000000e+00, %for.body43.lr.ph ], [ %add194, %for.body43 ]
  %arrayidx45 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %15 = load i32* %arrayidx45, align 4, !tbaa !0
  %mul46 = mul nsw i32 %15, 3
  %idxprom47 = sext i32 %mul46 to i64
  %arrayidx48 = getelementptr inbounds float* %pos, i64 %idxprom47
  %16 = load float* %arrayidx48, align 4, !tbaa !3
  %add49 = add nsw i32 %mul46, 1
  %idxprom50 = sext i32 %add49 to i64
  %arrayidx51 = getelementptr inbounds float* %pos, i64 %idxprom50
  %17 = load float* %arrayidx51, align 4, !tbaa !3
  %add52 = add nsw i32 %mul46, 2
  %idxprom53 = sext i32 %add52 to i64
  %arrayidx54 = getelementptr inbounds float* %pos, i64 %idxprom53
  %18 = load float* %arrayidx54, align 4, !tbaa !3
  %sub55 = fsub float %add18, %16
  %sub56 = fsub float %add22, %17
  %sub57 = fsub float %add26, %18
  %mul58 = fmul float %sub55, %sub55
  %mul59 = fmul float %sub56, %sub56
  %add60 = fadd float %mul58, %mul59
  %mul61 = fmul float %sub57, %sub57
  %add62 = fadd float %add60, %mul61
  %conv = fpext float %add62 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv63 = fptrunc double %div to float
  %mul64 = fmul float %add62, %conv63
  %mul65 = fmul float %mul64, %tabscale
  %conv66 = fptosi float %mul65 to i32
  %conv67 = sitofp i32 %conv66 to float
  %sub68 = fsub float %mul65, %conv67
  %mul69 = fmul float %sub68, %sub68
  %mul70 = mul nsw i32 %conv66, 12
  %idxprom71 = sext i32 %15 to i64
  %arrayidx72 = getelementptr inbounds float* %charge, i64 %idxprom71
  %19 = load float* %arrayidx72, align 4, !tbaa !3
  %mul73 = fmul float %mul29, %19
  %arrayidx75 = getelementptr inbounds float* %chargeB, i64 %idxprom71
  %20 = load float* %arrayidx75, align 4, !tbaa !3
  %mul76 = fmul float %mul32, %20
  %mul77 = fmul float %sub, %mul73
  %mul78 = fmul float %mul76, %lambda
  %add79 = fadd float %mul77, %mul78
  %idxprom80 = sext i32 %mul70 to i64
  %arrayidx81 = getelementptr inbounds float* %VFtab, i64 %idxprom80
  %21 = load float* %arrayidx81, align 4, !tbaa !3
  %add82449 = or i32 %mul70, 1
  %idxprom83 = sext i32 %add82449 to i64
  %arrayidx84 = getelementptr inbounds float* %VFtab, i64 %idxprom83
  %22 = load float* %arrayidx84, align 4, !tbaa !3
  %add85450 = or i32 %mul70, 2
  %idxprom86 = sext i32 %add85450 to i64
  %arrayidx87 = getelementptr inbounds float* %VFtab, i64 %idxprom86
  %23 = load float* %arrayidx87, align 4, !tbaa !3
  %mul88 = fmul float %23, %sub68
  %add89451 = or i32 %mul70, 3
  %idxprom90 = sext i32 %add89451 to i64
  %arrayidx91 = getelementptr inbounds float* %VFtab, i64 %idxprom90
  %24 = load float* %arrayidx91, align 4, !tbaa !3
  %mul92 = fmul float %24, %mul69
  %add93 = fadd float %22, %mul88
  %add94 = fadd float %add93, %mul92
  %mul95 = fmul float %sub68, %add94
  %add96 = fadd float %21, %mul95
  %add97 = fadd float %mul88, %add94
  %mul98 = fmul float %mul92, 2.000000e+00
  %add99 = fadd float %mul98, %add97
  %mul100 = fmul float %add79, %add96
  %mul101 = fmul float %add79, %add99
  %sub102 = fsub float %mul76, %mul73
  %mul103 = fmul float %sub102, %add96
  %add104 = fadd float %dvdl.1459, %mul103
  %arrayidx106 = getelementptr inbounds i32* %type, i64 %idxprom71
  %25 = load i32* %arrayidx106, align 4, !tbaa !0
  %mul107 = shl nsw i32 %25, 1
  %add108 = add nsw i32 %mul107, %mul36
  %arrayidx110 = getelementptr inbounds i32* %typeB, i64 %idxprom71
  %26 = load i32* %arrayidx110, align 4, !tbaa !0
  %mul111 = shl nsw i32 %26, 1
  %add112 = add nsw i32 %mul111, %mul40
  %idxprom113 = sext i32 %add108 to i64
  %arrayidx114 = getelementptr inbounds float* %nbfp, i64 %idxprom113
  %27 = load float* %arrayidx114, align 4, !tbaa !3
  %idxprom115 = sext i32 %add112 to i64
  %arrayidx116 = getelementptr inbounds float* %nbfp, i64 %idxprom115
  %28 = load float* %arrayidx116, align 4, !tbaa !3
  %mul117 = fmul float %sub, %27
  %mul118 = fmul float %28, %lambda
  %add119 = fadd float %mul117, %mul118
  %add120452 = or i32 %add108, 1
  %idxprom121 = sext i32 %add120452 to i64
  %arrayidx122 = getelementptr inbounds float* %nbfp, i64 %idxprom121
  %29 = load float* %arrayidx122, align 4, !tbaa !3
  %add123453 = or i32 %add112, 1
  %idxprom124 = sext i32 %add123453 to i64
  %arrayidx125 = getelementptr inbounds float* %nbfp, i64 %idxprom124
  %30 = load float* %arrayidx125, align 4, !tbaa !3
  %mul126 = fmul float %sub, %29
  %mul127 = fmul float %30, %lambda
  %add128 = fadd float %mul126, %mul127
  %add129 = add nsw i32 %mul70, 4
  %idxprom130 = sext i32 %add129 to i64
  %arrayidx131 = getelementptr inbounds float* %VFtab, i64 %idxprom130
  %31 = load float* %arrayidx131, align 4, !tbaa !3
  %add132 = add nsw i32 %mul70, 5
  %idxprom133 = sext i32 %add132 to i64
  %arrayidx134 = getelementptr inbounds float* %VFtab, i64 %idxprom133
  %32 = load float* %arrayidx134, align 4, !tbaa !3
  %add135 = add nsw i32 %mul70, 6
  %idxprom136 = sext i32 %add135 to i64
  %arrayidx137 = getelementptr inbounds float* %VFtab, i64 %idxprom136
  %33 = load float* %arrayidx137, align 4, !tbaa !3
  %mul138 = fmul float %sub68, %33
  %add139 = add nsw i32 %mul70, 7
  %idxprom140 = sext i32 %add139 to i64
  %arrayidx141 = getelementptr inbounds float* %VFtab, i64 %idxprom140
  %34 = load float* %arrayidx141, align 4, !tbaa !3
  %mul142 = fmul float %mul69, %34
  %add143 = fadd float %32, %mul138
  %add144 = fadd float %add143, %mul142
  %mul145 = fmul float %sub68, %add144
  %add146 = fadd float %31, %mul145
  %add147 = fadd float %mul138, %add144
  %mul148 = fmul float %mul142, 2.000000e+00
  %add149 = fadd float %mul148, %add147
  %mul150 = fmul float %add119, %add146
  %mul151 = fmul float %add119, %add149
  %sub152 = fsub float %28, %27
  %mul153 = fmul float %sub152, %add146
  %add154 = fadd float %add104, %mul153
  %add155 = add nsw i32 %mul70, 8
  %idxprom156 = sext i32 %add155 to i64
  %arrayidx157 = getelementptr inbounds float* %VFtab, i64 %idxprom156
  %35 = load float* %arrayidx157, align 4, !tbaa !3
  %add158 = add nsw i32 %mul70, 9
  %idxprom159 = sext i32 %add158 to i64
  %arrayidx160 = getelementptr inbounds float* %VFtab, i64 %idxprom159
  %36 = load float* %arrayidx160, align 4, !tbaa !3
  %add161 = add nsw i32 %mul70, 10
  %idxprom162 = sext i32 %add161 to i64
  %arrayidx163 = getelementptr inbounds float* %VFtab, i64 %idxprom162
  %37 = load float* %arrayidx163, align 4, !tbaa !3
  %mul164 = fmul float %sub68, %37
  %add165 = add nsw i32 %mul70, 11
  %idxprom166 = sext i32 %add165 to i64
  %arrayidx167 = getelementptr inbounds float* %VFtab, i64 %idxprom166
  %38 = load float* %arrayidx167, align 4, !tbaa !3
  %mul168 = fmul float %mul69, %38
  %add169 = fadd float %36, %mul164
  %add170 = fadd float %add169, %mul168
  %mul171 = fmul float %sub68, %add170
  %add172 = fadd float %35, %mul171
  %add173 = fadd float %mul164, %add170
  %mul174 = fmul float %mul168, 2.000000e+00
  %add175 = fadd float %mul174, %add173
  %mul176 = fmul float %add128, %add172
  %mul177 = fmul float %add128, %add175
  %add178 = fadd float %vnbtot.0458, %mul150
  %add179 = fadd float %add178, %mul176
  %sub180 = fsub float %30, %29
  %mul181 = fmul float %sub180, %add172
  %add182 = fadd float %add154, %mul181
  %add183 = fadd float %mul101, %mul151
  %add184 = fadd float %add183, %mul177
  %mul185 = fmul float %add184, %tabscale
  %39 = fmul float %conv63, %mul185
  %mul187 = fsub float -0.000000e+00, %39
  %add188 = fadd float %vctot.0460, %mul100
  %mul189 = fmul float %sub55, %mul187
  %mul190 = fmul float %sub56, %mul187
  %mul191 = fmul float %sub57, %mul187
  %add192 = fadd float %fix1.0457, %mul189
  %add193 = fadd float %fiy1.0456, %mul190
  %add194 = fadd float %fiz1.0455, %mul191
  %arrayidx196 = getelementptr inbounds float* %faction, i64 %idxprom47
  %40 = load float* %arrayidx196, align 4, !tbaa !3
  %sub197 = fsub float %40, %mul189
  store float %sub197, float* %arrayidx196, align 4, !tbaa !3
  %arrayidx202 = getelementptr inbounds float* %faction, i64 %idxprom50
  %41 = load float* %arrayidx202, align 4, !tbaa !3
  %sub203 = fsub float %41, %mul190
  store float %sub203, float* %arrayidx202, align 4, !tbaa !3
  %arrayidx209 = getelementptr inbounds float* %faction, i64 %idxprom53
  %42 = load float* %arrayidx209, align 4, !tbaa !3
  %sub210 = fsub float %42, %mul191
  store float %sub210, float* %arrayidx209, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %43 = trunc i64 %indvars.iv.next to i32
  %cmp42 = icmp slt i32 %43, %6
  br i1 %cmp42, label %for.body43, label %for.end

for.end:                                          ; preds = %for.body43, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add188, %for.body43 ]
  %dvdl.1.lcssa = phi float [ %dvdl.0468, %for.body ], [ %add182, %for.body43 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add179, %for.body43 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add192, %for.body43 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add193, %for.body43 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add194, %for.body43 ]
  %arrayidx215 = getelementptr inbounds float* %faction, i64 %idxprom16
  %44 = load float* %arrayidx215, align 4, !tbaa !3
  %add216 = fadd float %fix1.0.lcssa, %44
  store float %add216, float* %arrayidx215, align 4, !tbaa !3
  %arrayidx221 = getelementptr inbounds float* %faction, i64 %idxprom20
  %45 = load float* %arrayidx221, align 4, !tbaa !3
  %add222 = fadd float %fiy1.0.lcssa, %45
  store float %add222, float* %arrayidx221, align 4, !tbaa !3
  %arrayidx228 = getelementptr inbounds float* %faction, i64 %idxprom24
  %46 = load float* %arrayidx228, align 4, !tbaa !3
  %add229 = fadd float %fiz1.0.lcssa, %46
  store float %add229, float* %arrayidx228, align 4, !tbaa !3
  %arrayidx234 = getelementptr inbounds float* %fshift, i64 %idxprom1
  %47 = load float* %arrayidx234, align 4, !tbaa !3
  %add235 = fadd float %fix1.0.lcssa, %47
  store float %add235, float* %arrayidx234, align 4, !tbaa !3
  %arrayidx240 = getelementptr inbounds float* %fshift, i64 %idxprom3
  %48 = load float* %arrayidx240, align 4, !tbaa !3
  %add241 = fadd float %fiy1.0.lcssa, %48
  store float %add241, float* %arrayidx240, align 4, !tbaa !3
  %arrayidx247 = getelementptr inbounds float* %fshift, i64 %idxprom6
  %49 = load float* %arrayidx247, align 4, !tbaa !3
  %add248 = fadd float %fiz1.0.lcssa, %49
  store float %add248, float* %arrayidx247, align 4, !tbaa !3
  %arrayidx253 = getelementptr inbounds i32* %gid, i64 %indvars.iv471
  %50 = load i32* %arrayidx253, align 4, !tbaa !0
  %idxprom254 = sext i32 %50 to i64
  %arrayidx255 = getelementptr inbounds float* %Vc, i64 %idxprom254
  %51 = load float* %arrayidx255, align 4, !tbaa !3
  %add256 = fadd float %vctot.0.lcssa, %51
  store float %add256, float* %arrayidx255, align 4, !tbaa !3
  %arrayidx260 = getelementptr inbounds float* %Vnb, i64 %idxprom254
  %52 = load float* %arrayidx260, align 4, !tbaa !3
  %add261 = fadd float %vnbtot.0.lcssa, %52
  store float %add261, float* %arrayidx260, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next472 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end266, label %for.body

for.end266:                                       ; preds = %for.end, %entry
  %dvdl.0.lcssa = phi float [ 0.000000e+00, %entry ], [ %dvdl.1.lcssa, %for.end ]
  %53 = load float* %dvdlambda, align 4, !tbaa !3
  %add267 = fadd float %dvdl.0.lcssa, %53
  store float %add267, float* %dvdlambda, align 4, !tbaa !3
  ret void
}
