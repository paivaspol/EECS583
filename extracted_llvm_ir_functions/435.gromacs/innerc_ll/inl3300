define void @inl3300(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab) #0 {
entry:
  %cmp396 = icmp sgt i32 %nri, 0
  br i1 %cmp396, label %for.body.lr.ph, label %for.end228

for.body.lr.ph:                                   ; preds = %entry
  %mul30 = shl i32 %ntype, 1
  br label %for.body

for.body:                                         ; preds = %for.end, %for.body.lr.ph
  %indvars.iv398 = phi i64 [ 0, %for.body.lr.ph ], [ %indvars.iv.next399, %for.end ]
  %arrayidx = getelementptr inbounds i32* %shift, i64 %indvars.iv398
  %0 = load i32* %arrayidx, align 4, !tbaa !0
  %mul = mul nsw i32 %0, 3
  %idxprom1 = sext i32 %mul to i64
  %arrayidx2 = getelementptr inbounds float* %shiftvec, i64 %idxprom1
  %1 = load float* %arrayidx2, align 4, !tbaa !3
  %add = add nsw i32 %mul, 1
  %idxprom3 = sext i32 %add to i64
  %arrayidx4 = getelementptr inbounds float* %shiftvec, i64 %idxprom3
  %2 = load float* %arrayidx4, align 4, !tbaa !3
  %add5 = add nsw i32 %mul, 2
  %idxprom6 = sext i32 %add5 to i64
  %arrayidx7 = getelementptr inbounds float* %shiftvec, i64 %idxprom6
  %3 = load float* %arrayidx7, align 4, !tbaa !3
  %arrayidx9 = getelementptr inbounds i32* %iinr, i64 %indvars.iv398
  %4 = load i32* %arrayidx9, align 4, !tbaa !0
  %mul10 = mul nsw i32 %4, 3
  %arrayidx12 = getelementptr inbounds i32* %jindex, i64 %indvars.iv398
  %5 = load i32* %arrayidx12, align 4, !tbaa !0
  %indvars.iv.next399 = add i64 %indvars.iv398, 1
  %arrayidx15 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next399
  %6 = load i32* %arrayidx15, align 4, !tbaa !0
  %idxprom16 = sext i32 %mul10 to i64
  %arrayidx17 = getelementptr inbounds float* %pos, i64 %idxprom16
  %7 = load float* %arrayidx17, align 4, !tbaa !3
  %add18 = fadd float %1, %7
  %add19 = add nsw i32 %mul10, 1
  %idxprom20 = sext i32 %add19 to i64
  %arrayidx21 = getelementptr inbounds float* %pos, i64 %idxprom20
  %8 = load float* %arrayidx21, align 4, !tbaa !3
  %add22 = fadd float %2, %8
  %add23 = add nsw i32 %mul10, 2
  %idxprom24 = sext i32 %add23 to i64
  %arrayidx25 = getelementptr inbounds float* %pos, i64 %idxprom24
  %9 = load float* %arrayidx25, align 4, !tbaa !3
  %add26 = fadd float %3, %9
  %idxprom27 = sext i32 %4 to i64
  %arrayidx28 = getelementptr inbounds float* %charge, i64 %idxprom27
  %10 = load float* %arrayidx28, align 4, !tbaa !3
  %mul29 = fmul float %10, %facel
  %arrayidx32 = getelementptr inbounds i32* %type, i64 %idxprom27
  %11 = load i32* %arrayidx32, align 4, !tbaa !0
  %mul33 = mul nsw i32 %mul30, %11
  %cmp35385 = icmp slt i32 %5, %6
  br i1 %cmp35385, label %for.body36.lr.ph, label %for.end

for.body36.lr.ph:                                 ; preds = %for.body
  %12 = sext i32 %5 to i64
  br label %for.body36

for.body36:                                       ; preds = %for.body36.lr.ph, %for.body36
  %indvars.iv = phi i64 [ %12, %for.body36.lr.ph ], [ %indvars.iv.next, %for.body36 ]
  %vctot.0390 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add150, %for.body36 ]
  %vnbtot.0389 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add144, %for.body36 ]
  %fix1.0388 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add154, %for.body36 ]
  %fiy1.0387 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add155, %for.body36 ]
  %fiz1.0386 = phi float [ 0.000000e+00, %for.body36.lr.ph ], [ %add156, %for.body36 ]
  %arrayidx38 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %13 = load i32* %arrayidx38, align 4, !tbaa !0
  %mul39 = mul nsw i32 %13, 3
  %idxprom40 = sext i32 %mul39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %14 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = add nsw i32 %mul39, 1
  %idxprom43 = sext i32 %add42 to i64
  %arrayidx44 = getelementptr inbounds float* %pos, i64 %idxprom43
  %15 = load float* %arrayidx44, align 4, !tbaa !3
  %add45 = add nsw i32 %mul39, 2
  %idxprom46 = sext i32 %add45 to i64
  %arrayidx47 = getelementptr inbounds float* %pos, i64 %idxprom46
  %16 = load float* %arrayidx47, align 4, !tbaa !3
  %sub = fsub float %add18, %14
  %sub48 = fsub float %add22, %15
  %sub49 = fsub float %add26, %16
  %mul50 = fmul float %sub, %sub
  %mul51 = fmul float %sub48, %sub48
  %add52 = fadd float %mul50, %mul51
  %mul53 = fmul float %sub49, %sub49
  %add54 = fadd float %add52, %mul53
  %conv = fpext float %add54 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv55 = fptrunc double %div to float
  %mul56 = fmul float %add54, %conv55
  %mul57 = fmul float %mul56, %tabscale
  %conv58 = fptosi float %mul57 to i32
  %conv59 = sitofp i32 %conv58 to float
  %sub60 = fsub float %mul57, %conv59
  %mul61 = fmul float %sub60, %sub60
  %mul62 = mul nsw i32 %conv58, 12
  %idxprom63 = sext i32 %13 to i64
  %arrayidx64 = getelementptr inbounds float* %charge, i64 %idxprom63
  %17 = load float* %arrayidx64, align 4, !tbaa !3
  %mul65 = fmul float %mul29, %17
  %idxprom66 = sext i32 %mul62 to i64
  %arrayidx67 = getelementptr inbounds float* %VFtab, i64 %idxprom66
  %18 = load float* %arrayidx67, align 4, !tbaa !3
  %add68381 = or i32 %mul62, 1
  %idxprom69 = sext i32 %add68381 to i64
  %arrayidx70 = getelementptr inbounds float* %VFtab, i64 %idxprom69
  %19 = load float* %arrayidx70, align 4, !tbaa !3
  %add71382 = or i32 %mul62, 2
  %idxprom72 = sext i32 %add71382 to i64
  %arrayidx73 = getelementptr inbounds float* %VFtab, i64 %idxprom72
  %20 = load float* %arrayidx73, align 4, !tbaa !3
  %mul74 = fmul float %20, %sub60
  %add75383 = or i32 %mul62, 3
  %idxprom76 = sext i32 %add75383 to i64
  %arrayidx77 = getelementptr inbounds float* %VFtab, i64 %idxprom76
  %21 = load float* %arrayidx77, align 4, !tbaa !3
  %mul78 = fmul float %21, %mul61
  %add79 = fadd float %19, %mul74
  %add80 = fadd float %add79, %mul78
  %mul81 = fmul float %sub60, %add80
  %add82 = fadd float %18, %mul81
  %add83 = fadd float %mul74, %add80
  %mul84 = fmul float %mul78, 2.000000e+00
  %add85 = fadd float %mul84, %add83
  %mul86 = fmul float %mul65, %add82
  %mul87 = fmul float %mul65, %add85
  %arrayidx89 = getelementptr inbounds i32* %type, i64 %idxprom63
  %22 = load i32* %arrayidx89, align 4, !tbaa !0
  %mul90 = shl nsw i32 %22, 1
  %add91 = add nsw i32 %mul90, %mul33
  %idxprom92 = sext i32 %add91 to i64
  %arrayidx93 = getelementptr inbounds float* %nbfp, i64 %idxprom92
  %23 = load float* %arrayidx93, align 4, !tbaa !3
  %add94384 = or i32 %add91, 1
  %idxprom95 = sext i32 %add94384 to i64
  %arrayidx96 = getelementptr inbounds float* %nbfp, i64 %idxprom95
  %24 = load float* %arrayidx96, align 4, !tbaa !3
  %add97 = add nsw i32 %mul62, 4
  %idxprom98 = sext i32 %add97 to i64
  %arrayidx99 = getelementptr inbounds float* %VFtab, i64 %idxprom98
  %25 = load float* %arrayidx99, align 4, !tbaa !3
  %add100 = add nsw i32 %mul62, 5
  %idxprom101 = sext i32 %add100 to i64
  %arrayidx102 = getelementptr inbounds float* %VFtab, i64 %idxprom101
  %26 = load float* %arrayidx102, align 4, !tbaa !3
  %add103 = add nsw i32 %mul62, 6
  %idxprom104 = sext i32 %add103 to i64
  %arrayidx105 = getelementptr inbounds float* %VFtab, i64 %idxprom104
  %27 = load float* %arrayidx105, align 4, !tbaa !3
  %mul106 = fmul float %sub60, %27
  %add107 = add nsw i32 %mul62, 7
  %idxprom108 = sext i32 %add107 to i64
  %arrayidx109 = getelementptr inbounds float* %VFtab, i64 %idxprom108
  %28 = load float* %arrayidx109, align 4, !tbaa !3
  %mul110 = fmul float %mul61, %28
  %add111 = fadd float %26, %mul106
  %add112 = fadd float %add111, %mul110
  %mul113 = fmul float %sub60, %add112
  %add114 = fadd float %25, %mul113
  %add115 = fadd float %mul106, %add112
  %mul116 = fmul float %mul110, 2.000000e+00
  %add117 = fadd float %mul116, %add115
  %mul118 = fmul float %23, %add114
  %mul119 = fmul float %23, %add117
  %add120 = add nsw i32 %mul62, 8
  %idxprom121 = sext i32 %add120 to i64
  %arrayidx122 = getelementptr inbounds float* %VFtab, i64 %idxprom121
  %29 = load float* %arrayidx122, align 4, !tbaa !3
  %add123 = add nsw i32 %mul62, 9
  %idxprom124 = sext i32 %add123 to i64
  %arrayidx125 = getelementptr inbounds float* %VFtab, i64 %idxprom124
  %30 = load float* %arrayidx125, align 4, !tbaa !3
  %add126 = add nsw i32 %mul62, 10
  %idxprom127 = sext i32 %add126 to i64
  %arrayidx128 = getelementptr inbounds float* %VFtab, i64 %idxprom127
  %31 = load float* %arrayidx128, align 4, !tbaa !3
  %mul129 = fmul float %sub60, %31
  %add130 = add nsw i32 %mul62, 11
  %idxprom131 = sext i32 %add130 to i64
  %arrayidx132 = getelementptr inbounds float* %VFtab, i64 %idxprom131
  %32 = load float* %arrayidx132, align 4, !tbaa !3
  %mul133 = fmul float %mul61, %32
  %add134 = fadd float %30, %mul129
  %add135 = fadd float %add134, %mul133
  %mul136 = fmul float %sub60, %add135
  %add137 = fadd float %29, %mul136
  %add138 = fadd float %mul129, %add135
  %mul139 = fmul float %mul133, 2.000000e+00
  %add140 = fadd float %mul139, %add138
  %mul141 = fmul float %24, %add137
  %mul142 = fmul float %24, %add140
  %add143 = fadd float %vnbtot.0389, %mul118
  %add144 = fadd float %add143, %mul141
  %add145 = fadd float %mul87, %mul119
  %add146 = fadd float %add145, %mul142
  %mul147 = fmul float %add146, %tabscale
  %33 = fmul float %conv55, %mul147
  %mul149 = fsub float -0.000000e+00, %33
  %add150 = fadd float %vctot.0390, %mul86
  %mul151 = fmul float %sub, %mul149
  %mul152 = fmul float %sub48, %mul149
  %mul153 = fmul float %sub49, %mul149
  %add154 = fadd float %fix1.0388, %mul151
  %add155 = fadd float %fiy1.0387, %mul152
  %add156 = fadd float %fiz1.0386, %mul153
  %arrayidx158 = getelementptr inbounds float* %faction, i64 %idxprom40
  %34 = load float* %arrayidx158, align 4, !tbaa !3
  %sub159 = fsub float %34, %mul151
  store float %sub159, float* %arrayidx158, align 4, !tbaa !3
  %arrayidx164 = getelementptr inbounds float* %faction, i64 %idxprom43
  %35 = load float* %arrayidx164, align 4, !tbaa !3
  %sub165 = fsub float %35, %mul152
  store float %sub165, float* %arrayidx164, align 4, !tbaa !3
  %arrayidx171 = getelementptr inbounds float* %faction, i64 %idxprom46
  %36 = load float* %arrayidx171, align 4, !tbaa !3
  %sub172 = fsub float %36, %mul153
  store float %sub172, float* %arrayidx171, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %37 = trunc i64 %indvars.iv.next to i32
  %cmp35 = icmp slt i32 %37, %6
  br i1 %cmp35, label %for.body36, label %for.end

for.end:                                          ; preds = %for.body36, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add150, %for.body36 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add144, %for.body36 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add154, %for.body36 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add155, %for.body36 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add156, %for.body36 ]
  %arrayidx177 = getelementptr inbounds float* %faction, i64 %idxprom16
  %38 = load float* %arrayidx177, align 4, !tbaa !3
  %add178 = fadd float %fix1.0.lcssa, %38
  store float %add178, float* %arrayidx177, align 4, !tbaa !3
  %arrayidx183 = getelementptr inbounds float* %faction, i64 %idxprom20
  %39 = load float* %arrayidx183, align 4, !tbaa !3
  %add184 = fadd float %fiy1.0.lcssa, %39
  store float %add184, float* %arrayidx183, align 4, !tbaa !3
  %arrayidx190 = getelementptr inbounds float* %faction, i64 %idxprom24
  %40 = load float* %arrayidx190, align 4, !tbaa !3
  %add191 = fadd float %fiz1.0.lcssa, %40
  store float %add191, float* %arrayidx190, align 4, !tbaa !3
  %arrayidx196 = getelementptr inbounds float* %fshift, i64 %idxprom1
  %41 = load float* %arrayidx196, align 4, !tbaa !3
  %add197 = fadd float %fix1.0.lcssa, %41
  store float %add197, float* %arrayidx196, align 4, !tbaa !3
  %arrayidx202 = getelementptr inbounds float* %fshift, i64 %idxprom3
  %42 = load float* %arrayidx202, align 4, !tbaa !3
  %add203 = fadd float %fiy1.0.lcssa, %42
  store float %add203, float* %arrayidx202, align 4, !tbaa !3
  %arrayidx209 = getelementptr inbounds float* %fshift, i64 %idxprom6
  %43 = load float* %arrayidx209, align 4, !tbaa !3
  %add210 = fadd float %fiz1.0.lcssa, %43
  store float %add210, float* %arrayidx209, align 4, !tbaa !3
  %arrayidx215 = getelementptr inbounds i32* %gid, i64 %indvars.iv398
  %44 = load i32* %arrayidx215, align 4, !tbaa !0
  %idxprom216 = sext i32 %44 to i64
  %arrayidx217 = getelementptr inbounds float* %Vc, i64 %idxprom216
  %45 = load float* %arrayidx217, align 4, !tbaa !3
  %add218 = fadd float %vctot.0.lcssa, %45
  store float %add218, float* %arrayidx217, align 4, !tbaa !3
  %arrayidx222 = getelementptr inbounds float* %Vnb, i64 %idxprom216
  %46 = load float* %arrayidx222, align 4, !tbaa !3
  %add223 = fadd float %vnbtot.0.lcssa, %46
  store float %add223, float* %arrayidx222, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next399 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end228, label %for.body

for.end228:                                       ; preds = %for.end, %entry
  ret void
}
