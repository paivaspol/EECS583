define void @inl3420(i32 %nri, i32* nocapture %iinr, i32* nocapture %jindex, i32* nocapture %jjnr, i32* nocapture %shift, float* nocapture %shiftvec, float* nocapture %fshift, i32* nocapture %gid, float* nocapture %pos, float* nocapture %faction, float* nocapture %charge, float %facel, float* nocapture %Vc, i32* nocapture %type, i32 %ntype, float* nocapture %nbfp, float* nocapture %Vnb, float %tabscale, float* nocapture %VFtab, float %exptabscale) #0 {
entry:
  %0 = load i32* %iinr, align 4, !tbaa !0
  %idxprom = sext i32 %0 to i64
  %arrayidx1 = getelementptr inbounds float* %charge, i64 %idxprom
  %1 = load float* %arrayidx1, align 4, !tbaa !3
  %add = add nsw i32 %0, 1
  %idxprom2 = sext i32 %add to i64
  %arrayidx3 = getelementptr inbounds float* %charge, i64 %idxprom2
  %2 = load float* %arrayidx3, align 4, !tbaa !3
  %mul = fmul float %1, %facel
  %mul4 = fmul float %2, %facel
  %arrayidx7 = getelementptr inbounds i32* %type, i64 %idxprom
  %3 = load i32* %arrayidx7, align 4, !tbaa !0
  %mul8 = mul i32 %3, %ntype
  %cmp798 = icmp sgt i32 %nri, 0
  br i1 %cmp798, label %for.body, label %for.end431

for.body:                                         ; preds = %entry, %for.end.for.body_crit_edge
  %4 = phi i32 [ %.pre, %for.end.for.body_crit_edge ], [ %0, %entry ]
  %indvars.iv800 = phi i64 [ %indvars.iv.next801, %for.end.for.body_crit_edge ], [ 0, %entry ]
  %arrayidx10 = getelementptr inbounds i32* %shift, i64 %indvars.iv800
  %5 = load i32* %arrayidx10, align 4, !tbaa !0
  %mul11 = mul nsw i32 %5, 3
  %idxprom12 = sext i32 %mul11 to i64
  %arrayidx13 = getelementptr inbounds float* %shiftvec, i64 %idxprom12
  %6 = load float* %arrayidx13, align 4, !tbaa !3
  %add14 = add nsw i32 %mul11, 1
  %idxprom15 = sext i32 %add14 to i64
  %arrayidx16 = getelementptr inbounds float* %shiftvec, i64 %idxprom15
  %7 = load float* %arrayidx16, align 4, !tbaa !3
  %add17 = add nsw i32 %mul11, 2
  %idxprom18 = sext i32 %add17 to i64
  %arrayidx19 = getelementptr inbounds float* %shiftvec, i64 %idxprom18
  %8 = load float* %arrayidx19, align 4, !tbaa !3
  %mul22 = mul nsw i32 %4, 3
  %arrayidx24 = getelementptr inbounds i32* %jindex, i64 %indvars.iv800
  %9 = load i32* %arrayidx24, align 4, !tbaa !0
  %indvars.iv.next801 = add i64 %indvars.iv800, 1
  %arrayidx27 = getelementptr inbounds i32* %jindex, i64 %indvars.iv.next801
  %10 = load i32* %arrayidx27, align 4, !tbaa !0
  %idxprom28 = sext i32 %mul22 to i64
  %arrayidx29 = getelementptr inbounds float* %pos, i64 %idxprom28
  %11 = load float* %arrayidx29, align 4, !tbaa !3
  %add30 = fadd float %6, %11
  %add31 = add nsw i32 %mul22, 1
  %idxprom32 = sext i32 %add31 to i64
  %arrayidx33 = getelementptr inbounds float* %pos, i64 %idxprom32
  %12 = load float* %arrayidx33, align 4, !tbaa !3
  %add34 = fadd float %7, %12
  %add35 = add nsw i32 %mul22, 2
  %idxprom36 = sext i32 %add35 to i64
  %arrayidx37 = getelementptr inbounds float* %pos, i64 %idxprom36
  %13 = load float* %arrayidx37, align 4, !tbaa !3
  %add38 = fadd float %8, %13
  %add39 = add nsw i32 %mul22, 3
  %idxprom40 = sext i32 %add39 to i64
  %arrayidx41 = getelementptr inbounds float* %pos, i64 %idxprom40
  %14 = load float* %arrayidx41, align 4, !tbaa !3
  %add42 = fadd float %6, %14
  %add43 = add nsw i32 %mul22, 4
  %idxprom44 = sext i32 %add43 to i64
  %arrayidx45 = getelementptr inbounds float* %pos, i64 %idxprom44
  %15 = load float* %arrayidx45, align 4, !tbaa !3
  %add46 = fadd float %7, %15
  %add47 = add nsw i32 %mul22, 5
  %idxprom48 = sext i32 %add47 to i64
  %arrayidx49 = getelementptr inbounds float* %pos, i64 %idxprom48
  %16 = load float* %arrayidx49, align 4, !tbaa !3
  %add50 = fadd float %8, %16
  %add51 = add nsw i32 %mul22, 6
  %idxprom52 = sext i32 %add51 to i64
  %arrayidx53 = getelementptr inbounds float* %pos, i64 %idxprom52
  %17 = load float* %arrayidx53, align 4, !tbaa !3
  %add54 = fadd float %6, %17
  %add55 = add nsw i32 %mul22, 7
  %idxprom56 = sext i32 %add55 to i64
  %arrayidx57 = getelementptr inbounds float* %pos, i64 %idxprom56
  %18 = load float* %arrayidx57, align 4, !tbaa !3
  %add58 = fadd float %7, %18
  %add59 = add nsw i32 %mul22, 8
  %idxprom60 = sext i32 %add59 to i64
  %arrayidx61 = getelementptr inbounds float* %pos, i64 %idxprom60
  %19 = load float* %arrayidx61, align 4, !tbaa !3
  %add62 = fadd float %8, %19
  %cmp64775 = icmp slt i32 %9, %10
  br i1 %cmp64775, label %for.body65.lr.ph, label %for.end

for.body65.lr.ph:                                 ; preds = %for.body
  %20 = sext i32 %9 to i64
  br label %for.body65

for.body65:                                       ; preds = %for.body65.lr.ph, %for.body65
  %indvars.iv = phi i64 [ %20, %for.body65.lr.ph ], [ %indvars.iv.next, %for.body65 ]
  %vctot.0786 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add313, %for.body65 ]
  %vnbtot.0785 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add208, %for.body65 ]
  %fix1.0784 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add219, %for.body65 ]
  %fiy1.0783 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add220, %for.body65 ]
  %fiz1.0782 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add221, %for.body65 ]
  %fix2.0781 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add272, %for.body65 ]
  %fiy2.0780 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add273, %for.body65 ]
  %fiz2.0779 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add274, %for.body65 ]
  %fix3.0778 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add317, %for.body65 ]
  %fiy3.0777 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add318, %for.body65 ]
  %fiz3.0776 = phi float [ 0.000000e+00, %for.body65.lr.ph ], [ %add319, %for.body65 ]
  %arrayidx67 = getelementptr inbounds i32* %jjnr, i64 %indvars.iv
  %21 = load i32* %arrayidx67, align 4, !tbaa !0
  %mul68 = mul nsw i32 %21, 3
  %idxprom69 = sext i32 %mul68 to i64
  %arrayidx70 = getelementptr inbounds float* %pos, i64 %idxprom69
  %22 = load float* %arrayidx70, align 4, !tbaa !3
  %add71 = add nsw i32 %mul68, 1
  %idxprom72 = sext i32 %add71 to i64
  %arrayidx73 = getelementptr inbounds float* %pos, i64 %idxprom72
  %23 = load float* %arrayidx73, align 4, !tbaa !3
  %add74 = add nsw i32 %mul68, 2
  %idxprom75 = sext i32 %add74 to i64
  %arrayidx76 = getelementptr inbounds float* %pos, i64 %idxprom75
  %24 = load float* %arrayidx76, align 4, !tbaa !3
  %sub = fsub float %add30, %22
  %sub77 = fsub float %add34, %23
  %sub78 = fsub float %add38, %24
  %mul79 = fmul float %sub, %sub
  %mul80 = fmul float %sub77, %sub77
  %add81 = fadd float %mul79, %mul80
  %mul82 = fmul float %sub78, %sub78
  %add83 = fadd float %add81, %mul82
  %sub84 = fsub float %add42, %22
  %sub85 = fsub float %add46, %23
  %sub86 = fsub float %add50, %24
  %mul87 = fmul float %sub84, %sub84
  %mul88 = fmul float %sub85, %sub85
  %add89 = fadd float %mul87, %mul88
  %mul90 = fmul float %sub86, %sub86
  %add91 = fadd float %add89, %mul90
  %sub92 = fsub float %add54, %22
  %sub93 = fsub float %add58, %23
  %sub94 = fsub float %add62, %24
  %mul95 = fmul float %sub92, %sub92
  %mul96 = fmul float %sub93, %sub93
  %add97 = fadd float %mul95, %mul96
  %mul98 = fmul float %sub94, %sub94
  %add99 = fadd float %add97, %mul98
  %conv = fpext float %add83 to double
  %call = tail call double @sqrt(double %conv) #2
  %div = fdiv double 1.000000e+00, %call
  %conv100 = fptrunc double %div to float
  %conv101 = fpext float %add91 to double
  %call102 = tail call double @sqrt(double %conv101) #2
  %div103 = fdiv double 1.000000e+00, %call102
  %conv104 = fptrunc double %div103 to float
  %conv105 = fpext float %add99 to double
  %call106 = tail call double @sqrt(double %conv105) #2
  %div107 = fdiv double 1.000000e+00, %call106
  %conv108 = fptrunc double %div107 to float
  %mul109 = fmul float %add83, %conv100
  %mul110 = fmul float %mul109, %tabscale
  %conv111 = fptosi float %mul110 to i32
  %conv112 = sitofp i32 %conv111 to float
  %sub113 = fsub float %mul110, %conv112
  %mul114 = fmul float %sub113, %sub113
  %mul115 = mul nsw i32 %conv111, 12
  %idxprom116 = sext i32 %21 to i64
  %arrayidx117 = getelementptr inbounds float* %charge, i64 %idxprom116
  %25 = load float* %arrayidx117, align 4, !tbaa !3
  %mul118 = fmul float %mul, %25
  %idxprom119 = sext i32 %mul115 to i64
  %arrayidx120 = getelementptr inbounds float* %VFtab, i64 %idxprom119
  %26 = load float* %arrayidx120, align 4, !tbaa !3
  %add121765 = or i32 %mul115, 1
  %idxprom122 = sext i32 %add121765 to i64
  %arrayidx123 = getelementptr inbounds float* %VFtab, i64 %idxprom122
  %27 = load float* %arrayidx123, align 4, !tbaa !3
  %add124766 = or i32 %mul115, 2
  %idxprom125 = sext i32 %add124766 to i64
  %arrayidx126 = getelementptr inbounds float* %VFtab, i64 %idxprom125
  %28 = load float* %arrayidx126, align 4, !tbaa !3
  %mul127 = fmul float %sub113, %28
  %add128767 = or i32 %mul115, 3
  %idxprom129 = sext i32 %add128767 to i64
  %arrayidx130 = getelementptr inbounds float* %VFtab, i64 %idxprom129
  %29 = load float* %arrayidx130, align 4, !tbaa !3
  %mul131 = fmul float %mul114, %29
  %add132 = fadd float %27, %mul127
  %add133 = fadd float %add132, %mul131
  %mul134 = fmul float %sub113, %add133
  %add135 = fadd float %26, %mul134
  %add136 = fadd float %mul127, %add133
  %mul137 = fmul float %mul131, 2.000000e+00
  %add138 = fadd float %mul137, %add136
  %mul139 = fmul float %mul118, %add135
  %mul140 = fmul float %mul118, %add138
  %arrayidx142 = getelementptr inbounds i32* %type, i64 %idxprom116
  %30 = load i32* %arrayidx142, align 4, !tbaa !0
  %tmp = add i32 %30, %mul8
  %tmp774 = mul i32 %tmp, 3
  %idxprom145 = sext i32 %tmp774 to i64
  %arrayidx146 = getelementptr inbounds float* %nbfp, i64 %idxprom145
  %31 = load float* %arrayidx146, align 4, !tbaa !3
  %add147 = add nsw i32 %tmp774, 1
  %idxprom148 = sext i32 %add147 to i64
  %arrayidx149 = getelementptr inbounds float* %nbfp, i64 %idxprom148
  %32 = load float* %arrayidx149, align 4, !tbaa !3
  %add150 = add nsw i32 %tmp774, 2
  %idxprom151 = sext i32 %add150 to i64
  %arrayidx152 = getelementptr inbounds float* %nbfp, i64 %idxprom151
  %33 = load float* %arrayidx152, align 4, !tbaa !3
  %add153 = add nsw i32 %mul115, 4
  %idxprom154 = sext i32 %add153 to i64
  %arrayidx155 = getelementptr inbounds float* %VFtab, i64 %idxprom154
  %34 = load float* %arrayidx155, align 4, !tbaa !3
  %add156 = add nsw i32 %mul115, 5
  %idxprom157 = sext i32 %add156 to i64
  %arrayidx158 = getelementptr inbounds float* %VFtab, i64 %idxprom157
  %35 = load float* %arrayidx158, align 4, !tbaa !3
  %add159 = add nsw i32 %mul115, 6
  %idxprom160 = sext i32 %add159 to i64
  %arrayidx161 = getelementptr inbounds float* %VFtab, i64 %idxprom160
  %36 = load float* %arrayidx161, align 4, !tbaa !3
  %mul162 = fmul float %sub113, %36
  %add163 = add nsw i32 %mul115, 7
  %idxprom164 = sext i32 %add163 to i64
  %arrayidx165 = getelementptr inbounds float* %VFtab, i64 %idxprom164
  %37 = load float* %arrayidx165, align 4, !tbaa !3
  %mul166 = fmul float %mul114, %37
  %add167 = fadd float %35, %mul162
  %add168 = fadd float %add167, %mul166
  %mul169 = fmul float %sub113, %add168
  %add170 = fadd float %34, %mul169
  %add171 = fadd float %mul162, %add168
  %mul172 = fmul float %mul166, 2.000000e+00
  %add173 = fadd float %mul172, %add171
  %mul174 = fmul float %31, %add170
  %mul175 = fmul float %31, %add173
  %mul176 = fmul float %mul109, %33
  %mul177 = fmul float %mul176, %exptabscale
  %conv178 = fptosi float %mul177 to i32
  %conv179 = sitofp i32 %conv178 to float
  %sub180 = fsub float %mul177, %conv179
  %mul181 = fmul float %sub180, %sub180
  %mul182 = mul nsw i32 %conv178, 12
  %add183 = add nsw i32 %mul182, 8
  %idxprom184 = sext i32 %add183 to i64
  %arrayidx185 = getelementptr inbounds float* %VFtab, i64 %idxprom184
  %38 = load float* %arrayidx185, align 4, !tbaa !3
  %add186 = add nsw i32 %mul182, 9
  %idxprom187 = sext i32 %add186 to i64
  %arrayidx188 = getelementptr inbounds float* %VFtab, i64 %idxprom187
  %39 = load float* %arrayidx188, align 4, !tbaa !3
  %add189 = add nsw i32 %mul182, 10
  %idxprom190 = sext i32 %add189 to i64
  %arrayidx191 = getelementptr inbounds float* %VFtab, i64 %idxprom190
  %40 = load float* %arrayidx191, align 4, !tbaa !3
  %mul192 = fmul float %sub180, %40
  %add193 = add nsw i32 %mul182, 11
  %idxprom194 = sext i32 %add193 to i64
  %arrayidx195 = getelementptr inbounds float* %VFtab, i64 %idxprom194
  %41 = load float* %arrayidx195, align 4, !tbaa !3
  %mul196 = fmul float %mul181, %41
  %add197 = fadd float %39, %mul192
  %add198 = fadd float %add197, %mul196
  %mul199 = fmul float %sub180, %add198
  %add200 = fadd float %38, %mul199
  %add201 = fadd float %mul192, %add198
  %mul202 = fmul float %mul196, 2.000000e+00
  %add203 = fadd float %mul202, %add201
  %mul204 = fmul float %32, %add200
  %mul205 = fmul float %32, %33
  %mul206 = fmul float %mul205, %add203
  %add207 = fadd float %vnbtot.0785, %mul174
  %add208 = fadd float %add207, %mul204
  %add209 = fadd float %mul140, %mul175
  %mul210 = fmul float %add209, %tabscale
  %mul211 = fmul float %mul206, %exptabscale
  %add212 = fadd float %mul210, %mul211
  %42 = fmul float %conv100, %add212
  %mul214 = fsub float -0.000000e+00, %42
  %add215 = fadd float %vctot.0786, %mul139
  %mul216 = fmul float %sub, %mul214
  %mul217 = fmul float %sub77, %mul214
  %mul218 = fmul float %sub78, %mul214
  %add219 = fadd float %fix1.0784, %mul216
  %add220 = fadd float %fiy1.0783, %mul217
  %add221 = fadd float %fiz1.0782, %mul218
  %arrayidx223 = getelementptr inbounds float* %faction, i64 %idxprom69
  %43 = load float* %arrayidx223, align 4, !tbaa !3
  %sub224 = fsub float %43, %mul216
  %arrayidx227 = getelementptr inbounds float* %faction, i64 %idxprom72
  %44 = load float* %arrayidx227, align 4, !tbaa !3
  %sub228 = fsub float %44, %mul217
  %arrayidx231 = getelementptr inbounds float* %faction, i64 %idxprom75
  %45 = load float* %arrayidx231, align 4, !tbaa !3
  %sub232 = fsub float %45, %mul218
  %mul233 = fmul float %add91, %conv104
  %mul234 = fmul float %mul233, %tabscale
  %conv235 = fptosi float %mul234 to i32
  %conv236 = sitofp i32 %conv235 to float
  %sub237 = fsub float %mul234, %conv236
  %mul238 = fmul float %sub237, %sub237
  %mul239 = mul nsw i32 %conv235, 12
  %mul242 = fmul float %mul4, %25
  %idxprom243 = sext i32 %mul239 to i64
  %arrayidx244 = getelementptr inbounds float* %VFtab, i64 %idxprom243
  %46 = load float* %arrayidx244, align 4, !tbaa !3
  %add245768 = or i32 %mul239, 1
  %idxprom246 = sext i32 %add245768 to i64
  %arrayidx247 = getelementptr inbounds float* %VFtab, i64 %idxprom246
  %47 = load float* %arrayidx247, align 4, !tbaa !3
  %add248769 = or i32 %mul239, 2
  %idxprom249 = sext i32 %add248769 to i64
  %arrayidx250 = getelementptr inbounds float* %VFtab, i64 %idxprom249
  %48 = load float* %arrayidx250, align 4, !tbaa !3
  %mul251 = fmul float %sub237, %48
  %add252770 = or i32 %mul239, 3
  %idxprom253 = sext i32 %add252770 to i64
  %arrayidx254 = getelementptr inbounds float* %VFtab, i64 %idxprom253
  %49 = load float* %arrayidx254, align 4, !tbaa !3
  %mul255 = fmul float %mul238, %49
  %add256 = fadd float %47, %mul251
  %add257 = fadd float %add256, %mul255
  %mul258 = fmul float %sub237, %add257
  %add259 = fadd float %46, %mul258
  %add260 = fadd float %mul251, %add257
  %mul261 = fmul float %mul255, 2.000000e+00
  %add262 = fadd float %mul261, %add260
  %mul263 = fmul float %mul242, %add259
  %mul264 = fmul float %mul242, %add262
  %mul265 = fmul float %mul264, %tabscale
  %50 = fmul float %conv104, %mul265
  %mul267 = fsub float -0.000000e+00, %50
  %add268 = fadd float %add215, %mul263
  %mul269 = fmul float %sub84, %mul267
  %mul270 = fmul float %sub85, %mul267
  %mul271 = fmul float %sub86, %mul267
  %add272 = fadd float %fix2.0781, %mul269
  %add273 = fadd float %fiy2.0780, %mul270
  %add274 = fadd float %fiz2.0779, %mul271
  %sub275 = fsub float %sub224, %mul269
  %sub276 = fsub float %sub228, %mul270
  %sub277 = fsub float %sub232, %mul271
  %mul278 = fmul float %add99, %conv108
  %mul279 = fmul float %mul278, %tabscale
  %conv280 = fptosi float %mul279 to i32
  %conv281 = sitofp i32 %conv280 to float
  %sub282 = fsub float %mul279, %conv281
  %mul283 = fmul float %sub282, %sub282
  %mul284 = mul nsw i32 %conv280, 12
  %idxprom288 = sext i32 %mul284 to i64
  %arrayidx289 = getelementptr inbounds float* %VFtab, i64 %idxprom288
  %51 = load float* %arrayidx289, align 4, !tbaa !3
  %add290771 = or i32 %mul284, 1
  %idxprom291 = sext i32 %add290771 to i64
  %arrayidx292 = getelementptr inbounds float* %VFtab, i64 %idxprom291
  %52 = load float* %arrayidx292, align 4, !tbaa !3
  %add293772 = or i32 %mul284, 2
  %idxprom294 = sext i32 %add293772 to i64
  %arrayidx295 = getelementptr inbounds float* %VFtab, i64 %idxprom294
  %53 = load float* %arrayidx295, align 4, !tbaa !3
  %mul296 = fmul float %sub282, %53
  %add297773 = or i32 %mul284, 3
  %idxprom298 = sext i32 %add297773 to i64
  %arrayidx299 = getelementptr inbounds float* %VFtab, i64 %idxprom298
  %54 = load float* %arrayidx299, align 4, !tbaa !3
  %mul300 = fmul float %mul283, %54
  %add301 = fadd float %52, %mul296
  %add302 = fadd float %add301, %mul300
  %mul303 = fmul float %sub282, %add302
  %add304 = fadd float %51, %mul303
  %add305 = fadd float %mul296, %add302
  %mul306 = fmul float %mul300, 2.000000e+00
  %add307 = fadd float %mul306, %add305
  %mul308 = fmul float %mul242, %add304
  %mul309 = fmul float %mul242, %add307
  %mul310 = fmul float %mul309, %tabscale
  %55 = fmul float %conv108, %mul310
  %mul312 = fsub float -0.000000e+00, %55
  %add313 = fadd float %add268, %mul308
  %mul314 = fmul float %sub92, %mul312
  %mul315 = fmul float %sub93, %mul312
  %mul316 = fmul float %sub94, %mul312
  %add317 = fadd float %fix3.0778, %mul314
  %add318 = fadd float %fiy3.0777, %mul315
  %add319 = fadd float %fiz3.0776, %mul316
  %sub320 = fsub float %sub275, %mul314
  store float %sub320, float* %arrayidx223, align 4, !tbaa !3
  %sub323 = fsub float %sub276, %mul315
  store float %sub323, float* %arrayidx227, align 4, !tbaa !3
  %sub327 = fsub float %sub277, %mul316
  store float %sub327, float* %arrayidx231, align 4, !tbaa !3
  %indvars.iv.next = add i64 %indvars.iv, 1
  %56 = trunc i64 %indvars.iv.next to i32
  %cmp64 = icmp slt i32 %56, %10
  br i1 %cmp64, label %for.body65, label %for.end

for.end:                                          ; preds = %for.body65, %for.body
  %vctot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add313, %for.body65 ]
  %vnbtot.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add208, %for.body65 ]
  %fix1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add219, %for.body65 ]
  %fiy1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add220, %for.body65 ]
  %fiz1.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add221, %for.body65 ]
  %fix2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add272, %for.body65 ]
  %fiy2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add273, %for.body65 ]
  %fiz2.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add274, %for.body65 ]
  %fix3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add317, %for.body65 ]
  %fiy3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add318, %for.body65 ]
  %fiz3.0.lcssa = phi float [ 0.000000e+00, %for.body ], [ %add319, %for.body65 ]
  %arrayidx332 = getelementptr inbounds float* %faction, i64 %idxprom28
  %57 = load float* %arrayidx332, align 4, !tbaa !3
  %add333 = fadd float %fix1.0.lcssa, %57
  store float %add333, float* %arrayidx332, align 4, !tbaa !3
  %arrayidx338 = getelementptr inbounds float* %faction, i64 %idxprom32
  %58 = load float* %arrayidx338, align 4, !tbaa !3
  %add339 = fadd float %fiy1.0.lcssa, %58
  store float %add339, float* %arrayidx338, align 4, !tbaa !3
  %arrayidx345 = getelementptr inbounds float* %faction, i64 %idxprom36
  %59 = load float* %arrayidx345, align 4, !tbaa !3
  %add346 = fadd float %fiz1.0.lcssa, %59
  store float %add346, float* %arrayidx345, align 4, !tbaa !3
  %arrayidx352 = getelementptr inbounds float* %faction, i64 %idxprom40
  %60 = load float* %arrayidx352, align 4, !tbaa !3
  %add353 = fadd float %fix2.0.lcssa, %60
  store float %add353, float* %arrayidx352, align 4, !tbaa !3
  %arrayidx359 = getelementptr inbounds float* %faction, i64 %idxprom44
  %61 = load float* %arrayidx359, align 4, !tbaa !3
  %add360 = fadd float %fiy2.0.lcssa, %61
  store float %add360, float* %arrayidx359, align 4, !tbaa !3
  %arrayidx366 = getelementptr inbounds float* %faction, i64 %idxprom48
  %62 = load float* %arrayidx366, align 4, !tbaa !3
  %add367 = fadd float %fiz2.0.lcssa, %62
  store float %add367, float* %arrayidx366, align 4, !tbaa !3
  %arrayidx373 = getelementptr inbounds float* %faction, i64 %idxprom52
  %63 = load float* %arrayidx373, align 4, !tbaa !3
  %add374 = fadd float %fix3.0.lcssa, %63
  store float %add374, float* %arrayidx373, align 4, !tbaa !3
  %arrayidx380 = getelementptr inbounds float* %faction, i64 %idxprom56
  %64 = load float* %arrayidx380, align 4, !tbaa !3
  %add381 = fadd float %fiy3.0.lcssa, %64
  store float %add381, float* %arrayidx380, align 4, !tbaa !3
  %arrayidx387 = getelementptr inbounds float* %faction, i64 %idxprom60
  %65 = load float* %arrayidx387, align 4, !tbaa !3
  %add388 = fadd float %fiz3.0.lcssa, %65
  store float %add388, float* %arrayidx387, align 4, !tbaa !3
  %arrayidx393 = getelementptr inbounds float* %fshift, i64 %idxprom12
  %66 = load float* %arrayidx393, align 4, !tbaa !3
  %add394 = fadd float %fix1.0.lcssa, %66
  %add395 = fadd float %fix2.0.lcssa, %add394
  %add396 = fadd float %fix3.0.lcssa, %add395
  store float %add396, float* %arrayidx393, align 4, !tbaa !3
  %arrayidx401 = getelementptr inbounds float* %fshift, i64 %idxprom15
  %67 = load float* %arrayidx401, align 4, !tbaa !3
  %add402 = fadd float %fiy1.0.lcssa, %67
  %add403 = fadd float %fiy2.0.lcssa, %add402
  %add404 = fadd float %fiy3.0.lcssa, %add403
  store float %add404, float* %arrayidx401, align 4, !tbaa !3
  %arrayidx410 = getelementptr inbounds float* %fshift, i64 %idxprom18
  %68 = load float* %arrayidx410, align 4, !tbaa !3
  %add411 = fadd float %fiz1.0.lcssa, %68
  %add412 = fadd float %fiz2.0.lcssa, %add411
  %add413 = fadd float %fiz3.0.lcssa, %add412
  store float %add413, float* %arrayidx410, align 4, !tbaa !3
  %arrayidx418 = getelementptr inbounds i32* %gid, i64 %indvars.iv800
  %69 = load i32* %arrayidx418, align 4, !tbaa !0
  %idxprom419 = sext i32 %69 to i64
  %arrayidx420 = getelementptr inbounds float* %Vc, i64 %idxprom419
  %70 = load float* %arrayidx420, align 4, !tbaa !3
  %add421 = fadd float %vctot.0.lcssa, %70
  store float %add421, float* %arrayidx420, align 4, !tbaa !3
  %arrayidx425 = getelementptr inbounds float* %Vnb, i64 %idxprom419
  %71 = load float* %arrayidx425, align 4, !tbaa !3
  %add426 = fadd float %vnbtot.0.lcssa, %71
  store float %add426, float* %arrayidx425, align 4, !tbaa !3
  %lftr.wideiv = trunc i64 %indvars.iv.next801 to i32
  %exitcond = icmp eq i32 %lftr.wideiv, %nri
  br i1 %exitcond, label %for.end431, label %for.end.for.body_crit_edge

for.end.for.body_crit_edge:                       ; preds = %for.end
  %arrayidx21.phi.trans.insert = getelementptr inbounds i32* %iinr, i64 %indvars.iv.next801
  %.pre = load i32* %arrayidx21.phi.trans.insert, align 4, !tbaa !0
  br label %for.body

for.end431:                                       ; preds = %for.end, %entry
  ret void
}
