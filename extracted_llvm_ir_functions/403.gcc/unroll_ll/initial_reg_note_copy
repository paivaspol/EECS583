define internal fastcc %struct.rtx_def* @initial_reg_note_copy(%struct.rtx_def* %notes, %struct.inline_remap* %map) #0 {
entry:
  %cmp = icmp eq %struct.rtx_def* %notes, null
  br i1 %cmp, label %return, label %if.end

if.end:                                           ; preds = %entry
  %0 = bitcast %struct.rtx_def* %notes to i32*
  %bf.load = load i32* %0, align 8
  %bf.clear = and i32 %bf.load, 65535
  %call = tail call %struct.rtx_def* @rtx_alloc(i32 %bf.clear) #6
  %bf.load1 = load i32* %0, align 8
  %bf.clear2 = and i32 %bf.load1, 16711680
  %1 = bitcast %struct.rtx_def* %call to i32*
  %bf.load3 = load i32* %1, align 8
  %bf.clear4 = and i32 %bf.load3, -16711681
  %bf.set = or i32 %bf.clear4, %bf.clear2
  store i32 %bf.set, i32* %1, align 8
  %bf.load5 = load i32* %0, align 8
  %bf.clear6 = and i32 %bf.load5, 65535
  switch i32 %bf.clear6, label %if.else24 [
    i32 3, label %if.then8
    i32 4, label %if.then16
  ]

if.then8:                                         ; preds = %if.end
  %arrayidx = getelementptr inbounds %struct.rtx_def* %notes, i64 0, i32 1, i64 0
  %rtx = bitcast %union.rtunion_def* %arrayidx to %struct.rtx_def**
  %2 = load %struct.rtx_def** %rtx, align 8, !tbaa !0
  %call9 = tail call %struct.rtx_def* @copy_rtx_and_substitute(%struct.rtx_def* %2, %struct.inline_remap* %map, i32 0) #6
  %3 = getelementptr inbounds %struct.rtx_def* %call, i64 0, i32 1, i64 0, i32 0
  %call9.c = ptrtoint %struct.rtx_def* %call9 to i64
  store i64 %call9.c, i64* %3, align 8, !tbaa !0
  br label %if.end26

if.then16:                                        ; preds = %if.end
  %arrayidx18 = getelementptr inbounds %struct.rtx_def* %notes, i64 0, i32 1, i64 0
  %rtx19 = bitcast %union.rtunion_def* %arrayidx18 to %struct.rtx_def**
  %4 = load %struct.rtx_def** %rtx19, align 8, !tbaa !0
  %call20 = tail call %struct.rtx_def* @copy_rtx(%struct.rtx_def* %4) #6
  %5 = getelementptr inbounds %struct.rtx_def* %call, i64 0, i32 1, i64 0, i32 0
  %call20.c = ptrtoint %struct.rtx_def* %call20 to i64
  store i64 %call20.c, i64* %5, align 8, !tbaa !0
  br label %if.end26

if.else24:                                        ; preds = %if.end
  tail call void @fancy_abort(i8* getelementptr inbounds ([50 x i8]* @.str13, i64 0, i64 0), i32 1724, i8* getelementptr inbounds ([22 x i8]* @__FUNCTION__.initial_reg_note_copy, i64 0, i64 0)) #7
  unreachable

if.end26:                                         ; preds = %if.then16, %if.then8
  %arrayidx28 = getelementptr inbounds %struct.rtx_def* %notes, i64 0, i32 1, i64 1
  %rtx29 = bitcast %union.rtunion_def* %arrayidx28 to %struct.rtx_def**
  %6 = load %struct.rtx_def** %rtx29, align 8, !tbaa !0
  %call30 = tail call fastcc %struct.rtx_def* @initial_reg_note_copy(%struct.rtx_def* %6, %struct.inline_remap* %map) #8
  %7 = getelementptr inbounds %struct.rtx_def* %call, i64 0, i32 1, i64 1, i32 0
  %call30.c = ptrtoint %struct.rtx_def* %call30 to i64
  store i64 %call30.c, i64* %7, align 8, !tbaa !0
  ret %struct.rtx_def* %call

return:                                           ; preds = %entry
  ret %struct.rtx_def* null
}
